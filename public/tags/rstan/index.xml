<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rstan on datanalytics</title>
    <link>/tags/rstan/</link>
    <description>Recent content in rstan on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Fri, 16 Nov 2018 08:13:33 +0000</lastBuildDate><atom:link href="/tags/rstan/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Colinealidad y posterioris</title>
      <link>/2018/11/16/colinealidad-y-posterioris/</link>
      <pubDate>Fri, 16 Nov 2018 08:13:33 +0000</pubDate>
      
      <guid>/2018/11/16/colinealidad-y-posterioris/</guid>
      <description>En esta entrada voy a crear un conjunto de datos donde dos variables tienen una correlación muy alta, ajustar un modelo de regresión y obtener la siguiente representación de la distribución a posteriori de los coeficientes,
donde se aprecia el efecto de la correlación entre x1 y x2.
El código,
library(mvtnorm) library(rstan) library(psych) n &amp;lt;- 100 corr_coef &amp;lt;- .9 x &amp;lt;- rmvnorm(n, c(0, 0), sigma = matrix(c(1, corr_coef, corr_coef, 1), 2, 2)) plot(x) x1 &amp;lt;- x[,1] x2 &amp;lt;- x[,2] x3 &amp;lt;- runif(n) - 0.</description>
    </item>
    
    <item>
      <title>ABC</title>
      <link>/2018/10/23/abc-2/</link>
      <pubDate>Tue, 23 Oct 2018 08:13:01 +0000</pubDate>
      
      <guid>/2018/10/23/abc-2/</guid>
      <description>Que quiere decir approximate Bayesian computation. Es un truco para pobres y desafortunados que no pueden quitarle la A a BC y usar directamente cosas como Stan o similares. El que no quiera prioris, además, puede usar el ABC para estimar la forma de la verosimilitud alrededor de una estimación puntual.
Por supuesto, el objetivo es obtener una estimación de la posteriori para poder medir la incertidumbre de parámetros, etc. La idea es que se dispone de unos datos, $latex X$ y un mecanismo de generación de datos $latex X^\prime = f(\theta)$, donde $latex \theta$ es un vector de parámetros.</description>
    </item>
    
    <item>
      <title>Curso de estadística aplicada con Stan: ejercicio 1</title>
      <link>/2018/07/17/curso-de-estadistica-aplicada-con-stan-ejercicio-1/</link>
      <pubDate>Tue, 17 Jul 2018 08:13:10 +0000</pubDate>
      
      <guid>/2018/07/17/curso-de-estadistica-aplicada-con-stan-ejercicio-1/</guid>
      <description>A primeros de julio impartí un curso de estadística bayesiana aplicada con Stan. Tengo que examinar a los alumnos y he aquí el primero de los ejercicios:
En un país, se extrae una muestra de 2000 hombres y mujeres con la siguiente distribución:
men &amp;lt;- 170 + 3 * rt(1000, 6) women &amp;lt;- 160 + 2 * rt(1000, 5) heights &amp;lt;- c(men, women)  Ajusta una distribución (una mezcla de dos distribuciones de Student) usando los datos anteriores, i.</description>
    </item>
    
    <item>
      <title>Kriging con Stan</title>
      <link>/2018/03/01/kriging-con-stan/</link>
      <pubDate>Thu, 01 Mar 2018 08:13:08 +0000</pubDate>
      
      <guid>/2018/03/01/kriging-con-stan/</guid>
      <description>Este mes de julio, cuórum mediante, impartiré en la UPC un curso que he maltitulado, mor de brevedad, Estadística Bayesiana Aplicada.
Los cursos de estadística bayesiana son teoría, mucha teoría, y unos ejemplos tontos que quieren justificarla. Del tipo: hagamos lo que ya sabemos hacer de otra manera más; busquemos una alternativa molona al p-valor (y usémosla como usar íamos un p-valor, por supuesto), etc.
Mi curso debería haberse titulado algo así como: Problemas reales (aunque simplificados por motivos estrictamente pedagógicos) resueltos con tecnología bayesiana porque, si no, dígame Vd.</description>
    </item>
    
    <item>
      <title>Sobre el problema de las martingalas: ¿cuántos sabíais la respuesta?</title>
      <link>/2017/12/19/sobre-el-problema-de-las-martingalas-cuantos-sabiais-la-respuesta/</link>
      <pubDate>Tue, 19 Dec 2017 08:13:06 +0000</pubDate>
      
      <guid>/2017/12/19/sobre-el-problema-de-las-martingalas-cuantos-sabiais-la-respuesta/</guid>
      <description>Pues no se sabe bien. Además, habrá quién pudiéndola haber averiguado, prefirió dejarse llevar por la intuición y errar. Pero volvamos a los hechos. Dado
En un país hipotético, las familias tienen críos hasta que nace el primer varón. En un año, en promedio, nacen:
&amp;mdash; Carlos Gil Bellosta (@gilbellosta) December 10, 2017  la pregunta urgente es: ¿cuántos podrían haber conocido la respuesta? Suponiendo que el conocimiento de la respuesta es algo binarizable (¿lo es?</description>
    </item>
    
    <item>
      <title>&#34;Intervalos&#34; de confianza con forma de rosquilla</title>
      <link>/2017/11/07/intervalos-de-confianza-con-forma-de-rosquilla/</link>
      <pubDate>Tue, 07 Nov 2017 08:13:44 +0000</pubDate>
      
      <guid>/2017/11/07/intervalos-de-confianza-con-forma-de-rosquilla/</guid>
      <description>Envalentonado por el comentario de Iñaki Úcar a mi entrada del otro día, que me remitía a este artículo, decidí rizar el rizo y crear intervalos de confianza no ya discontinuos sino con otra propiedad topológica imposible: homeomorfos con un toro.
Y aquí está:
El modelo, el código y demás,
library(rstan) library(ggplot2) n &amp;lt;- 100 a1 &amp;lt;- 1 a2 &amp;lt;- 1 sigma &amp;lt;- 0.4 datos &amp;lt;- data.frame(x1 = rnorm(n, 2, 0.</description>
    </item>
    
    <item>
      <title>Va de si hay una o dos lambdas</title>
      <link>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</link>
      <pubDate>Wed, 18 Jan 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Vivimos en un mundo opaco e interconectado</title>
      <link>/2017/01/17/vivimos-en-un-mundo-opaco-e-interconectado/</link>
      <pubDate>Tue, 17 Jan 2017 11:40:51 +0000</pubDate>
      
      <guid>/2017/01/17/vivimos-en-un-mundo-opaco-e-interconectado/</guid>
      <description>Vivimos en un mundo opaco: como en los cuentecillos de Asimov, somos usuarios de tecnologías que ni conocemos ni controlamos. Parametrizamos nuestras máquinas y las echamos a correr. Poco más podemos hacer que fiarnos de quienes nos las proporcionan.
Luego pasan cosas como que, de repente, resulta que Stan, en las últimas versiones, ha estado produciendo muestras sesgadas. ¿Qué resultados condicionará eso río abajo?
Un caso mucho más famoso es el de la resonancia magnética (fMRI): un error en el software concomitante pone bajo sospecha hasta 40000 artículos sobre estudios del cerebro.</description>
    </item>
    
    <item>
      <title>Lo que pasa cuando omites la priori con variables categóricas</title>
      <link>/2017/01/12/lo-que-pasa-cuando-omites-la-priori-con-variables-categoricas/</link>
      <pubDate>Thu, 12 Jan 2017 08:13:32 +0000</pubDate>
      
      <guid>/2017/01/12/lo-que-pasa-cuando-omites-la-priori-con-variables-categoricas/</guid>
      <description>Stan. Modelo multinivel. Variable categórica. Codificación con ceros y unos. Matriz. Coeficiente vector[n_ccaa] Cccaa. Sin priori.
Catástrofe:
(Coeficientes hasta 15000. Sin tasa, con tiempo. Los valores desorbitados, en ceros de la dummy).
Priori.
for (i in 1:n_ccaa) Cccaa[i] ~ cauchy(0, 20);
¿Por qué no?
Tachán:
(¿Para qué verbos?)</description>
    </item>
    
    <item>
      <title>Gestión de la mendacidad encuestoelectoral: los números</title>
      <link>/2016/07/04/gestion-de-la-mendacidad-encuestoelectoral-los-numeros/</link>
      <pubDate>Mon, 04 Jul 2016 08:13:31 +0000</pubDate>
      
      <guid>/2016/07/04/gestion-de-la-mendacidad-encuestoelectoral-los-numeros/</guid>
      <description>Continuando con la entrada anterior, ahora, números.
Primero, el planteamiento (cuatro partidos, etc.):
probs &amp;lt;- c(4, 3, 2, 1) probs &amp;lt;- probs / sum(probs) partidos &amp;lt;- letters[1:length(probs)]  Nos hará falta más adelante
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) library(rstan) library(ggplot2) library(reshape2)  Sigo con el proceso de muestreo. Reitero: cada encuestador enseña al encuestado una tarjeta al azar donde aparece el nombre de dos partidos y le pregunta si ha votado (o piensa votar) a alguno de ellos.</description>
    </item>
    
    <item>
      <title>Censura a la izquierda en las universidades españolas</title>
      <link>/2016/06/13/censura-a-la-izquierda-en-las-universidades-espanolas/</link>
      <pubDate>Mon, 13 Jun 2016 08:13:39 +0000</pubDate>
      
      <guid>/2016/06/13/censura-a-la-izquierda-en-las-universidades-espanolas/</guid>
      <description>(Aviso: esta entrada podría competir dignamente en una competición de titulares engañosos. Es posible que si no sepas de qué hablo regularmente te interese más esto).
En España hay pruebas de acceso a la universidad que y en algunos sitios publican las notas de corte para acceder a determinados estudios. Las he bajado escrapeando El País así
library(rvest) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) library(rstan) library(reshape2) options(mc.cores = 2) url &amp;lt;- &amp;quot;http://elpais.com/especiales/universidades/&amp;quot; pagina &amp;lt;- read_html(url, encoding = &amp;quot;UTF8&amp;quot;) urls_provs &amp;lt;- html_nodes(pagina, &amp;quot;a&amp;quot;) urls_provs &amp;lt;- html_attr(urls_provs, &amp;quot;href&amp;quot;) urls_provs &amp;lt;- paste0(&amp;quot;http://elpais.</description>
    </item>
    
    <item>
      <title>Diapositivas de mi charla &#34;Datos, modelos y parámetros&#34;</title>
      <link>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</link>
      <pubDate>Thu, 14 Apr 2016 09:13:35 +0000</pubDate>
      
      <guid>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</guid>
      <description>Las diapositivas de mi charla Datos, modelos y parámetros en el grupo Machine Learning Spain pueden verse/bajarse de aquí.</description>
    </item>
    
    <item>
      <title>¿Nos vemos en el Machine Learning Spain XII?</title>
      <link>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</link>
      <pubDate>Tue, 05 Apr 2016 09:13:58 +0000</pubDate>
      
      <guid>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</guid>
      <description>Porque voy a dar una charla en él. Es este jueves, por la tarde, en el Campus de Google de Madrid (los detalles).
Se tratará de una introducción a y justificación de aproximaciones más bayesianas de lo habitual a problemas reales del análisis de datos. Que comenzará con una explicación sobre cuándo 100% no significa 100% para terminar con lo que viene siéndome habitual últimamente: un ejemplo en rstan con su discusión.</description>
    </item>
    
    <item>
      <title>Mezclas de distribuciones con rstan</title>
      <link>/2016/03/03/mezclas-de-distribuciones-con-rstan/</link>
      <pubDate>Thu, 03 Mar 2016 09:13:13 +0000</pubDate>
      
      <guid>/2016/03/03/mezclas-de-distribuciones-con-rstan/</guid>
      <description>y &amp;lt;- c(rnorm(1000), rnorm(2000, 1, 0.5))
es una mezcla de dos normales (N(0, 1) y N(1, 0.5)) con pesos 1/3 y 2/3 respectivamente. Pero, ¿cómo podríamos estimar los parámetros a partir de esos datos?
Se puede usar, p.e., flexmix, que implementa eso del EM. Pero en el librillo de este maestrillo dice
library(rstan) y &amp;lt;- c(rnorm(1000), rnorm(2000, 1, 0.5)) codigo &amp;lt;- &amp;quot; data { int&amp;lt;lower=1&amp;gt; K; // number of mixture components int&amp;lt;lower=1&amp;gt; N; // number of data points real y[N]; // observations } parameters { simplex[K] theta; // mixing proportions real mu[K]; // locations of mixture components real&amp;lt;lower=0&amp;gt; sigma[K]; // scales of mixture components } model { real ps[K]; // temp for log component densities sigma ~ cauchy(0,2.</description>
    </item>
    
    <item>
      <title>Diapositivas (y código fuente) de mi charla sobre rstan</title>
      <link>/2016/02/12/diapositivas-y-codigo-fuente-de-mi-charla-sobre-rstan/</link>
      <pubDate>Fri, 12 Feb 2016 09:13:23 +0000</pubDate>
      
      <guid>/2016/02/12/diapositivas-y-codigo-fuente-de-mi-charla-sobre-rstan/</guid>
      <description>Las diapositivas de mi charla sobre rstan en el grupo de usuarios de R de Madrid del 2016-02-11 están aquí.
(Y los vídeos).</description>
    </item>
    
    <item>
      <title>rstan y rstanarm en Medialab-Prado este jueves</title>
      <link>/2016/02/08/rstan-y-rstanarm-en-medialab-prado-este-jueves/</link>
      <pubDate>Mon, 08 Feb 2016 09:13:19 +0000</pubDate>
      
      <guid>/2016/02/08/rstan-y-rstanarm-en-medialab-prado-este-jueves/</guid>
      <description>Este jueves (2016-02-11), a las 19:00, hablaré de rstan y de rstanarm en Medialab-Prado dentro de la reunión de usuarios de R de Madrid. Con el concurso de estos paquetes, replantearé tres problemas estadísticos conocidos desde una óptica bayesiana:
 * Pruebas de hipótesis * Regresión lineal * Modelos estructurales de series temporales  Si quieres asistir, reserva tu plaza aquí.
Probablemente, discutiré todos esos modelos en estas páginas en los próximos días, además de colgar las diapositivas y sus fuentes.</description>
    </item>
    
    <item>
      <title>Análisis estadístico de respuestas ocultas en encuestas</title>
      <link>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</link>
      <pubDate>Fri, 22 Jan 2016 08:13:24 +0000</pubDate>
      
      <guid>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</guid>
      <description>A veces se hacen encuestas sobre temas sobre los que los encuestados son reticentes a revelar la verdad (p.e., ¿es Vd. un zombi?). Un procedimiento conocido para recabar tal tipo de información es el siguiente:
 * Se le invita al encuestado a tirar al aire una _moneda_ con las caras etiquetadas con _sí_ y _no_; la _moneda_ no es una moneda porque tiene una probabidad conocida (y distinta del 50%) de caer en _sí_.</description>
    </item>
    
    <item>
      <title>Un problema &#34;sencillo&#34;: posiciones y ruido</title>
      <link>/2015/09/18/un-problema-sencillo-posiciones-y-ruido/</link>
      <pubDate>Fri, 18 Sep 2015 08:13:23 +0000</pubDate>
      
      <guid>/2015/09/18/un-problema-sencillo-posiciones-y-ruido/</guid>
      <description>Voy a describir la solución un problema sencillo. Se trata de un objeto que se mueve a una velocidad no necesariamente constante en línea recta. Este objeto emite su posición y velocidad periódicamente (p.e., cada segundo). Por centrar ideas, su posición y velocidad reales en esos momentos es
n &amp;lt;- 100 v.real &amp;lt;- rnorm(n, 1, 0.2) x.real &amp;lt;- cumsum(v.real)  (Perdóneseme lo gañán de la física que aplico para calcular las posiciones: prometo que se puede y que sé hacerlo mejor; pero para el presente caso, vale).</description>
    </item>
    
    <item>
      <title>No uses el test de Wilcoxon, nos dice Gelman</title>
      <link>/2015/07/20/no-uses-el-test-de-wilcoxon-nos-dice-gelman/</link>
      <pubDate>Mon, 20 Jul 2015 08:13:59 +0000</pubDate>
      
      <guid>/2015/07/20/no-uses-el-test-de-wilcoxon-nos-dice-gelman/</guid>
      <description>Andrew Gelman nos invita a no usar más el test de Wilcoxon.
El test de Wilcoxon reemplaza las observaciones obtenidas por sus rangos y construye un estadístico basado en estos últimos. Eso implica descartar información pero puede ayudar a ganar robustez en situaciones en que los datos se desvíen de la normalidad.
¿Qué sugiere Gelman? Que si realmente estamos dispuestos a descartar información, en lugar de reemplazar las observaciones originales por sus rangos, usemos z-scores —los cuantiles de la normal estándar correspondientes a los cuantiles muestrales—, y usemos la teoría normal (en su doble acepción).</description>
    </item>
    
    <item>
      <title>Un modelo jerárquico para lo de Casillas</title>
      <link>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</link>
      <pubDate>Wed, 15 Jul 2015 08:13:42 +0000</pubDate>
      
      <guid>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</guid>
      <description>Vuelvo a lo de Casillas inspirándome en el primer ejemplo de este artículo de Gelman et al.
El planteamiento es el siguiente: el número de paradas, $latex n_i$ que realiza el $latex i$-ésimo portero tiene una distribución binomial
$latex n_i \sim B(N_i, p_i)$
donde $latex N_i$ es el número de disparos entre los palos y $latex p_i$ es la habilidad innata del portero. Estas habilidades innatas siguen una distribución dada, la de habilidades innatas de los porteros de primera división, que podemos suponer que sigue una distribución beta</description>
    </item>
    
    <item>
      <title>Diferencia de medias a la bayesiana con salsa de stan</title>
      <link>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</link>
      <pubDate>Thu, 25 Jun 2015 08:13:35 +0000</pubDate>
      
      <guid>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</guid>
      <description>El habitual problema de la diferencia de medias suele formularse de la siguiente manera: hay observaciones $latex y_{1i}$ e $latex y_{2i}$ donde
$latex y_{ji} \sim N(\mu_j, \sigma)$
e interesa saber si $latex \mu_1 = \mu_2$. Obviamente, se desconoce $latex \sigma$. De cómo resolvió Gosset el problema están los libros de estadística llenos. En R,
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) N1 &amp;lt;- 50 N2 &amp;lt;- 50 mu1 &amp;lt;- 1 mu2 &amp;lt;- -0.5 sig1 &amp;lt;- 1 sig2 &amp;lt;- 1 y1 &amp;lt;- rnorm(N1, mu1, sig1) y2 &amp;lt;- rnorm(N2, mu2, sig2) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
  </channel>
</rss>
