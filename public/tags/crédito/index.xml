<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>crédito on datanalytics</title>
    <link>/tags/cr%C3%A9dito/</link>
    <description>Recent content in crédito on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 15 Mar 2016 09:13:51 +0000</lastBuildDate><atom:link href="/tags/cr%C3%A9dito/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>¿Se puede explicar la predicción de un modelo de caja negra?</title>
      <link>/2016/03/15/se-puede-explicar-la-prediccion-de-un-modelo-de-caja-negra/</link>
      <pubDate>Tue, 15 Mar 2016 09:13:51 +0000</pubDate>
      
      <guid>/2016/03/15/se-puede-explicar-la-prediccion-de-un-modelo-de-caja-negra/</guid>
      <description>Imaginemos un banco que construye modelos para determinar si se concede o no un crédito. Este banco tiene varias opciones para crear el modelo. Sin embargo, en algunos países el regulador exige que el banco pueda explicar el motivo de la denegación de un crédito cuando un cliente lo solicite.
Esa restricción impediría potencialmente usar modelos de caja negra como el que construyo a continuación:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/randomForest&amp;quot;&amp;gt;randomForest) raw &amp;lt;- read.table(&amp;quot;http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data&amp;quot;, sep = &amp;quot;,&amp;quot;, na.</description>
    </item>
    
  </channel>
</rss>
