<!DOCTYPE html>
<html class="no-js" lang="es">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>nlp - datanalytics</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="nlp" />
<meta property="og:description" content="asdf" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/tags/nlp/" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alegreya:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/tags/nlp/index.xml" title="datanalytics">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="datanalytics" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">datanalytics</div>
					<div class="logo__tagline">Estadística y análisis de datos</div>
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<header class="main__header">
		<h1 class="main__title">nlp</h1>
	</header><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2019/04/08/demasiada-gente-conozco-que-todavia-no-sabe-de-gpt-2/" rel="bookmark">
			Demasiada gente conozco que todavía no sabe de GPT-2
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2019-04-08T09:13:10Z">2019-4-8</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/computaci%C3%B3n/" rel="category">computación</a>, <a class="meta__link" href="/categories/varios/" rel="category">varios</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Así que si eres uno de ellos, lee esto. Todo. Completo. Incluidos los motivos por los que no se va a liberar tal cual.
Si te quedas con ganas de más, lee esto (un divertimento) o, más en serio, esto otro, donde se da cuenta de uno de los logros de GPT-2 que, a primera vista, pasa desapercibido: que ha logrado adquirir determinadas habilidades sin haber sido entrenado específicamente para ello.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2019/03/22/analisis-clasificacion-etc-de-textos-muy-cortos/" rel="bookmark">
			Análisis (clasificación, etc.) de textos muy cortos
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2019-03-22T08:13:37Z">2019-3-22</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>, <a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Uno de mis proyectos permanentemente pospuestos es el del análisis de textos muy cortos. Se citarán Twitter y similares, aunque el € está en otros sitios, como los mensajes asociados a transferencias bancarias, reseñas o keywords.
Pero parece que no soy el único interesado en el tema. Otros con más tiempo y talento han desarrollado [BTM](https://cran.r-project.org/web/packages/BTM/index.html), que parece ser una versión modificada de LDA para el análisis de textos cortos.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2019/03/20/mariposa/" rel="bookmark">
			Mariposa
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2019-03-20T08:13:30Z">2019-3-20</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Quieres saber dónde está el escorpión,
Ni ayer ni antes vos sos corona dorada.
Ya os ves más tal cual tortuga pintada,
A él nos gusta andar con cola marrón.
Ella es quién son las alas de algún gorrión.
Si al fin podés ver tu imagen manchada,
O hoy vas bajo un cielo azul plateada,
Por qué estás tan lejos del aguijón.
No hay luz que al sol se enreda en tus palmera.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2019/02/28/9884/" rel="bookmark">
			Entre lo fofo y lo hierático,modelos loglineales
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2019-02-28T08:13:00Z">2019-2-28</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/ciencia-de-datos/" rel="category">ciencia de datos</a>, <a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>, <a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El contexto, por fijar ideas, el problema de taguear fechas en textos.
La estrategia gomosa, fofa (ñof, ñof, ñof), y en la que parecen parecer creer algunos, embeddings más TensorFlow.
La estrategia hierática, inflexible y reminiscente de robots de pelis de serie B, expresiones regulares encadenadas con ORs.
En la mitad donde mora la virtud, extracción de features (principalmente con expresiones regulares) y luego, esto.
Nota: esta entrada es un recordatorio para mí mismo y por si retorna cierto asunto que dejé postergado hace un par de días.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2018/10/15/dos-ejercicios-propuestos-sobre-embeddings/" rel="bookmark">
			Dos ejercicios (propuestos) sobre &#34;embeddings&#34;
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2018-10-15T08:13:11Z">2018-10-15</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/ciencia-de-datos/" rel="category">ciencia de datos</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Se me han ocurrido en los dos últimos días un par de ejercicios sobre embeddings que no voy a hacer. Pero tal vez alguien con una agenda más despejada que la mía se anime. Uno es más bien tonto; el otro es más serio.
El primero consiste en tomar las provincias, los códigos postales o las secciones censales y crear textos que sean, para cada una de ellas, las colindantes. Luego, construir un embedding de dimensión 2.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2018/10/03/de-que-matriz-son-los-embeddings-una-factorizacion/" rel="bookmark">
			¿De qué matriz son los &#34;embeddings&#34; una factorización?
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2018-10-03T08:13:49Z">2018-10-3</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/ciencia-de-datos/" rel="category">ciencia de datos</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Hoy, embeddings. Esto va de reducir la dimensionalidad de un espacio generado por palabras (procedentes de textos). Si a cada palabra le asignamos un vector índice (todo ceros y un uno donde le corresponde), la dimensión del espacio de palabras es excesiva.
La ocurrencia de algunos es asociar a cada palabra, $latex W_i$, un vector $latex w_i$ corto (p.e., 100) con entradas $latex w_{ij}$ a determinar de la manera que se explica a continuación.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2018/01/05/preludio-de-mas-por-venir/" rel="bookmark">
			Preludio (de más por venir)
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2018-01-05T08:13:29Z">2018-1-5</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/n%C3%BAmeros/" rel="category">números</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El preludio esto:
Que tiene el interés y la interpretación (muchas de ellas, como se podrá barruntar más abajo, de corte técnico) que cada uno quiera darle.
La cuestión es que he ocerreado todas las portadas de El País y puedo buscar en el texto (adviértase la cursiva) resultante. Creo contar con una voluntaria para construir una aplicación web similar a la de los n-gramas de Google.
Igual subo los datos a algún sitio en algún momento.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2016/05/30/mis-conciudadanos-no-tienen-wifi/" rel="bookmark">
			¿Mis conciudadanos no tienen wifi?
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2016-05-30T08:13:01Z">2016-5-30</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		A alguien leí el otro día que decía que en un bar de carretera habían colocado un cartel diciendo: &ldquo;Hemos quitado el periódico y hemos puesto wifi&rdquo;. Viene esto a cuento de
library(rvest) library(&lt;a href=&quot;http://inside-r.org/packages/cran/tm&quot;&gt;tm) library(wordcloud) res &lt;- sapply(1:17, function(i){ url &lt;- paste(&quot;https://decide.madrid.es/participatory_budget/investment_projects?geozone=all&amp;page=&quot;, i, &quot;&amp;random_seed=0.28&quot;, sep = &quot;&quot;) tmp &lt;- html_nodes(read_html(url), xpath = &quot;//div[starts-with(@id, 'spending_proposal')]/div/div/div[1]/div/h3/a/text()&quot;) as.character(tmp) }) tmp &lt;- unlist(res) tmp &lt;- Corpus(VectorSource(tmp)) tmp &lt;- tm_map(tmp, stripWhitespace) tmp &lt;- tm_map(tmp, content_transformer(tolower)) tmp &lt;- tm_map(tmp, removeWords, stopwords(&quot;spanish&quot;)) wordcloud(tmp, scale=c(5,0.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2016/05/06/un-corpus-de-textos-en-espanol-para-nlp/" rel="bookmark">
			Un corpus de textos en español para NLP
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2016-05-06T08:13:49Z">2016-5-6</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Mañana doy clase de NLP en el máster de ciencia de datos de KSchool. Para lo que necesito un corpus decente. Los hay en inglés a tutiplén, pero las hordas de lingüistas hispanoparlantes que se pagan los vicios a costa de tajadas de mi IRPF han sido incapaces de colgar ninguno en español que pueda ubicar y reutilizar.
Necesito una colección de textos en español con ciertas características:
 * Tener un cierto tamaño (¿unas cuantas centenas de ellos?
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2016/04/29/90-millones-de-euros-en-tecnologias-del-lenguaje/" rel="bookmark">
			90 millones de euros en tecnologías del lenguaje
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2016-04-29T08:13:31Z">2016-4-29</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/varios/" rel="category">varios</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El gobierno español ha anunciado (ya hace un tiempo) un plan de impulso a las tecnologías del lenguaje con una dotación de 90 millones de euros (lo que costó el fichaje de Ronaldo).
Veremos en unos años qué ha dado de sí la cosa. En particular, si habrá permitido que los usuarios de R dispongamos de herramientas libres (porque de momento, ya están cobrándonoslas vía Agencia Tributaria) para hacer nuestros cacharreos.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2013/05/13/charla-un-lematizador-probabilistico-con-r/" rel="bookmark">
			Charla: un lematizador probabilístico con R
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2013-05-13T07:18:08Z">2013-5-13</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>, <a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El jueves 16 de mayo hablaré en el Grupo de Interés Local de Madrid de R sobre lematizadores probabilísticos.
Hablaré sobre el proceso de lematizacion y trataré de mostrar su importancia dentro del mundo del llamado procesamiento del lenguaje natural (NLP). La lematización es un proceso humilde dentro del NLP del que apenas nadie habla: su ejercicio solo ha hecho famoso a Martin Porter. Lo eclipsan otras aplicaciones más vistosas, como el siempre sobrevalorado análisis del sentimiento.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2012/01/05/un-lematizador-para-el-espanol-con-r-ii/" rel="bookmark">
			Un lematizador para el español con R (II)
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2012-01-05T06:42:00Z">2012-1-5</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El otro día publiqué mi pequeño lematizador para el español con R. Era el subproducto de un antiguo proyecto mío de cuyos resultados daré noticia en los próximos días.
Pero veo con infinita satisfacción que Emilio Torres, viejo conocido de quienes, por ejemplo, hayáis asistido a las II o III Jornadas de Usuarios de R, ha estado abundando en el asunto y, ciertamente mejorándolo (cosa que, todo hay que decir, tiene escaso mérito): basta mirar los sus comentarios a la entrada original.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2011/12/13/un-lematizador-para-el-espanol-con-r-cutre-mejorable/" rel="bookmark">
			Un lematizador para el español con R... ¿cutre? ¿mejorable?
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2011-12-13T07:23:56Z">2011-12-13</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/nlp/" rel="category">nlp</a>, <a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Uno de los pasos previos para realizar lo que se viene llamando minería de texto es lematizar el texto. Desafortunadamente, no existen buenos lematizadores en español. Al menos, buenos lematizadores libres.
Existen el llamado algoritmo de porter y snowball pero, o son demasiado crudos o están más pensados para un lenguaje con muchas menos variantes morfológicas que el español.
Sinceramente, no sé a qué se dedican —me consta que los hay— los lingüistas computacionales de la hispanidad entera: ¿no son capaces de liberar una herramienta de lematización medianamente decente que podamos usar los demás?
	</div>
</article>
</main>

<div class="pagination">
	<span class="pagination__item pagination__item--current">1/2</span>
	<a class="pagination__item pagination__item--next btn" href="/tags/nlp/page/2/">»</a>
</div>

			</div>
			
<aside class="sidebar">
<div class="widget-recent widget">
	<h4 class="widget__title">Más Recientes</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/2021/12/09/mas-sobre-exceso-mortalidad-noviembre-2021/">Sobre el exceso de mortalidad en noviembre de 2021</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/09/mas-sobre-la-estimacion-de-probabilidades-de-eventos-que-no-se-repiten/">Más sobre la estimación de probabilidades de eventos que no se repiten</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/07/estadistica-vs-siquiatria-la-aparente-contradiccion-la-profunda-sintesis/">Estadística vs siquiatría: la aparente contradicción, la profunda síntesis</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/02/por-que-cabe-argumentar-que-estos-resultados-infraestiman-la-efectividad-de-las-vacunas-contra-el-covid/">¿Por qué cabe argumentar que estos resultados infraestiman la efectividad de las vacunas contra el covid?</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/11/25/un-episodio-relevante-para-estas-paginas-extraido-de-un-espia-perfecto/">Un episodio relevante para estas páginas extraído de &#34;Un espía perfecto&#34;</a></li>
		</ul>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 datanalytics.
      
		</div>
	</div>
</footer>

	</div>
<script async defer src="/js/menu.js"></script>

</body>
</html>