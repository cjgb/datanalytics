<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scraping on datanalytics</title>
    <link>/tags/scraping/</link>
    <description>Recent content in scraping on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Fri, 20 Oct 2017 08:13:02 +0000</lastBuildDate><atom:link href="/tags/scraping/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>He tratado de contrastar una hipótesis sin éxito, así que solo publico el subproducto</title>
      <link>/2017/10/20/he-tratado-de-contrastar-una-hipotesis-sin-exito-asi-que-solo-publico-el-subproducto/</link>
      <pubDate>Fri, 20 Oct 2017 08:13:02 +0000</pubDate>
      
      <guid>/2017/10/20/he-tratado-de-contrastar-una-hipotesis-sin-exito-asi-que-solo-publico-el-subproducto/</guid>
      <description>Inspirado por esto he tratado de contrastar una hipótesis en otro contexto.
Las cosas, o se hacen bien, o no se hacen. Como mi análisis se ha complicado con casos y casitos particulares, aunque siga pensándo cierta (en caso de tener que apostar, como priori, claro) la hipótesis de partida, abandono su búsqueda.
Como subproducto, esto:
library(xml2) library(stringr) library(plyr) library(lubridate) periodos &amp;lt;- expand.grid(anno = 2010:2017, mes = 1:12) periodos$ind &amp;lt;- periodos$anno * 100 + periodos$mes periodos &amp;lt;- periodos[periodos$ind &amp;lt; 201711,] periodos &amp;lt;- paste(periodos$anno, str_pad(periodos$mes, 2, pad = &amp;quot;0&amp;quot;), sep = &amp;quot;_&amp;quot;) raw &amp;lt;- lapply(periodos, function(x){ url &amp;lt;- paste0(&amp;quot;http://www.</description>
    </item>
    
    <item>
      <title>Tod[rep(&#39;a&#39;, 831)]s y tod[rep(&#39;o&#39;, 6450)]s los autores de paquetes de R</title>
      <link>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</link>
      <pubDate>Wed, 31 Aug 2016 08:13:15 +0000</pubDate>
      
      <guid>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</guid>
      <description>En los últimos tiempos se ha puesto de moda un subgénero periodístico que es una manera de generar artículos de acuerdo con el siguiente algoritmo:
 1. Se toma una lista de personas. 2. Se cuenta en ella el número de mujeres (a) y de hombres (b). 3. Si a &amp;gt;= b, GOTO 1; si no, se copipega y se mutatismutandea un manido argumento.  No sabiéndome sustraer al encanto del último grito, he escrito y corrido</description>
    </item>
    
    <item>
      <title>Cómo capturar datos usados en visualizaciones en la red: una alternativa robusta al scraping</title>
      <link>/2016/05/19/como-capturar-datos-usados-en-visualizaciones-en-la-red-una-alternativa-robusta-al-scraping/</link>
      <pubDate>Thu, 19 May 2016 08:13:00 +0000</pubDate>
      
      <guid>/2016/05/19/como-capturar-datos-usados-en-visualizaciones-en-la-red-una-alternativa-robusta-al-scraping/</guid>
      <description>Se me pregunta cómo llegué a los datos con los que armé esta entrada. Recuérdese que gráficos como los que aparecen aquí los pinta tu propio navegador con javascript. De alguna manera, el servidor manda datos a tu navegador y, por lo tanto, de alguna manera, esos datos obran en tu poder. Sólo hay que saber capturarlos.
La manera (más bien, una de ellas):
 * Abre la página con Chrome * Abre [_Chrome DevTools_](https://developer.</description>
    </item>
    
    <item>
      <title>Madrid decide, propone, vota, etc.</title>
      <link>/2015/10/09/madrid-decide-propone-vota-etc/</link>
      <pubDate>Fri, 09 Oct 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/10/09/madrid-decide-propone-vota-etc/</guid>
      <description>De siempre, no sé por qué motivo, me interesaron esas cosas relacionadas con la democracia directa. En la feria del libro del año nosecuántos compré un libro al respecto (que presté y no me han devuelto). He seguido de cerca del desarrollo de plataformas como Agora y conozco a alguno de sus desarrolladores. Di guerrita en Suiza a los locales para que me explicasen pros, contras y funcionamientos de lo que allí tienen instalado.</description>
    </item>
    
    <item>
      <title>Para los que buscáis proyectos de análisis / visualización de datos</title>
      <link>/2015/05/07/para-los-que-buscais-proyectos-de-analisis-visualizacion-de-datos/</link>
      <pubDate>Thu, 07 May 2015 08:13:49 +0000</pubDate>
      
      <guid>/2015/05/07/para-los-que-buscais-proyectos-de-analisis-visualizacion-de-datos/</guid>
      <description>Igual hay alguien que busca un proyecto interesante de análisis / visualización de datos. Tengo uno en mente para el que ando sin tiempo. Así que lo sugiero aquí por si alguien quiere hincarle el diente.
Consiste en:
 * [Bajarse el BOE](http://www.datanalytics.com/2014/04/24/aventuras-de-web-scraping-como-bajarse-todo-el-boe/) hasta cuando hay texto en formatos decentes (principios de los 90, si no recuerdo mal) * Extraer los [1,2,3,¿4?-gramas](http://en.wikipedia.org/wiki/N-gram) * Construir algo [parecido a esto](https://books.google.com/ngrams/graph?content=energ%C3%ADa+nuclear%2C+energ%C3%ADa+e%C3%B3lica&amp;amp;year_start=1800&amp;amp;year_end=2000&amp;amp;corpus=21&amp;amp;smoothing=3&amp;amp;share=&amp;amp;direct_url=t1%3B%2Cenerg%C3%ADa%20nuclear%3B%2Cc0%3B.t1%3B%2Cenerg%C3%ADa%20e%C3%B3lica%3B%2Cc0) * Ponerme en la letra chiquita de los créditos y pagarme una cerveza  ¿O no es interesante?</description>
    </item>
    
    <item>
      <title>Embalses en España: otro ejercicio inconcluso de &#34;web scraping&#34;</title>
      <link>/2014/04/30/embalses-en-espana-otro-ejercicio-inconcluso-de-web-scraping/</link>
      <pubDate>Wed, 30 Apr 2014 06:51:55 +0000</pubDate>
      
      <guid>/2014/04/30/embalses-en-espana-otro-ejercicio-inconcluso-de-web-scraping/</guid>
      <description>Vi el otro día que alguien había conseguido datos de la entrada en funcionamiento de las presas de EE.UU. y me picó la curiosidad: ¿se podrán conseguir también para España?
La respuesta es afirmativa.
El código para bajarse (y adecentar un poco) la base de datos es:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/XML&amp;quot;&amp;gt;XML) ## bajada de datos tmp &amp;lt;- lapply(1:47, function(x) readLines(paste(&amp;quot;http://www.seprem.es/presases.php?p=&amp;quot;, x, sep = &amp;quot;&amp;quot;))) tmp2 &amp;lt;- lapply(tmp, readHTMLTable) ## limpieza de datos res &amp;lt;- lapply(tmp2, function(x) x[[1]]) res &amp;lt;- do.</description>
    </item>
    
    <item>
      <title>Aventuras de &#34;web scraping&#34;: cómo bajarse todo el BOE</title>
      <link>/2014/04/24/aventuras-de-web-scraping-como-bajarse-todo-el-boe/</link>
      <pubDate>Thu, 24 Apr 2014 07:47:56 +0000</pubDate>
      
      <guid>/2014/04/24/aventuras-de-web-scraping-como-bajarse-todo-el-boe/</guid>
      <description>Rescato aquí para futura o ajena referencia un pedazo de código que utilicé un día para un proyecto que se abortó y que tenía que ver con el análisis del texto del BOE. Reza así:
setwd(&amp;quot;~/boe/boes&amp;quot;) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/RCurl&amp;quot;&amp;gt;RCurl) h = getCurlHandle() for( i in 1:3231){ mi.url &amp;lt;- paste(&amp;quot;http://www.boe.es/diario_boe/xml.php?id=BOE-A-2013-&amp;quot;, i, sep = &amp;quot;&amp;quot;) nom.fich &amp;lt;- paste(&amp;quot;2013-A-&amp;quot;, formatC(i, width = 6, format = &amp;quot;d&amp;quot;, flag = &amp;quot;0&amp;quot;), &amp;quot;.xml&amp;quot;, sep = &amp;quot;&amp;quot;) res &amp;lt;- getURI(mi.</description>
    </item>
    
  </channel>
</rss>
