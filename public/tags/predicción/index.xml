<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>predicción on datanalytics</title>
    <link>/tags/predicci%C3%B3n/</link>
    <description>Recent content in predicción on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Thu, 09 Dec 2021 09:13:00 +0000</lastBuildDate><atom:link href="/tags/predicci%C3%B3n/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Más sobre la estimación de probabilidades de eventos que no se repiten</title>
      <link>/2021/12/09/mas-sobre-la-estimacion-de-probabilidades-de-eventos-que-no-se-repiten/</link>
      <pubDate>Thu, 09 Dec 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/12/09/mas-sobre-la-estimacion-de-probabilidades-de-eventos-que-no-se-repiten/</guid>
      <description>Hace un tiempo hablé sobre la estimación de probabilidades de eventos que ocurren una única vez: elecciones, etc. Argumentaba cómo pueden ser descompuestos en dos partes muy distintas cualitativamente: una asociada a eventos que sí que se han repetido; otra, específica y única. El tamaño relativo de ambas componentes afecta a eficacia del mecanismo de estimación.
Esta vez quiero ilustrarlo con un ejemplo extraído, traducido y adaptado de aquí que ilustra el procedimiento.</description>
    </item>
    
    <item>
      <title>Causalidad inversa: más sobre los momentos &#34;Le Verrier&#34;</title>
      <link>/2021/10/19/causalidad-inversa-mas-sobre-los-momentos-le-verrier/</link>
      <pubDate>Tue, 19 Oct 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/10/19/causalidad-inversa-mas-sobre-los-momentos-le-verrier/</guid>
      <description>Escribí el otro día sobre los llamados momentos Le Verrier. Que, siguiendo la nomenclatura de Why ask why? Forward causal inference and reverse causal questions no son otra cosa que ejercicios de causalidad inversa con final feliz.
Efectivamente, según el artículo, las cuestiones de índole causal son de dos tipos: prospectivas y retrospectivas (o inversas), en una traducción muy libre. Las primeras, más habituales, se refieren a cuáles serán los efectos de una causa.</description>
    </item>
    
    <item>
      <title>Cuantificación de la incertidumbre</title>
      <link>/2021/10/05/cuantificacion-de-la-incertidumbre/</link>
      <pubDate>Tue, 05 Oct 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/10/05/cuantificacion-de-la-incertidumbre/</guid>
      <description>IBM ha desarrollado una iniciativa, Uncertainty Quantification 360, que describe así:
En la página del proyecto hay documentación abundante pero recomiendo comenzar por la demo.</description>
    </item>
    
    <item>
      <title>Esos felices &#34;momentos Le Verrier&#34;</title>
      <link>/2021/10/01/esos-felices-momentos-le-verrier/</link>
      <pubDate>Fri, 01 Oct 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/10/01/esos-felices-momentos-le-verrier/</guid>
      <description>Son muy infrecuentes, lo admito. Pero cuando ocurren, le dan a uno ganas de poner los pies encima la mesa y fumarse un puro.
¿Qué son? Imagina que te pasan unos datos con el objetivo de realizar determinadas predicciones. Creas un modelo razonable —hasta bueno, dirías—, basado en primeros principios y que funciona bastante bien&amp;hellip; excepto en unos cuantos casos irreductibles (sí, como aquellos galos de su aldea). Compruebas el modelo una y mil veces y no le ves problemas significativos; revisas los datos de nuevo, especialmente en esos casos en los que el modelo falla, y parecen tener sentido.</description>
    </item>
    
    <item>
      <title>Sobre predicciones puntuales</title>
      <link>/2020/06/25/sobre-predicciones-puntuales/</link>
      <pubDate>Thu, 25 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/25/sobre-predicciones-puntuales/</guid>
      <description>Como tan a menudo se nos olvida, Taleb nos recuerda, breve y conciso, un par de cositas sobre las predicciones puntuales aquí. Además, casi todo lo que tiene que decir se resume en:</description>
    </item>
    
    <item>
      <title>Sobre &#34;Predicción, estimación y atribución&#34;</title>
      <link>/2020/06/10/sobre-prediccion-estimacion-y-atribucion/</link>
      <pubDate>Wed, 10 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/10/sobre-prediccion-estimacion-y-atribucion/</guid>
      <description>Subrayo hoy aquí tres cuestiones que considero importantes del reciente artículo Prediction, Estimation, and Attribution de B. Efron (para otra visión, véase esto).
La primera es que existe una cadena de valor en la modelización estadística que va del producto más ordinario, la predicción, a la estimación y de este, al más deseable, la atribución. En la terminología de Efron,
 estimación consiste en la determinación de los parámetros subyacentes (e importantes) del modelo; específicamente se refiere a la estimación puntual; * atribución tiene que ver con intervalos de confianza, p-valores, etc.</description>
    </item>
    
    <item>
      <title>Cosas que ocurrirán sin lugar a dudas tras el coronavirus</title>
      <link>/2020/04/15/cosas-que-ocurriran-sin-lugar-a-dudas-tras-el-coronavirus/</link>
      <pubDate>Wed, 15 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/15/cosas-que-ocurriran-sin-lugar-a-dudas-tras-el-coronavirus/</guid>
      <description>Hay mucha incertidumbre sobre cómo será el mundo post-coronavirus. Pero una cosa es segura: tendremos gráficas tales como
hasta en la sopa. La buena noticia para quienes son ellos y su ideología, es que hay tantos grados de libertad, i.e., la posibilidad de elegir muy cuidadosamente
 las variables que colocar en el eje x, las fuentes, los años de los datos, etc., * los indicadores que colocar en el eje y, * los países, provincias, regiones, etc.</description>
    </item>
    
    <item>
      <title>Tengo cuenta en Hypermind</title>
      <link>/2020/04/10/tengo-cuenta-en-hypermind/</link>
      <pubDate>Fri, 10 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/10/tengo-cuenta-en-hypermind/</guid>
      <description>Acaban de notificarme que han aprobado mi cuenta en Hypermind. Hypermind es un mercado de predicciones cuyo funcionamiento está descrito aquí y aquí mejor que yo pudiera hacerlo.
Ya iré contando. En tanto, una imagen extraída de uno de los enlaces anteriores que vale por mil palabras:</description>
    </item>
    
    <item>
      <title>k-vecinos &#43; lmer</title>
      <link>/2020/03/19/k-vecinos-lmer/</link>
      <pubDate>Wed, 18 Mar 2020 22:11:00 +0000</pubDate>
      
      <guid>/2020/03/19/k-vecinos-lmer/</guid>
      <description>El de los k-vecinos es uno de mis métodos favoritos de modelización. Al menos, teóricamente: luego, en la práctica, es complicado construir una función de distancias decente. Pero tiene la ventaja indiscutible de ser tremendamente local: las predicciones para una observación concreta dependen únicamente de su entorno.
[lme4::lmer](https://CRAN.R-project.org/package=lme4) (y sus derivados) es ya casi la lente a través de la que imagino cómo operan las variables dentro de un modelo. Desafortunadamente, es un modelo global y no gestiona particularmente bien las interacciones, cuando son muchas y complejas.</description>
    </item>
    
    <item>
      <title>Clasificación vs predicción</title>
      <link>/2020/03/05/clasificacion-vs-prediccion-2/</link>
      <pubDate>Thu, 05 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/05/clasificacion-vs-prediccion-2/</guid>
      <description>Aquí se recomienda, con muy buen criterio, no realizar clasificación pura, i.e., asignando etiquetas 0-1 (en casos binarios), sino proporcionar en la medida de lo posible probabilidades. Y llegado el caso, distribuciones de probabilidades, claro.
La clave es, por supuesto:</description>
    </item>
    
    <item>
      <title>Intervalos de confianza, intervalos de predicción</title>
      <link>/2020/03/04/intervalos-de-confianza-intervalos-de-prediccion/</link>
      <pubDate>Wed, 04 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/04/intervalos-de-confianza-intervalos-de-prediccion/</guid>
      <description>Contexto:
modelo &amp;lt;- lm(dist ~ speed, data = cars)  Intervalos de confianza:
head(predict(modelo, interval = &amp;quot;confidence&amp;quot;)) # fit lwr upr #1 -1.849460 -12.329543 8.630624 #2 -1.849460 -12.329543 8.630624 #3 9.947766 1.678977 18.216556 #4 9.947766 1.678977 18.216556 #5 13.880175 6.307527 21.452823 #6 17.812584 10.905120 24.720047  Intervalos de predicción:
head(predict(modelo, interval = &amp;quot;prediction&amp;quot;)) # fit lwr upr #1 -1.849460 -34.49984 30.80092 #2 -1.849460 -34.49984 30.80092 #3 9.947766 -22.06142 41.95696 #4 9.</description>
    </item>
    
    <item>
      <title>&#34;Para razonar rigurosamente bajo incertidumbre hay que recurrir al lenguaje de la probabilidad&#34;</title>
      <link>/2020/03/03/para-razonar-rigurosamente-bajo-incertidumbre-hay-que-recurrir-al-lenguaje-de-la-probabilidad/</link>
      <pubDate>Tue, 03 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/03/para-razonar-rigurosamente-bajo-incertidumbre-hay-que-recurrir-al-lenguaje-de-la-probabilidad/</guid>
      <description>Así arranca este artículo, que presenta una extensión de XGBoost para predicciones probabilísticas. Es decir, un paquete que promete no solo una estimación del valor central de la predicción sino de su distribución.
La versión equivalente de lo anterior en el mundo de los random forests está descrito aquí, disponible aquí y mucho me temo que muy pronto voy a poder contar por aquí si está a la altura de las expectativas.</description>
    </item>
    
    <item>
      <title>Análisis y predicción de series temporales intermitentes</title>
      <link>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</link>
      <pubDate>Mon, 04 Nov 2019 09:13:16 +0000</pubDate>
      
      <guid>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</guid>
      <description>Hace tiempo me tocó analizar unas series temporales bastante particulares. Representaban la demanda diaria de determinados productos y cada día esta podía ser de un determinado número de kilos. Pero muchas de las series eran esporádicas: la mayoría de los días la demanda era cero.
Eran casos de las llamadas series temporales intermitentes.
Supongo que hay muchas maneras de modelizarlas y, así, al vuelo, se me ocurre pensar en algo similar a los modelos con inflación de ceros.</description>
    </item>
    
    <item>
      <title>¿Tienes un sistema predictivo guay? Vale, pero dame los dos números</title>
      <link>/2019/10/24/tienes-un-sistema-predictivo-guay-vale-pero-dame-los-dos-numeros/</link>
      <pubDate>Thu, 24 Oct 2019 09:13:36 +0000</pubDate>
      
      <guid>/2019/10/24/tienes-un-sistema-predictivo-guay-vale-pero-dame-los-dos-numeros/</guid>
      <description>No, no me vale que me digas que aciertas el 97% de las veces. Dime cuántas veces aciertas cuando sí y cuántas veces aciertas cuando no.
Si no, cualquiera.
Nota: estaba buscando la referencia a la última noticia de ese estilo que me había llegado, pero no la encuentro. No obstante, seguro, cualquier día de estos encontrarás un ejemplo de lo que denuncio.</description>
    </item>
    
    <item>
      <title>¿Escenarios jerárquicos? (para encuestas electorales en contextos multipartidistas)</title>
      <link>/2019/05/30/escenarios-jerarquicos-para-encuestas-electorales-en-contextos-multipartidistas/</link>
      <pubDate>Thu, 30 May 2019 09:13:55 +0000</pubDate>
      
      <guid>/2019/05/30/escenarios-jerarquicos-para-encuestas-electorales-en-contextos-multipartidistas/</guid>
      <description>Existe una brecha conceptual entre los pronósticos electorales,
que son continuos y cómo percibimos los resultados, de manera discreta: p.e., el partido X y el partido Y suman (o no).
Después de las elecciones, sobre todo de muchas de las últimas, el público siente perplejidad (frente a los resultados que acaban siendo) a la vista de las predicciones que se hicieron. Y los hacedores de pronósticos publican el consabido artículo explicando que esos escenarios que acabaron sucediendo estaban de alguna manera recogidos en sus (en el óptimo de los casos) histogramas.</description>
    </item>
    
    <item>
      <title>¡Bien por AIReF!</title>
      <link>/2019/05/13/bien-por-airef/</link>
      <pubDate>Mon, 13 May 2019 09:13:17 +0000</pubDate>
      
      <guid>/2019/05/13/bien-por-airef/</guid>
      <description>Años ha, cuando quería mostrar gráficos como
tenía que irme al extranjero. Pero hoy he estado hojeando el informe sobre la actualización del programa de estabilidad 2019-2022 de AIReF, he visto cosas como
y me he emocionado mucho.</description>
    </item>
    
    <item>
      <title>Reglas de &#34;scoring&#34; impropias: un ejemplo</title>
      <link>/2019/01/23/reglas-de-scoring-impropias-un-ejemplo/</link>
      <pubDate>Wed, 23 Jan 2019 08:13:07 +0000</pubDate>
      
      <guid>/2019/01/23/reglas-de-scoring-impropias-un-ejemplo/</guid>
      <description>Todo lo que he venido escribiendo sobre reglas de scoring propias vino en el fondo motivado por Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules, una entrada en el blog de Frank Harrell en la que se discute el siguiente caso.
El tipo simula unos datos para ser ajustados mediante una regresión logística (de manera que conoce la verdad subyacente). Después construye varios modelos alternativos para ajustarlos y utiliza varios scorings distintos para seleccionar el mejor modelo.</description>
    </item>
    
    <item>
      <title>Scorings: interpolando (y extrapolando) entre el de Brier y el lineal</title>
      <link>/2019/01/21/scorings-interpolando-y-extrapolando-entre-el-de-brier-y-el-lineal/</link>
      <pubDate>Mon, 21 Jan 2019 08:13:13 +0000</pubDate>
      
      <guid>/2019/01/21/scorings-interpolando-y-extrapolando-entre-el-de-brier-y-el-lineal/</guid>
      <description>Rápidamente y para poner el limpio unas cosas que tenía en borrador. El scoring lineal del que me he ocupado en entradas anteriores (p.e., esta o esta) está asociado a un exponente $latex \lambda = 1$ y el de Brier, a $latex \lambda = 2$. Entre ambos (y a la derecha del 2) hay otros scorings posibles.
Una penalización de $latex (1-p)^\lambda$ (véanse las entradas enlazadas más arriba para averiguar a qué me refiero), un predictor tiene un incentivo para modificar su predicción para alcanzar un scoring más alto, salvo en el caso en que $latex \lambda = 2$, en el que le compensa ser lo más sincero posible.</description>
    </item>
    
    <item>
      <title>Mejores predictores: un ejemplo (el de Brier)</title>
      <link>/2019/01/17/mejores-predictores-un-ejemplo-el-de-brier/</link>
      <pubDate>Thu, 17 Jan 2019 08:13:15 +0000</pubDate>
      
      <guid>/2019/01/17/mejores-predictores-un-ejemplo-el-de-brier/</guid>
      <description>La entrada de hoy casi me la escribe un comentarista (al que le estoy muy agradecido) ayer. Retomo el tema.
Ayer premiaba a cada predictor con $latex p(X)$, es decir, le daba $latex p$ punticos si ocurría $latex X$ y $latex 1-p$ punticos sin no ocurría. La cosa no cambia si nos alineamos con lo que está escrito por ahí y en lugar de premiar, penalizamos. Es decir, si en lugar de maximizar $latex p(X)$, buscamos minimizar $latex 1 - p(X)$.</description>
    </item>
    
    <item>
      <title>Una de las mil maneras malas de elegir al mejor predictor</title>
      <link>/2019/01/16/una-de-las-mil-maneras-malas-de-elegir-al-mejor-predictor/</link>
      <pubDate>Wed, 16 Jan 2019 08:13:36 +0000</pubDate>
      
      <guid>/2019/01/16/una-de-las-mil-maneras-malas-de-elegir-al-mejor-predictor/</guid>
      <description>El contexto, ayer.
La cosa es que se nos podría ocurrir premiar a los predictores cuando asignan probabilidad alta a los sucesos que ocurrieron y baja a los que no. Por ejemplo, si el evento $latex i$ ocurre, premiar al predictor con $latex p_i$ y si no ocurre, con $latex 1 - p_i$. Escrito de otra manera, con $latex p_i(X_i)$ (que quiere decir la probabilidad correspondiente al evento observado).
Como hay varios eventos, cada predictor se llevaría un premio igual a $latex s = \sum_i p_i(X_i)$ y sería mejor aquél predictor con el mayor valor de $latex s$.</description>
    </item>
    
    <item>
      <title>¿Quién será el mejor predictor? ¿Cómo se podrá medir?</title>
      <link>/2019/01/15/quien-sera-el-mejor-predictor-como-se-podra-medir/</link>
      <pubDate>Tue, 15 Jan 2019 08:13:22 +0000</pubDate>
      
      <guid>/2019/01/15/quien-sera-el-mejor-predictor-como-se-podra-medir/</guid>
      <description>He tropezado con un problema nuevo y sobre el que escribiré más estos días. Hoy y aquí solo lo formulo.
Existe una serie de eventos dicotómicos $latex X_i$ que pueden ocurrir o no ocurrir, cada uno de ellos con su probabilidad real (pero desconocida) de ocurrencia $latex q_i$. Antes de que ocurran o no, a dos expertos se les preguntan las probabilidades de ocurrencia de dichos eventos y producen predicciones $latex p_{1i}$ y $latex p_{2i}$.</description>
    </item>
    
    <item>
      <title>Clasificación vs predicción</title>
      <link>/2019/01/14/clasificacion-vs-prediccion/</link>
      <pubDate>Mon, 14 Jan 2019 08:13:30 +0000</pubDate>
      
      <guid>/2019/01/14/clasificacion-vs-prediccion/</guid>
      <description>Traduzco de aquí:
  El resto es tanto o más aprovechable.</description>
    </item>
    
    <item>
      <title>Más sobre las proyecciones de población del INE</title>
      <link>/2018/10/22/mas-sobre-las-proyecciones-de-poblacion-del-ine/</link>
      <pubDate>Mon, 22 Oct 2018 08:13:53 +0000</pubDate>
      
      <guid>/2018/10/22/mas-sobre-las-proyecciones-de-poblacion-del-ine/</guid>
      <description>Bastante he hablado de las proyecciones de población del INE (p.e., aquí o aquí). Insisto porque el gráfico que aparece en la segunda página de la nota de prensa de las últimas, a saber,
se parece muchísimo a un gráfico que garabateé en el Bar Chicago de Zúrich (el peor garito de la peor calle de una de las mejores ciudades del mundo), con demasiadas cervezas en el cuerpo y mientras nos reíamos hasta de las bombillas.</description>
    </item>
    
    <item>
      <title>Consecuencias indeseadas de la falta de humildad</title>
      <link>/2018/07/16/consecuencias-indeseadas-de-la-falta-de-humildad/</link>
      <pubDate>Mon, 16 Jul 2018 08:13:00 +0000</pubDate>
      
      <guid>/2018/07/16/consecuencias-indeseadas-de-la-falta-de-humildad/</guid>
      <description>Me refiero a estas:
La historia, resumida, es que Kiko Llaneras publica sus predicciones para el mundial en El País, i.e.,
y a la vista de los acontecimientos balompédicos, tiempo le ha faltado al del tuit para lanzarse en tromba contra quienes prentenden cuantificar fenónenos complejos y contra Llaneras en particular. Y luego, claro, parte de nosotros, le hemos atizado con bastante razón. Pero no, argumentaré, toda.
Me retrotraigo. Hay mucha gente que paga su hipoteca escribiendo bonito.</description>
    </item>
    
    <item>
      <title>Lo (mínimo) que hay que saber de series temporales: breve, conciso e indoloro</title>
      <link>/2017/04/06/lo-minimo-que-hay-que-saber-de-series-temporales-breve-conciso-e-indoloro/</link>
      <pubDate>Thu, 06 Apr 2017 08:13:28 +0000</pubDate>
      
      <guid>/2017/04/06/lo-minimo-que-hay-que-saber-de-series-temporales-breve-conciso-e-indoloro/</guid>
      <description>Es Forecasting: principles and practice, de Hyndman y Athana­sopou­los.</description>
    </item>
    
    <item>
      <title>Si se estudió que las autopistas eran viables, ¿por qué están ahora en quiebra?</title>
      <link>/2016/10/04/si-se-estudio-que-las-autopistas-eran-viables-por-que-estan-ahora-en-quiebra/</link>
      <pubDate>Tue, 04 Oct 2016 08:13:21 +0000</pubDate>
      
      <guid>/2016/10/04/si-se-estudio-que-las-autopistas-eran-viables-por-que-estan-ahora-en-quiebra/</guid>
      <description>Así titula El Mundo un artículo en el que el mismo periódico se responde:
En estudios de esa naturaleza, primero se decide cuánto tienen que dar los números, y luego se contrata a alguno de los que aparecen en
[caption id=&amp;ldquo;attachment_7902&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;830&amp;rdquo;]Fotografías de la manifestación por la ciencia en Madrid, 27S 2013[/caption]
para que cohoneste las cifras con citas de aquí y allá (con tal de que estén en inglés) y fórmulas tipografiadas en Word.</description>
    </item>
    
    <item>
      <title>Contaminación y restricciones de tráfico en Madrid: ¿por qué no se puede ni prevenir ni &#34;estimar&#34;?</title>
      <link>/2015/12/07/contaminacion-y-restricciones-de-trafico-en-madrid-por-que-no-se-puede-ni-prevenir-ni-estimar/</link>
      <pubDate>Mon, 07 Dec 2015 08:13:26 +0000</pubDate>
      
      <guid>/2015/12/07/contaminacion-y-restricciones-de-trafico-en-madrid-por-que-no-se-puede-ni-prevenir-ni-estimar/</guid>
      <description>Aparentemente, porque así lo establece el protocolo de actuación, del ayuntamiento de la villa. Lo resume la imagen

que bajé de Twitter y que me llamó la atención sobremanera. Algún gobierno municipal decidió en su día que estaba fuera de lugar tanto prevenir como estimar.
Me preocupa que dicho gobierno municipal estuviese reñido con el refranero en lo concerniente a la prevención. Pero no es el asunto, entiendo, por el que mis lectores me visitan.</description>
    </item>
    
    <item>
      <title>La funesta manía de querer acertar</title>
      <link>/2015/09/29/la-funesta-mania-de-querer-acertar/</link>
      <pubDate>Tue, 29 Sep 2015 08:13:51 +0000</pubDate>
      
      <guid>/2015/09/29/la-funesta-mania-de-querer-acertar/</guid>
      <description>Vayan dos cosas por delante:
 * Que la de pretender acertar es una perniciosa manía. Más loable es la de tratar de evitar un fallo catastrófico. * Que recomiendo muy mucho seguir las cosas que hace [Kiko Llaneras](https://twitter.com/kikollan).  Dicho lo cual&amp;hellip;
Kiko Llaneras ha estado elaborando predicciones del resultado de las elecciones en Cataluña durante la precampaña. Pueden verse aquí. El documento enlazado incluye una discusión de la metodología.</description>
    </item>
    
    <item>
      <title>El porqué de los mínimos cuadrados con restricciones</title>
      <link>/2014/06/09/por-que-de-los-minimos-cuadrados-con-restricciones/</link>
      <pubDate>Mon, 09 Jun 2014 07:15:06 +0000</pubDate>
      
      <guid>/2014/06/09/por-que-de-los-minimos-cuadrados-con-restricciones/</guid>
      <description>Avisé en mi entrada del otro día: no me preguntéis por qué (imponer restricciones en un problema de mínimos cuadrados).
Pero cuanto más pienso sobre ello, menos claro lo tengo. ¿Por qué restricciones?
Primero, el contexto. O el casi contexto. Porque no es exactamente así. Pero sí parecido. Supongamos que queremos predecir algo y construimos, p.e., 4 modelos. Se nos ocurre (y hay buenas razones para ello) combinar los predictores.</description>
    </item>
    
    <item>
      <title>Científicos de datos, aprended de los actuarios</title>
      <link>/2014/03/18/cientificos-de-datos-aprended-de-los-actuarios/</link>
      <pubDate>Tue, 18 Mar 2014 07:35:19 +0000</pubDate>
      
      <guid>/2014/03/18/cientificos-de-datos-aprended-de-los-actuarios/</guid>
      <description>Los actuarios fueron tal vez los primeros científicos de datos. Aparentemente, la primera tabla de mortalidad fue creada por John Graunt en 1662.
Los actuarios hablan de la esperanza de vida. Pero no son tan pendejos como los científicos de datos de hoy en día en eso de pretender que la esperanza de vida es la vida. Los actuarios saben que en una cohorte con una esperanza de vida de 78 años habrá quien muera a los tres, a los quince, a los cincuenta y a los noventa.</description>
    </item>
    
    <item>
      <title>Victoria o diferencia de puntos, ahora con &#34;random forests&#34;</title>
      <link>/2014/03/07/victoria-o-diferencia-de-puntos-ahora-con-random-forests/</link>
      <pubDate>Fri, 07 Mar 2014 07:35:05 +0000</pubDate>
      
      <guid>/2014/03/07/victoria-o-diferencia-de-puntos-ahora-con-random-forests/</guid>
      <description>Después de hablar con tirios y troyanos sobre mi entrada sobre los efectos de binarizar una variable objetivo continua, he decidido tomarme la justicia por mi mano y llamar a la caballería. Es decir, utilizar random forests.
Aquí va el código:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/randomForest&amp;quot;&amp;gt;randomForest) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) my.coefs &amp;lt;- -2:2 n &amp;lt;- 200 train.n &amp;lt;- floor(2*n/3) test.error &amp;lt;- function(){ X &amp;lt;- matrix(rnorm(n*5), n, 5) Y &amp;lt;- 0.2 + X %*% my.coefs + rnorm(n) Y.</description>
    </item>
    
    <item>
      <title>Error de tipo I, error de tipo II</title>
      <link>/2014/01/10/error-de-tipo-i-error-de-tipo-ii/</link>
      <pubDate>Fri, 10 Jan 2014 08:05:09 +0000</pubDate>
      
      <guid>/2014/01/10/error-de-tipo-i-error-de-tipo-ii/</guid>
      <description>Aquí está la noticia sobre el resultado de un error de tipo I: Danone takes legal action over milk scare.
Este otro, sobre un error de tipo II: Wave a banknote at a pundit and he&amp;rsquo;ll predict anything.
Siempre me ha llamado la atención el segundo caso: ¿tienen realmente responsabilidades penales los geólogos? He leído algunos artículos al respecto y nunca he visto el caso planteado de la manera en que voy a hacerlo aquí.</description>
    </item>
    
    <item>
      <title>Use SAS para predecir como un pulpo</title>
      <link>/2010/07/13/use-sas-para-predecir-como-un-pulpo/</link>
      <pubDate>Tue, 13 Jul 2010 21:25:16 +0000</pubDate>
      
      <guid>/2010/07/13/use-sas-para-predecir-como-un-pulpo/</guid>
      <description>Para el otoño volverá a tener lugar el congreso de usuarios de SAS en España. El anuncio que me acaba de llegar —con su referencia al ubicuo pulpo Paul— no puede ser más desafortunado. Por si desaparece el enlace, reproduzco con una captura de pantalla aquí lo más sustancioso del mismo:

Addenda:
Comí el jueves con la más infiel de mis lectoras (creo que ni lectora es) y convinimos en que el mensaje de SAS resulta, cuando menos, insultante para cuantos nos dedicamos al sufrido oficio de la estadística y actividades concomitantes.</description>
    </item>
    
  </channel>
</rss>
