<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>harrell on datanalytics</title>
    <link>/tags/harrell/</link>
    <description>Recent content in harrell on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 02 Apr 2019 09:13:36 +0000</lastBuildDate><atom:link href="/tags/harrell/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>¿Vale realmente el &#34;bootstrap&#34; para comparar modelos?</title>
      <link>/2019/04/02/vale-realmente-el-bootstrap-para-comparar-modelos/</link>
      <pubDate>Tue, 02 Apr 2019 09:13:36 +0000</pubDate>
      
      <guid>/2019/04/02/vale-realmente-el-bootstrap-para-comparar-modelos/</guid>
      <description>Es una pregunta legítima —en el sentido de que ignoro la respuesta— que tengo. Para plantearla en sus debidos términos:
Contexto:
Tenemos modelos y queremos compararlos. Queremos que funcionen en el universo, pero solo disponemos de él una muestra.
Acto 1:
Para desatascar el nudo lógico, recurrimos a técnicas como:
 Entrenamiento y validación,j * jackknife y sobre todo, * su popular evolución, la validación cruzada.  Todas ellas bien sabidas y discutidas en todos los manuales.</description>
    </item>
    
    <item>
      <title>Reglas de &#34;scoring&#34; impropias: un ejemplo</title>
      <link>/2019/01/23/reglas-de-scoring-impropias-un-ejemplo/</link>
      <pubDate>Wed, 23 Jan 2019 08:13:07 +0000</pubDate>
      
      <guid>/2019/01/23/reglas-de-scoring-impropias-un-ejemplo/</guid>
      <description>Todo lo que he venido escribiendo sobre reglas de scoring propias vino en el fondo motivado por Damage Caused by Classification Accuracy and Other Discontinuous Improper Accuracy Scoring Rules, una entrada en el blog de Frank Harrell en la que se discute el siguiente caso.
El tipo simula unos datos para ser ajustados mediante una regresión logística (de manera que conoce la verdad subyacente). Después construye varios modelos alternativos para ajustarlos y utiliza varios scorings distintos para seleccionar el mejor modelo.</description>
    </item>
    
    <item>
      <title>Clasificación vs predicción</title>
      <link>/2019/01/14/clasificacion-vs-prediccion/</link>
      <pubDate>Mon, 14 Jan 2019 08:13:30 +0000</pubDate>
      
      <guid>/2019/01/14/clasificacion-vs-prediccion/</guid>
      <description>Traduzco de aquí:
  El resto es tanto o más aprovechable.</description>
    </item>
    
  </channel>
</rss>
