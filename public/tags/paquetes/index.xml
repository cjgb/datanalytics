<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>paquetes on datanalytics</title>
    <link>/tags/paquetes/</link>
    <description>Recent content in paquetes on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 21 Sep 2021 09:13:00 +0000</lastBuildDate><atom:link href="/tags/paquetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Aún más sobre propagación de errores (y rv)</title>
      <link>/2021/09/21/aun-mas-sobre-propagacion-de-errores-y-rv/</link>
      <pubDate>Tue, 21 Sep 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/09/21/aun-mas-sobre-propagacion-de-errores-y-rv/</guid>
      <description>[Menos mal que se me ha ocurrido buscar en mi propio blog sobre el asunto y descubrir —no lo recordaba— que ya había tratado el asunto previamente en entradas como esta, esta o esta.]
El problema de la propagación de errores lo cuentan muy bien Iñaki Úcar y sus coautores aquí. Por resumirlo: tienes una cantidad, $latex X$ conocida solo aproximadamente —en concreto, con cierto error— e interesa conocer y acotar el error de una expresión $latex f(X)$.</description>
    </item>
    
    <item>
      <title>PCA robusto</title>
      <link>/2021/06/01/pca-robusto/</link>
      <pubDate>Tue, 01 Jun 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/06/01/pca-robusto/</guid>
      <description>Esta semana he descubierto el PCA robusto. En la frase anterior he conjugado el verbo en cursiva porque lo he pretendido usar con un significado que matiza el habitual: no es que haya tropezado con él fortuitamente, sino que el PCA robusto forma parte de esa inmensa masa de conocimiento estadístico que ignoro pero que, llegado el caso, con un par de clicks, una lectura en diagonal y la descarga del software adecuado, puedo incorporarlo y usarlo a voluntad.</description>
    </item>
    
    <item>
      <title>Un viejo truco para que R vuele</title>
      <link>/2021/05/18/un-viejo-truco-para-que-r-vuele/</link>
      <pubDate>Tue, 18 May 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/05/18/un-viejo-truco-para-que-r-vuele/</guid>
      <description>Existe un viejo truco —mas no por ello conocido— para que R vuele. Lo aprendí en una conferencia de uno de los padres de R (aunque ya no recuerdo quién era) en la primera década del siglo. El problema que tenía entre manos era el de ajustar unos cuantos miles de regresiones logísticas. Además de hacer uso de los métodos de paralelización, aún muy rudimentarios en la época, uno de los trucos más efectivos que utilizaba era el de desnudar las funciones.</description>
    </item>
    
    <item>
      <title>Análisis de eventos recurrentes</title>
      <link>/2020/12/02/analisis-de-eventos-recurrentes/</link>
      <pubDate>Wed, 02 Dec 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/12/02/analisis-de-eventos-recurrentes/</guid>
      <description>He sido fan del análisis de los eventos recurrentes desde antes incluso de saber que existía tal cosa formalmente.
Es una extensión del análisis de la supervivencia donde resucitas y vuelves a morirte a lo Sísifo. Es decir, en el análisis de la supervivencia, te mueres y ya; por eso, si quieres extender el análisis de la supervivencia a asuntos tales como compras de clientes es necesario usar el calzador muy heterodoxamente.</description>
    </item>
    
    <item>
      <title>Una herramienta para el análisis no paramétrico de series temporales</title>
      <link>/2020/09/17/una-herramienta-para-el-analisis-no-parametrico-de-series-temporales/</link>
      <pubDate>Thu, 17 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/17/una-herramienta-para-el-analisis-no-parametrico-de-series-temporales/</guid>
      <description>Sí, es un ejemplar de mi colección de rarezas estadísticas, técnicas que no entran dentro del currículo estándar pero que pudieran resultar útiles en algún momento, para algún caso particular.
Hoy, perfiles matriciales para series temporales, una técnica que sirve esencialmente, para identificar formas que se repiten en series temporales, como
Entiendo además que, como consecuencia, también para señalar aquellos ciclos en que se produzcan perfiles anómalos, para su evaluación. Pero dejo que consultéis la información en, por ejemplo, aquí y aquí.</description>
    </item>
    
    <item>
      <title>Contrariamente a lo que creía recordar, &#34;Hot deck&#34; != LOCF</title>
      <link>/2020/09/03/contrariamente-a-lo-que-creia-recordar-hot-deck-locf/</link>
      <pubDate>Thu, 03 Sep 2020 08:13:00 +0000</pubDate>
      
      <guid>/2020/09/03/contrariamente-a-lo-que-creia-recordar-hot-deck-locf/</guid>
      <description>Imputación (que es algo en lo que muy a regañadientes estoy trabajando estos días).
Si de verdad tienes que imputar datos en una tabla (y solo en ese caso), solo hay un criterio: construye un modelo para predecir los valores faltantes en función del resto y reemplaza el NA por la su predicción.
El modelo puede ser tan tonto como
lm(my_col ~ 1, na.rm = T)
que resulta en la popular estrategia de reemplazar los NAs por la media del resto de las observaciones.</description>
    </item>
    
    <item>
      <title>Por supuesto que tengo más variables que observaciones... ¿y?</title>
      <link>/2020/07/23/por-supuesto-que-tengo-mas-variables-que-observaciones-y/</link>
      <pubDate>Thu, 23 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/23/por-supuesto-que-tengo-mas-variables-que-observaciones-y/</guid>
      <description>He intentado replicar los resultados de la entrada de ayer con GAM (vía [mgcv](https://CRAN.R-project.org/package=mgcv)) así (véase el enlace anterior para la definición de los datos):
library(mgcv) modelo_gam &amp;lt;- gam( y ~ x + s(id, bs = &amp;quot;re&amp;quot;), data = datos, method = &amp;quot;REML&amp;quot;, family = &amp;quot;poisson&amp;quot;)  Y nada:
Error in gam(y ~ x + s(id, bs = &amp;quot;re&amp;quot;), data = datos, method = &amp;quot;REML&amp;quot;, : Model has more coefficients than data  Sí, ya sé que tengo más variables que observaciones.</description>
    </item>
    
    <item>
      <title>Cuidado con la aleatoriedad &#34;pochola&#34;</title>
      <link>/2020/06/15/cuidado-con-la-aleatoriedad-pochola/</link>
      <pubDate>Mon, 15 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/15/cuidado-con-la-aleatoriedad-pochola/</guid>
      <description>Abundo sobre mi entrada del otro día. Usando números aleatorios hirsutos,
n &amp;lt;- 200 x &amp;lt;- runif(n) plot(cumsum(x - .5), type = &amp;quot;l&amp;quot;)  produce
mientras que
library(randtoolbox) s &amp;lt;- sobol(n, 1, scrambling = 3) plot(cumsum(s - .5), type = &amp;quot;l&amp;quot;)  genera
que tiene un cariz totalmente distinto.</description>
    </item>
    
    <item>
      <title>Aleatoriedad hirsuta, aleatoriedad pochola</title>
      <link>/2020/06/08/aleatoriedad-hirsuta-aleatoriedad-pochola/</link>
      <pubDate>Mon, 08 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/08/aleatoriedad-hirsuta-aleatoriedad-pochola/</guid>
      <description>Contemplando y comparando
y
se me han venido a la mente los adjetivos hirsuto y pocholo para calificar las respectivas formas de aleatoriedad que representan. La primera es el resultado del habitual
n &amp;lt;- 200 x &amp;lt;- runif(n) y &amp;lt;- runif(n) plot(x, y, pch = 16)  mientras que la segunda exige el más sofisticado
library(randtoolbox) s &amp;lt;- sobol(n, 2, scrambling = 3) x &amp;lt;- s[,1] y &amp;lt;- s[,2] plot(x, y, pch = 16)  Se ve que Sobol quería rellenar más armoniosamente el espacio.</description>
    </item>
    
    <item>
      <title>Optimización estocástica</title>
      <link>/2020/05/22/optimizacion-estocastica/</link>
      <pubDate>Fri, 22 May 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/05/22/optimizacion-estocastica/</guid>
      <description>Una de los proyectos en los que estoy trabajando últimamente está relacionado con un problema de optimización no lineal: tengo un modelo (o una familia de modelos) no lineales con una serie de parámetros, unos datos y se trata de lo que no mercería más explicación: encontrar los que minimizan cierta función de error.
Tengo implementadas dos vías:
 La nls, que usa un optimizador numérico genérico para encontrar esos mínimos.</description>
    </item>
    
    <item>
      <title>CausalImpact me ha complacido mucho</title>
      <link>/2020/03/27/causalimpact-me-ha-complacido-mucho/</link>
      <pubDate>Fri, 27 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/27/causalimpact-me-ha-complacido-mucho/</guid>
      <description>Estoy aquí analizando datos para un cliente interesado en estudiar si como consecuencia de uno de esos impuestos modennos con los que las administraciones nos quieren hacer más sanos y robustos. En concreto, le he echado un vistazo a si el impuesto ha encarecido el precio de los productos gravados (sí) y si ha disminuido su demanda (no) usando [CausalImpact](https://CRAN.R-project.org/package=CausalImpact) y me ha complacido mucho que la salida de summary(model, &amp;quot;report&amp;quot;) sea:</description>
    </item>
    
    <item>
      <title>Densidades unidimensionales en R</title>
      <link>/2020/03/26/densidades-unidimensionales-en-r/</link>
      <pubDate>Thu, 26 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/26/densidades-unidimensionales-en-r/</guid>
      <description>Es un asunto tangencial que, además, se soluciona las más de las veces con density. Pero parece que tiene mucha más ciencia detrás.
Por algún motivo, acabé un día en la página del paquete [logspline](https://CRAN.R-project.org/package=logspline), que ajusta densidades usando splines. Su promesa es que puede realizar ajustes de densidades tan finos como
que está extraído de Polynomial Splines and their Tensor Products in Extended Linear Modeling, el artículo que le sirve de base teórica.</description>
    </item>
    
    <item>
      <title>Más sobre el &#34;método delta&#34;: propagate</title>
      <link>/2020/03/10/mas-sobre-el-metodo-delta-propagate/</link>
      <pubDate>Tue, 10 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/10/mas-sobre-el-metodo-delta-propagate/</guid>
      <description>Por referencia y afán de completar dos entradas que hice hace un tiempo sobre el método delta, esta y esta, dejo constar mención al paquete [propagate](https://CRAN.R-project.org/package=propagate), que contiene métodos para la propagación de la incertidumbre.
Para desavisados: si $latex x \sim N(5,1)$ e $latex y \sim N(10,1)$, ¿cómo sería la distribución de $latex x/y$? Etc.</description>
    </item>
    
    <item>
      <title>Una R-referencia con referencias para epidemiólogos circunstanciales</title>
      <link>/2020/03/09/una-r-referencia-con-referencias-para-epidemiologos-circunstanciales/</link>
      <pubDate>Mon, 09 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/09/una-r-referencia-con-referencias-para-epidemiologos-circunstanciales/</guid>
      <description>Lo del coronavirus nos ha convertido a todos en epidemiólogos circunstanciales. Casi ninguno de vosotros tenéis acceso a los datos necesarios para hacer cosas por vuestra cuenta, pero sí, tal vez gracias a esta entrada, las herramientas necesarias para ello.
Podéis empezar por el paquete [survellance](https://CRAN.R-project.org/package=surveillance) de R, que implementa muchos de los métodos más modernos para la monitorización de brotes epidémicos.
En particular, puede que os interese la función bodaDelay, intitulada Bayesian Outbreak Detection in the Presence of Reporting Delays, y que implementa una serie de métodos para estimar el número real de casos cuando las notificaciones de los positivos llegan tarde.</description>
    </item>
    
    <item>
      <title>To IRLS or not to IRLS</title>
      <link>/2020/02/24/to-irls-or-not-to-irls/</link>
      <pubDate>Mon, 24 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/24/to-irls-or-not-to-irls/</guid>
      <description>A veces tomas un artículo de vaya uno a saber qué disciplina, sismología, p.e., y no dejas de pensar: los métodos estadísticos que usa esta gente son de hace 50 años. Luego cabe preguntarse: ¿pasará lo mismo en estadística con respecto a otras disciplinas?
Por razones que no vienen al caso, me he visto en la tesitura de tener que encontrar mínimos de funciones que podrían cuasicatalogarse como de mínimos cuadrados no lineales.</description>
    </item>
    
    <item>
      <title>Análisis estadístico de mezclas</title>
      <link>/2020/02/19/analisis-estadistico-de-mezclas/</link>
      <pubDate>Wed, 19 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/19/analisis-estadistico-de-mezclas/</guid>
      <description>No es algo que ocurra habitualmente. Creo que conozco a alguien que me dijo que lo tuvo que hacer una vez. Pero podría ocurrir en algún momento que tuvieses que analizar mezclas, es decir, situaciones experimentales en las que lo importante es la proporción de ciertos ingredientes (con la restricción obvia de que dichas proporciones suman la unidad).
Para más datos, Mixture Experiments in R Using mixexp, que describe el paquete de R [mixexp](https://CRAN.</description>
    </item>
    
    <item>
      <title>No sé cómo traducir &#34;Partially additive (generalized) linear model trees&#34;</title>
      <link>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</link>
      <pubDate>Wed, 12 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</guid>
      <description>Sin embargo, basta con mirar la foto
leer la entrada de hace unos días, que se refiere a algo muy parecido (y que, en particular, describe los datos usados en el modelo que representa) y, en el peor de los casos, esto, para hacerse idea de su utilidad y relevancia.</description>
    </item>
    
    <item>
      <title>model4you</title>
      <link>/2020/02/06/model4you/</link>
      <pubDate>Thu, 06 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/06/model4you/</guid>
      <description>Un grupo de estudiantes se examina en horas distintas con exámenes parecidos pero no iguales. Se pretende estudiar si el examen tiene algún efecto sobre la nota final y para eso se hace algo así como
bmod_math &amp;lt;- lm(pcorrect ~ group, data = MathExam)  para obtener una distribución de la nota media por grupo descrita bien
cbind(estimate = coef(bmod_math), confint(bmod_math)) ## estimate 2.5% 97.5% ## (Intercept) 57.600184 55.122708 60.07766 ## group2 -2.</description>
    </item>
    
    <item>
      <title>El &#34;método delta&#34;, ahora con NIMBLE</title>
      <link>/2020/02/03/el-metodo-delta-ahora-con-nimble/</link>
      <pubDate>Mon, 03 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/03/el-metodo-delta-ahora-con-nimble/</guid>
      <description>NIMBLE ha sido uno de mis más recientes y provechosos descubrimientos. Mejor que hablar de él, que otros lo harán mejor y con más criterio que yo, lo usaré para replantear el problema asociado el método delta que me ocupó el otro día.
Casi autoexplicativo:
library(nimble) src &amp;lt;- nimbleCode({ T_half &amp;lt;- log(.5) / k k ~ dnorm(-0.035, sd = 0.00195) }) mcmc.out &amp;lt;- nimbleMCMC(code = src, constants = list(), data = list(), inits = list(k = -0.</description>
    </item>
    
    <item>
      <title>bamlss promete regresión bayesiana flexible</title>
      <link>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</link>
      <pubDate>Tue, 19 Nov 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</guid>
      <description>Un paquete relativamente nuevo de R (las primeras versiones son de 2017) que llevo un tiempo siguiendo de reojo es [bamlss](https://CRAN.R-project.org/package=bamlss).
bamlss es un paquete que permite especificar y ajustar varios tipos de modelos usando en principio métodos bayesianos, aunque tampoco necesariamente.
No puedo decir mucho más de él de momento. Habrá que ver cómo se comporta más allá de los ejemplos discutidos en la documentación. Muchos paquetes tienden a hacer trivial lo que antes era sencillo e imposible lo que antes difícil.</description>
    </item>
    
    <item>
      <title>tfprobability debería llamarse tfeoprobability</title>
      <link>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</link>
      <pubDate>Tue, 12 Nov 2019 09:13:04 +0000</pubDate>
      
      <guid>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</guid>
      <description>Porque, aunque la intención sea buena, el DSL (que ni siquiera llega a serlo) es muy, muy feo. Que en este contexto, además, quiere decir antinatural.
La demostración, aquí, aquí o aquí.</description>
    </item>
    
    <item>
      <title>Análisis y predicción de series temporales intermitentes</title>
      <link>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</link>
      <pubDate>Mon, 04 Nov 2019 09:13:16 +0000</pubDate>
      
      <guid>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</guid>
      <description>Hace tiempo me tocó analizar unas series temporales bastante particulares. Representaban la demanda diaria de determinados productos y cada día esta podía ser de un determinado número de kilos. Pero muchas de las series eran esporádicas: la mayoría de los días la demanda era cero.
Eran casos de las llamadas series temporales intermitentes.
Supongo que hay muchas maneras de modelizarlas y, así, al vuelo, se me ocurre pensar en algo similar a los modelos con inflación de ceros.</description>
    </item>
    
    <item>
      <title>DLMs</title>
      <link>/2019/10/31/dlms/</link>
      <pubDate>Thu, 31 Oct 2019 09:13:08 +0000</pubDate>
      
      <guid>/2019/10/31/dlms/</guid>
      <description>O Distributed Lag Models (véase, por ejemplo, [dLagM](https://cran.r-project.org/web/packages/dLagM/index.html)).
Son modelos para estimar el impacto de una serie temporal sobre otra en situaciones como la siguientes:
 Una serie mide excesos de temperaturas (en verano). * La otra, defunciones.  Existe un efecto causal (débil, pero medible) de la primera sobre la segunda. Pero las defunciones no ocurren el día mismo en que ocurren los excesos de temperaturas, sino que suelen demorarse unos cuantos días.</description>
    </item>
    
    <item>
      <title>ranger (o cómo el truco para hacerlo rápido es hacerlo, subrepticiamente, mal)</title>
      <link>/2019/09/26/ranger-o-como-el-truco-para-hacerlo-rapido-es-hacerlo-subrepticiamente-mal/</link>
      <pubDate>Thu, 26 Sep 2019 09:13:14 +0000</pubDate>
      
      <guid>/2019/09/26/ranger-o-como-el-truco-para-hacerlo-rapido-es-hacerlo-subrepticiamente-mal/</guid>
      <description>[ranger](https://cran.r-project.org/package=ranger) llegó para hacerlo mismo que [randomForest](https://cran.r-project.org/package=randomForest), solo que más deprisa y usando menos memoria.
Lo que no nos contaron es que lo consiguió haciendo trampas. En particular, en el tratamiento de las variables categóricas. Si no andas con cuidado, las considera ordenadas (y ordenadas alfabéticamente).
[Si te da igual ocho que ochenta, no te preocupará el asunto. Tranquilo: hay muchos como tú.]
El diagnóstico dado (por eso lo omito) está contado aquí.</description>
    </item>
    
    <item>
      <title>¿Qué más puede colgar de un árbol?</title>
      <link>/2019/09/12/que-mas-puede-colgar-de-un-arbol/</link>
      <pubDate>Thu, 12 Sep 2019 09:13:43 +0000</pubDate>
      
      <guid>/2019/09/12/que-mas-puede-colgar-de-un-arbol/</guid>
      <description>[Abundando en ¿Qué puede colgar de un árbol?]
¡Grafos!</description>
    </item>
    
    <item>
      <title>Cartogramas con recmap</title>
      <link>/2019/07/15/cartogramas-con-recmap/</link>
      <pubDate>Mon, 15 Jul 2019 09:13:02 +0000</pubDate>
      
      <guid>/2019/07/15/cartogramas-con-recmap/</guid>
      <description>He construido
que, obviamente no es la gran maravilla, basándome en Rectangular Statistical Cartograms in R: The recmap Package y usando
library(rgdal) library(pxR) library(recmap) provs &amp;lt;- readOGR(dsn = &amp;quot;provincias/&amp;quot;, layer = &amp;quot;Provincias&amp;quot;) pobl &amp;lt;- as.data.frame(read.px(&amp;quot;2852.px&amp;quot;, encoding = &amp;quot;latin1&amp;quot;), use.codes = T) pobl2 &amp;lt;- as.data.frame(read.px(&amp;quot;2852.px&amp;quot;, encoding = &amp;quot;latin1&amp;quot;)) pobl$nombre &amp;lt;- pobl2$Provincias pobl &amp;lt;- pobl[, c(&amp;quot;Provincias&amp;quot;, &amp;quot;nombre&amp;quot;, &amp;quot;value&amp;quot;)] colnames(pobl) &amp;lt;- c(&amp;quot;COD_PROV&amp;quot;, &amp;quot;nombre&amp;quot;, &amp;quot;poblacion&amp;quot;) pobl &amp;lt;- pobl[pobl$COD_PROV != &amp;quot;null&amp;quot;,] pobl &amp;lt;- pobl[!pobl$COD_PROV %in% c(&amp;quot;51&amp;quot;, &amp;quot;52&amp;quot;, &amp;quot;38&amp;quot;, &amp;quot;07&amp;quot;, &amp;quot;35&amp;quot;),] dat &amp;lt;- merge(provs, pobl, by = &amp;quot;COD_PROV&amp;quot;, all.</description>
    </item>
    
    <item>
      <title>1  3  6 19 30 34  2  7 18 31 33 16  9 27 22 14 11 25 24 12 13 23 26 10 15 21 28  8 17 32  4  5 20 29 35</title>
      <link>/2019/05/27/1-3-6-19-30-34-2-7-18-31-33-16-9-27-22-14-11-25-24-12-13-23-26-10-15-21-28-8-17-32-4-5-20-29-35/</link>
      <pubDate>Mon, 27 May 2019 09:13:33 +0000</pubDate>
      
      <guid>/2019/05/27/1-3-6-19-30-34-2-7-18-31-33-16-9-27-22-14-11-25-24-12-13-23-26-10-15-21-28-8-17-32-4-5-20-29-35/</guid>
      <description>Son los enteros del 1 al 35 ordenados de forma que dos consecutivos en la serie suman un cuadrado perfecto. Los he obtenido así:
library(adagio) foo &amp;lt;- function(n){ desde &amp;lt;- 1:n hasta &amp;lt;- 1:n todos &amp;lt;- expand.grid(desde, hasta) todos &amp;lt;- todos[todos$Var1 &amp;lt; todos$Var2,] todos$sqrt &amp;lt;- sqrt(todos$Var1 + todos$Var2) todos &amp;lt;- todos[todos$sqrt == round(todos$sqrt),] todos$sqrt &amp;lt;- NULL vertices &amp;lt;- as.vector(t(todos)) hamiltonian(vertices) } foo(35)  Notas:
 Esta entrada está inspirada en algo que he visto en Twitter (pero cuya referencia he olvidado guardar).</description>
    </item>
    
    <item>
      <title>¿Qué puede colgar de un árbol?</title>
      <link>/2019/05/21/que-puede-colgar-de-un-arbol/</link>
      <pubDate>Tue, 21 May 2019 09:13:54 +0000</pubDate>
      
      <guid>/2019/05/21/que-puede-colgar-de-un-arbol/</guid>
      <description>Predicciones puntuales:
O (sub)modelos:
Y parece que ahora también distribuciones:
Notas:
 Obviamente, la clasificación anterior no es mutuamente excluyente. * La tercera gráfica está extraída de Transformation Forests, un artículo donde se describe el paquete trtf de R. * Los autores dicen que [r]egression models for supervised learning problems with a continuous target are commonly understood as models for the conditional mean of the target given predictors. ¿Vosotros lo hacéis así?</description>
    </item>
    
    <item>
      <title>Elecciones e índice (supernaíf) de Shapley</title>
      <link>/2019/05/07/elecciones-e-indice-supernaif-de-shapley/</link>
      <pubDate>Tue, 07 May 2019 09:13:34 +0000</pubDate>
      
      <guid>/2019/05/07/elecciones-e-indice-supernaif-de-shapley/</guid>
      <description>Aprovechando que el paquete [GameTheoryAllocation](https://cran.r-project.org/package=GameTheoryAllocation) ha emergido de mi FIFO de pendientes a los pocos días de conocerse los resultados de las [adjetivo superlativizado omitidísimo] elecciones generales, voy a calcular de la manera más naíf que se me ocurre el índice de Shapley de los distintos partidos. Que es:
Al menos, de acuerdo con el siguiente código:
&amp;lt;code&amp;gt;library(GameTheoryAllocation) partidos &amp;lt;- c(123, 66, 57, 35, 24, 15, 7, 7, 6, 4, 2, 2, 1, 1) names(partidos) &amp;lt;- c(&amp;quot;psoe&amp;quot;, &amp;quot;pp&amp;quot;, &amp;quot;cs&amp;quot;, &amp;quot;iu&amp;quot;, &amp;quot;vox&amp;quot;, &amp;quot;erc&amp;quot;, &amp;quot;epc&amp;quot;, &amp;quot;ciu&amp;quot;, &amp;quot;pnv&amp;quot;, &amp;quot;hb&amp;quot;, &amp;quot;cc&amp;quot;, &amp;quot;na&amp;quot;, &amp;quot;compr&amp;quot;, &amp;quot;prc&amp;quot;) coaliciones &amp;lt;- coalitions(length(partidos)) tmp &amp;lt;- coaliciones$Binary profit &amp;lt;- tmp %*% partidos profit &amp;lt;- 1 * (profit &amp;gt; 175) res &amp;lt;- Shapley_value(profit, game = &amp;quot;profit&amp;quot;) res &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Simulación de procesos de Poisson no homogéneos y autoexcitados</title>
      <link>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</link>
      <pubDate>Fri, 05 Apr 2019 09:13:37 +0000</pubDate>
      
      <guid>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</guid>
      <description>Fueron mis modelos favoritos un tiempo, cuando modelaba visitas y revisitas de usuarios a cierto malhadado portal.
Si las visitas fuesen aleatorias (en cierto sentido), tendrían un aspecto no muy distinto del que se obtiene haciendo
library(IHSEP) suppressWarnings(set.seed(exp(pi * complex(imaginary = 1)))) tms &amp;lt;- simPois(int = function(x) .1, cens = 1000) hist(tms, breaks = 100, main = &amp;quot;Proceso homogéneo de Poisson&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;frecuencia&amp;quot;)  Es decir,</description>
    </item>
    
    <item>
      <title>Análisis (clasificación, etc.) de textos muy cortos</title>
      <link>/2019/03/22/analisis-clasificacion-etc-de-textos-muy-cortos/</link>
      <pubDate>Fri, 22 Mar 2019 08:13:37 +0000</pubDate>
      
      <guid>/2019/03/22/analisis-clasificacion-etc-de-textos-muy-cortos/</guid>
      <description>Uno de mis proyectos permanentemente pospuestos es el del análisis de textos muy cortos. Se citarán Twitter y similares, aunque el € está en otros sitios, como los mensajes asociados a transferencias bancarias, reseñas o keywords.
Pero parece que no soy el único interesado en el tema. Otros con más tiempo y talento han desarrollado [BTM](https://cran.r-project.org/web/packages/BTM/index.html), que parece ser una versión modificada de LDA para el análisis de textos cortos.</description>
    </item>
    
    <item>
      <title>vecpart: modelización de moderadores con árboles</title>
      <link>/2019/02/18/9857/</link>
      <pubDate>Mon, 18 Feb 2019 08:13:43 +0000</pubDate>
      
      <guid>/2019/02/18/9857/</guid>
      <description>En un GLM (aún más generalizado que la G de las siglas) puede haber coeficientes moderados. Usando una terminología muy ad hoc, en el modelo pueden entrar predictores y moderadores. Lo cual quiere decir que la parte lineal puede ser de la forma
$latex \sum_i X_i \beta_i(Z_i),$
donde las $latex X_i$ son los predictores propiamente dichos y las variables $latex Z_i$ son moderadoras, es decir, que modifican el efecto de los predictores a través de una función arbitraria $latex \beta_i$.</description>
    </item>
    
    <item>
      <title>Una cosa buena, una cosa mala</title>
      <link>/2019/02/13/una-cosa-buena-una-cosa-mala/</link>
      <pubDate>Wed, 13 Feb 2019 08:13:09 +0000</pubDate>
      
      <guid>/2019/02/13/una-cosa-buena-una-cosa-mala/</guid>
      <description>Que son la misma: esta.
Comienzo por lo malo: ¿realmente necesitamos 17+1 INEs publicando la vistas de la misma información a través de 17+1 APIs, 17+1 paquetes de R y (17+1)*N mantenedores y desarrolladores?
Lo bueno: tiene buena pinta y es encomiable tanto el esfuerzo de los autores como su vocación de servicio público.
Nota: Espero que no enfaden demasiado el 50% de los juicios que he emitido a quien me ha enviado el enlace para su evaluación y posible difusión.</description>
    </item>
    
    <item>
      <title>Demasiados colores (para el hijo de un daltónico)</title>
      <link>/2019/02/01/demasiados-colores-para-el-hijo-de-un-daltonico/</link>
      <pubDate>Fri, 01 Feb 2019 08:13:47 +0000</pubDate>
      
      <guid>/2019/02/01/demasiados-colores-para-el-hijo-de-un-daltonico/</guid>
      <description>Mi padre me enseñó muchas cosas (leer, sumar, etc.). Pero mi infancia fue monocromática porque era daltónico. Siempre dibujé con lápiz (primero) y tinta (después). Las témperas y los rotuladores fueron mi tormento.
R tiene colores. Un montón. Y paletas de colores. Demasiadas. Una búsqueda entre los paquetes disponibles actualmente en CRAN de color proporciona 88 coincidencias, a las que deben sumarse las 35 adicionales de colour. Algunos de esos paquetes se refieren a asuntos tales como &amp;ldquo;Optimal Block Designs for Two-Colour cDNA Microarray Experiments&amp;rdquo;, pero los más ofrecen cosas tales como:</description>
    </item>
    
    <item>
      <title>¿Hay demasiados paquetes en R?</title>
      <link>/2019/01/31/hay-demasiados-paquetes-en-r/</link>
      <pubDate>Thu, 31 Jan 2019 08:13:31 +0000</pubDate>
      
      <guid>/2019/01/31/hay-demasiados-paquetes-en-r/</guid>
      <description>Por su importancia, traigo aquí y resumo una serie de argumentos que he encontrado en otra parte acerca del ecosistema de paquetes en R. Que son:
 Muchos paquetes no tienen el soporte adecuado a medio plazo. * Además, hay demasiados. * Pero su calidad es desigual. * Y muchos reinventan la rueda (lo manifiesta la escasa interdependencia entre los paquetes). * Finalmente, no es para nada sencillo identificar el paquete que puede ser útil para un fin determinado.</description>
    </item>
    
    <item>
      <title>data.tree: porque no todos los datos son tabulares</title>
      <link>/2018/12/18/data-tree-porque-no-todos-los-datos-son-tabulares/</link>
      <pubDate>Tue, 18 Dec 2018 08:13:45 +0000</pubDate>
      
      <guid>/2018/12/18/data-tree-porque-no-todos-los-datos-son-tabulares/</guid>
      <description>De acuerdo, casi todos los datos son tabulares. Digamos que el 90% de ellos. Pero muchos de ellos, no. Y data.tree es un paquete con muy buena pinta para manejar estructuras arborescentes de datos: véanse esta y esta viñeta.
Como no podía ser de otra manera, tiene funciones para recorrer, filtrar y podar los árboles de datos.
La aplicación gracias a la cual di con él es el paquete [prof.tree](http://ipub.com/r-profiling/), que es lo mismo que el Rprof de toda la vida&amp;hellip; solo que mola más:</description>
    </item>
    
    <item>
      <title>Cuatro paquetes interesantes de R</title>
      <link>/2018/11/05/cuatro-paquetes-interesantes-de-r/</link>
      <pubDate>Mon, 05 Nov 2018 08:13:50 +0000</pubDate>
      
      <guid>/2018/11/05/cuatro-paquetes-interesantes-de-r/</guid>
      <description>Son paquetes que marcado como potencialmente relevantes pero que aún no he revisado como debiera. Tal vez alguien tenga algo más que decir sobre ellos. Tiene los comentarios, por supuesto, abiertos.
longRPart2: Particionamiento recursivo para modelos longitudinales. Extiende ctree y, por supuesto, mob del paquete party a datos de tipo longitudinal.
radiant: Más que un paquete, es un conjunto de paquetes para business analytics usando R y Shiny. Ni idea de para qué parte de ese amplio campo del business analytics puede resultar útil, pero si resulta que es precisamente el tuyo, ¡enhorabuena!</description>
    </item>
    
    <item>
      <title>&#34;Embeddings&#34; y análisis del carrito de la compra</title>
      <link>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</link>
      <pubDate>Thu, 04 Oct 2018 08:13:34 +0000</pubDate>
      
      <guid>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</guid>
      <description>Escribiendo la entrada del otro día sobre embeddings, no se me pasó por alto que la fórmula
$latex \frac{P(W_i,C_i)}{P(W_i)P(C_i)}$
que escribí en ella es análoga al llamado lift (¿es el lift?) del llamado análisis del carrito de la compra, i.e., el estudio de productos que tienden a comprarse juntos (véase, por ejemplo, esto).
Lo cual me lleva a sugerir mas no escribir una entrada en la que se rehagan este tipo de análisis usando embeddings: los ítems como palabras, los carritos como textos, etc.</description>
    </item>
    
    <item>
      <title>Planes de búsqueda y rescate con R</title>
      <link>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</link>
      <pubDate>Tue, 02 Oct 2018 13:09:10 +0000</pubDate>
      
      <guid>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</guid>
      <description>Existe un paquete muy curioso en CRAN, [rSARP](https://cran.r-project.org/package=rSARP) para diseñar, optimizar y comunicar la evolución de planes de búsqueda y/o rescate (p.e., de un niño desaparecido en un monte).
Es particularmente interesante porque este tipo de problemas lo tienen todo: desde distribuciones a priori (sobre dónde es más probable encontrar lo que se busca) hasta la decisión final (explórese tanto aquí y tanto allá) teniendo en cuenta restricciones de tiempo y recursos.</description>
    </item>
    
    <item>
      <title>Los datos están histogramizados... ¿quién los deshisotogramizará?</title>
      <link>/2018/09/18/los-datos-estan-histogramizados-quien-los-deshisotogramizara/</link>
      <pubDate>Tue, 18 Sep 2018 08:13:51 +0000</pubDate>
      
      <guid>/2018/09/18/los-datos-estan-histogramizados-quien-los-deshisotogramizara/</guid>
      <description>Hace un tiempo quise hacer cosas malísimas con datos fiscales de España y Dinamarca. Pero los datos estaban histogramizados:
Gracias a Freakonometrics di con binequality. Adaptando su código, escribo
library(rvest) library(plyr) dk &amp;lt;- read_html(&amp;quot;http://www.skm.dk/english/facts-and-figures/progression-in-the-income-tax-system&amp;quot;) tmp &amp;lt;- html_nodes(dk, &amp;quot;table&amp;quot;) tmp &amp;lt;- html_table(tmp[[2]]) header &amp;lt;- tmp[1,] tmp &amp;lt;- tmp[-c(1, 2),] colnames(tmp) &amp;lt;- header # elimino declaraciones negativas tmp &amp;lt;- tmp[-1,] # elimino el total tmp &amp;lt;- tmp[-(nrow(tmp)),] colnames(tmp) &amp;lt;- c(&amp;quot;rango&amp;quot;, &amp;quot;contribuyentes&amp;quot;, &amp;quot;X1&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;tax1&amp;quot;, &amp;quot;tax2&amp;quot;, &amp;quot;pct&amp;quot;) irpf_dk &amp;lt;- tmp[, c(&amp;quot;rango&amp;quot;, &amp;quot;contribuyentes&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;tax1&amp;quot;, &amp;quot;tax2&amp;quot;)] irpf_dk$contribuyentes &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Contraargumentando (materialmente) sobre la falacia del fiscal</title>
      <link>/2018/09/13/contraargumentando-materialmente-sobre-la-falacia-del-fiscal/</link>
      <pubDate>Thu, 13 Sep 2018 08:13:23 +0000</pubDate>
      
      <guid>/2018/09/13/contraargumentando-materialmente-sobre-la-falacia-del-fiscal/</guid>
      <description>Hace un par de días hablé de la falacia del fiscal y granos de arroz. La entrada iba acompañada de
y la lección era: es raro no encontrar ningún clúster cuando se tiran al azar granos de arroz sobre una superficie. De lo que se derivaban más cosas que es ocioso repetir aquí.
Pero el gráfico no es desconocido para los viejos del lugar: se parece mucho al de la página 319 de ESL.</description>
    </item>
    
    <item>
      <title>Series temporales y &#34;motifs&#34;</title>
      <link>/2018/09/10/series-temporales-y-motifs/</link>
      <pubDate>Mon, 10 Sep 2018 08:13:53 +0000</pubDate>
      
      <guid>/2018/09/10/series-temporales-y-motifs/</guid>
      <description>Un motif es un patrón que se repite en una serie temporal:
Para saber más sobre ellos, p.e., Finding Motif Sets in Time Series. Y para identificarlos con R, STMotif.</description>
    </item>
    
    <item>
      <title>¿Por que slt-ear si puedes stR-ear?</title>
      <link>/2018/07/25/por-que-slt-ear-si-puedes-str-ear/</link>
      <pubDate>Wed, 25 Jul 2018 08:13:42 +0000</pubDate>
      
      <guid>/2018/07/25/por-que-slt-ear-si-puedes-str-ear/</guid>
      <description>La función stl (véase aquí un ejemplo de uso). Pero tiene sus limitaciones.
El paquete stR la extiende y permite, entre otras cosas, introducir distintos tipos de estacionalidades (p.e., anuales y semanales).</description>
    </item>
    
    <item>
      <title>kamila: Clústering con variables categóricas</title>
      <link>/2018/07/20/kamila-clustering-con-variables-categoricas/</link>
      <pubDate>Fri, 20 Jul 2018 08:13:58 +0000</pubDate>
      
      <guid>/2018/07/20/kamila-clustering-con-variables-categoricas/</guid>
      <description>La codificación de las variables categóricas en problemas de clústering es la fuente de la mayor parte de los problemas con que se encuentran los desdichados que se ven forzados a aplicar este tipo de técnicas.
Existen algoritmos que tratan de resolver el problema sin necesidad de realizar codificaciones numéricas. kamila es un paquete de R que implementa uno de ellos. El artículo que lo acompaña, A semiparametric method for clustering mixed data aporta los detalles, que en resumen son:</description>
    </item>
    
    <item>
      <title>¿Un voluntario para aggiornar MicroDatosEs?</title>
      <link>/2018/03/26/un-voluntario-para-aggiornar-microdatoses/</link>
      <pubDate>Mon, 26 Mar 2018 08:13:29 +0000</pubDate>
      
      <guid>/2018/03/26/un-voluntario-para-aggiornar-microdatoses/</guid>
      <description>Mi paquete MicroDatosEs ya forma parte de rOpenSpain. Sin embargo, está falto de ciertas mejoras a las que aspiran los paquetes que forman parte de dicho repositorio.
Una de ellas es la de migrar la documentación del paquete a roxigen2. Lo podría hacer yo, pero es muy aburrido. Sin embargo, entiendo que puede ser entretenido (además de sencillo) para alguien que:
 * No sepa de qué va eso de `roxigen2` pero me tome la palabra en eso de que es importante.</description>
    </item>
    
    <item>
      <title>¿Podría ser la solución que almas caritativas creasen viñetas espontáneamente?</title>
      <link>/2018/03/08/podria-ser-la-solucion-que-almas-caritativas-creasen-vinetas-espontaneamente/</link>
      <pubDate>Thu, 08 Mar 2018 08:13:23 +0000</pubDate>
      
      <guid>/2018/03/08/podria-ser-la-solucion-que-almas-caritativas-creasen-vinetas-espontaneamente/</guid>
      <description>Uno de los modelos más útiles potencialmente y que menos atención recibe es el de los modelos de conteos autoexcitados. Es decir, aquellos en los que un evento incrementa durante cierto tiempo la probabilidad de que ocurra otro. Creedme, ocurre así muy a menudo en muchas aplicaciones.
Por eso se pone uno muy contento cuando descubre paquetes de R como este.
Pero el hecho de que unos académicos lo hayan creado y puesto ahí por mor de las neonormas (administrativas, morales o de señalamiento) de reproducibilidad, no significa que lo hayan desarrollado para los usuarios finales.</description>
    </item>
    
    <item>
      <title>Documentar como el culo, no pensar en el usuario final, ser incapaz de ponerte en su situación, etc.</title>
      <link>/2018/02/28/documentar-como-el-culo-no-pensar-en-el-usuario-final-ser-incapaz-de-ponerte-en-su-situacion-etc/</link>
      <pubDate>Wed, 28 Feb 2018 08:13:54 +0000</pubDate>
      
      <guid>/2018/02/28/documentar-como-el-culo-no-pensar-en-el-usuario-final-ser-incapaz-de-ponerte-en-su-situacion-etc/</guid>
      <description>De vez en cuando pruebo paquetes promisorios. No es infrecuente que cosas que he intentado hace años, algún ejemplo más o menos sencillo que he publicado aquí, acabe convirtiéndose en la piedra angular de algo facturable. Incluso de algo facturable por mí.
geozoning podía haber sido uno de esos. La promesa del paquete es que puede ayudarte a segmentar regiones del espacio de acuerdo con alguna variable, una especie de clústering para información de tipo espacial.</description>
    </item>
    
    <item>
      <title>¿Podéis probarme/le CatastRo? Porfa...</title>
      <link>/2018/02/19/podeis-probarme-le-catastro-porfa/</link>
      <pubDate>Mon, 19 Feb 2018 08:13:59 +0000</pubDate>
      
      <guid>/2018/02/19/podeis-probarme-le-catastro-porfa/</guid>
      <description>CatastRo es un paquete de R para explotar la API del Catastro que fue realizado por un alumno mío de la UTAD, Ángel Delgado, como proyecto de fin de máster.
Ahora, una vez integrado en rOpenSpain, toca transformarlo de un proyecto académico en un paquete útil y práctico. Vamos, exponerlo al proceloso piélago del uso para que le crujan las costuras y ver cuáles son las mejoras más pertinentes.
Así que estáis todos invitados a probar el código, verificar que la documentación documenta, que los ejemplos ejemplifican, etc.</description>
    </item>
    
    <item>
      <title>mgm (no la de las pelis sino la de los modelos gráficos)</title>
      <link>/2018/01/25/mgm-no-la-de-las-pelis-sino-la-de-los-modelos-graficos/</link>
      <pubDate>Thu, 25 Jan 2018 08:13:12 +0000</pubDate>
      
      <guid>/2018/01/25/mgm-no-la-de-las-pelis-sino-la-de-los-modelos-graficos/</guid>
      <description>Cayeron en mis manos unos datos que no puedo publicar, pero me atreveré a presentar algunos resultados anonimizados. Se trata de una tabla de puntuaciones numéricas (18 en total, cada una en su columna) proporcionadas por unos cuantos centenares de sujetos (filas). Era de interés un estudio cualitativo de las posibles relaciones de dependencia entre las variables.
La manera más rápida de comenzar, un heatmap(cor(dat)), para obtener
Y luego PCA y todas esas cosas.</description>
    </item>
    
    <item>
      <title>dbf · xlsx · pdf</title>
      <link>/2017/11/24/dbf-xlsx-pdf/</link>
      <pubDate>Fri, 24 Nov 2017 08:13:55 +0000</pubDate>
      
      <guid>/2017/11/24/dbf-xlsx-pdf/</guid>
      <description>Me escriben pidiendo consejo sobre cómo leer datos contenidos en (una serie larga de) ficheros en formatos .dbf, .xlsx (con un formato extraño) y .pdf.
.dbf
No tengo ni curiosidad por averiguar de dónde proceden. Simplemente,
 library(foreign) res &amp;lt;-read.dbf(&amp;quot;R0010.DBF&amp;quot;)  funciona de maravilla.
.xlsx
Estos sí que sé de dónde vienen (y me guardo la opinión). El problema aquí no era leer directamente tablas contenidas en hojas sino ir extrayendo celdas y rangos de hojas.</description>
    </item>
    
    <item>
      <title>Arqueólogos bayesianos</title>
      <link>/2017/11/23/arqueologos-bayesianos/</link>
      <pubDate>Thu, 23 Nov 2017 08:13:26 +0000</pubDate>
      
      <guid>/2017/11/23/arqueologos-bayesianos/</guid>
      <description>Se ve que hay arqueólogos bayesianos. Un problema con el que se encuentran es que tropiezan con cacharros antiguos y quieren estimar su antigüedad.
Así que prueban distintos métodos (¿químicos?), cada uno de los cuales con su precisión, y acaban recopilando una serie de estimaciones y errores. Obviamente, tienen que combinarlas de alguna manera.
El modelo más simple es
$latex M_i \sim N(\mu, \sigma_i)$
donde $latex \mu$ es la antigüedad (desconocida) del artefacto y los $latex \sigma_i$ son las varianzas distintas de los distintos métodos de medida, que arrojan las estimaciones $latex M_i$.</description>
    </item>
    
    <item>
      <title>Modelos directos, inversos y en los que tanto da</title>
      <link>/2017/10/23/modelos-directos-inversos-y-en-los-que-tanto-da/</link>
      <pubDate>Mon, 23 Oct 2017 08:13:15 +0000</pubDate>
      
      <guid>/2017/10/23/modelos-directos-inversos-y-en-los-que-tanto-da/</guid>
      <description>Continúo con esto que concluí con una discusión que me negué a resolver sobre la geometría de los errores.
Que es la manera de entender que los problemas directos e inversos no son exactamente el mismo. Digamos que no es una medida invariante frente a reflexiones del plano (que es lo que hacemos realmente al considerar el modelo inverso).
¿Pero y si medimos la distancia (ortogonal) entre los puntos $latex (x,y)$ y la curva $latex y = f(x)$ (o, equivalentemente, $latex x = f^{-1}(x)$)?</description>
    </item>
    
    <item>
      <title>CatastRo, un paquete de R para consultar la API del Catastro</title>
      <link>/2017/10/02/catastro-un-paquete-de-r-para-consultar-la-api-del-catastro/</link>
      <pubDate>Mon, 02 Oct 2017 08:12:35 +0000</pubDate>
      
      <guid>/2017/10/02/catastro-un-paquete-de-r-para-consultar-la-api-del-catastro/</guid>
      <description>Informo de que está disponible en GitHub el paquete CatastRo para consultar la API pública del Catastro.
No es una API particularmente extensa, pero es de esperar que se amplíe el catálogo de servicios disponible cuando comencemos a machacarla (o no: a saber qué hay en la mente de esa gente).
El paquete es el trabajo de fin de máster de mi alumno Ángel Delgado Panadero en el máster de ciencia de datos de la UTAD.</description>
    </item>
    
    <item>
      <title>Creo que darán que hablar (los GRF)</title>
      <link>/2017/07/06/creo-que-daran-que-hablar-los-grf/</link>
      <pubDate>Thu, 06 Jul 2017 08:13:52 +0000</pubDate>
      
      <guid>/2017/07/06/creo-que-daran-que-hablar-los-grf/</guid>
      <description>El artículo, el código y el paquete.</description>
    </item>
    
    <item>
      <title>qgraph para representar grafos que son correlaciones que son vinos</title>
      <link>/2017/03/15/qgraph-para-representar-grafos-que-son-correlaciones-que-son-vinos/</link>
      <pubDate>Wed, 15 Mar 2017 08:13:37 +0000</pubDate>
      
      <guid>/2017/03/15/qgraph-para-representar-grafos-que-son-correlaciones-que-son-vinos/</guid>
      <description>Me vais a permitir que escriba una entrada sin mayores pretensiones, inspirada en y adaptada de aquí y que sirva solo de que para representar correlaciones entre variables podemos recurrir a los grafos como en
library(qgraph) wine.quality &amp;lt;- read.csv(&amp;quot;https://goo.gl/0Fz1S8&amp;quot;, sep = &amp;quot;;&amp;quot;) qgraph(cor(wine.quality), shape= &amp;quot;circle&amp;quot;, posCol = &amp;quot;darkgreen&amp;quot;, negCol= &amp;quot;darkred&amp;quot;, layout = &amp;quot;groups&amp;quot;, vsize=13)  que pinta
mostrando resumidamente cómo se relacionan entre sí determinadas características de los vinos y cómo en última instancia influyen en su calidad (qlt).</description>
    </item>
    
    <item>
      <title>Wikipedia &#43; prophet</title>
      <link>/2017/03/03/wikipedia-prophet/</link>
      <pubDate>Fri, 03 Mar 2017 08:13:17 +0000</pubDate>
      
      <guid>/2017/03/03/wikipedia-prophet/</guid>
      <description>El otro día escribí sobre visitas a la Wikipedia. El otro día (posiblemente otro) oí hablar de prophet.
Hoy con
library(wikipediatrend) library(prophet) library(ggplot2) visitas &amp;lt;- wp_trend(&amp;quot;R_(lenguaje_de_programaci%C3%B3n)&amp;quot;, from = &amp;quot;2010-01-01&amp;quot;, to = Sys.Date(), lang = &amp;quot;es&amp;quot;) mis.visitas &amp;lt;- visitas[, c(&amp;quot;date&amp;quot;, &amp;quot;count&amp;quot;)] colnames(mis.visitas) &amp;lt;- c(&amp;quot;ds&amp;quot;, &amp;quot;y&amp;quot;) pasado &amp;lt;- mis.visitas[1:1500,] m &amp;lt;- prophet(pasado) futuro &amp;lt;- make_future_dataframe(m, periods = nrow(mis.visitas) - 1500) prediccion &amp;lt;- predict(m, futuro) pred.plot &amp;lt;- plot(m, prediccion) pred.plot + geom_line(data = mis.</description>
    </item>
    
    <item>
      <title>Probando hunspell para el procesamiento de texto en español</title>
      <link>/2017/02/20/probando-hunspell-para-el-procesamiento-de-texto-en-espanol/</link>
      <pubDate>Mon, 20 Feb 2017 08:13:50 +0000</pubDate>
      
      <guid>/2017/02/20/probando-hunspell-para-el-procesamiento-de-texto-en-espanol/</guid>
      <description>El paquete hunspell de R permite procesar texto utilizando como soporte la infraestructura proporcionada por Hunspell, el corrector ortográfico que subyace a muchas aplicaciones en R.
Existe una viñeta que ilustra el uso del paquete pero, como siempre, en inglés. En español las cosas son parecidas pero, como siempre, nunca exactamente iguales. En esta entrada, por lo tanto, voy a repasar partes de la viñeta aplicándolas a nuestra tan frecuentemente maltratada mas por ello no menos querida por algunos como yo (pausa) lengua.</description>
    </item>
    
    <item>
      <title>Habiendo mónadas, ¿quién quiere callbacks?</title>
      <link>/2016/11/24/habiendo-monadas-quien-quiere-callbacks/</link>
      <pubDate>Thu, 24 Nov 2016 08:13:35 +0000</pubDate>
      
      <guid>/2016/11/24/habiendo-monadas-quien-quiere-callbacks/</guid>
      <description>Nunca me he visto en la tesitura de tener que usar callbacks porque no son mi guerra. Pero por lo que he oído de la gente que sabe mucho más que yo, son uno de esos infiernos de los que hay que huir con el mismo pavor que de los fors, los ifs, los elses (¡argggg! ¡he escrito else!) y los whiles.
Una pequeña maravilla teórica que me ha hecho replantearme la absoluta inutilidad de aquello que estudié en Álgebra III (funtores y demás) son las mónadas.</description>
    </item>
    
    <item>
      <title>Detrás de la detección de anomalías en series temporales</title>
      <link>/2016/11/16/detras-de-la-deteccion-de-anomalias-en-series-temporales/</link>
      <pubDate>Wed, 16 Nov 2016 08:13:02 +0000</pubDate>
      
      <guid>/2016/11/16/detras-de-la-deteccion-de-anomalias-en-series-temporales/</guid>
      <description>Por azares, me ha tocado lidiar con eso de la detección de anomalías. Que es un problema que tiene que ver con dónde colocar las marcas azules en
El anterior es el gráfico construido con los datos de ejemplo del paquete AnomalyDetection. De hecho, así:
library(AnomalyDetection) data(raw_data) res &amp;lt;- AnomalyDetectionTs(raw_data, max_anoms=0.02, direction=&#39;both&#39;, plot=TRUE) res$plot  Aparentemente, AnomalyDetectionTs hace lo que cabría sospechar. Primero, una descomposición de la serie temporal, tal como</description>
    </item>
    
    <item>
      <title>R en paralelo (pero ahora, con futuros)</title>
      <link>/2016/11/04/r-en-paralelo-pero-ahora-con-futuros/</link>
      <pubDate>Fri, 04 Nov 2016 08:13:59 +0000</pubDate>
      
      <guid>/2016/11/04/r-en-paralelo-pero-ahora-con-futuros/</guid>
      <description>Esta entrada extiende y mejora una homónima de 2014.
El problema de entonces consistía en calcular por separado y en paralelo objetos A, B y C para combinarlos después. Cuando, por supuesto, el cálculo de A, B y C es pesado.
El muy reciente paquete future incorpora a R un mecanismo disponible en otros lenguajes de programación: un cierto tipo de datos, los futuros, que contienen promesas de valores que se calculan fuera del hilo principal del programa.</description>
    </item>
    
    <item>
      <title>Selección de variables con bosques aleatorios</title>
      <link>/2016/09/06/seleccion-de-variables-con-bosques-aleatorios/</link>
      <pubDate>Tue, 06 Sep 2016 08:13:39 +0000</pubDate>
      
      <guid>/2016/09/06/seleccion-de-variables-con-bosques-aleatorios/</guid>
      <description>Desde el principio de mis tiempos he seleccionado variables relevantes como subproducto de los árboles primero y de los bosques aleatorios después. Cierto que he hecho casi inconfesables incursiones en los métodos stepwise, pero han sido marginales y anecdóticas.
La idea es casi siempre la misma, se haga a mano o con ayuda de paquetes ad hoc: las variables importantes tienden a aparecer en el modelo (o submodelos), las otras no.</description>
    </item>
    
    <item>
      <title>Tod[rep(&#39;a&#39;, 831)]s y tod[rep(&#39;o&#39;, 6450)]s los autores de paquetes de R</title>
      <link>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</link>
      <pubDate>Wed, 31 Aug 2016 08:13:15 +0000</pubDate>
      
      <guid>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</guid>
      <description>En los últimos tiempos se ha puesto de moda un subgénero periodístico que es una manera de generar artículos de acuerdo con el siguiente algoritmo:
 1. Se toma una lista de personas. 2. Se cuenta en ella el número de mujeres (a) y de hombres (b). 3. Si a &amp;gt;= b, GOTO 1; si no, se copipega y se mutatismutandea un manido argumento.  No sabiéndome sustraer al encanto del último grito, he escrito y corrido</description>
    </item>
    
    <item>
      <title>Dos nuevos tutoriales sobre data.table y dplyr</title>
      <link>/2016/07/12/dos-nuevos-tutoriales-sobre-data-table-y-dplyr/</link>
      <pubDate>Tue, 12 Jul 2016 08:13:34 +0000</pubDate>
      
      <guid>/2016/07/12/dos-nuevos-tutoriales-sobre-data-table-y-dplyr/</guid>
      <description>Los productos de Apple, aun admitiendo su calidad, resuelven problemas que yo hace años que no tenía. Tanto data.table como dplyr vinieron a resolver problemas a los que muchos nos enfrentábamos con sudor y lágrimas.
Ha aparecido recientemente una serie de tutoriales sobre ambos paquetes que recomiendo:
 * El de [`data.table`](https://rollingyours.wordpress.com/2016/06/14/fast-aggregation-of-large-data-with-the-data-table-package/) * El de `dplyr` ([parte I](https://rollingyours.wordpress.com/2016/06/29/express-intro-to-dplyr/), [parte II](https://rollingyours.wordpress.com/2016/07/07/express-dplyr-part-ii/))  Y mis comentarios:
 * Para el 99% de mis problemas de manipulación de datos, me sobra con, además de R base, `reshape2` y `plyr`.</description>
    </item>
    
    <item>
      <title>R I/O (o rio)</title>
      <link>/2016/07/07/r-io-o-rio/</link>
      <pubDate>Thu, 07 Jul 2016 08:13:53 +0000</pubDate>
      
      <guid>/2016/07/07/r-io-o-rio/</guid>
      <description>rio es otro de esos desasosegantes paquetes de R. rio contiene esencialmente tres funciones,
 * `import`, que lo lee _todo_ * `export`, que lo escribe _todo_ y * `convert`, que transforma un fichero de un formato a otro.  Según su documentación, uno puede hacer cosas como
export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.csv&amp;quot;) export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.rds&amp;quot;) export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.sav&amp;quot;)  para guardar mtcars en cualquiera de los formatos indicados por la extensión y luego</description>
    </item>
    
    <item>
      <title>Cartogramas rectangulares con R</title>
      <link>/2016/05/10/cartogramas-rectangulares-con-r/</link>
      <pubDate>Tue, 10 May 2016 08:13:22 +0000</pubDate>
      
      <guid>/2016/05/10/cartogramas-rectangulares-con-r/</guid>
      <description>* [Galería](http://cartodraw.science/recmap/gallery/) * [Paquete](https://cran.r-project.org/web/packages/recmap/index.html)  Y, lo siento, no tengo ejemplos míos. Pero si te animas, fabricas uno y lo enlazas en los comentarios, seguro que a alguien le sirve.</description>
    </item>
    
    <item>
      <title>Ahora caRtociudad encuentra información administrativa relativa a un punto</title>
      <link>/2016/04/15/ahora-cartociudad-encuentra-informacion-administrativa-relativa-a-un-punto/</link>
      <pubDate>Fri, 15 Apr 2016 09:13:20 +0000</pubDate>
      
      <guid>/2016/04/15/ahora-cartociudad-encuentra-informacion-administrativa-relativa-a-un-punto/</guid>
      <description>Y lo hace así:
library(caRtociudad) get_cartociudad_location_info(40.473219,-3.7227241, year = 2015) # $seccion # [1] &amp;quot;2807908148&amp;quot; # # $distrito # [1] &amp;quot;2807908&amp;quot; # # $provincia # [1] &amp;quot;Madrid&amp;quot; # # $municipio # [1] &amp;quot;Madrid&amp;quot;  Esto da respuesta a una pregunta de Rubén.
La función es en su mayor parte (salvo algunos retoques más estéticos que otra cosa míos) de Luz Frías, que hizo omiso caso de la inexistente docuentación del INE sobre su servicio de mapas y capturó directamente la petición que el portal de Cartociudad hace al servicio.</description>
    </item>
    
    <item>
      <title>storr: como Redis, pero con R</title>
      <link>/2016/02/09/storr-como-redis-pero-con-r/</link>
      <pubDate>Tue, 09 Feb 2016 09:13:43 +0000</pubDate>
      
      <guid>/2016/02/09/storr-como-redis-pero-con-r/</guid>
      <description>Probablemente no habéis utilizado nunca Redis. Redis es un sistema de almacenamiento basado en parejas clave-valor. Es similar a un diccionario de Python o a un entorno en R. Salvo que el almacenamiento es externo al proceso: los datos se guardan en un sistema distribuido y potencialmente ilimitado en cuanto a capacidad.
Si queréis probar algo parecido, además de los diccionarios y los entornos, podéis probar con storr , un paquete reciente de R.</description>
    </item>
    
    <item>
      <title>Una revisita a &#34;¿Cuántos peces hay en un lago?&#34;</title>
      <link>/2015/12/10/una-revisita-a-cuantos-peces-hay-en-un-lago/</link>
      <pubDate>Thu, 10 Dec 2015 08:13:09 +0000</pubDate>
      
      <guid>/2015/12/10/una-revisita-a-cuantos-peces-hay-en-un-lago/</guid>
      <description>Hace ya dos años escribí ¿Cuántos peces hay en un lago? La rescato ahora que se ha publicado el paquete multimark de R, que permite realizar los mismos análisis básicos que hice entonces más muchos otros más sofisticados para resolver variantes del problema.</description>
    </item>
    
    <item>
      <title>Mi otra debilidad: procesos de Poisson &#34;autoexcitados&#34;</title>
      <link>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</link>
      <pubDate>Thu, 19 Nov 2015 08:13:18 +0000</pubDate>
      
      <guid>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</guid>
      <description>La primera es la factorización positiva de matrices positivas. La otra, como bien titula la entrada, los procesos de Poisson autoexcitados.
Por eso no podía dejar de traer a la atención de mis lectores seismic. Aunque lo de Twitter ya huela.</description>
    </item>
    
    <item>
      <title>Lo poco y lo mucho; lo malo, lo regular y lo bueno</title>
      <link>/2015/11/16/lo-poco-y-lo-mucho-lo-malo-lo-regular-y-lo-bueno/</link>
      <pubDate>Mon, 16 Nov 2015 08:13:53 +0000</pubDate>
      
      <guid>/2015/11/16/lo-poco-y-lo-mucho-lo-malo-lo-regular-y-lo-bueno/</guid>
      <description>Estos días pasados ha habido un hilo en la lista de correo de ayuda de R en español (¿todavía no te has dado de alta en ella?) en la que alguien preguntaba cómo crear paquetes y dónde encontrar documentación al respecto.
La buena intención de quienes han tratado de ayudarle, me temo, ha sido contraproducente. Lo han empapelado con una lista (casi con aspiraciones de exhaustividad) de recursos y más recursos en los que se indica cómo resolver el problema.</description>
    </item>
    
    <item>
      <title>NMF: una técnica mergente de análisis no supervisado</title>
      <link>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</link>
      <pubDate>Mon, 14 Sep 2015 08:13:50 +0000</pubDate>
      
      <guid>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</guid>
      <description>[N]NMF (se encuentra con una o dos enes) es una técnica de análisis no supervisado emergente. Se cuenta entre mis favoritas.
[N]NMF significa non negative matrix factorization y, como SVD, descompone una matriz M como UDV&#39;. Solo que, en este caso, las entradas de M son todas positivas. Y la descomposición es UV&#39;, donde las entradas de ambas matrices son también positivas.
¿Qué tipo de matrices tienen entradas estrictamente positivas?</description>
    </item>
    
    <item>
      <title>Efectos en regresiones logísticas</title>
      <link>/2015/07/14/efectos-en-regresiones-logisticas/</link>
      <pubDate>Tue, 14 Jul 2015 08:13:54 +0000</pubDate>
      
      <guid>/2015/07/14/efectos-en-regresiones-logisticas/</guid>
      <description>Rescato y reconvierto un comentario de mi buen amigo José Luis Cañadas en una entrada mía reciente en la de hoy.
Sugiere José Luis el uso del paquete effects de R para estudiar el efecto de (que el caso concreto de interés, aunque hay otros) las variables de un modelo logístico.
Nos copia el código
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/effects&amp;quot;&amp;gt;effects) mod.cowles &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/glm&amp;quot;&amp;gt;glm(volunteer ~ sex + neuroticism*extraversion, data = Cowles, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/family&amp;quot;&amp;gt;family = &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Oh, no, ¡datastepr!</title>
      <link>/2015/06/09/oh-no-datastepr/</link>
      <pubDate>Tue, 09 Jun 2015 08:12:02 +0000</pubDate>
      
      <guid>/2015/06/09/oh-no-datastepr/</guid>
      <description>Hoy no estoy de humor. He tratado de completar mi primer anillo en dos años y ha resultado un total fracaso. Mi bici buena estaba pinchada: me he enterado a un kilómetro de casa. He tenido que salir en otra, una de esas viejas de Decathlon, que no sé bien cómo apareció una vez en mi casa, que pesa un quintal y que cambia de marchas cuando y como quiere.</description>
    </item>
    
    <item>
      <title>Parametrización para vagos muy, muy vagos</title>
      <link>/2015/02/05/parametrizacion-para-vagos-muy-muy-vagos/</link>
      <pubDate>Thu, 05 Feb 2015 07:13:14 +0000</pubDate>
      
      <guid>/2015/02/05/parametrizacion-para-vagos-muy-muy-vagos/</guid>
      <description>Un ejemplo sencillo. Tengo un programa que contiene, por ejemplo, una consulta tal que
query &amp;lt;- &amp;quot;select * from mitabla where country = 24 and year = 2014&amp;quot;  Hay gente sumamente diligente, con una enorme capacidad de trabajo y con vocación de hormiguita que en mil ejecuciones distintas (distinto país, distinto año) del código anterior sería capaz de editar la consulta a mano. Probablemente usando el block de notas. Esa gente, que además suele madrugar mucho, siempre me ha dado cierta envidia.</description>
    </item>
    
    <item>
      <title>Dónde guardar los paquetes de R (en Linux, al menos)</title>
      <link>/2015/01/21/donde-guardar-los-paquetes-de-r-en-linux-al-menos/</link>
      <pubDate>Wed, 21 Jan 2015 07:13:02 +0000</pubDate>
      
      <guid>/2015/01/21/donde-guardar-los-paquetes-de-r-en-linux-al-menos/</guid>
      <description>En todos mis Linux, desde el principio de los tiempos, R guardaba los paquetes en
 * `/usr/lib/R/library` * `/usr/lib/R/site-library` (¡a veces y no sé por qué!) * `/usr/local/lib/R/site-library`  Bajo /usr/lib deberían instalarse solo aquellos que vienen de serie con la instalación de R (o que se instalan usando el sistema de actualización de paquetes de la distribución de Linux) mientras que bajo /usr/local vivirían los instalados posteriormente por el usuario (véase esto).</description>
    </item>
    
    <item>
      <title>El impacto (causal) de Google</title>
      <link>/2014/09/23/el-impacto-causal-de-google/</link>
      <pubDate>Tue, 23 Sep 2014 07:13:07 +0000</pubDate>
      
      <guid>/2014/09/23/el-impacto-causal-de-google/</guid>
      <description>Voy a escribir sobre un artículo como no debe hacerse: sin haberlo leído. Los bayesianos dirían que esta opinión que aquí voy a vertir es mi prior para cuando encuentre el tiempo y bajo la cual matizaré lo que en el se diga. Lo advierto, en todo caso, para que quien me lea no renuncie al sanísimo escepticismo.
Voy a hablar de Inferring causal impact using Bayesian structural time-series models y del paquete de R que lo acompaña, CausalImpact, cuyos autores trabajan en Google.</description>
    </item>
    
    <item>
      <title>Veinte paquetes de R para científicos de datos</title>
      <link>/2014/03/12/veinte-paquetes-de-r-para-cientificos-de-datos/</link>
      <pubDate>Wed, 12 Mar 2014 07:11:28 +0000</pubDate>
      
      <guid>/2014/03/12/veinte-paquetes-de-r-para-cientificos-de-datos/</guid>
      <description>Me llegó recientemente un artículo con una lista de veinte paquetes de R para data scientists. Y no la encuentro afortunada. Voy a agrupar esos veinte paquetes en algunas categorías y añadiré comentarios. La primera de ellas es la de manipulación de datos, tal vez la más amplia, que recoge los siguientes: sqldf, plyr, stringr (para procesar texto), lubridate (para procesar fechas),reshape2 y los paquetes de acceso a bases de datos.</description>
    </item>
    
    <item>
      <title>Gráficos de pares de variables mejorados (con R)</title>
      <link>/2011/12/29/graficos-de-pares-de-variables-mejorados-con-r/</link>
      <pubDate>Thu, 29 Dec 2011 06:51:03 +0000</pubDate>
      
      <guid>/2011/12/29/graficos-de-pares-de-variables-mejorados-con-r/</guid>
      <description>Un gráfico de pares de variables —que no he sabido traducir mejor desde el original inglés pairplot— es algo como lo siguiente:

Es posible ahora construir gráficos de pares más sofisticados e informativos usando el paquete GGally de R. Usando el código (extraído de SAS and R)
1 2 3 4 5 6 7 8 9 10  library(GGally) ds &amp;lt;- read.csv(&amp;#34;http://www.math.smith.edu/r/data/help.csv&amp;#34;) ds$sex &amp;lt;- as.factor( ifelse(ds$female==1, &amp;#34;female&amp;#34;, &amp;#34;male&amp;#34;) ) ds$housing &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>El paquete reshape de R (I): melt</title>
      <link>/2011/09/07/el-paquete-reshape-de-r-i-melt/</link>
      <pubDate>Wed, 07 Sep 2011 07:45:36 +0000</pubDate>
      
      <guid>/2011/09/07/el-paquete-reshape-de-r-i-melt/</guid>
      <description>El paquete reshape de R consta esencialmene de dos funciones, melt y cast, muy útiles para determinado tipo de transformaciones de de datos.
La función melt se describe sucintamente con el siguiente gráfico:

Es decir, toma un data.frame y lo funde (¡dejaré de ser amigo de quien pronuncie meltea!) o, visto de otra manera, estira.
He aquí unos ejemplos:
1 2 3  library(reshape) iris.m &amp;lt;- melt(iris) iris.m   Nótese cómo melt es inteligente y no necesita (en muchas ocasiones) que se le especifiquen cosas evidentes.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (IV): funciones genéricas</title>
      <link>/2011/08/04/desarrollo-de-paquetes-con-r-iv-funciones-genericas/</link>
      <pubDate>Thu, 04 Aug 2011 07:26:52 +0000</pubDate>
      
      <guid>/2011/08/04/desarrollo-de-paquetes-con-r-iv-funciones-genericas/</guid>
      <description>La función plot es genérica. Uno puede aplicársela a un data.frame o a un objeto de la clase lm. Y en el fondo, plot sólo elige cuál de sus métodos, es decir, las funciones que realizan el trabajo verdaderamente, aplicar. Para ver cuáles son los métodos asociados a plot basta con ejecutar en R
1  methods(plot)   La salida es autoexplicativa.
Podemos hacer un pequeño experimento creando una función genérica, foo, bastante tonta:</description>
    </item>
    
    <item>
      <title>El paquete pxR, en CRAN</title>
      <link>/2011/07/28/el-paquete-pxr-en-cran/</link>
      <pubDate>Thu, 28 Jul 2011 06:54:45 +0000</pubDate>
      
      <guid>/2011/07/28/el-paquete-pxr-en-cran/</guid>
      <description>El 1 de junio escribí en la lista de ayuda de R en español para ver si alguien se animaba a colaborar en la creación de un paquete de R para importar datos en formato PC-Axis.
Este formato es usado por gran número de institutos estadísticos, entre ellos el INE español, para difundir y pubicar datos en formato electrónico. Existe una herramienta gratuita pero cerrada para analizar este tipo de datos, pero clamaba al cielo que los usuarios de R no contásemos con una manera de importarlos directamente.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (III): check, check, check</title>
      <link>/2011/07/12/desarrollo-de-paquetes-con-r-iii-check-check-check/</link>
      <pubDate>Tue, 12 Jul 2011 07:35:00 +0000</pubDate>
      
      <guid>/2011/07/12/desarrollo-de-paquetes-con-r-iii-check-check-check/</guid>
      <description>Uno de los pasos más importantes en el desarrollo de un paquete es verificar que funciona correctamente. Un check comprueba la estructura del paquete, la consistencia entre el código y la documentación, que no faltan secciones importantes en esta última, que los ejemplos pueden ejecutarse sin problemas, etc.
De ahí que sirva para para muchos propósitos. En particular, si uno elige los ejemplos que acompañan a la documentación de las funciones con buen criterio, éstos servirán no sólo para ilustrar el comportamiento de las funciones sino, también, para verificar el funcionamiento del paquete.</description>
    </item>
    
    <item>
      <title>Paquetes huérfanos de R</title>
      <link>/2011/07/01/paquetes-huerfanos-de-r/</link>
      <pubDate>Fri, 01 Jul 2011 07:13:49 +0000</pubDate>
      
      <guid>/2011/07/01/paquetes-huerfanos-de-r/</guid>
      <description>Ayer hablaba con Juan José Gibaja (al que finalmente conocí en persona) y me contaba cómo había usado un paquete de R —no recuerdo cuál— que misteriosamente había desaparecido de CRAN.
—¡Imposible! Los paquetes no desaparecen: quedan huérfanos.
Efectivamente, en la lista de paquetes de CRAN, abajo, se mencionan los llamados paquetes húerfanos. Según el README, se trata de paquetes cuyos autores o mantenedores
 han decidido desentenderse del paquete o los mensajes que les envían desde CRAN rebotan o no son contestados.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (II): primeros pasos</title>
      <link>/2011/06/30/desarrollo-de-paquetes-con-r-ii-primeros-pasos/</link>
      <pubDate>Thu, 30 Jun 2011 07:36:54 +0000</pubDate>
      
      <guid>/2011/06/30/desarrollo-de-paquetes-con-r-ii-primeros-pasos/</guid>
      <description>La segunda entrada en mi serie sobre la creación de paquetes con R cubre los primeros pasos en la creación de uno. Bastan para tener una primera versión de un paquete en minutos. Pero antes, unos consejos generales:
 Usar algún tipo de sistema operativo basado en Unix: Linux, Mac OS, etc. o Cygwin en el peor de los casos. Tengo que confesar que yo comencé a usar Linux precisamente por este motivo: los procedimientos y herramientas que se utilizan para construir paquetes de R están influenciadas por la tradición Unix.</description>
    </item>
    
    <item>
      <title>Sweave, investigación reproducible... y más</title>
      <link>/2011/06/23/sweave-investigacion-reproducible-y-mas/</link>
      <pubDate>Thu, 23 Jun 2011 07:08:45 +0000</pubDate>
      
      <guid>/2011/06/23/sweave-investigacion-reproducible-y-mas/</guid>
      <description>Me consta que algunos de mis lectores están al tanto de eso que llaman investigación reproducible. De acuerdo con la Wikipedia (en inglés),
 [E]l término investigación reproducible se atribuye a Jon Claerbout, de la Universidad de Stanford y se refiere a la idea de que el producto final de la investigación no debería circunscribirse a un artículo sino comprender también el entorno computacional completo usado en la generación los resultados que contiene, tales como el código, los datos, etc.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (I): ¿para qué?</title>
      <link>/2011/06/21/desarrollo-de-paquetes-con-r-i-para-que/</link>
      <pubDate>Tue, 21 Jun 2011 07:17:10 +0000</pubDate>
      
      <guid>/2011/06/21/desarrollo-de-paquetes-con-r-i-para-que/</guid>
      <description>Por popular demanda, voy a comenzar una serie de entradas sobre desarrollo de paquetes con R. Mi idea consiste en establecer un diálogo con mis lectores que me permita pulirlas para acabar escribiendo un documento que pueda resultar útil a los usuarios de R.
En el primero me voy a limitar a explicar para qué puede resultar útil desarrollar paquetes. Lo voy a hacer desde mi experiencia de desarrollador y desde el particular punto de vista de mis hábitos y manías personales.</description>
    </item>
    
    <item>
      <title>Una herramienta para construir paquetes de R sobre Windows</title>
      <link>/2011/06/15/una-herramienta-para-construir-paquetes-de-r-sobre-windows/</link>
      <pubDate>Wed, 15 Jun 2011 07:07:21 +0000</pubDate>
      
      <guid>/2011/06/15/una-herramienta-para-construir-paquetes-de-r-sobre-windows/</guid>
      <description>Construir paquetes multiplataforma con R supone todo un reto para quienes tenemos un acceso limitado o nulo a determinados sistemas operativos. En particular, a muchos nos resulta complicado acceder a una máquina Windows con todas las herramientas necesarias para crear y comprobar los paquetes.
Pero Uwe Ligges, el encargado de los paquetes binarios de Windows para CRAN ha puesto en funcionamiento un servicio para poder compilarlos. En la página de información de este servicio pueden consultarse las instrucciones para subir los paquetes y los caveats:</description>
    </item>
    
    <item>
      <title>Dos perspectivas sobre el problema de los valores no informados</title>
      <link>/2011/05/30/dos-perspectivas-sobre-el-problema-de-los-valores-no-informados/</link>
      <pubDate>Mon, 30 May 2011 07:48:59 +0000</pubDate>
      
      <guid>/2011/05/30/dos-perspectivas-sobre-el-problema-de-los-valores-no-informados/</guid>
      <description>Me llegó el otro día información acerca de un curso sobre métodos para afrontar el problema planteado por los valores no informados (missing observations) que su autor agrupaba bajo etiquetas bastante simpáticas: el bueno, el malo y el impensable. Tal vez faltaba el feo, tal vez porque lo son todos ellos, igual que el bendito problema que suponen. Añadía, sin mayores abundamientos, que
 explicaría cómo la solución común es en general la peor; mostraría por qué cierta solución sencilla, relativamente común y con mala fama no es habitualmente tan mala, explicando, además, cuáles son las situaciones en las que funciona y no funciona e indicaría dos soluciones que proporcionan resultados insesgados, una de las cuales es sencilla de implementar pero sólo funciona en ciertas circunstancias y la otra, aunque más complicada, funciona siempre.</description>
    </item>
    
    <item>
      <title>Se buscan &#34;alpha testers&#34; para rPython</title>
      <link>/2011/05/24/se-buscan-alpha-testers-para-rpython/</link>
      <pubDate>Tue, 24 May 2011 07:00:49 +0000</pubDate>
      
      <guid>/2011/05/24/se-buscan-alpha-testers-para-rpython/</guid>
      <description>Busco alpha testers para mi paquete rPython. El paquete es la evolución natural de rJython, un paquete de R que permite llamar a Jython, el dialecto de Python que corre sobre la máquina virtual de Java, desde R.
rPython permite llamar al verdadero Python. Funciona perfectamente en mi máquina, pero necesito ver qué problemas de instalación y uso aparecen en otras plataformas. De momento, sólo funcionaría sobre plataformas UNIX o Linux.</description>
    </item>
    
    <item>
      <title>La versión 0.7 del paquete colbycol, en CRAN</title>
      <link>/2011/05/23/la-version-0-7-del-paquete-colbycol-en-cran/</link>
      <pubDate>Mon, 23 May 2011 13:18:39 +0000</pubDate>
      
      <guid>/2011/05/23/la-version-0-7-del-paquete-colbycol-en-cran/</guid>
      <description>Me complace anunciar la subida a CRAN de la versión 0.7 del paquete colbycol.
La diferencia esencial con respecto a la anterior es:
 Utiliza el paquete filehash para crear el objeto que almacena los datos en disco. Incorpora algunas mejoras de uso sugeridas por los usuarios que facilitan la manipulación de los datos.  Espero poder publicar un estudio comparado del rendimiento en los próximos días.</description>
    </item>
    
    <item>
      <title>Paralelización de bucles con foreach</title>
      <link>/2011/04/08/paralelizacion-de-bucles-con-foreach/</link>
      <pubDate>Fri, 08 Apr 2011 07:26:41 +0000</pubDate>
      
      <guid>/2011/04/08/paralelizacion-de-bucles-con-foreach/</guid>
      <description>Parcialmente en agradecimiento a Revolution Analytics por haber concedido una subvención a las III Jornadas de usuarios de R voy a discutir en esta entrada cómo paralelizar bucles usando los paquetes foreach y doMC desarrollados por dicha empresa.
El paquete foreach contiene, esencialmente, una única función, foreach, que, en su forma más básica, permite ejecutar bucles con una sintaxis un tanto peculiar:
1  foreach( i = 1:3 ) %do% log( i )   Volveré sobre algunas operaciones interesantes y bastante útiles que permite realizar esta función porque, de todas ellas, hoy me ocuparé sólo de una: la que abre la puerta de una manera sencilla a la paralelización de bucles.</description>
    </item>
    
    <item>
      <title>Nueva versión de paquete colbycol</title>
      <link>/2011/04/07/nueva-version-de-paquete-colbycol/</link>
      <pubDate>Thu, 07 Apr 2011 07:55:34 +0000</pubDate>
      
      <guid>/2011/04/07/nueva-version-de-paquete-colbycol/</guid>
      <description>Hace unos días subí a CRAN la última versión de mi paquete colbycol. Incluí algunas mejoras sugeridas por uno de sus usuarios así como otras que estaban esperando a que liberase mi agenda. Además, añadí un pequeño tutorial en la página del paquete.
El paquete colbycol está pensado para resolver —aunque sólo sea parcialmente— uno de los problemas más acuciantes de quienes usamos R para el análisis de datos muy grandes: leer ficheros de datos de gran tamaño.</description>
    </item>
    
    <item>
      <title>R y Excel: una alternativa</title>
      <link>/2011/03/23/r-y-excel-una-alternativa/</link>
      <pubDate>Wed, 23 Mar 2011 09:56:13 +0000</pubDate>
      
      <guid>/2011/03/23/r-y-excel-una-alternativa/</guid>
      <description>Los amantes de Excel están de enhorabuena. Ahora tienen una alternativa a RExcel, una extensión de Excel que le permite interactuar con R: XLConnect, un paquete multiplataforma de R que permite:
 Trabajar con ficheros de Excel 97 (.xls) y OOXML (.xlsx) Crear y eliminar hojas dentro de documentos Leer y escribir rangos de valores (ranges) Leer y escribir hojas de cálculo Añadir gráficos Asociar estilos a celdas Definir el tamaño de las filas y columnas Etc.</description>
    </item>
    
    <item>
      <title>R, HDF5 y bases de datos orientadas a columnas</title>
      <link>/2011/03/10/r-hdf5-y-bases-de-datos-orientadas-a-columnas/</link>
      <pubDate>Thu, 10 Mar 2011 09:25:23 +0000</pubDate>
      
      <guid>/2011/03/10/r-hdf5-y-bases-de-datos-orientadas-a-columnas/</guid>
      <description>Tras escribir el otro día sobre RevoscaleR, he tropezado con un paquete de R, HDF5 que le permite hacer cosas parecidas usando tecnologías libres. Puede encontrarse más información sobre HDF5 en la Wikipedia y en la página del proyecto.

De todos modos, y como dejé escrito como respuesta a un comentario en la entrada que indico más arriba, una solución definitiva al problema del análisis de conjuntos de datos grandes con R podría venir de la mano de una integración adecuada con un gestor de bases de datos orientado a columnas.</description>
    </item>
    
    <item>
      <title>Enredando con el paquete googleVis de R</title>
      <link>/2011/02/17/enredando-con-el-paquete-googlevis-de-r/</link>
      <pubDate>Thu, 17 Feb 2011 09:22:41 +0000</pubDate>
      
      <guid>/2011/02/17/enredando-con-el-paquete-googlevis-de-r/</guid>
      <description>Si el otro día denuncié un gráfico engañabobos (y algún otro me explayaré muy constructivamente sobre el intercambio de correos que mantuve con sus autores), hoy he querido reproducirlo con el paquete googleVis de R.
Habedlo:
[cf]googleViz[/cf]
El código utilizado para generarlo es:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  library(googleVis) library(reshape) a &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Nuevo paquete para procesar texto en R: stringr</title>
      <link>/2011/01/20/nuevo-paquete-para-procesar-texto-en-r-stringr/</link>
      <pubDate>Thu, 20 Jan 2011 09:56:47 +0000</pubDate>
      
      <guid>/2011/01/20/nuevo-paquete-para-procesar-texto-en-r-stringr/</guid>
      <description>Hadley Wickman, el autor de plyr, reshape y ggplot2, ha vuelto a la carga en su exitoso empeño por hacernos cambiar de forma de programar en R.
Con su nuevo paquete, stringr, aspira a facilitarnos aún más la vida. En un reciente artículo, enumera sus ventajas:
 Procesa factores y caracteres de la misma manera (de verdad, muy práctico) Da a las funciones nombres y argumentos consistentes Simplifica las operaciones de procesamiento de cadenas eliminando opciones que apenas se usan Produce salidas que pueden ser utilizadas fácilmente como entradas a otras funciones Incorpora funciones para procesar texto presentes en otros lenguajes pero no en R  </description>
    </item>
    
    <item>
      <title>¡Qué mala suerte tengo con las anomalías!</title>
      <link>/2010/10/29/que-mala-suerte-tengo-con-las-anomalias/</link>
      <pubDate>Fri, 29 Oct 2010 00:16:28 +0000</pubDate>
      
      <guid>/2010/10/29/que-mala-suerte-tengo-con-las-anomalias/</guid>
      <description>El siempre muy benéfico Banco de Santander me ha proporcionado &amp;mdash;onerosamente: veráse el porqué&amp;mdash; un conjunto de datos con el que ilustrar a los lectores de este blog en el uso del paquete outliers de R. Los datos son los siguientes:
1 2  dia &amp;lt;- 17:26 precio &amp;lt;- 10 + c( 22, 21, 39, 18, 24, 26, 26,26,29, 28 ) / 100   Los días son los discurridos desde que di una orden de adquisición de un fondo de inversión a través de dicha entidad financiera hasta que tuve constancia de que se había completado: el dinero se había adeudado de la cuenta corriente y las participaciones, aparecían listadas en la cuenta de valores.</description>
    </item>
    
    <item>
      <title>El paquete multicore de R</title>
      <link>/2010/09/01/el-paquete-multicore-de-r/</link>
      <pubDate>Wed, 01 Sep 2010 22:24:44 +0000</pubDate>
      
      <guid>/2010/09/01/el-paquete-multicore-de-r/</guid>
      <description>Tengo acceso a una máquina que, aunque anda un poco corta de memoria, cuenta con ocho CPUs. Tenía unas simulaciones bastante pesadas que correr y quise aprovechar su naturaleza perfectamente paralelizable. Y, de paso, hacer con R lo mismo por lo que he visto a un consultor de SAS cobrar a razón de 3.000 dólares diarios.
En el fondo, es una trivialidad. Supongamos que la función que implementa la simulación se llama foo.</description>
    </item>
    
    <item>
      <title>rJython: un nuevo paquete para llamar a Python desde R</title>
      <link>/2010/07/13/rjython-un-nuevo-paquete-para-llamar-a-python-desde-r/</link>
      <pubDate>Tue, 13 Jul 2010 22:18:03 +0000</pubDate>
      
      <guid>/2010/07/13/rjython-un-nuevo-paquete-para-llamar-a-python-desde-r/</guid>
      <description>Ya está disponible el paquete rJython que permite llamar a Python desde R. Aunque todavía no se ha subido a CRAN, puede instalarse así:
1  install.packages(&amp;#34;rJython&amp;#34;, repos=&amp;#34;http://R-Forge.R-project.org&amp;#34;)   Una vez instalado puede probarse el paquete ejecutando, por ejemplo,
1 2 3 4 5 6 7 8 9 10 11  rJython &amp;lt;- rJython() a &amp;lt;- 1:4 jython.assign(rJython, &amp;#34;a&amp;#34;, a) jython.exec(rJython, &amp;#34;b = len( a )&amp;#34;) jython.get(rJython, &amp;#34;b&amp;#34;) rJython$exec(&amp;#34;import math&amp;#34;) jython.</description>
    </item>
    
    <item>
      <title>Gráficos en R con símbolos arbitrarios: código, comentarios y fin</title>
      <link>/2010/06/28/graficos-en-r-con-simbolos-arbitrarios-codigo-comentarios-y-fin/</link>
      <pubDate>Mon, 28 Jun 2010 22:36:10 +0000</pubDate>
      
      <guid>/2010/06/28/graficos-en-r-con-simbolos-arbitrarios-codigo-comentarios-y-fin/</guid>
      <description>Prometí el otro día revelar los secretos (pensaba que no lo eran tanto) del gráfico que mostré en esta entrada. Los impacientes tienen aquí todo lo que necesitan. Tienen que ejecutar primero el guión svg2ps.sh que invoca inkscape para transformar los ficheros svg (incluidos en la descarga) de las banderas (obtenidos de la Wikipedia) en ficheros postscript.
El programa src.R genera entonces el gráfico utilizando dos paquetes de R: grImport y lattice.</description>
    </item>
    
    <item>
      <title>Datatables: tablas con búsqueda binaria en R</title>
      <link>/2010/05/09/datatables-tablas-con-busqueda-binaria-en-r/</link>
      <pubDate>Sun, 09 May 2010 15:28:47 +0000</pubDate>
      
      <guid>/2010/05/09/datatables-tablas-con-busqueda-binaria-en-r/</guid>
      <description>No hace mucho me enfrenté con un problema en el trabajo. Quería cruzar dos tablas, una de algunos miles de millones de registros y otra de algunos cientos de miles para, simplemente, contar el número de filas finales que aparecían por fecha.
Cada una de las tablas tenía algunos filtros y agregaciones; el cruce final se realizaba sobre las subconsultas resultantes. El gestor de bases de datos que utilizamos, Teradata (sin comentarios), no podía con el cruce: las decisiones que tomaba internamente el presunto optimizador de consultas conducían inexorablemente a un error de espacio.</description>
    </item>
    
  </channel>
</rss>
