<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nmf on datanalytics</title>
    <link>/tags/nmf/</link>
    <description>Recent content in nmf on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Wed, 14 Oct 2020 09:13:00 +0000</lastBuildDate><atom:link href="/tags/nmf/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Explicación de los scorings de &#34;ciertos&#34; modelos</title>
      <link>/2020/10/14/explicacion-de-los-scorings-de-ciertos-modelos/</link>
      <pubDate>Wed, 14 Oct 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/10/14/explicacion-de-los-scorings-de-ciertos-modelos/</guid>
      <description>Esta entrada la hago por petición popular y para rematar de alguna manera lo que incoé hace unos días. Seré breve hasta lo telegráfico:
 Tomo las observaciones con scorings más altos (en un árbol construido con ranger y cariño). 2. Veo cuáles son los árboles que les asignan scorings más altos. 3. Anoto las variables implicadas en las ramas por donde bajan las observaciones (1) en los árboles (2). 4.</description>
    </item>
    
    <item>
      <title>Análisis de arquetipos</title>
      <link>/2020/07/21/analisis-de-arquetipos/</link>
      <pubDate>Tue, 21 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/21/analisis-de-arquetipos/</guid>
      <description>De eso trata un artículo de los noventa de Breiman. Es decir, de encontrar dentro de conjuntos de datos conjuntos finitos de sujetos puros que permiten representar cualquier otro como una mezcla (o combinación convexa) de ellos.
Ideas a vuelapluma:
 Cuando leo sobre el asunto, la palabra que no deja de aparecérseme es outlier. Curiosamente, la busco en el texto y se resiste a aparecer. Pero me aterra la posibilidad de estar caracterizando a los sujetos normales (¿aún se puede usar la expresión?</description>
    </item>
    
    <item>
      <title>&#34;Embeddings&#34; y análisis del carrito de la compra</title>
      <link>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</link>
      <pubDate>Thu, 04 Oct 2018 08:13:34 +0000</pubDate>
      
      <guid>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</guid>
      <description>Escribiendo la entrada del otro día sobre embeddings, no se me pasó por alto que la fórmula
$latex \frac{P(W_i,C_i)}{P(W_i)P(C_i)}$
que escribí en ella es análoga al llamado lift (¿es el lift?) del llamado análisis del carrito de la compra, i.e., el estudio de productos que tienden a comprarse juntos (véase, por ejemplo, esto).
Lo cual me lleva a sugerir mas no escribir una entrada en la que se rehagan este tipo de análisis usando embeddings: los ítems como palabras, los carritos como textos, etc.</description>
    </item>
    
    <item>
      <title>NMF: una técnica mergente de análisis no supervisado</title>
      <link>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</link>
      <pubDate>Mon, 14 Sep 2015 08:13:50 +0000</pubDate>
      
      <guid>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</guid>
      <description>[N]NMF (se encuentra con una o dos enes) es una técnica de análisis no supervisado emergente. Se cuenta entre mis favoritas.
[N]NMF significa non negative matrix factorization y, como SVD, descompone una matriz M como UDV&#39;. Solo que, en este caso, las entradas de M son todas positivas. Y la descomposición es UV&#39;, donde las entradas de ambas matrices son también positivas.
¿Qué tipo de matrices tienen entradas estrictamente positivas?</description>
    </item>
    
    <item>
      <title>IV Meetup Machine Learning Spain: diapositivas y enlaces</title>
      <link>/2015/03/05/iv-meetup-machine-learning-spain-diapositivas-y-enlaces/</link>
      <pubDate>Thu, 05 Mar 2015 12:36:27 +0000</pubDate>
      
      <guid>/2015/03/05/iv-meetup-machine-learning-spain-diapositivas-y-enlaces/</guid>
      <description>Las diapositivas que compilé para esto pueden bajarse de aquí.
Son, premeditadamente, insuficientes para seguir el hilo de la charla. De todos modos, gran parte de las ideas a las que se refieren están descritas con algo más de detalle aquí.
Creo que se grabó un vídeo, pero no sé ni si ni cuándo o cómo estará disponible.</description>
    </item>
    
    <item>
      <title>IV Meetup Machine Learning Spain: factorización no negativa de matrices y algunas aplicaciones</title>
      <link>/2015/03/03/iv-meetup-machine-learning-spain-factorizacion-no-negativa-de-matrices-y-algunas-aplicaciones/</link>
      <pubDate>Tue, 03 Mar 2015 08:13:34 +0000</pubDate>
      
      <guid>/2015/03/03/iv-meetup-machine-learning-spain-factorizacion-no-negativa-de-matrices-y-algunas-aplicaciones/</guid>
      <description>Me han invitado a hablar en el IV Meetup Machine Learning Spain. Será el miércoles 4 de marzo en el lugar que en el enlace anterior indica.
Mi charla será una versión extendida de un tema, la factorización no negativa de matrices y algunas aplicaciones, que mis lectores más fieles ya conocen.
No sé cuántos de mis lectores de Madrid y derredores querrán sumarse. Tampoco sé cuántos de ellos, al acabar, que ya será hora de cenar, querrán hacerlo conmigo en MartinaCocina, a un par de cuadras del lugar del evento, para hablar de cosas interesantes.</description>
    </item>
    
    <item>
      <title>Factorizaciones positivas de matrices igualmente positivas</title>
      <link>/2014/06/19/factorizaciones-positivas-de-matrices-igualmente-positivas/</link>
      <pubDate>Thu, 19 Jun 2014 07:01:38 +0000</pubDate>
      
      <guid>/2014/06/19/factorizaciones-positivas-de-matrices-igualmente-positivas/</guid>
      <description>Cuando tenía 18 años, pensaba, llegué a aprender todo lo que había que saber sobre factorización de matrices. Incluida la inutilidad de Jordan. El otro día, con un ciento y pico por ciento más de años, he descubierto una clase entera de factorizaciones que aquellos planes de estudios viejunos no contemplaban y que, ¡carajo!, aparte de útiles engarzan con otras ideas la mar de interesantes.
Se trata de factorizaciones positivas de matrices igualmente positivas.</description>
    </item>
    
  </channel>
</rss>
