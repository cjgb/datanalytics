<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ctree on datanalytics</title>
    <link>/tags/ctree/</link>
    <description>Recent content in ctree on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 21 May 2019 09:13:54 +0000</lastBuildDate><atom:link href="/tags/ctree/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>¿Qué puede colgar de un árbol?</title>
      <link>/2019/05/21/que-puede-colgar-de-un-arbol/</link>
      <pubDate>Tue, 21 May 2019 09:13:54 +0000</pubDate>
      
      <guid>/2019/05/21/que-puede-colgar-de-un-arbol/</guid>
      <description>Predicciones puntuales:
O (sub)modelos:
Y parece que ahora también distribuciones:
Notas:
 Obviamente, la clasificación anterior no es mutuamente excluyente. * La tercera gráfica está extraída de Transformation Forests, un artículo donde se describe el paquete trtf de R. * Los autores dicen que [r]egression models for supervised learning problems with a continuous target are commonly understood as models for the conditional mean of the target given predictors. ¿Vosotros lo hacéis así?</description>
    </item>
    
    <item>
      <title>Repensando la codificación por impacto</title>
      <link>/2017/01/10/repensando-la-codificacion-por-impacto/</link>
      <pubDate>Tue, 10 Jan 2017 08:13:49 +0000</pubDate>
      
      <guid>/2017/01/10/repensando-la-codificacion-por-impacto/</guid>
      <description>Hay una entrada mía, esta, que me ronda la cabeza y con la que no sé si estoy completamente de acuerdo. Trata de justificar la codificación por impacto de variables categóricas en modelos lineales (generalizados o no) y cuanto más la releo, menos me la creo. O, más bien, comienzo a cuestinarme más seriamente contextos en los que funciona y contextos en los que no.
Pero comencemos por uno simple: los árboles.</description>
    </item>
    
    <item>
      <title>evtree: árboles globales</title>
      <link>/2015/01/12/evtree-arboles-globales/</link>
      <pubDate>Mon, 12 Jan 2015 07:13:44 +0000</pubDate>
      
      <guid>/2015/01/12/evtree-arboles-globales/</guid>
      <description>Tengo por delante otro proyecto que tiene mucho de análisis exploratorio de datos. Sospecho que más de un árbol construiré. Los árboles son como la Wikipedia: prácticamente nunca el último pero casi siempre el primer recurso.
Esta vez, además, por entretenerme un poco, probaré el paquete [evtree](http://cran.r-project.org/web/packages/evtree/index.html). Aunque no porque espere sorprendentes mejoras con respecto a los tradicionales, ctree y rpart.
¿Qué tiene aquél que los diferencie de los otros dos?</description>
    </item>
    
    <item>
      <title>Importancia de variables en árboles</title>
      <link>/2013/11/06/importancia-de-variables-en-arboles/</link>
      <pubDate>Wed, 06 Nov 2013 07:49:59 +0000</pubDate>
      
      <guid>/2013/11/06/importancia-de-variables-en-arboles/</guid>
      <description>Los árboles (o árboles de inferencia condicional) valen fundamentalmente para hacerse una idea de cómo y en qué grado opera una variable en un modelo controlando por el efecto del resto. Su valor reside fundamentalmente en la interpretabilidad.
No obstante lo cual, no es infrecuente construir árboles muy grandes. Y el tamaño dificulta censar qué variables y en qué manera aparecen. Por eso me vi obligado recientemente a crear un pequeño prototipo para extraer el peso de las variables de un árbol.</description>
    </item>
    
  </channel>
</rss>
