<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on datanalytics</title>
    <link>/tags/spark/</link>
    <description>Recent content in spark on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 17 May 2016 08:13:04 +0000</lastBuildDate><atom:link href="/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Melt y cast en Spark con scala</title>
      <link>/2016/05/17/melt-y-cast-en-spark-con-scala/</link>
      <pubDate>Tue, 17 May 2016 08:13:04 +0000</pubDate>
      
      <guid>/2016/05/17/melt-y-cast-en-spark-con-scala/</guid>
      <description>Trabajar con Spark usando Scala implica renunciar a ese paraíso que son las funciones melt y (d)cast de reshape2.
¿O no?
&amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;import &amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;org.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;apache.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;spark.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;sql.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;types.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;StructField; &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;import &amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;org.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;apache.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;spark.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;sql.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;types.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;StructType; &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;import &amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;org.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;apache.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;spark.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;sql.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;types.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;StringType; &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;import &amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;org.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;apache.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;spark.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;sql.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;types.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;DoubleType; &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;import &amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;org.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;apache.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;spark.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;sql.&amp;lt;span style=&amp;quot;color:#0053ff;font-weight:700&amp;quot;&amp;gt;Row; &amp;lt;span style=&amp;quot;color:#af82d4&amp;quot;&amp;gt;/** Create some data **/ &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;val nrows = &amp;lt;span style=&amp;quot;color:#a8017e&amp;quot;&amp;gt;20 &amp;lt;span style=&amp;quot;color:#069;font-weight:700&amp;quot;&amp;gt;val origDF = sc.</description>
    </item>
    
    <item>
      <title>Curso de ASPgems: Descubre Spark en 8 semanas</title>
      <link>/2015/09/24/curso-de-aspgems-descubre-spark-en-8-semanas/</link>
      <pubDate>Thu, 24 Sep 2015 08:13:42 +0000</pubDate>
      
      <guid>/2015/09/24/curso-de-aspgems-descubre-spark-en-8-semanas/</guid>
      <description>En el Meetup de hoy me he enterado de que mis colegas de ASPgems están organizando un curso de Spark. Y no por colegas sino por competentes, lo divulgo por aquí.
La información al respecto, aquí.
Advertencia: El curso no es gratuito y ASPgems me ha invitado a dos cervezas a la salida del Meetup de hoy. Pero, tranquilos, mi precio no es ese.</description>
    </item>
    
    <item>
      <title>SparkR 1.4: carga de ficheros CSV</title>
      <link>/2015/06/23/sparkr-1-4-carga-de-ficheros-csv/</link>
      <pubDate>Tue, 23 Jun 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/06/23/sparkr-1-4-carga-de-ficheros-csv/</guid>
      <description>He instalado Spark 1.4 recientemente y he comenzado a cacharrear. Antes de nada, quiero cargar datos.
Advierto que ha cambiado sustancialmente la API de SparkR. Entre otras novedades, desapareció (o más bien, se escondió) la función textFile, que permitía leer ficheros línea a línea. Ahora está pero no se exporta. La verás solo si haces SparkR:::textFile. ¿Signo de deprecación?
Se pueden crear un DataFrame (tablas distribuidas de Spark) a partir de un data.</description>
    </item>
    
    <item>
      <title>Liberado Spark 1.4</title>
      <link>/2015/06/17/liberado-spark-1-4/</link>
      <pubDate>Wed, 17 Jun 2015 08:13:15 +0000</pubDate>
      
      <guid>/2015/06/17/liberado-spark-1-4/</guid>
      <description>El anuncio de la liberación de la versión 1.4 de Spark se ha materializado. Está aquí.
¿Qué trae de novedad la versión 1.4? La integración con SparkR —antes había que instalarlo con algo de dolor independientemente— y, aparentemente, data.frames distribuidos y, cuentan, una sintaxis similar a la de dplyr —honestamente, hubiera preferido otra— para manipularlos.
Iré desgranando por aquí novedades. Y estoy pensando organizar una install &amp;amp; tutorial party un día de estos en Madrid.</description>
    </item>
    
    <item>
      <title>Spark gana la competición Gray Sort de 2014</title>
      <link>/2014/11/20/spark-gana-la-competicion-gray-sort-de-2014/</link>
      <pubDate>Thu, 20 Nov 2014 07:13:12 +0000</pubDate>
      
      <guid>/2014/11/20/spark-gana-la-competicion-gray-sort-de-2014/</guid>
      <description>Esta de hoy es una entrada muy friqui que se sirve de la casi excusa de que los creadores de Apache Spark han ganado la competición Gray Sort de 2014 para recomendar a sus lectores a estar alerta a las novedades que llegan.

Todavía colea el siglo XX y todavía pagan dinero por cosas que algún día consideraremos tan entrañables como el ZX Spectrum de 48kB tales como:
 * Colorear casillas en Excel.</description>
    </item>
    
    <item>
      <title>Componentes conexas (de grafos) en Spark</title>
      <link>/2014/09/15/componentes-conexas-de-grafos-en-spark/</link>
      <pubDate>Mon, 15 Sep 2014 07:13:46 +0000</pubDate>
      
      <guid>/2014/09/15/componentes-conexas-de-grafos-en-spark/</guid>
      <description>Uno de mis últimos pet projects tiene que ver con el análisis de las componentes conexas de unos grafos muy grandes. Como aquí pero con datos de un tamaño muchos órdenes de magnitud mayores. Usando Spark, claro. Y ya que lo cito, aprovecho la ocasión para regalar un consejo a mis lectores más jóvenes: no esperéis a los cuarenta para aprender Scala y Spark.
Voy a limitarme a copiar el código para referencia mía y de otros.</description>
    </item>
    
    <item>
      <title>En serio con Spark: instalación</title>
      <link>/2014/07/18/en-serio-con-spark-instalacion/</link>
      <pubDate>Fri, 18 Jul 2014 07:13:59 +0000</pubDate>
      
      <guid>/2014/07/18/en-serio-con-spark-instalacion/</guid>
      <description>Me he puesto en modo estoy serio con Spark. Lo instalé en mi ya manida máquina virtual (voy a subir una nueva versión de ella pronto), pero hoy la voy a instalar en mi portátil. Y con la idea de, en los próximos días, montar un clúster en condiciones.
Los pasos son los siguientes:
 1. Ir a la [página de descargas](http://spark.apache.org/downloads.html) y seleccionar una versión ya precompilada. Hay varias porque Spark se enlaza con librerías relacionadas con Hadoop (aunque uno puede utilizar Spark perfectamente sin él) y hay varias versiones mutuamente incompatibles de Hadoop.</description>
    </item>
    
    <item>
      <title>Estrategias escalables (con R)</title>
      <link>/2014/07/09/estrategias-escalables-con-r/</link>
      <pubDate>Wed, 09 Jul 2014 07:13:41 +0000</pubDate>
      
      <guid>/2014/07/09/estrategias-escalables-con-r/</guid>
      <description>Hay quienes preguntan cómo cargar con R un csv de 8GB en un portátil de 4GB de RAM. La verdad, he leído respuestas la mar de extravagantes a este tipo de cuestiones: p.e., recomendar SQLite.
Yo recomendaría Scalable Strategies for Computing with Massive Data. Entre otras cosas, porque para eso lo escribieron sus autores: para que se lea. Y porque está cargado de razón y buenos consejos.
Una cosa con la que tropezará enseguida quien lo hojee es:</description>
    </item>
    
    <item>
      <title>Hoy he echado de menos Scala</title>
      <link>/2014/06/12/hoy-he-echado-de-menos-scala/</link>
      <pubDate>Thu, 12 Jun 2014 07:00:56 +0000</pubDate>
      
      <guid>/2014/06/12/hoy-he-echado-de-menos-scala/</guid>
      <description>Hoy he escrito
last.date &amp;lt;- max(Filter(function(x) format(x, &amp;quot;%m&amp;quot;) == &amp;quot;03&amp;quot;, all.filled.data$Date))  y he echado mucho de menos Scala.
Más sobre Scala:
 * Si yo fuera rey, todos los niños aprenderían Scala. * Al tipo que inventó Scala le gustan tanto o más los [_oneliners_](http://es.wikipedia.org/wiki/Los_santos_inocentes_(novela)) que a mí. * Todavía me llevo mal con el compilador. * La gente viene a Suiza y aprende el alemán malhablado de aquí; yo, ya véis, Scala.</description>
    </item>
    
  </channel>
</rss>
