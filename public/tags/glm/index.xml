<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>glm on datanalytics</title>
    <link>/tags/glm/</link>
    <description>Recent content in glm on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 12 Jan 2021 09:13:00 +0000</lastBuildDate><atom:link href="/tags/glm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sobre la relación entre la teoría de la relatividad y la regresión logística</title>
      <link>/2021/01/12/sobre-la-relacion-entre-la-teoria-de-la-relatividad-y-la-regresion-logistica/</link>
      <pubDate>Tue, 12 Jan 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/01/12/sobre-la-relacion-entre-la-teoria-de-la-relatividad-y-la-regresion-logistica/</guid>
      <description>Según la teoría de la relatividad, las velocidades (lineales) se suman así:
v1 &amp;lt;- 100000 v2 &amp;lt;- 100000 velocidad_luz &amp;lt;- 300000 suma_relativista &amp;lt;- function(x,y){ (x + y) / (1 + x * y / velocidad_luz^2) } suma_relativista(v1, v2) # 180000  Lo que es todavía menos conocido es que esa operación es equivalente a la suma ordinaria de velocidades a través de una transformación de ida y vuelta vía la arcotangente hiperbólica (véase esto).</description>
    </item>
    
    <item>
      <title>El modelo de Poisson es razonablemente robusto (pero atención a lo de &#34;razonablemente&#34;)</title>
      <link>/2020/10/07/el-modelo-de-poisson-es-razonablemente-robusto-pero-atencion-a-lo-de-razonablemente/</link>
      <pubDate>Wed, 07 Oct 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/10/07/el-modelo-de-poisson-es-razonablemente-robusto-pero-atencion-a-lo-de-razonablemente/</guid>
      <description>Una de las consencuencias del coronavirus es que vamos a tener que replantearnos lo que significa ajustar series temporales. Es decir, comenzar a ajustar series temporales y no repetir la consabida teoría que subyace a los modelos ARIMA simplemente porque es guay.
También tendremos que replantearnos qué hacer con los outliers que la pandemia va dejando tras de sí. Y tratar de hacerlo más elegantemente que cierta gente, por supuesto. En particular, habrá que ver cuál y cómo es el efecto de los outliers en determinados modelos.</description>
    </item>
    
    <item>
      <title>Un decepcionante método de &#34;inferencia robusta&#34; para GLMs de Poisson</title>
      <link>/2020/09/24/un-decepcionante-metodo-de-inferencia-robusta-para-glms-de-poisson/</link>
      <pubDate>Thu, 24 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/24/un-decepcionante-metodo-de-inferencia-robusta-para-glms-de-poisson/</guid>
      <description>[Quod si sal evanuerit in quo sallietur ad nihilum valet ultra nisi ut mittatur foras et conculcetur ab hominibus.]
Vuelvo con mi monotema de los últimos días: cómo hacer GLMs de Poisson robustos. Encuentro la tesis Robust Inference for Generalized Linear Models: Binary and Poisson Regression y pienso: ajá, será cuestión de copipegar.
Nada más lejos de la realidad. El método propuesto en la tesis está basado en asignaciones de pesos a las observaciones usando kernels con centros y anchuras basadas respectivamente en</description>
    </item>
    
    <item>
      <title>Una diferencia teórica importante entre los lm y el resto de los glm</title>
      <link>/2020/09/22/una-diferencia-teorica-importante-entre-los-lm-y-el-resto-de-los-glm/</link>
      <pubDate>Tue, 22 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/22/una-diferencia-teorica-importante-entre-los-lm-y-el-resto-de-los-glm/</guid>
      <description>[Este es un extracto, una píldora atómica, de mi charla del otro día sobre el modelo de Poisson y al sobredispersión.]
Aunque me guste expresar el modelo lineal de la forma
$latex y_i \sim N(a_0 + \sum_j a_j x_{ij}, \sigma_i)$
hoy, para lo que sigue, es más conveniente la representación tradicional
$latex y_i = a_0 + \sum_j a_j x_{ij} + \epsilon_i$
donde si no sabes lo que es cada cosa, más vale que no sigas leyendo.</description>
    </item>
    
    <item>
      <title>Charla sobre cosas que no te han contado sobre le modelo de Poisson (y de paso, el logístico)</title>
      <link>/2020/09/16/charla-sobre-cosas-que-no-te-han-contado-sobre-le-modelo-de-poisson-y-de-paso-el-logistico/</link>
      <pubDate>Wed, 16 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/16/charla-sobre-cosas-que-no-te-han-contado-sobre-le-modelo-de-poisson-y-de-paso-el-logistico/</guid>
      <description>Este es un anuncio de una charla que daré este viernes (2020-09-18) dentro del congreso virtual EncuentRos en la fase R. Ni que decir tiene que los detalles logísticos pueden consultarse en el enlace anterior.
Hablaré de cuestiones relativas al modelo de Possion (gran parte de las cuales pueden trasladarse también al logístico) de las que se habla poco y sobre las que la teoría que uno tropieza por ahí no es del todo clara pero que se manifiestan claramente en datos como los de la monitorización de la mortalidad, que será discutida también de pasada.</description>
    </item>
    
    <item>
      <title>Aún más sobre la presunta sobredispersión en modelos de Poisson</title>
      <link>/2020/07/22/aun-mas-sobre-la-presunta-sobredispersion-en-modelos-de-poisson/</link>
      <pubDate>Wed, 22 Jul 2020 12:59:20 +0000</pubDate>
      
      <guid>/2020/07/22/aun-mas-sobre-la-presunta-sobredispersion-en-modelos-de-poisson/</guid>
      <description>[Esta entrada continúa el ciclo al que he dedicado esta y esta otra entradas durante los últimos días.]
Las dos entradas anteriores de la serie se resumen en que:
 el modelo de Poisson no recoge todas las fuentes de error que pueden existir en los datos y que * las soluciones al uso (como, p.e., usar modelos quasi-Poisson) son puros remiendos.  Si el error en el modelo de Poisson entra (también) en el término lineal, podemos modelar ese error explícitamente.</description>
    </item>
    
    <item>
      <title>No, tus datos no &#34;tienen sobredispersión&#34;: es que el gato de Nelder se ha merendado la epsilon</title>
      <link>/2020/07/16/no-tus-datos-no-tienen-sobredispersion-es-que-el-gato-de-nelder-se-ha-merendado-la-epsilon/</link>
      <pubDate>Thu, 16 Jul 2020 12:05:57 +0000</pubDate>
      
      <guid>/2020/07/16/no-tus-datos-no-tienen-sobredispersion-es-que-el-gato-de-nelder-se-ha-merendado-la-epsilon/</guid>
      <description>El modelo de Poisson viene a decir que si y es una variable con valores 0, 1,&amp;hellip; y x1,&amp;hellip;, xn son variables explicativas tiene cierto sentido en algunos casos plantear un modelo de la forma
$latex y | x_i \sim \text{Pois}(\exp(a_0 + \sum_i a_i x_i) ),$
Es decir , para cada combinación de las xi, el modelo proporciona el parámetro de una distribución de Poisson de la que y es una realización.</description>
    </item>
    
    <item>
      <title>¿Lineal o logística?</title>
      <link>/2020/02/14/lineal-o-logistica/</link>
      <pubDate>Fri, 14 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/14/lineal-o-logistica/</guid>
      <description>Hay cosas tan obvias que ni se plantea la alternativa. Pero luego va R. Gomila y escribe Logistic or Linear? Estimating Causal Effects of Treatments on Binary Outcomes Using Regression Analysis que se resume en lo siguiente: cuando te interese la explicación y no la predicción, aunque tu y sea binaria, usa regresión lineal y pasa de la logística.
Nota: La sección 4.2 de An Introduction to Statistical Learning de se titula precisamente Why Not Linear Regression?</description>
    </item>
    
    <item>
      <title>No sé cómo traducir &#34;Partially additive (generalized) linear model trees&#34;</title>
      <link>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</link>
      <pubDate>Wed, 12 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</guid>
      <description>Sin embargo, basta con mirar la foto
leer la entrada de hace unos días, que se refiere a algo muy parecido (y que, en particular, describe los datos usados en el modelo que representa) y, en el peor de los casos, esto, para hacerse idea de su utilidad y relevancia.</description>
    </item>
    
    <item>
      <title>Sobre los coeficientes de los GLM en Scikit-learn</title>
      <link>/2019/12/02/sobre-los-coeficientes-de-los-glm-en-scikit-learn/</link>
      <pubDate>Mon, 02 Dec 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/12/02/sobre-los-coeficientes-de-los-glm-en-scikit-learn/</guid>
      <description>Pensé que ya había escrito sobre el asunto porque tropecé con él en un proyecto hace un tiempo. Pero mi menoria se había confundido con otra entrada, Sobre la peculiarisima implementacion del modelo lineal en (pseudo-)Scikit-learn, donde se discute, precisamente, un problema similar si se lo mira de cierta manera o diametralmente opuesto si se ve con otra perspectiva.
Allí el problema era que Scikit-learn gestionaba muy sui generis el insidioso problema de la colinealidad.</description>
    </item>
    
    <item>
      <title>(g)lms con coeficientes &gt; 0 (p.e.)</title>
      <link>/2019/08/21/glms-con-coeficientes-0-p-e/</link>
      <pubDate>Wed, 21 Aug 2019 09:13:51 +0000</pubDate>
      
      <guid>/2019/08/21/glms-con-coeficientes-0-p-e/</guid>
      <description>Alguien quería un glm forzando determinados coeficientes &amp;gt;0. * Una solución 100% bayesiana no era una opción.  Hay varias opciones por ahí. Pero me ha sorprendido que la opción esté disponible en glmnet::glmnet:
Filosóficamente, es un tanto sorprendente: de alguna manera, glmnet es glm con prioris alrededor del cero. Los límites superiores e inferiores permiten introducir información a priori adicional no necesariamente compatible con la anterior.
Desde el punto de vista de la implementación, tiene sentido que estas opciones estén disponibles.</description>
    </item>
    
    <item>
      <title>Modelos log-lineales y GLMs con regularización</title>
      <link>/2019/02/25/modelos-log-lineales-y-glms-con-regularizacion/</link>
      <pubDate>Mon, 25 Feb 2019 08:13:14 +0000</pubDate>
      
      <guid>/2019/02/25/modelos-log-lineales-y-glms-con-regularizacion/</guid>
      <description>Hace años tomé el curso de NLP de M. Collings en Coursera (¡muy recomendable!), uno de cuyos capítulos trataba de los llamados modelos loglineales. En esto, Collings sigue una nomenclatura un tanto personal porque la mayor parte de la gente se refiere con ese nombre a algo que no es exactamente lo mismo (y dentro del mundo de las tablas de contingencia).
El otro día, sin embargo, me pensé que los modelos loglineales à la Collings me serían muy útiles para un problema de clasificación en el que estamos trabajando.</description>
    </item>
    
    <item>
      <title>Podría ser Simpson, pero a lo mejor es &#34;otra cosita&#34;</title>
      <link>/2018/09/04/podria-ser-simpson-pero-a-lo-mejor-es-otra-cosita/</link>
      <pubDate>Tue, 04 Sep 2018 08:13:49 +0000</pubDate>
      
      <guid>/2018/09/04/podria-ser-simpson-pero-a-lo-mejor-es-otra-cosita/</guid>
      <description>Observo en The deadly effects of losing health insurance cómo el efecto de interés, 15% sobre una población se convierte en efectos del 16%, 23% y 30% en sus tres subpoblaciones (útimas columnas de la tabla que ocupa la página 25). Es raro que el efecto combinado no esté cerca de la media ponderada (por población) de cada uno de sus subcomponentes.
Podría ser Simpson, pero hay motivos para pensar que hayan cambiado las proporciones de las poblaciones subyacentes (demasiado).</description>
    </item>
    
    <item>
      <title>¿Cómo era el regulador en 1973?</title>
      <link>/2016/03/16/como-era-el-regulador-en-1973/</link>
      <pubDate>Wed, 16 Mar 2016 09:13:57 +0000</pubDate>
      
      <guid>/2016/03/16/como-era-el-regulador-en-1973/</guid>
      <description>Estos días he estado haciendo de campaña promoviendo el uso de nuevas técnicas de análisis de datos en ámbitos como, p.e., el riesgo de crédito, uno de esos campos sujetos al parecer de un regulador (el Banco de España, en este caso).
La gente con la que he debatido al respecto tiende a aplicar esa forma cuasiperfecta de censura que es la autocensura previa. La autocensura previa ni siquiera requiere la acción explícita del censor: es el potencial censurado el que la aplica de mejor o peor gana automáticamente&amp;hellip; por si las moscas.</description>
    </item>
    
    <item>
      <title>Grandes datos, máquinas pequeñas (y regresiones logísticas con variables categóricas)</title>
      <link>/2015/01/27/grandes-datos-maquinas-pequenas-y-regresiones-logisticas-con-variables-categoricas/</link>
      <pubDate>Tue, 27 Jan 2015 07:13:49 +0000</pubDate>
      
      <guid>/2015/01/27/grandes-datos-maquinas-pequenas-y-regresiones-logisticas-con-variables-categoricas/</guid>
      <description>Preguntaba el otro día Emilio Torres esto en R-help-es. Resumo la pregunta. Se trata de una simulación de unos datos y su ajuste mediante una regresión logística para ver si los coeficientes obtenidos son o no los esperados (teóricamente y por construcción).
El código de Emilio (cuyos resultados no podemos reproducir porque no nos ha contado qué similla usa) es
logisticsimulation &amp;lt;- function(n){ dat &amp;lt;- data.frame(x1=sample(0:1, n,replace=TRUE), x2=sample(0:1, n,replace=TRUE)) odds &amp;lt;- exp(-1 - 4 * dat$x1 + 7*dat$x2 - 1 *dat$x1* dat$x2 ) pr &amp;lt;- odds/(1+odds) res &amp;lt;- replicate(100, { dat$y &amp;lt;- rbinom(n,1,pr) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>No me ha salido, pero lo cuento igual</title>
      <link>/2015/01/20/no-me-ha-salido-pero-lo-cuento-igual/</link>
      <pubDate>Tue, 20 Jan 2015 07:13:54 +0000</pubDate>
      
      <guid>/2015/01/20/no-me-ha-salido-pero-lo-cuento-igual/</guid>
      <description>Creo que todos sabéis la historia de las admisiones de la Universidad de Berkeley y la paradoja de Simpson. Con palabras, muchas palabras, está contado, por ejemplo, aquí. Y si buscáis ubc admissions simpson en Google la encontraréis también en modo --verbose en muchos más sitios.
En R puede resumirse en
library(reshape2) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) data(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/UCBAdmissions&amp;quot;&amp;gt;UCBAdmissions) raw &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/as.data.frame&amp;quot;&amp;gt;as.data.frame(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/UCBAdmissions&amp;quot;&amp;gt;UCBAdmissions) dat &amp;lt;- dcast(raw, Gender + Dept ~ &amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/AdMit&amp;quot;&amp;gt;Admit) mod.</description>
    </item>
    
    <item>
      <title>La diapositiva perdida, versión algo más extendida</title>
      <link>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</link>
      <pubDate>Mon, 22 Sep 2014 07:13:49 +0000</pubDate>
      
      <guid>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</guid>
      <description>Tuve que saltarme una diapositiva en el DataBeers de Madrid del pasado jueves.
(A propósito, aquí están las 1+20 diapositivas).
La decimonona, de la que trata la entrada, viene a hablar de lo siguiente. Tenemos una base de datos con sujetos (ids) que hacen cosas en determinados momentos. No es inhabitual calcular la frecuencia de esos sujetos así:
&amp;lt;code&amp;gt;select id, count(*) as freq from mytabla where fecha between current_date - 7 and current_date group by id ; &amp;lt;/code&amp;gt;  Esa variable se utiliza frecuentemente ya sea como descriptor de los sujetos o como alimento de otros modelos.</description>
    </item>
    
    <item>
      <title>¿Victoria o diferencia de puntos? ¿lm o glm?</title>
      <link>/2014/03/04/victoria-o-diferencia-de-puntos-lm-o-glm/</link>
      <pubDate>Tue, 04 Mar 2014 07:08:18 +0000</pubDate>
      
      <guid>/2014/03/04/victoria-o-diferencia-de-puntos-lm-o-glm/</guid>
      <description>Supongamos que queremos construir un modelo para predecir quién ganará un determinado partido de baloncesto basándonos en datos diversos. Y en un histórico, por supuesto.
Podemos utilizar una regresión logística así:
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) my.coefs &amp;lt;- -2:2 n &amp;lt;- 200 train.n &amp;lt;- floor(2*n/3) test.error.glm &amp;lt;- function(){ X &amp;lt;- matrix(rnorm(n*5), n, 5) Y &amp;lt;- (0.2 + X %*% my.coefs + rnorm(n)) &amp;gt; 0 train &amp;lt;- sample(1:n, train.n) X &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/as.data.frame&amp;quot;&amp;gt;as.data.frame(X) X$Y &amp;lt;- Y mod.</description>
    </item>
    
    <item>
      <title>Experimentos con el paquete gbm</title>
      <link>/2014/02/06/experimentos-con-el-paquete-gbm/</link>
      <pubDate>Thu, 06 Feb 2014 08:07:56 +0000</pubDate>
      
      <guid>/2014/02/06/experimentos-con-el-paquete-gbm/</guid>
      <description>No conocía el paquete gbm. Pero como ahora ando rodeado de data scientists que no son estadísticos&amp;hellip;
Bueno, la cuestión es que había que ajustar un modelo para el que yo habría hecho algo parecido a
dat &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/read.csv&amp;quot;&amp;gt;read.csv(&amp;quot;http://www.ats.ucla.edu/stat/data/poisson_sim.csv&amp;quot;) summary(m.glm &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/glm&amp;quot;&amp;gt;glm(num_awards ~ prog + math, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/family&amp;quot;&amp;gt;family = &amp;quot;poisson&amp;quot;, data = dat)) # Call: # glm(formula = num_awards ~ prog + math, family = &amp;quot;poisson&amp;quot;, data = dat) # # Deviance Residuals: # Min 1Q Median 3Q Max # -2.</description>
    </item>
    
    <item>
      <title>Algunos problemas de la regresión paso a paso (&#34;stepwise&#34;)</title>
      <link>/2014/01/28/algunos-problemas-de-la-regresion-paso-a-paso-stepwise/</link>
      <pubDate>Tue, 28 Jan 2014 08:58:55 +0000</pubDate>
      
      <guid>/2014/01/28/algunos-problemas-de-la-regresion-paso-a-paso-stepwise/</guid>
      <description>Fueron problemas planteados por Frank Harrell, recopilados aquí y ahora traducidos por mí para mi bitácora.
Problemas de la regresión paso a paso:
 * La R-cuadrado obtenida está muy sesgada hacia arriba. * Los test F y chi-cuadrado que aparecen al lado de las variables no siguen dichas distribuciones. * Los intervalos de confianza son demasiado (e incorrectamente) estrechos. * Los p-valores obtenidos no tienen el significado esperado y el de corregirlos adecuadamente es un problema muy difícil.</description>
    </item>
    
    <item>
      <title>Corrección por exposición del modelo logístico</title>
      <link>/2012/04/11/correccion-por-exposicion-del-modelo-logistico/</link>
      <pubDate>Wed, 11 Apr 2012 06:52:19 +0000</pubDate>
      
      <guid>/2012/04/11/correccion-por-exposicion-del-modelo-logistico/</guid>
      <description>He tropezado con una extensión curiosa y que no conocía del modelo logístico que lo emparenta un tanto con los modelos de supervivencia. Es un problema que aparece en los modelos de los actuarios, por ejemplo, y en la supervivencia de nidos (sí, nidos de bichos alados), parece.
Es el siguiente: supongamos que unos sujetos están expuestos a un cierto suceso cuya probabilidad, $latex p_i$, depende del sujeto a través del esquema habitual de la regresión logística (es decir, depende de algunas variables como el sexo, etc.</description>
    </item>
    
  </channel>
</rss>
