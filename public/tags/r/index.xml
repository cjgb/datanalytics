<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>r on datanalytics</title>
    <link>/tags/r/</link>
    <description>Recent content in r on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 21 Sep 2021 09:13:00 +0000</lastBuildDate><atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Aún más sobre propagación de errores (y rv)</title>
      <link>/2021/09/21/aun-mas-sobre-propagacion-de-errores-y-rv/</link>
      <pubDate>Tue, 21 Sep 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/09/21/aun-mas-sobre-propagacion-de-errores-y-rv/</guid>
      <description>[Menos mal que se me ha ocurrido buscar en mi propio blog sobre el asunto y descubrir —no lo recordaba— que ya había tratado el asunto previamente en entradas como esta, esta o esta.]
El problema de la propagación de errores lo cuentan muy bien Iñaki Úcar y sus coautores aquí. Por resumirlo: tienes una cantidad, $latex X$ conocida solo aproximadamente —en concreto, con cierto error— e interesa conocer y acotar el error de una expresión $latex f(X)$.</description>
    </item>
    
    <item>
      <title>Mi apuesta para el larguísimo plazo: Julia</title>
      <link>/2021/07/14/mi-apuesta-para-el-larguisimo-plazo-julia/</link>
      <pubDate>Wed, 14 Jul 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/07/14/mi-apuesta-para-el-larguisimo-plazo-julia/</guid>
      <description>Larguísimo, arriba, significa algo así como 10 o 20 años. Vamos, como cuando comencé con R allá por el 2001. * R es, reconozcámoslo, un carajal. Pocas cosas mejores que esta para convencerse. * No dejo de pensar en aquello que me dijo un profesor en 2001: que R no podría desplazar a SAS porque no tenía soporte modelos mixtos. Yo no sabía qué eran los modelos mixtos en esa época pero, desde entonces, vine a entender y considerar que &amp;ldquo;tener soporte para modelos mixtos&amp;rdquo; venía a ser como aquello que convertía a un lenguaje para el análisis de datos en una alternativa viable y seria a lo existente.</description>
    </item>
    
    <item>
      <title>PCA robusto</title>
      <link>/2021/06/01/pca-robusto/</link>
      <pubDate>Tue, 01 Jun 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/06/01/pca-robusto/</guid>
      <description>Esta semana he descubierto el PCA robusto. En la frase anterior he conjugado el verbo en cursiva porque lo he pretendido usar con un significado que matiza el habitual: no es que haya tropezado con él fortuitamente, sino que el PCA robusto forma parte de esa inmensa masa de conocimiento estadístico que ignoro pero que, llegado el caso, con un par de clicks, una lectura en diagonal y la descarga del software adecuado, puedo incorporarlo y usarlo a voluntad.</description>
    </item>
    
    <item>
      <title>Un viejo truco para que R vuele</title>
      <link>/2021/05/18/un-viejo-truco-para-que-r-vuele/</link>
      <pubDate>Tue, 18 May 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/05/18/un-viejo-truco-para-que-r-vuele/</guid>
      <description>Existe un viejo truco —mas no por ello conocido— para que R vuele. Lo aprendí en una conferencia de uno de los padres de R (aunque ya no recuerdo quién era) en la primera década del siglo. El problema que tenía entre manos era el de ajustar unos cuantos miles de regresiones logísticas. Además de hacer uso de los métodos de paralelización, aún muy rudimentarios en la época, uno de los trucos más efectivos que utilizaba era el de desnudar las funciones.</description>
    </item>
    
    <item>
      <title>Hay mil motivos para criticar una regresión &#34;trucha&#34;, pero una R² baja no es uno de ellos</title>
      <link>/2021/02/16/hay-mil-motivos-para-criticar-una-regresion-trucha-pero-una-r%c2%b2-baja-no-es-uno-de-ellos/</link>
      <pubDate>Tue, 16 Feb 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/02/16/hay-mil-motivos-para-criticar-una-regresion-trucha-pero-una-r%c2%b2-baja-no-es-uno-de-ellos/</guid>
      <description>Todo esto arranca con el tuit:
https://twitter.com/juanrallo/status/1356242130746941443
Esa gráfica, extraída de un documento de la OCDE, creo, fue uno de los argumentos esgrimidos por JR Rallo para defender cierta postura que no viene al caso. Lo relevante para estas páginas es que fue contestado y protestado por muchos —de algunos de los cuales, dada su autoproclamada condición de divulgadores científicos, cabría esperar más— en términos exclusivamente de lo pequeño de la R².</description>
    </item>
    
    <item>
      <title>Análisis de eventos recurrentes</title>
      <link>/2020/12/02/analisis-de-eventos-recurrentes/</link>
      <pubDate>Wed, 02 Dec 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/12/02/analisis-de-eventos-recurrentes/</guid>
      <description>He sido fan del análisis de los eventos recurrentes desde antes incluso de saber que existía tal cosa formalmente.
Es una extensión del análisis de la supervivencia donde resucitas y vuelves a morirte a lo Sísifo. Es decir, en el análisis de la supervivencia, te mueres y ya; por eso, si quieres extender el análisis de la supervivencia a asuntos tales como compras de clientes es necesario usar el calzador muy heterodoxamente.</description>
    </item>
    
    <item>
      <title>IGN &#43; R &#43; leaflet</title>
      <link>/2020/10/13/ign-r-leaflet/</link>
      <pubDate>Tue, 13 Oct 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/10/13/ign-r-leaflet/</guid>
      <description>Iba a escribir una entrada técnica al respecto, pero resulta que ya la había hecho hace un tiempo y no me acordaba.
Solo quiero abundar en el tema para recordaros que si os interesa mostrar mapas de España vía [leaflet](https://rstudio.github.io/leaflet/), en lugar de usar las capas por defecto, que vaya a saber uno de dónde las sacan, uno siempre puede tirar de la cartografía oficial.
Uno de los motivos puede ser que el mapa forme parte de una aplicación seria.</description>
    </item>
    
    <item>
      <title>Una guía (breve, concisa) para crear código (y proyectos) reproducibles</title>
      <link>/2020/09/30/una-guia-breve-concisa-para-crear-codigo-y-proyectos-reproducibles/</link>
      <pubDate>Wed, 30 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/30/una-guia-breve-concisa-para-crear-codigo-y-proyectos-reproducibles/</guid>
      <description>Está aquí y creo que no se le puede quitar ni poner una coma. Es particularmente oportuna porque trata todas esas cosas que nunca se enseñan y que la mucha gente, en el peor de los casos, malaprende.</description>
    </item>
    
    <item>
      <title>En defensa de iris</title>
      <link>/2020/09/21/en-defensa-de-iris/</link>
      <pubDate>Mon, 21 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/21/en-defensa-de-iris/</guid>
      <description>El archiconocido conjunto de datos iris es víctima reciente de un ataque relacionado con su pecado original: haber tenido unos padres estigmatizados hoy por su otrora popular idea de que gracias a la ciencia podríamos construir un futuro mejor.
También ha sido víctima de ataques, esta vez más endógenos, relacionados con lo menguado de su tamaño y lo trivial de su estructura.
Vengo aquí a romper una lanza —tres, más bien— en favor de este muy querido de los más conjunto de datos.</description>
    </item>
    
    <item>
      <title>Esto no es práctico, pero sí bonito; bonito, además, de esa forma inasequible a la chusma</title>
      <link>/2020/09/18/esto-no-es-practico-pero-si-bonito-bonito-ademas-de-esa-forma-inasequible-a-la-chusma/</link>
      <pubDate>Fri, 18 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/18/esto-no-es-practico-pero-si-bonito-bonito-ademas-de-esa-forma-inasequible-a-la-chusma/</guid>
      <description>Va de muestrear los números $latex 1, \dots, n$ que tienen asignadas probabilidades $latex p_1, \dots, p_n$. Una manera muy impráctica (en R, basta usar sample) y nada intuitiva de hacerlo es recurriendo a la distribución de Gumbel:
library(evd) pes &amp;lt;- runif(5) pes &amp;lt;- pes / sum(pes) gammas &amp;lt;- log(pes) + 2 x &amp;lt;- rgumbel(length(pes)) muestra &amp;lt;- which.max(gammas + x)  O, en masa, aplicando
get_samples &amp;lt;- function(n){ replicate(n, { x &amp;lt;- rgumbel(length(pes)) which.</description>
    </item>
    
    <item>
      <title>Una herramienta para el análisis no paramétrico de series temporales</title>
      <link>/2020/09/17/una-herramienta-para-el-analisis-no-parametrico-de-series-temporales/</link>
      <pubDate>Thu, 17 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/17/una-herramienta-para-el-analisis-no-parametrico-de-series-temporales/</guid>
      <description>Sí, es un ejemplar de mi colección de rarezas estadísticas, técnicas que no entran dentro del currículo estándar pero que pudieran resultar útiles en algún momento, para algún caso particular.
Hoy, perfiles matriciales para series temporales, una técnica que sirve esencialmente, para identificar formas que se repiten en series temporales, como
Entiendo además que, como consecuencia, también para señalar aquellos ciclos en que se produzcan perfiles anómalos, para su evaluación. Pero dejo que consultéis la información en, por ejemplo, aquí y aquí.</description>
    </item>
    
    <item>
      <title>Distribuciones (¿de renta? ¿solo de renta?) a partir de histogramas</title>
      <link>/2020/09/10/distribuciones-de-renta-solo-de-renta-a-partir-de-histogramas/</link>
      <pubDate>Thu, 10 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/10/distribuciones-de-renta-solo-de-renta-a-partir-de-histogramas/</guid>
      <description>En el primer número de la novísima revista Spanish Journal of Statistics aparece un artículo con un título tentador: Recovering income distributions from aggregated data via micro-simulations.
Es decir, un artículo que nos puede permitir, por ejemplo, muestrear lo que la AEAT llama rendimientos a partir de lo que publica (aquí):
Uno de los métodos de los que sostienen el ignominioso a mí me funciona está basado en el modelo</description>
    </item>
    
    <item>
      <title>Más sobre variables instrumentales con R</title>
      <link>/2020/09/08/mas-sobre-variables-instrumentales-con-r/</link>
      <pubDate>Tue, 08 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/08/mas-sobre-variables-instrumentales-con-r/</guid>
      <description>[El título de esta entrada tiene un + delante porque ya escribí sobre el asuntotiempo atrás.]
Con la excusa de la reciente publicación del paquete ivreg (para el ajuste de modelos con variables instrumentales, por si el contexto no lo hace evidente), he mirado a ver quién estaba construyendo y ajustando modelos generativos menos triviales que los míos (véase el enlace anterior) para que quede más claro de qué va la cosa.</description>
    </item>
    
    <item>
      <title>Contrariamente a lo que creía recordar, &#34;Hot deck&#34; != LOCF</title>
      <link>/2020/09/03/contrariamente-a-lo-que-creia-recordar-hot-deck-locf/</link>
      <pubDate>Thu, 03 Sep 2020 08:13:00 +0000</pubDate>
      
      <guid>/2020/09/03/contrariamente-a-lo-que-creia-recordar-hot-deck-locf/</guid>
      <description>Imputación (que es algo en lo que muy a regañadientes estoy trabajando estos días).
Si de verdad tienes que imputar datos en una tabla (y solo en ese caso), solo hay un criterio: construye un modelo para predecir los valores faltantes en función del resto y reemplaza el NA por la su predicción.
El modelo puede ser tan tonto como
lm(my_col ~ 1, na.rm = T)
que resulta en la popular estrategia de reemplazar los NAs por la media del resto de las observaciones.</description>
    </item>
    
    <item>
      <title>Misma p, distinto n, luego...</title>
      <link>/2020/07/30/misma-p-distinto-n-luego/</link>
      <pubDate>Thu, 30 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/30/misma-p-distinto-n-luego/</guid>
      <description>Tres situaciones. La primera:
n &amp;lt;- 20 y &amp;lt;- 15 test &amp;lt;- prop.test(y, n, p = .5) test$p.value # [1] 0.04417134 test$conf.int # 0.5058845 0.9040674  La segunda:
n &amp;lt;- 200 y &amp;lt;- 115 test &amp;lt;- prop.test(y, n, p = 0.5) test$p.value #[1] 0.04030497 test$conf.int # 0.5032062 0.6438648  Y la tercera:
n &amp;lt;- 2000 y &amp;lt;- 1046 test &amp;lt;- prop.test(y, n, p = 0.5) test$p.value #[1] 0.0418688 test$conf.int # 0.</description>
    </item>
    
    <item>
      <title>Por supuesto que tengo más variables que observaciones... ¿y?</title>
      <link>/2020/07/23/por-supuesto-que-tengo-mas-variables-que-observaciones-y/</link>
      <pubDate>Thu, 23 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/23/por-supuesto-que-tengo-mas-variables-que-observaciones-y/</guid>
      <description>He intentado replicar los resultados de la entrada de ayer con GAM (vía [mgcv](https://CRAN.R-project.org/package=mgcv)) así (véase el enlace anterior para la definición de los datos):
library(mgcv) modelo_gam &amp;lt;- gam( y ~ x + s(id, bs = &amp;quot;re&amp;quot;), data = datos, method = &amp;quot;REML&amp;quot;, family = &amp;quot;poisson&amp;quot;)  Y nada:
Error in gam(y ~ x + s(id, bs = &amp;quot;re&amp;quot;), data = datos, method = &amp;quot;REML&amp;quot;, : Model has more coefficients than data  Sí, ya sé que tengo más variables que observaciones.</description>
    </item>
    
    <item>
      <title>Sobremuestreando x (y no y)</title>
      <link>/2020/06/29/sobremuestreando-x-y-no-y/</link>
      <pubDate>Mon, 29 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/29/sobremuestreando-x-y-no-y/</guid>
      <description>Construyo unos datos (artificiales, para conocer la verdad):
n &amp;lt;- 10000 x1 &amp;lt;- rnorm(n) x2 &amp;lt;- rnorm(n) probs &amp;lt;- -2 + x1 + x2 probs &amp;lt;- 1 / (1 + exp(-probs)) y &amp;lt;- sapply(probs, function(p) rbinom(1, 1, p)) dat &amp;lt;- data.frame(y = y, x1 = x1, x2 = x2)  Construyo un modelo de clasificación (logístico, que hoy no hace falta inventar, aunque podría ser cualquier otro):
summary(glm(y ~ x1 + x2, data = dat, family = binomial)) #Call: #glm(formula = y ~ x1 + x2, family = binomial, data = dat) # #Deviance Residuals: # Min 1Q Median 3Q Max #-2.</description>
    </item>
    
    <item>
      <title>Cuidado con la aleatoriedad &#34;pochola&#34;</title>
      <link>/2020/06/15/cuidado-con-la-aleatoriedad-pochola/</link>
      <pubDate>Mon, 15 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/15/cuidado-con-la-aleatoriedad-pochola/</guid>
      <description>Abundo sobre mi entrada del otro día. Usando números aleatorios hirsutos,
n &amp;lt;- 200 x &amp;lt;- runif(n) plot(cumsum(x - .5), type = &amp;quot;l&amp;quot;)  produce
mientras que
library(randtoolbox) s &amp;lt;- sobol(n, 1, scrambling = 3) plot(cumsum(s - .5), type = &amp;quot;l&amp;quot;)  genera
que tiene un cariz totalmente distinto.</description>
    </item>
    
    <item>
      <title>Aleatoriedad hirsuta, aleatoriedad pochola</title>
      <link>/2020/06/08/aleatoriedad-hirsuta-aleatoriedad-pochola/</link>
      <pubDate>Mon, 08 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/08/aleatoriedad-hirsuta-aleatoriedad-pochola/</guid>
      <description>Contemplando y comparando
y
se me han venido a la mente los adjetivos hirsuto y pocholo para calificar las respectivas formas de aleatoriedad que representan. La primera es el resultado del habitual
n &amp;lt;- 200 x &amp;lt;- runif(n) y &amp;lt;- runif(n) plot(x, y, pch = 16)  mientras que la segunda exige el más sofisticado
library(randtoolbox) s &amp;lt;- sobol(n, 2, scrambling = 3) x &amp;lt;- s[,1] y &amp;lt;- s[,2] plot(x, y, pch = 16)  Se ve que Sobol quería rellenar más armoniosamente el espacio.</description>
    </item>
    
    <item>
      <title>De histograma a distribuciones (usando la de Burr)</title>
      <link>/2020/06/05/de-histograma-a-distribuciones-usando-la-de-burr/</link>
      <pubDate>Fri, 05 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/05/de-histograma-a-distribuciones-usando-la-de-burr/</guid>
      <description>Tengo una entrada perpetuamente pendiente que se pospone, entre otras cosas, porque aún no he encontrado una manera satisfactoria para muestrear histogramas. Una de las vías sería dar con (y ajustar) una distribución subyacente que generase unos histogramas similares.
Hoy voy a contar un ejemplo de cómo puede fallar tal estrategia.
Por un lado he bajado datos de la distribución de renta en España del INE:
Por otro, me he dejado convencer temporalmente de que la distribución de Burr podría ser conveniente para modelar la distribución de ingresos de los hogares (Wikipedia dixit!</description>
    </item>
    
    <item>
      <title>Optimización estocástica</title>
      <link>/2020/05/22/optimizacion-estocastica/</link>
      <pubDate>Fri, 22 May 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/05/22/optimizacion-estocastica/</guid>
      <description>Una de los proyectos en los que estoy trabajando últimamente está relacionado con un problema de optimización no lineal: tengo un modelo (o una familia de modelos) no lineales con una serie de parámetros, unos datos y se trata de lo que no mercería más explicación: encontrar los que minimizan cierta función de error.
Tengo implementadas dos vías:
 La nls, que usa un optimizador numérico genérico para encontrar esos mínimos.</description>
    </item>
    
    <item>
      <title>¿Agregar antes de modelar?</title>
      <link>/2020/05/11/agregar-antes-de-modelar/</link>
      <pubDate>Mon, 11 May 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/05/11/agregar-antes-de-modelar/</guid>
      <description>El otro día me pasaron unos datos artificiales para poder probar el ajuste de cierto tipo de modelos. El autor de la simulación construyó tres conjuntos de pares (x,y) y luego los agregó (media de los y agrupando por x) antes de proporcionármelos.
¿Tiene sentido agregar antes de modelar? Incluso sin entrar en el problema del potencial número desigual de observaciones por punto (datos desbalanceados) o las heterogeneidades entre las distintas iteraciones (que nos llevaría al mundo de los modelos mixtos).</description>
    </item>
    
    <item>
      <title>Más sobre el consumo alimentario mensual en los hogares españoles en R</title>
      <link>/2020/04/28/mas-sobre-el-consumo-alimentario-mensual-en-los-hogares-espanoles-en-r/</link>
      <pubDate>Tue, 28 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/28/mas-sobre-el-consumo-alimentario-mensual-en-los-hogares-espanoles-en-r/</guid>
      <description>He actualizado el repositorio que anuncié aquí, es decir, este, con una función adicional cuya razón de ser es la siguiente:
 El ministerio de la cosa hace una encuesta sobre hábitos de compra y consumo de alimentos en España. * Luego proporciona dos vistas sobre los mismos datos: * Una, en forma de ficheros .xls con más profundidad histórica, datos más recientes y menos variables. * Otra, a través de un formulario web que devuelve páginas con tablas html que tiene menos profundidad histórica, tiene un retraso mayor de publicación pero alguna variable más (p.</description>
    </item>
    
    <item>
      <title>Reducción de la dimensionalidad</title>
      <link>/2020/04/22/reduccion-de-la-dimensionalidad/</link>
      <pubDate>Wed, 22 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/22/reduccion-de-la-dimensionalidad/</guid>
      <description>está extraído de aquí.</description>
    </item>
    
    <item>
      <title>Regresión tradicional vs multinivel</title>
      <link>/2020/04/13/regresion-tradicional-vs-multinivel/</link>
      <pubDate>Mon, 13 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/13/regresion-tradicional-vs-multinivel/</guid>
      <description>Ayer se leía en Twitter que
https://twitter.com/joscani/status/1249017607199621123
Cabe preguntarse qué pasa si se analizan los mismos datos usando ambas técnicas. Obviamente, hay muchos tipos de datos y supongo que los resultados variarán según qué variante se utilice. Aquí voy a centrarme en unos donde hay medidas repetidas de un factor aleatorio. También voy a situarme en un contexto académico, en el que interesan más las estimaciones de los efectos fijos, que en uno más próximo a mi mundo, la consultoría, donde son más relevantes las estimaciones regularizadas de los efectos aleatorios.</description>
    </item>
    
    <item>
      <title>Spike and slab: otro método para seleccionar variables</title>
      <link>/2020/04/07/spike-and-slab-otro-metodo-para-seleccionar-variables/</link>
      <pubDate>Tue, 07 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/07/spike-and-slab-otro-metodo-para-seleccionar-variables/</guid>
      <description>Me sorprende ver todavía a gente utilizar técnicas stepwise para la selección de variables en modelos. Sobre todo, existiendo herramientas como elastic net o lasso.
Otra de las técnicas disponibles es la del spike and slab (de la que oí hablar, recuerdo, por primera vez en el artículo de Varian Big Data: New Tricks for Econometrics). Es una técnica de inspiración bayesiana en cuya versión más cruda se imponen sobre las variables del modelo de regresión prioris que son una mezcla de dos distribuciones:</description>
    </item>
    
    <item>
      <title>Consumo alimentario mensual en los hogares españoles en R</title>
      <link>/2020/04/01/consumo-alimentario-mensual-en-los-hogares-espanoles-en-r/</link>
      <pubDate>Wed, 01 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/01/consumo-alimentario-mensual-en-los-hogares-espanoles-en-r/</guid>
      <description>[Coge aire: aquí arranca una frase muy larga] Simplemente, que he creado un repositorio en GitHub para extraer información de los ficheros excel y sus muchas pestañas que componen el sistema de difusión de datos estadísticos sobre consumo de alimentos y bebidas de las familias que realiza el ministerio de como se llame ahora.
La página de ministerio es esta; el repositorio, este.
Nota: hay mucha información muy buena que merece ser más conocida y mejor explotada.</description>
    </item>
    
    <item>
      <title>CausalImpact me ha complacido mucho</title>
      <link>/2020/03/27/causalimpact-me-ha-complacido-mucho/</link>
      <pubDate>Fri, 27 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/27/causalimpact-me-ha-complacido-mucho/</guid>
      <description>Estoy aquí analizando datos para un cliente interesado en estudiar si como consecuencia de uno de esos impuestos modennos con los que las administraciones nos quieren hacer más sanos y robustos. En concreto, le he echado un vistazo a si el impuesto ha encarecido el precio de los productos gravados (sí) y si ha disminuido su demanda (no) usando [CausalImpact](https://CRAN.R-project.org/package=CausalImpact) y me ha complacido mucho que la salida de summary(model, &amp;quot;report&amp;quot;) sea:</description>
    </item>
    
    <item>
      <title>Densidades unidimensionales en R</title>
      <link>/2020/03/26/densidades-unidimensionales-en-r/</link>
      <pubDate>Thu, 26 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/26/densidades-unidimensionales-en-r/</guid>
      <description>Es un asunto tangencial que, además, se soluciona las más de las veces con density. Pero parece que tiene mucha más ciencia detrás.
Por algún motivo, acabé un día en la página del paquete [logspline](https://CRAN.R-project.org/package=logspline), que ajusta densidades usando splines. Su promesa es que puede realizar ajustes de densidades tan finos como
que está extraído de Polynomial Splines and their Tensor Products in Extended Linear Modeling, el artículo que le sirve de base teórica.</description>
    </item>
    
    <item>
      <title>Casos de coronavirus en Madrid provincia: un modelo un poco menos crudo basado en la mortalidad (II)</title>
      <link>/2020/03/20/casos-de-coronavirus-en-madrid-provincia-un-modelo-un-poco-menos-crudo-basado-en-la-mortalidad-ii/</link>
      <pubDate>Fri, 20 Mar 2020 09:18:28 +0000</pubDate>
      
      <guid>/2020/03/20/casos-de-coronavirus-en-madrid-provincia-un-modelo-un-poco-menos-crudo-basado-en-la-mortalidad-ii/</guid>
      <description>[Nota: el código relevante sigue estando en GitHub. No es EL código sino UN código que sugiere todos los cambios que se te puedan ocurrir. Entre otras cosas, ilustra cómo de dependientes son los resultados de la formulación del modelo, cosa muchas veces obviada.]
Continúo con la entrada de ayer, que contenía más errores que información útil respecto a objetivos y métodos.
Los objetivos del análisis son los de obtener una estimación del número de casos activos de coronavirus en la provincia de Madrid.</description>
    </item>
    
    <item>
      <title>Casos de coronavirus en Madrid provincia: un modelo muy crudo basado en la mortalidad</title>
      <link>/2020/03/19/casos-de-coronavirus-en-madrid-provincia-un-modelo-muy-crudo-basado-en-la-mortalidad/</link>
      <pubDate>Thu, 19 Mar 2020 17:48:07 +0000</pubDate>
      
      <guid>/2020/03/19/casos-de-coronavirus-en-madrid-provincia-un-modelo-muy-crudo-basado-en-la-mortalidad/</guid>
      <description>[Nota: si no sabes interpretar las hipótesis embebidas en el código que publico, que operan como enormes caveats, no hagas caso en absoluto a los resultados. He publicado esto para ver si otros que saben más que yo lo pulen y consiguen un modelo más razonable usándolo tal vez, ojalá, como núcleo.]
[Edición: He subido el código a GitHub.]
[El código de esta sección y los resultados contienen errores de bulto; consúltese el código de GitHub.</description>
    </item>
    
    <item>
      <title>lme4 &#43; simulate</title>
      <link>/2020/03/18/lme4-simulate/</link>
      <pubDate>Wed, 18 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/18/lme4-simulate/</guid>
      <description>Esta entrada es casi una referencia para mí. Cada vez tiro más de [lme4](https://CRAN.R-project.org/package=lme4) en mis modelos y en uno en concreto que tengo entre manos toca simular escenarios. Para lo cual, [simulate.merMod](https://www.rdocumentation.org/packages/lme4/versions/1.1-21/topics/simulate.merMod).
Véamoslo en funcionamiento. Primero, datos (ANOVA-style) y el modelo que piden a gritos:
library(plyr) library(lme4) a &amp;lt;- c(0,0,0, -1, -1, 1, 1, -2, 2) factors &amp;lt;- letters[1:length(a)] datos &amp;lt;- ldply(1:100, function(i){ data.frame(x = factors, y = a + rnorm(length(a))) }) modelo &amp;lt;- lmer(y ~ (1 | x), data = datos)  El resumen del modelo está niquelado:</description>
    </item>
    
    <item>
      <title>Interacciones y selección de modelos</title>
      <link>/2020/03/16/interacciones-y-seleccion-de-modelos/</link>
      <pubDate>Mon, 16 Mar 2020 15:41:00 +0000</pubDate>
      
      <guid>/2020/03/16/interacciones-y-seleccion-de-modelos/</guid>
      <description>Desafortunadamente, el concepto de interacción, muy habitual en modelización estadística, no ha penetrado la literatura del llamado ML. Esencialmente, el concepto de interacción recoge el hecho de que un fenómeno puede tener un efecto distinto en subpoblaciones distintas que se identifican por un nivel en una variable categórica.
El modelo lineal clásico,
$latex y \sim x_1 + x_2 + \dots$
no tiene en cuenta las interacciones (aunque extensiones suyas, sí, por supuesto).</description>
    </item>
    
    <item>
      <title>Seguimiento de los nuevos casos diarios de coronavirus en «tiempo real» con R</title>
      <link>/2020/03/10/seguimiento-de-los-nuevos-casos-diarios-de-coronavirus-en-tiempo-real-con-r/</link>
      <pubDate>Tue, 10 Mar 2020 18:23:28 +0000</pubDate>
      
      <guid>/2020/03/10/seguimiento-de-los-nuevos-casos-diarios-de-coronavirus-en-tiempo-real-con-r/</guid>
      <description>El código usado en
https://twitter.com/gilbellosta/status/1237443017663041537
es
library(reshape2) library(ggplot2) library(plyr) url &amp;lt;- &amp;quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv&amp;quot; cvirus &amp;lt;- read.table(url, sep = &amp;quot;,&amp;quot;, header = T) cvirus$Lat &amp;lt;- cvirus$Long &amp;lt;- NULL cvirus$Province.State &amp;lt;- NULL cvirus &amp;lt;- melt(cvirus, id.vars = &amp;quot;Country.Region&amp;quot;) colnames(cvirus) &amp;lt;- c(&amp;quot;país&amp;quot;, &amp;quot;fecha&amp;quot;, &amp;quot;casos&amp;quot;) cvirus$fecha &amp;lt;- as.Date(as.character(cvirus$fecha), format = &amp;quot;X%m.%d.%y&amp;quot;) tmp &amp;lt;- cvirus[cvirus$país %in% c(&amp;quot;Italy&amp;quot;, &amp;quot;Spain&amp;quot;, &amp;quot;France&amp;quot;, &amp;quot;Germany&amp;quot;, &amp;quot;South Korea&amp;quot;, &amp;quot;UK&amp;quot;),] foo &amp;lt;- function(x){ x &amp;lt;- x[order(x$fecha),] data.frame(fecha = x$fecha[-1], casos = diff(x$casos)) } res &amp;lt;- ddply(tmp, .</description>
    </item>
    
    <item>
      <title>Seguimiento del coronavirus en &#34;tiempo real&#34; con R</title>
      <link>/2020/03/09/seguimiento-del-coronavirus-en-tiempo-real-con-r/</link>
      <pubDate>Mon, 09 Mar 2020 14:26:00 +0000</pubDate>
      
      <guid>/2020/03/09/seguimiento-del-coronavirus-en-tiempo-real-con-r/</guid>
      <description>Mi código (guarrongo) para seguir la evolución del coronavirus por país en cuasi-tiempo real:
library(reshape2) library(ggplot2) url &amp;lt;- &amp;quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv&amp;quot; cvirus &amp;lt;- read.table(url, sep = &amp;quot;,&amp;quot;, header = T) cvirus$Lat &amp;lt;- cvirus$Long &amp;lt;- NULL cvirus$Province.State &amp;lt;- NULL cvirus &amp;lt;- melt(cvirus, id.vars = &amp;quot;Country.Region&amp;quot;) colnames(cvirus) &amp;lt;- c(&amp;quot;país&amp;quot;, &amp;quot;fecha&amp;quot;, &amp;quot;casos&amp;quot;) cvirus &amp;lt;- cvirus[cvirus$país %in% c(&amp;quot;Italy&amp;quot;, &amp;quot;Spain&amp;quot;),] cvirus$fecha &amp;lt;- as.Date(as.character(cvirus$fecha), format = &amp;quot;X%m.%d.%y&amp;quot;) ggplot(cvirus, aes(x = fecha, y = casos, col = país)) + geom_line() tmp &amp;lt;- cvirus tmp$fecha[tmp$país == &amp;quot;Spain&amp;quot;] &amp;lt;- tmp$fecha[tmp$país == &amp;quot;Spain&amp;quot;] - 9 ggplot(tmp, aes(x = fecha, y = casos, col = país)) + geom_line() tmp &amp;lt;- tmp[tmp$fecha &amp;gt; as.</description>
    </item>
    
    <item>
      <title>Una R-referencia con referencias para epidemiólogos circunstanciales</title>
      <link>/2020/03/09/una-r-referencia-con-referencias-para-epidemiologos-circunstanciales/</link>
      <pubDate>Mon, 09 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/09/una-r-referencia-con-referencias-para-epidemiologos-circunstanciales/</guid>
      <description>Lo del coronavirus nos ha convertido a todos en epidemiólogos circunstanciales. Casi ninguno de vosotros tenéis acceso a los datos necesarios para hacer cosas por vuestra cuenta, pero sí, tal vez gracias a esta entrada, las herramientas necesarias para ello.
Podéis empezar por el paquete [survellance](https://CRAN.R-project.org/package=surveillance) de R, que implementa muchos de los métodos más modernos para la monitorización de brotes epidémicos.
En particular, puede que os interese la función bodaDelay, intitulada Bayesian Outbreak Detection in the Presence of Reporting Delays, y que implementa una serie de métodos para estimar el número real de casos cuando las notificaciones de los positivos llegan tarde.</description>
    </item>
    
    <item>
      <title>Intervalos de confianza, intervalos de predicción</title>
      <link>/2020/03/04/intervalos-de-confianza-intervalos-de-prediccion/</link>
      <pubDate>Wed, 04 Mar 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/03/04/intervalos-de-confianza-intervalos-de-prediccion/</guid>
      <description>Contexto:
modelo &amp;lt;- lm(dist ~ speed, data = cars)  Intervalos de confianza:
head(predict(modelo, interval = &amp;quot;confidence&amp;quot;)) # fit lwr upr #1 -1.849460 -12.329543 8.630624 #2 -1.849460 -12.329543 8.630624 #3 9.947766 1.678977 18.216556 #4 9.947766 1.678977 18.216556 #5 13.880175 6.307527 21.452823 #6 17.812584 10.905120 24.720047  Intervalos de predicción:
head(predict(modelo, interval = &amp;quot;prediction&amp;quot;)) # fit lwr upr #1 -1.849460 -34.49984 30.80092 #2 -1.849460 -34.49984 30.80092 #3 9.947766 -22.06142 41.95696 #4 9.</description>
    </item>
    
    <item>
      <title>&#34;Algoritmos&#34; y acatarrantes definiciones de &#34;justicia&#34;</title>
      <link>/2020/02/26/algoritmos-y-acatarrantes-definiciones-de-justicia/</link>
      <pubDate>Wed, 26 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/26/algoritmos-y-acatarrantes-definiciones-de-justicia/</guid>
      <description>Lee Justicia: los límites de la inteligencia artificial&amp;hellip; y humana y cuando acabes, te propongo un pequeño experimento probabilístico. Por referencia, reproduzco aquí los criterios de justicia del artículo que glosa el que enlazo:
Centrémonos en (B), sabiendo que, por simetría, lo que cuento se aplica también a (C).
Supongamos que tenemos dos grupos, cada uno de ellos de
n &amp;lt;- 1000000  personas para estar en las asíntotas que aman los frecuentistas.</description>
    </item>
    
    <item>
      <title>To IRLS or not to IRLS</title>
      <link>/2020/02/24/to-irls-or-not-to-irls/</link>
      <pubDate>Mon, 24 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/24/to-irls-or-not-to-irls/</guid>
      <description>A veces tomas un artículo de vaya uno a saber qué disciplina, sismología, p.e., y no dejas de pensar: los métodos estadísticos que usa esta gente son de hace 50 años. Luego cabe preguntarse: ¿pasará lo mismo en estadística con respecto a otras disciplinas?
Por razones que no vienen al caso, me he visto en la tesitura de tener que encontrar mínimos de funciones que podrían cuasicatalogarse como de mínimos cuadrados no lineales.</description>
    </item>
    
    <item>
      <title>Análisis estadístico de mezclas</title>
      <link>/2020/02/19/analisis-estadistico-de-mezclas/</link>
      <pubDate>Wed, 19 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/19/analisis-estadistico-de-mezclas/</guid>
      <description>No es algo que ocurra habitualmente. Creo que conozco a alguien que me dijo que lo tuvo que hacer una vez. Pero podría ocurrir en algún momento que tuvieses que analizar mezclas, es decir, situaciones experimentales en las que lo importante es la proporción de ciertos ingredientes (con la restricción obvia de que dichas proporciones suman la unidad).
Para más datos, Mixture Experiments in R Using mixexp, que describe el paquete de R [mixexp](https://CRAN.</description>
    </item>
    
    <item>
      <title>No sé cómo traducir &#34;Partially additive (generalized) linear model trees&#34;</title>
      <link>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</link>
      <pubDate>Wed, 12 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/12/no-se-como-traducir-partially-additive-generalized-linear-model-trees/</guid>
      <description>Sin embargo, basta con mirar la foto
leer la entrada de hace unos días, que se refiere a algo muy parecido (y que, en particular, describe los datos usados en el modelo que representa) y, en el peor de los casos, esto, para hacerse idea de su utilidad y relevancia.</description>
    </item>
    
    <item>
      <title>Sobre la normalización de las direcciones postales</title>
      <link>/2020/02/10/sobre-la-normalizacion-de-las-direcciones-postales/</link>
      <pubDate>Mon, 10 Feb 2020 18:00:00 +0000</pubDate>
      
      <guid>/2020/02/10/sobre-la-normalizacion-de-las-direcciones-postales/</guid>
      <description>Lo de las direcciones postales es un caos. Trabajar con ellas, una tortura. Y cualquier proyecto de ciencia de datos que las emplee se convierte en la n-ésima reinvención de la rueda: normalización y tal.
Cuando todo debería ser más sencillo. Cada portal en España tiene asociado un número de policía, un identificador numérico único. Independientemente de que quienes lo habiten se refieran a él de formas variopintas, vernaculares y, en definitiva, desnormalizadas y desestandarizadas hasta pedir basta.</description>
    </item>
    
    <item>
      <title>model4you</title>
      <link>/2020/02/06/model4you/</link>
      <pubDate>Thu, 06 Feb 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/02/06/model4you/</guid>
      <description>Un grupo de estudiantes se examina en horas distintas con exámenes parecidos pero no iguales. Se pretende estudiar si el examen tiene algún efecto sobre la nota final y para eso se hace algo así como
bmod_math &amp;lt;- lm(pcorrect ~ group, data = MathExam)  para obtener una distribución de la nota media por grupo descrita bien
cbind(estimate = coef(bmod_math), confint(bmod_math)) ## estimate 2.5% 97.5% ## (Intercept) 57.600184 55.122708 60.07766 ## group2 -2.</description>
    </item>
    
    <item>
      <title>x[] &lt;- lapply(...)</title>
      <link>/2020/01/29/x/</link>
      <pubDate>Wed, 29 Jan 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/01/29/x/</guid>
      <description>Estos días he aprendido una expresión muy compacta para operar sobre las columnas de una tabla en R:
x &amp;lt;- iris # por ejemplo x[] &amp;lt;- lapply(x, function(x) factor(x)) # o cualquier otra función  Aunque lapply debería devolver (y, de hecho, devuelve) una lista, esos corchetes de x fuerzan de una manera contraintuitiva que la salida final sea una tabla.
La magia es consecuencia de que [&amp;lt;- es una función en sí misma (puedes consultar help(&amp;quot;[&amp;lt;-&amp;quot;) si quieres) con un comportamiento que es el que es (porque sí, a veces las cosas son simplemente como son).</description>
    </item>
    
    <item>
      <title>Siete llaves al sepulcro del método delta</title>
      <link>/2020/01/22/siete-llaves-al-sepulcro-del-metodo-delta/</link>
      <pubDate>Wed, 22 Jan 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/01/22/siete-llaves-al-sepulcro-del-metodo-delta/</guid>
      <description>El desafortunado tuit
https://twitter.com/gilbellosta/status/1219196123094700032
es de lo más parecido a que me repitan unos chorizos que me ha ocurrido últimamente. Salvo que en lugar de chorizos, lo que se me manifestaban fueron años estudiando matemáticas y, por extensión, las partes más analíticas de la estadística.
Con inmerecida delicadeza, se me respondió:
https://twitter.com/joscani/status/1219350615987511297
Y sí, hay que cerrar con siete llaves el sepulcro del método delta o, en su defecto, activar el pin parental el día que toque.</description>
    </item>
    
    <item>
      <title>De texto a función</title>
      <link>/2020/01/21/de-texto-a-funcion/</link>
      <pubDate>Tue, 21 Jan 2020 17:46:00 +0000</pubDate>
      
      <guid>/2020/01/21/de-texto-a-funcion/</guid>
      <description>Problema: convertir una expresión definida por un usuario (p.e., algo como &amp;quot;a+b&amp;quot;) en una función (i.e., function(a, b) a + b).
Solución:
gen_foo &amp;lt;- function(expr){ my_args &amp;lt;- all.vars(parse(text = expr)) expr &amp;lt;- paste0(&amp;quot;function(&amp;quot;, paste(my_args, collapse = &amp;quot;,&amp;quot;), &amp;quot;) &amp;quot;, expr) eval(parse(text = expr)) }  Demostración:
multiplica &amp;lt;- gen_foo(&amp;quot;a * b&amp;quot;) multiplica(5, 31)  </description>
    </item>
    
    <item>
      <title>Charla en el CodingClub de la UC3M este martes</title>
      <link>/2019/12/16/charla-en-el-codingclub-de-la-uc3m-este-martes/</link>
      <pubDate>Mon, 16 Dec 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/12/16/charla-en-el-codingclub-de-la-uc3m-este-martes/</guid>
      <description>Este martes 17 de diciembre hablaré durante una hora sobre (cierto tipo de) big data y modelos adecuados para modelizarlos en el CodingClub de la Universidad Carlos III.
 El contenido de la charla, entiendo, se publicará también después en el blog del CodingClub. * Los detalles (sitio, hora, etc.) están en el enlace indicado más arriba. * Obviamente, agradezco a los organizadores del CodingClub por haberme invitado. Espero no estar arrepentido el martes por la tarde de lo siguiente: es el ciclo de charlas sobre _cosas relacionadas con datos _más seria y mejor organizada que conozco.</description>
    </item>
    
    <item>
      <title>P-valores y decisiones</title>
      <link>/2019/12/04/p-valores-y-decisiones/</link>
      <pubDate>Wed, 04 Dec 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/12/04/p-valores-y-decisiones/</guid>
      <description>Los números de esta entrada son reales aunque disfrazados: proceden de un proyecto real. Para medir la efectividad de una serie de modelos que hemos creado en Circiter, hemos pedido al cliente lo de siempre: que parta la lista de sujetos en dos al azar para después poder medir los éxitos y fracasos usando dos procedimientos distintos.
Pero como tenemos dudas acerca del proceso de partición —que no controlamos nosotros— hemos medido el número de éxitos y fracasos en cada uno de los grupos en una prueba previa.</description>
    </item>
    
    <item>
      <title>La población envejece pero, ¿envejecen también los grupos de edad?</title>
      <link>/2019/12/03/la-poblacion-envejece-pero-envejecen-tambien-los-grupos-de-edad/</link>
      <pubDate>Tue, 03 Dec 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/12/03/la-poblacion-envejece-pero-envejecen-tambien-los-grupos-de-edad/</guid>
      <description>La pregunta es relevante porque en demografía, epidemiología y otras disciplinas entre las que no se suele contar la economía, se suele agrupar la población en grupos de edad (y/u otras variables relevantes). Son habituales los grupos de edad quinquenales y la pregunta es: ¿son homogéneos dichos grupos de edad a lo largo del tiempo?
No es una pregunta baladí: ha dado lugar a noticias como Why So Many White American Men Are Dying que no, no se explican por la desesperación o por la epidemia de opioides sino por el envejecimiento relativo de los grupos de edad en cuestión.</description>
    </item>
    
    <item>
      <title>bamlss promete regresión bayesiana flexible</title>
      <link>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</link>
      <pubDate>Tue, 19 Nov 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</guid>
      <description>Un paquete relativamente nuevo de R (las primeras versiones son de 2017) que llevo un tiempo siguiendo de reojo es [bamlss](https://CRAN.R-project.org/package=bamlss).
bamlss es un paquete que permite especificar y ajustar varios tipos de modelos usando en principio métodos bayesianos, aunque tampoco necesariamente.
No puedo decir mucho más de él de momento. Habrá que ver cómo se comporta más allá de los ejemplos discutidos en la documentación. Muchos paquetes tienden a hacer trivial lo que antes era sencillo e imposible lo que antes difícil.</description>
    </item>
    
    <item>
      <title>tfprobability debería llamarse tfeoprobability</title>
      <link>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</link>
      <pubDate>Tue, 12 Nov 2019 09:13:04 +0000</pubDate>
      
      <guid>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</guid>
      <description>Porque, aunque la intención sea buena, el DSL (que ni siquiera llega a serlo) es muy, muy feo. Que en este contexto, además, quiere decir antinatural.
La demostración, aquí, aquí o aquí.</description>
    </item>
    
    <item>
      <title>Análisis y predicción de series temporales intermitentes</title>
      <link>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</link>
      <pubDate>Mon, 04 Nov 2019 09:13:16 +0000</pubDate>
      
      <guid>/2019/11/04/analisis-y-prediccion-de-series-temporales-intermitentes/</guid>
      <description>Hace tiempo me tocó analizar unas series temporales bastante particulares. Representaban la demanda diaria de determinados productos y cada día esta podía ser de un determinado número de kilos. Pero muchas de las series eran esporádicas: la mayoría de los días la demanda era cero.
Eran casos de las llamadas series temporales intermitentes.
Supongo que hay muchas maneras de modelizarlas y, así, al vuelo, se me ocurre pensar en algo similar a los modelos con inflación de ceros.</description>
    </item>
    
    <item>
      <title>DLMs</title>
      <link>/2019/10/31/dlms/</link>
      <pubDate>Thu, 31 Oct 2019 09:13:08 +0000</pubDate>
      
      <guid>/2019/10/31/dlms/</guid>
      <description>O Distributed Lag Models (véase, por ejemplo, [dLagM](https://cran.r-project.org/web/packages/dLagM/index.html)).
Son modelos para estimar el impacto de una serie temporal sobre otra en situaciones como la siguientes:
 Una serie mide excesos de temperaturas (en verano). * La otra, defunciones.  Existe un efecto causal (débil, pero medible) de la primera sobre la segunda. Pero las defunciones no ocurren el día mismo en que ocurren los excesos de temperaturas, sino que suelen demorarse unos cuantos días.</description>
    </item>
    
    <item>
      <title>r -&gt; d -&gt; p -&gt; q</title>
      <link>/2019/10/30/r-d-p-q/</link>
      <pubDate>Wed, 30 Oct 2019 09:10:05 +0000</pubDate>
      
      <guid>/2019/10/30/r-d-p-q/</guid>
      <description>Primero fue la r (runif, rnorm, rpois,&amp;hellip;).
De la r surgió el histograma.
Y el histograma era casi siempre parecido.
Y aquello a lo que se parecía se llamó d (dunif, dnorm, etc.).
Y era bueno.
(Obviamente, debidamente normalizado con integral 1, algo sobre lo que afortunadamente la tontuna de las identidades culturales aún no ha protestado).
La p, una integral de la d, es una conveniencia que permite contestar rápido determinadas preguntas razonables y habituales.</description>
    </item>
    
    <item>
      <title>Se non è vero, non è vero (¡qué se le va a hacer!)</title>
      <link>/2019/10/21/si-non-e-vero-non-e-vero-que-se-le-va-a-hacer/</link>
      <pubDate>Mon, 21 Oct 2019 09:13:18 +0000</pubDate>
      
      <guid>/2019/10/21/si-non-e-vero-non-e-vero-que-se-le-va-a-hacer/</guid>
      <description>Me llegó por fuentes habitualmente fiables el vídeo
https://www.youtube.com/watch?v=2Fh_XmK3yis
que se resume en que el apagón del día 29 de septiembre en Tenerife, es decir, esta cosa tan horrorosa
fue producto de la variabilidad de la producción de la energía eólica. En particular, de una bajada drástica de la aportación de la eólica al mix consecuencia de un descenso en la intensidad del viento. Lo cual, de ser cierto, debería convertirse en referencia básica para ilustrar los perniciosos efectos de la variabilidad, etc.</description>
    </item>
    
    <item>
      <title>Voy a demostrar (con la ayuda del INE) que Airbnb no existe</title>
      <link>/2019/10/08/voy-a-demostrar-con-la-ayuda-del-ine-que-airbnb-no-existe/</link>
      <pubDate>Tue, 08 Oct 2019 09:13:31 +0000</pubDate>
      
      <guid>/2019/10/08/voy-a-demostrar-con-la-ayuda-del-ine-que-airbnb-no-existe/</guid>
      <description>Tan vasto es el fenómeno Airbnb que malo será no haya dejado traza en las estadísticas oficiales. Que como oficiales, son verdad.
No podemos hacer caso a las estadísticas de ocupación hotelera del INE porque son de lo de que dicen: hoteles (y asimilados). Airbnb tiene que dejarse notar en otra parte.
¿Cuál? Frontur, la estadística de movimientos turísticos en frontera del INE. (Sin enlace: los enlaces del INE van y vienen).</description>
    </item>
    
    <item>
      <title>flygskam punto ceeseuve</title>
      <link>/2019/10/03/flygskam-punto-ceeseuve/</link>
      <pubDate>Thu, 03 Oct 2019 09:13:02 +0000</pubDate>
      
      <guid>/2019/10/03/flygskam-punto-ceeseuve/</guid>
      <description>Para todos aquellos a los que volar les da vergüenza. Para todos aquellos que han sido víctimas de Vueling o Ryanair. Para todos aquellos que saben que cualquier cosa del mundo se puede encontrar mejor y más barata en Lavapiés. Para todos aquellos que han ido a JFK para enterarse de que su vuelo salía de Newark. Para todos aquellos a los que les han cancelado un billete de vuelta porque se durmieron y perdieron la la ida.</description>
    </item>
    
    <item>
      <title>BLAS, eficiencia y lme4</title>
      <link>/2019/10/02/blas-eficiencia-y-lme4/</link>
      <pubDate>Wed, 02 Oct 2019 09:13:30 +0000</pubDate>
      
      <guid>/2019/10/02/blas-eficiencia-y-lme4/</guid>
      <description>Cada cierto número de años me reencuentro con la cuestión de BLAS, ATLAS y todas esas cosas por tratar de arañar un poco de eficiencia a R.
Existen el BLAS de toda la vida que, parece ser, viene de serie con R y uno puede optar por otras versiones optimizadas como ATLAS u OpenBLAS, cuyas ventajas relativas, de acuerdo con estos benchmarks, no parecen demasiado claras.
Lo novedoso en esta revisita al problema es que he aprendido que a los anteriores se han sumado en estos últimos años, cuando menos:</description>
    </item>
    
    <item>
      <title>ranger (o cómo el truco para hacerlo rápido es hacerlo, subrepticiamente, mal)</title>
      <link>/2019/09/26/ranger-o-como-el-truco-para-hacerlo-rapido-es-hacerlo-subrepticiamente-mal/</link>
      <pubDate>Thu, 26 Sep 2019 09:13:14 +0000</pubDate>
      
      <guid>/2019/09/26/ranger-o-como-el-truco-para-hacerlo-rapido-es-hacerlo-subrepticiamente-mal/</guid>
      <description>[ranger](https://cran.r-project.org/package=ranger) llegó para hacerlo mismo que [randomForest](https://cran.r-project.org/package=randomForest), solo que más deprisa y usando menos memoria.
Lo que no nos contaron es que lo consiguió haciendo trampas. En particular, en el tratamiento de las variables categóricas. Si no andas con cuidado, las considera ordenadas (y ordenadas alfabéticamente).
[Si te da igual ocho que ochenta, no te preocupará el asunto. Tranquilo: hay muchos como tú.]
El diagnóstico dado (por eso lo omito) está contado aquí.</description>
    </item>
    
    <item>
      <title>¿Qué variable distingue mejor dos subgrupos?</title>
      <link>/2019/09/24/que-variable-distingue-mejor-dos-subgrupos/</link>
      <pubDate>Tue, 24 Sep 2019 09:13:25 +0000</pubDate>
      
      <guid>/2019/09/24/que-variable-distingue-mejor-dos-subgrupos/</guid>
      <description>Es una pregunta que surge reiteradamente. Por ejemplo, cuando se compara un clúster con el resto de la población y uno busca las variables que mejor lo caracterizan. Y crear gráficos como
(extraído de aquí) donde las variables están ordenadas de acuerdo con su poder discriminador.
Mi técnica favorita para crear tales indicadores es la EMD (earth mover&amp;rsquo;s distance) y/o sus generalizaciones, muy bien descritas en Optimal Transport and Wasserstein Distance y disponibles en R y Python.</description>
    </item>
    
    <item>
      <title>Mi consumo de electricidad, hora a hora</title>
      <link>/2019/09/18/mi-consumo-de-electricidad-hora-a-hora/</link>
      <pubDate>Wed, 18 Sep 2019 09:13:54 +0000</pubDate>
      
      <guid>/2019/09/18/mi-consumo-de-electricidad-hora-a-hora/</guid>
      <description>Por primera vez, mi compañía de electricidad ha sabido asignar a cada hora mi consumo (¿se acabarán de una vez las benditas facturas con consumo estimado?). Lo que me ha permitido construir esta gráfica horaria:
No publico el código por que dependería del proveedor. No hago comentarios porque solo a mí me competen. Pero invito a otros a echar un vistazo a su consumo, etc.</description>
    </item>
    
    <item>
      <title>Un modelo que alimenta una simulación</title>
      <link>/2019/09/16/un-modelo-que-alimenta-una-simulacion/</link>
      <pubDate>Mon, 16 Sep 2019 09:13:17 +0000</pubDate>
      
      <guid>/2019/09/16/un-modelo-que-alimenta-una-simulacion/</guid>
      <description>Tenemos en Circiter un proyecto sobre el que no puedo dar muchos detalles, pero que vamos a plantear (en versión muy resumida) como un modelo que alimenta una simulación.
El modelo no va a ser un modelo sino un modelo por sujeto (rebaños, los llamamos aquí). Los modelos serán, casi seguro, modelos mixtos (lmer/glmer).
Pero claro, si usas un modelo, por muy mixto que sea, con intención de simular, predict se queda muy corto (¡siempre da la el mismo resultado!</description>
    </item>
    
    <item>
      <title>Del &#34;Andalucía &#39;first&#39;&#34; al &#34;La Rioja por doquier&#34;</title>
      <link>/2019/09/13/del-andalucia-first-al-la-rioja-por-doquier/</link>
      <pubDate>Fri, 13 Sep 2019 09:13:21 +0000</pubDate>
      
      <guid>/2019/09/13/del-andalucia-first-al-la-rioja-por-doquier/</guid>
      <description>En este blog ya nos hemos graduado del &amp;ldquo;Andalucía first&amp;rdquo; (sí, esa reiterada manía a recordarnos que en Andalucía siempre hay más de todo lo que correlacione más o menos directamente con el número de habitantes).
Aquí nos llama la atención otro efecto que afecta a los segundos momentos: el &amp;ldquo;La Rioja por doquier&amp;rdquo;. Verbigracia:
Obvio. De hecho,
Que es un conocimiento que cabe esperar en un lector atento de Kahneman y cía.</description>
    </item>
    
    <item>
      <title>¿Qué más puede colgar de un árbol?</title>
      <link>/2019/09/12/que-mas-puede-colgar-de-un-arbol/</link>
      <pubDate>Thu, 12 Sep 2019 09:13:43 +0000</pubDate>
      
      <guid>/2019/09/12/que-mas-puede-colgar-de-un-arbol/</guid>
      <description>[Abundando en ¿Qué puede colgar de un árbol?]
¡Grafos!</description>
    </item>
    
    <item>
      <title>(g)lms con coeficientes &gt; 0 (p.e.)</title>
      <link>/2019/08/21/glms-con-coeficientes-0-p-e/</link>
      <pubDate>Wed, 21 Aug 2019 09:13:51 +0000</pubDate>
      
      <guid>/2019/08/21/glms-con-coeficientes-0-p-e/</guid>
      <description>Alguien quería un glm forzando determinados coeficientes &amp;gt;0. * Una solución 100% bayesiana no era una opción.  Hay varias opciones por ahí. Pero me ha sorprendido que la opción esté disponible en glmnet::glmnet:
Filosóficamente, es un tanto sorprendente: de alguna manera, glmnet es glm con prioris alrededor del cero. Los límites superiores e inferiores permiten introducir información a priori adicional no necesariamente compatible con la anterior.
Desde el punto de vista de la implementación, tiene sentido que estas opciones estén disponibles.</description>
    </item>
    
    <item>
      <title>Más sobre factores, strings y ordenación</title>
      <link>/2019/08/07/mas-sobre-factores-strings-y-ordenacion/</link>
      <pubDate>Wed, 07 Aug 2019 09:13:34 +0000</pubDate>
      
      <guid>/2019/08/07/mas-sobre-factores-strings-y-ordenacion/</guid>
      <description>Esta entrada debería ser un comentario más en esta otra, pero voy a abusar del privilegio de ser dueño de la plataforma para promocionarla.
Voy a decir cosas que son aproximadamente ciertas. Los detalles de la verdad de todo están en la ayuda y el código de sort y sus métodos.
En R hay dos métodos de ordenación: shell y radix. El primero es genérico y el segundo es mejor cuando en el vector hay muchos elementos repetidos (p.</description>
    </item>
    
    <item>
      <title>Hagan sus apuestas; luego, corran el siguiente código</title>
      <link>/2019/08/06/hagan-sus-apuestas-luego-corran-el-siguiente-codigo/</link>
      <pubDate>Tue, 06 Aug 2019 09:13:12 +0000</pubDate>
      
      <guid>/2019/08/06/hagan-sus-apuestas-luego-corran-el-siguiente-codigo/</guid>
      <description>library(microbenchmark) library(ggplot2) a_int &amp;lt;- sample(10:99, 1e6, replace = T) a_char &amp;lt;- paste(&amp;quot;P&amp;quot;, a_int, sep = &amp;quot;&amp;quot;) res &amp;lt;- microbenchmark( sort_int = sort(a_int), sort_char_radix = sort(a_char, method = &amp;quot;radix&amp;quot;), sort_char = sort(a_char), factor_trick = as.character(sort(as.factor(a_char))), times = 50 ) autoplot(res)  </description>
    </item>
    
    <item>
      <title>Dplyr parece que prefiere los factores</title>
      <link>/2019/08/05/dplyr-parece-que-prefiere-los-factores/</link>
      <pubDate>Mon, 05 Aug 2019 09:13:50 +0000</pubDate>
      
      <guid>/2019/08/05/dplyr-parece-que-prefiere-los-factores/</guid>
      <description>Con datos bajados de aquí:
library(MicroDatosEs) library(dplyr) library(microbenchmark) library(ggplot2) censo &amp;lt;- censo2010(&amp;quot;MicrodatosCP_NV_per_nacional_3VAR.txt&amp;quot;) censo_char &amp;lt;- as.data.frame(censo[, c(&amp;quot;CPRO&amp;quot;, &amp;quot;SEXO&amp;quot;, &amp;quot;ECIVIL&amp;quot;, &amp;quot;FACTOR&amp;quot;)]) censo_factor &amp;lt;- censo_char censo_factor$CPRO &amp;lt;- factor(censo_factor$CPRO) foo &amp;lt;- function(x) x %&amp;gt;% group_by(CPRO) %&amp;gt;% summarise(res = sum((SEXO == &amp;quot;Mujer&amp;quot;) * (ECIVIL == &amp;quot;Divorciado&amp;quot;) * FACTOR) / sum(FACTOR) * 100) res &amp;lt;- microbenchmark( char = foo(censo_char), factor = foo(censo_factor), times = 10 ) autoplot(res)  Da:
¿No es sorprendente? De hecho, plyr es más rápido que dplyr en este caso si no se usan factores.</description>
    </item>
    
    <item>
      <title>XI Jornadas de Usuarios de R</title>
      <link>/2019/07/24/xi-jornadas-de-usuarios-de-r/</link>
      <pubDate>Wed, 24 Jul 2019 09:13:44 +0000</pubDate>
      
      <guid>/2019/07/24/xi-jornadas-de-usuarios-de-r/</guid>
      <description>Esta entrada es un (otro, que sumar a este o este) recordatorio de que las XI Jornadas de Usuarios de R están en marcha.
Y que serán en Madrid, del 14 al 16 de noviembre, etc. Información toda ella que los enlaces anteriores extienden debidamente.
(Además hay una tarifa reducida cuyo plazo termina, aviso, muy, muy pronto.)</description>
    </item>
    
    <item>
      <title>Cartogramas con recmap</title>
      <link>/2019/07/15/cartogramas-con-recmap/</link>
      <pubDate>Mon, 15 Jul 2019 09:13:02 +0000</pubDate>
      
      <guid>/2019/07/15/cartogramas-con-recmap/</guid>
      <description>He construido
que, obviamente no es la gran maravilla, basándome en Rectangular Statistical Cartograms in R: The recmap Package y usando
library(rgdal) library(pxR) library(recmap) provs &amp;lt;- readOGR(dsn = &amp;quot;provincias/&amp;quot;, layer = &amp;quot;Provincias&amp;quot;) pobl &amp;lt;- as.data.frame(read.px(&amp;quot;2852.px&amp;quot;, encoding = &amp;quot;latin1&amp;quot;), use.codes = T) pobl2 &amp;lt;- as.data.frame(read.px(&amp;quot;2852.px&amp;quot;, encoding = &amp;quot;latin1&amp;quot;)) pobl$nombre &amp;lt;- pobl2$Provincias pobl &amp;lt;- pobl[, c(&amp;quot;Provincias&amp;quot;, &amp;quot;nombre&amp;quot;, &amp;quot;value&amp;quot;)] colnames(pobl) &amp;lt;- c(&amp;quot;COD_PROV&amp;quot;, &amp;quot;nombre&amp;quot;, &amp;quot;poblacion&amp;quot;) pobl &amp;lt;- pobl[pobl$COD_PROV != &amp;quot;null&amp;quot;,] pobl &amp;lt;- pobl[!pobl$COD_PROV %in% c(&amp;quot;51&amp;quot;, &amp;quot;52&amp;quot;, &amp;quot;38&amp;quot;, &amp;quot;07&amp;quot;, &amp;quot;35&amp;quot;),] dat &amp;lt;- merge(provs, pobl, by = &amp;quot;COD_PROV&amp;quot;, all.</description>
    </item>
    
    <item>
      <title>Nota para mí: usar flextable, usar flextable</title>
      <link>/2019/06/25/nota-para-mi-usar-flextable-usar-flextable/</link>
      <pubDate>Tue, 25 Jun 2019 09:13:46 +0000</pubDate>
      
      <guid>/2019/06/25/nota-para-mi-usar-flextable-usar-flextable/</guid>
      <description>De aquí a cuando lo tenga que usar realmente, seguro que me olvido. Así que retomo el uso original de este blog, que era el de dejarme notas a mí mismo y apunto: usa [flextable](https://cran.r-project.org/package=flextable).
¿Y por qué?, me preguntaré a mí mismo dentro de unos días. Pues por cosas como esta:
(Claro está, salvo que alguien tenga a bien proponer una alternativa mejor).</description>
    </item>
    
    <item>
      <title>Modelos GARCH (o: no me cuentes tu vida, dame el pxxx modelo generativo y ya)</title>
      <link>/2019/05/31/modelos-garch-o-no-me-cuentes-tu-vida-dame-el-p-modelo-generativo-y-ya/</link>
      <pubDate>Fri, 31 May 2019 09:11:07 +0000</pubDate>
      
      <guid>/2019/05/31/modelos-garch-o-no-me-cuentes-tu-vida-dame-el-p-modelo-generativo-y-ya/</guid>
      <description>Los modelos GARCH son otra de esas cosas de las que oyes hablar y como nunca se convierten en problemas de los de carne en el asador, preocupan poco y ocupan menos (más allá de que sabes que se trata de modelos similares a los de series temporales de toda la vida donde la varianza varía de cierta forma a lo largo del tiempo). Pero comienzas a leer cosas como esta y no te enteras de nada: solo hay letras y llamadas a funciones oscuras y oscurantistas.</description>
    </item>
    
    <item>
      <title>1  3  6 19 30 34  2  7 18 31 33 16  9 27 22 14 11 25 24 12 13 23 26 10 15 21 28  8 17 32  4  5 20 29 35</title>
      <link>/2019/05/27/1-3-6-19-30-34-2-7-18-31-33-16-9-27-22-14-11-25-24-12-13-23-26-10-15-21-28-8-17-32-4-5-20-29-35/</link>
      <pubDate>Mon, 27 May 2019 09:13:33 +0000</pubDate>
      
      <guid>/2019/05/27/1-3-6-19-30-34-2-7-18-31-33-16-9-27-22-14-11-25-24-12-13-23-26-10-15-21-28-8-17-32-4-5-20-29-35/</guid>
      <description>Son los enteros del 1 al 35 ordenados de forma que dos consecutivos en la serie suman un cuadrado perfecto. Los he obtenido así:
library(adagio) foo &amp;lt;- function(n){ desde &amp;lt;- 1:n hasta &amp;lt;- 1:n todos &amp;lt;- expand.grid(desde, hasta) todos &amp;lt;- todos[todos$Var1 &amp;lt; todos$Var2,] todos$sqrt &amp;lt;- sqrt(todos$Var1 + todos$Var2) todos &amp;lt;- todos[todos$sqrt == round(todos$sqrt),] todos$sqrt &amp;lt;- NULL vertices &amp;lt;- as.vector(t(todos)) hamiltonian(vertices) } foo(35)  Notas:
 Esta entrada está inspirada en algo que he visto en Twitter (pero cuya referencia he olvidado guardar).</description>
    </item>
    
    <item>
      <title>¿Qué puede colgar de un árbol?</title>
      <link>/2019/05/21/que-puede-colgar-de-un-arbol/</link>
      <pubDate>Tue, 21 May 2019 09:13:54 +0000</pubDate>
      
      <guid>/2019/05/21/que-puede-colgar-de-un-arbol/</guid>
      <description>Predicciones puntuales:
O (sub)modelos:
Y parece que ahora también distribuciones:
Notas:
 Obviamente, la clasificación anterior no es mutuamente excluyente. * La tercera gráfica está extraída de Transformation Forests, un artículo donde se describe el paquete trtf de R. * Los autores dicen que [r]egression models for supervised learning problems with a continuous target are commonly understood as models for the conditional mean of the target given predictors. ¿Vosotros lo hacéis así?</description>
    </item>
    
    <item>
      <title>Elecciones e índice (supernaíf) de Shapley</title>
      <link>/2019/05/07/elecciones-e-indice-supernaif-de-shapley/</link>
      <pubDate>Tue, 07 May 2019 09:13:34 +0000</pubDate>
      
      <guid>/2019/05/07/elecciones-e-indice-supernaif-de-shapley/</guid>
      <description>Aprovechando que el paquete [GameTheoryAllocation](https://cran.r-project.org/package=GameTheoryAllocation) ha emergido de mi FIFO de pendientes a los pocos días de conocerse los resultados de las [adjetivo superlativizado omitidísimo] elecciones generales, voy a calcular de la manera más naíf que se me ocurre el índice de Shapley de los distintos partidos. Que es:
Al menos, de acuerdo con el siguiente código:
&amp;lt;code&amp;gt;library(GameTheoryAllocation) partidos &amp;lt;- c(123, 66, 57, 35, 24, 15, 7, 7, 6, 4, 2, 2, 1, 1) names(partidos) &amp;lt;- c(&amp;quot;psoe&amp;quot;, &amp;quot;pp&amp;quot;, &amp;quot;cs&amp;quot;, &amp;quot;iu&amp;quot;, &amp;quot;vox&amp;quot;, &amp;quot;erc&amp;quot;, &amp;quot;epc&amp;quot;, &amp;quot;ciu&amp;quot;, &amp;quot;pnv&amp;quot;, &amp;quot;hb&amp;quot;, &amp;quot;cc&amp;quot;, &amp;quot;na&amp;quot;, &amp;quot;compr&amp;quot;, &amp;quot;prc&amp;quot;) coaliciones &amp;lt;- coalitions(length(partidos)) tmp &amp;lt;- coaliciones$Binary profit &amp;lt;- tmp %*% partidos profit &amp;lt;- 1 * (profit &amp;gt; 175) res &amp;lt;- Shapley_value(profit, game = &amp;quot;profit&amp;quot;) res &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Simulación de procesos de Poisson no homogéneos y autoexcitados</title>
      <link>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</link>
      <pubDate>Fri, 05 Apr 2019 09:13:37 +0000</pubDate>
      
      <guid>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</guid>
      <description>Fueron mis modelos favoritos un tiempo, cuando modelaba visitas y revisitas de usuarios a cierto malhadado portal.
Si las visitas fuesen aleatorias (en cierto sentido), tendrían un aspecto no muy distinto del que se obtiene haciendo
library(IHSEP) suppressWarnings(set.seed(exp(pi * complex(imaginary = 1)))) tms &amp;lt;- simPois(int = function(x) .1, cens = 1000) hist(tms, breaks = 100, main = &amp;quot;Proceso homogéneo de Poisson&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;frecuencia&amp;quot;)  Es decir,</description>
    </item>
    
    <item>
      <title>Mi semilla</title>
      <link>/2019/03/29/mi-semilla/</link>
      <pubDate>Fri, 29 Mar 2019 09:13:11 +0000</pubDate>
      
      <guid>/2019/03/29/mi-semilla/</guid>
      <description>suppressWarnings(set.seed(exp(pi * complex(imaginary = 1)))) runif(1) #[1] 0.4866672 set.seed(-1) runif(1) #[1] 0.4866672Coda: ¿De qué si no creéis que iba esto?</description>
    </item>
    
    <item>
      <title>Análisis (clasificación, etc.) de textos muy cortos</title>
      <link>/2019/03/22/analisis-clasificacion-etc-de-textos-muy-cortos/</link>
      <pubDate>Fri, 22 Mar 2019 08:13:37 +0000</pubDate>
      
      <guid>/2019/03/22/analisis-clasificacion-etc-de-textos-muy-cortos/</guid>
      <description>Uno de mis proyectos permanentemente pospuestos es el del análisis de textos muy cortos. Se citarán Twitter y similares, aunque el € está en otros sitios, como los mensajes asociados a transferencias bancarias, reseñas o keywords.
Pero parece que no soy el único interesado en el tema. Otros con más tiempo y talento han desarrollado [BTM](https://cran.r-project.org/web/packages/BTM/index.html), que parece ser una versión modificada de LDA para el análisis de textos cortos.</description>
    </item>
    
    <item>
      <title>Pesos de los componentes del QualityScore en Google Ads</title>
      <link>/2019/03/07/pesos-de-los-componentes-del-qualityscore-en-google-ads/</link>
      <pubDate>Thu, 07 Mar 2019 08:13:34 +0000</pubDate>
      
      <guid>/2019/03/07/pesos-de-los-componentes-del-qualityscore-en-google-ads/</guid>
      <description>El llamado QualityScore tiene su relevancia en Google Ads. Es un indicador con valores entre 1 y 10 asignado por Google que se basa en tres variables que están descritas por ahí:
 PostClickQualityScore * SearchPredictedCtr * CreativeQualityScore  Se trata de variables categóricas con tres niveles: en / por encima de / por debajo de la media.
Haciendo
&amp;lt;code&amp;gt;modelo &amp;lt;- lm(QualityScore ~ PostClickQualityScore + SearchPredictedCtr + CreativeQualityScore, data = tmp) summary(modelo)&amp;lt;/code&amp;gt;  se obtiene</description>
    </item>
    
    <item>
      <title>offset, porque el coeficiente es 1 necesariamente</title>
      <link>/2019/03/04/offset-porque-el-coeficiente-es-1-necesariamente/</link>
      <pubDate>Mon, 04 Mar 2019 08:13:43 +0000</pubDate>
      
      <guid>/2019/03/04/offset-porque-el-coeficiente-es-1-necesariamente/</guid>
      <description>Estos días me han preguntado sobre un modelo lineal tal que $latex y \sim x_1 + \dots$ donde el coeficiente de $latex x_1$ no se entiende si no es igual a 1. Es como si los datos se creasen de la forma
&amp;lt;code&amp;gt;n &amp;lt;- 100 x1 &amp;lt;- rnorm(n) x2 &amp;lt;- rnorm(n) y &amp;lt;- x1 + rnorm(n, .1) + .02 * x2&amp;lt;/code&amp;gt;  y se conociese el coeficiente de $latex x_1$ y no el de $latex x_2$.</description>
    </item>
    
    <item>
      <title>Sobre el agregador de noticias sobre R en español</title>
      <link>/2019/02/27/sobre-el-agregador-de-noticias-sobre-r-en-espanol/</link>
      <pubDate>Wed, 27 Feb 2019 08:13:50 +0000</pubDate>
      
      <guid>/2019/02/27/sobre-el-agregador-de-noticias-sobre-r-en-espanol/</guid>
      <description>Aprovecho que acabo de actualizar mi agregador de noticias sobre R en español para escribir este recordatorio.
La cosa es que hace ya un tiempo (¡lo anuncié en 2010!) creé una programita que rastrea una serie de blogs que publican cosas sobre R, extrae los corresondientes RSS, selecciona las entradas que tratan sobre R y:
 Crea un RSS combinado que guarda aquí (para los que aún uséis RSS, claro). * Publica esas entradas en una cuenta específica de Twitter, @noticiasSobreR.</description>
    </item>
    
    <item>
      <title>vecpart: modelización de moderadores con árboles</title>
      <link>/2019/02/18/9857/</link>
      <pubDate>Mon, 18 Feb 2019 08:13:43 +0000</pubDate>
      
      <guid>/2019/02/18/9857/</guid>
      <description>En un GLM (aún más generalizado que la G de las siglas) puede haber coeficientes moderados. Usando una terminología muy ad hoc, en el modelo pueden entrar predictores y moderadores. Lo cual quiere decir que la parte lineal puede ser de la forma
$latex \sum_i X_i \beta_i(Z_i),$
donde las $latex X_i$ son los predictores propiamente dichos y las variables $latex Z_i$ son moderadoras, es decir, que modifican el efecto de los predictores a través de una función arbitraria $latex \beta_i$.</description>
    </item>
    
    <item>
      <title>Modas y fotogenia del código secuencial</title>
      <link>/2019/02/14/modas-y-fotogenia-del-codigo-secuencial/</link>
      <pubDate>Thu, 14 Feb 2019 08:13:14 +0000</pubDate>
      
      <guid>/2019/02/14/modas-y-fotogenia-del-codigo-secuencial/</guid>
      <description>Este tipo de programación se puso de moda en los noventa:
Y yo decía: ¿dónde están mis bucles? ¿Y mis bifurcaciones?
Este tipo de programación está de moda últimamente:
&amp;lt;code&amp;gt;hourly_delay &amp;lt;- flights %&amp;gt;% filter(!is.na(dep_delay)) %&amp;gt;% group_by(date, hour) %&amp;gt;% summarise( delay = mean(dep_delay), n = n() ) %&amp;gt;% filter(n &amp;gt; 10)&amp;lt;/code&amp;gt;  Y todo bien, sí, pero sigo sin tener bucles o bifurcaciones.
Tal vez no hagan falta. Al menos, para cosas de andar por casa.</description>
    </item>
    
    <item>
      <title>Una cosa buena, una cosa mala</title>
      <link>/2019/02/13/una-cosa-buena-una-cosa-mala/</link>
      <pubDate>Wed, 13 Feb 2019 08:13:09 +0000</pubDate>
      
      <guid>/2019/02/13/una-cosa-buena-una-cosa-mala/</guid>
      <description>Que son la misma: esta.
Comienzo por lo malo: ¿realmente necesitamos 17+1 INEs publicando la vistas de la misma información a través de 17+1 APIs, 17+1 paquetes de R y (17+1)*N mantenedores y desarrolladores?
Lo bueno: tiene buena pinta y es encomiable tanto el esfuerzo de los autores como su vocación de servicio público.
Nota: Espero que no enfaden demasiado el 50% de los juicios que he emitido a quien me ha enviado el enlace para su evaluación y posible difusión.</description>
    </item>
    
    <item>
      <title>Sr. Python, muchas gracias por su candidatura; ya le llamaremos cuando... tenga modelos mixtos</title>
      <link>/2019/02/12/sr-python-muchas-gracias-por-su-candidatura-ya-le-llamaremos-cuando-tenga-modelos-mixtos/</link>
      <pubDate>Tue, 12 Feb 2019 08:13:49 +0000</pubDate>
      
      <guid>/2019/02/12/sr-python-muchas-gracias-por-su-candidatura-ya-le-llamaremos-cuando-tenga-modelos-mixtos/</guid>
      <description>Era casi todavía el siglo XX cuando yo, desesperado por hacer cosas que consideraba normales y que SAS no me permitía, pregunté a un profesor por algo como C pero para estadística. Y el profesor me contó que conocía a alguien que conocía a alguien que conocía a alguien que usaba una cosa nueva que se llamaba R y que podía servirme.
Fue amor a primera vista, pero esa es otra historia.</description>
    </item>
    
    <item>
      <title>Demasiados colores (para el hijo de un daltónico)</title>
      <link>/2019/02/01/demasiados-colores-para-el-hijo-de-un-daltonico/</link>
      <pubDate>Fri, 01 Feb 2019 08:13:47 +0000</pubDate>
      
      <guid>/2019/02/01/demasiados-colores-para-el-hijo-de-un-daltonico/</guid>
      <description>Mi padre me enseñó muchas cosas (leer, sumar, etc.). Pero mi infancia fue monocromática porque era daltónico. Siempre dibujé con lápiz (primero) y tinta (después). Las témperas y los rotuladores fueron mi tormento.
R tiene colores. Un montón. Y paletas de colores. Demasiadas. Una búsqueda entre los paquetes disponibles actualmente en CRAN de color proporciona 88 coincidencias, a las que deben sumarse las 35 adicionales de colour. Algunos de esos paquetes se refieren a asuntos tales como &amp;ldquo;Optimal Block Designs for Two-Colour cDNA Microarray Experiments&amp;rdquo;, pero los más ofrecen cosas tales como:</description>
    </item>
    
    <item>
      <title>¿Hay demasiados paquetes en R?</title>
      <link>/2019/01/31/hay-demasiados-paquetes-en-r/</link>
      <pubDate>Thu, 31 Jan 2019 08:13:31 +0000</pubDate>
      
      <guid>/2019/01/31/hay-demasiados-paquetes-en-r/</guid>
      <description>Por su importancia, traigo aquí y resumo una serie de argumentos que he encontrado en otra parte acerca del ecosistema de paquetes en R. Que son:
 Muchos paquetes no tienen el soporte adecuado a medio plazo. * Además, hay demasiados. * Pero su calidad es desigual. * Y muchos reinventan la rueda (lo manifiesta la escasa interdependencia entre los paquetes). * Finalmente, no es para nada sencillo identificar el paquete que puede ser útil para un fin determinado.</description>
    </item>
    
    <item>
      <title>Evaluación de trucos para multiplicaciones aproximadas</title>
      <link>/2019/01/29/evaluacion-de-trucos-para-multiplicaciones-aproximadas/</link>
      <pubDate>Tue, 29 Jan 2019 08:13:40 +0000</pubDate>
      
      <guid>/2019/01/29/evaluacion-de-trucos-para-multiplicaciones-aproximadas/</guid>
      <description>En Street Fighting Mathematics (leedlo) hay un capítulo en el que se discuten trucos para realizar mental y aproximadamente operaciones del tipo 3600 × 4.4 × 10^4 × 32.
La recomendación es la siguiente: contar ceros primero, gestionar las cifras significativas después. En el caso anterior, el autor identifica 8 ceros (tres del 3600, cuatro del 10^4 y uno del 32), quedando como cifras significativas 3.6, 4.4 y 3.2.
Para estas últimas, recomienda aproximarlas a 1, pocos (alrededor de 3) y 10.</description>
    </item>
    
    <item>
      <title>El discreto encanto de las animaciones</title>
      <link>/2019/01/28/el-discreto-encanto-de-las-animaciones/</link>
      <pubDate>Mon, 28 Jan 2019 08:13:45 +0000</pubDate>
      
      <guid>/2019/01/28/el-discreto-encanto-de-las-animaciones/</guid>
      <description>Representando datos, una animación es un gráfico en el que unas facetas (en terminología de ggplot2) ocultan el resto, como en
extraído de aquí y que representa la evolución del tamaño (superficie) de los coches habituales a lo largo del último siglo. Lo mismo pero evitando el indeseado efecto:
El código:
library(ggplot2) datos &amp;lt;- structure(list(year = c(1930L, 1950L, 1960L, 1970L, 1980L, 1990L, 2000L, 2010L, 2018L), width = c(1.45, 1.59, 1.54, 1.</description>
    </item>
    
    <item>
      <title>data.tree: porque no todos los datos son tabulares</title>
      <link>/2018/12/18/data-tree-porque-no-todos-los-datos-son-tabulares/</link>
      <pubDate>Tue, 18 Dec 2018 08:13:45 +0000</pubDate>
      
      <guid>/2018/12/18/data-tree-porque-no-todos-los-datos-son-tabulares/</guid>
      <description>De acuerdo, casi todos los datos son tabulares. Digamos que el 90% de ellos. Pero muchos de ellos, no. Y data.tree es un paquete con muy buena pinta para manejar estructuras arborescentes de datos: véanse esta y esta viñeta.
Como no podía ser de otra manera, tiene funciones para recorrer, filtrar y podar los árboles de datos.
La aplicación gracias a la cual di con él es el paquete [prof.tree](http://ipub.com/r-profiling/), que es lo mismo que el Rprof de toda la vida&amp;hellip; solo que mola más:</description>
    </item>
    
    <item>
      <title>Siete años después, dejo la presidencia de la Comunidad R Hispano</title>
      <link>/2018/12/11/siete-anos-despues-dejo-la-presidencia-de-la-comunidad-r-hispano/</link>
      <pubDate>Tue, 11 Dec 2018 08:13:55 +0000</pubDate>
      
      <guid>/2018/12/11/siete-anos-despues-dejo-la-presidencia-de-la-comunidad-r-hispano/</guid>
      <description>Eso, que dejo la comunidad de la Comunidad R Hispano. Ocho años después, que ya son. La noticia, en todo caso, no es tanto que abandone la presidencia sino las circunstancias que me condujeron a ella. Noticias viejas, pero noticias al fin y al cabo, que sirven para entender por qué lo fui entonces y por qué dejo de serlo ahora.
La Comunidad R Hispano (por qué se llama así y no, como habría sido natural, Asociación Española de Usuarios de R, es una larga historia que tal vez cuente algún día) se fundó en Madrid hace ocho años en el seno de las III Jornadas de Usuarios de R (a todo esto, esa página la hice yo en html puro y con vi como editor), cuando la comunidad (informal) de usuarios de R ya llevaba un tiempo desarrollando actividades.</description>
    </item>
    
    <item>
      <title>Colinealidad y posterioris</title>
      <link>/2018/11/16/colinealidad-y-posterioris/</link>
      <pubDate>Fri, 16 Nov 2018 08:13:33 +0000</pubDate>
      
      <guid>/2018/11/16/colinealidad-y-posterioris/</guid>
      <description>En esta entrada voy a crear un conjunto de datos donde dos variables tienen una correlación muy alta, ajustar un modelo de regresión y obtener la siguiente representación de la distribución a posteriori de los coeficientes,
donde se aprecia el efecto de la correlación entre x1 y x2.
El código,
library(mvtnorm) library(rstan) library(psych) n &amp;lt;- 100 corr_coef &amp;lt;- .9 x &amp;lt;- rmvnorm(n, c(0, 0), sigma = matrix(c(1, corr_coef, corr_coef, 1), 2, 2)) plot(x) x1 &amp;lt;- x[,1] x2 &amp;lt;- x[,2] x3 &amp;lt;- runif(n) - 0.</description>
    </item>
    
    <item>
      <title>¿Siguen votando igual los diputados?</title>
      <link>/2018/11/08/siguen-votando-igual-los-diputados/</link>
      <pubDate>Thu, 08 Nov 2018 08:13:19 +0000</pubDate>
      
      <guid>/2018/11/08/siguen-votando-igual-los-diputados/</guid>
      <description>Hace seis años escribí esto. Hoy actualizo aquella entrada para crear
Y, por supuesto, el código (que he tenido que reescribir en gran medida):
library(xml2) library(reshape2) library(plyr) # descarga y manipulación de datos dia_votacion &amp;lt;- function(n.votacion){ dir.create(&amp;quot;tmp&amp;quot;) url &amp;lt;- paste(&amp;quot;https://app.congreso.es/votacionesWeb/OpenData?sesion=&amp;quot;, n.votacion, &amp;quot;&amp;amp;completa;=1&amp;amp;legislatura;=12&amp;quot;, sep = &amp;quot;&amp;quot;) download.file( url, destfile = &amp;quot;./tmp/votos.zip&amp;quot;) try(unzip(&amp;quot;./tmp/votos.zip&amp;quot;, exdir = &amp;quot;./tmp&amp;quot;), TRUE) ficheros &amp;lt;- dir(&amp;quot;./tmp&amp;quot;, pattern = &amp;quot;.*xml&amp;quot;, full.names = T) if (length(ficheros) == 0) return(NULL) res &amp;lt;- lapply(ficheros, function(fichero){ print(fichero) datos &amp;lt;- as_list(read_xml(fichero)) sesion &amp;lt;- datos$Resultado$Informacion$Sesion numero &amp;lt;- datos$Resultado$Informacion$NumeroVotacion try(datos &amp;lt;- ldply(datos$Resultado$Votaciones, unlist), TRUE) if (class(datos) == &amp;quot;try-error&amp;quot;) return(NULL) if (class(datos) !</description>
    </item>
    
    <item>
      <title>Cuatro paquetes interesantes de R</title>
      <link>/2018/11/05/cuatro-paquetes-interesantes-de-r/</link>
      <pubDate>Mon, 05 Nov 2018 08:13:50 +0000</pubDate>
      
      <guid>/2018/11/05/cuatro-paquetes-interesantes-de-r/</guid>
      <description>Son paquetes que marcado como potencialmente relevantes pero que aún no he revisado como debiera. Tal vez alguien tenga algo más que decir sobre ellos. Tiene los comentarios, por supuesto, abiertos.
longRPart2: Particionamiento recursivo para modelos longitudinales. Extiende ctree y, por supuesto, mob del paquete party a datos de tipo longitudinal.
radiant: Más que un paquete, es un conjunto de paquetes para business analytics usando R y Shiny. Ni idea de para qué parte de ese amplio campo del business analytics puede resultar útil, pero si resulta que es precisamente el tuyo, ¡enhorabuena!</description>
    </item>
    
    <item>
      <title>Enlaces parasociológicos</title>
      <link>/2018/10/29/enlaces-parasociologicos/</link>
      <pubDate>Mon, 29 Oct 2018 08:13:21 +0000</pubDate>
      
      <guid>/2018/10/29/enlaces-parasociologicos/</guid>
      <description>Tenía tan bien guardados en el disco duro una serie de enlaces de interés parasociológico que no había forma humana de dar con ellos.
Para que no me vuelva a pasar y por su potencial interés para otros, los cuelgo aquí.
El primero de ellos (que no sé por qué lo guardé) son las diapositivas de una charla acerca de cómo transformar porcentajes de votos en escaños en España.
Los otros tres se refieren a la metodología que utiliza la gente de electionforecast.</description>
    </item>
    
    <item>
      <title>Extingámonos con dignidad: generaciones actuales y futuras, no incurramos en los errores de las anteriores</title>
      <link>/2018/10/08/extingamonos-con-dignidad-generaciones-actuales-y-futuras-no-incurramos-en-los-errores-de-las-anteriores/</link>
      <pubDate>Mon, 08 Oct 2018 08:13:43 +0000</pubDate>
      
      <guid>/2018/10/08/extingamonos-con-dignidad-generaciones-actuales-y-futuras-no-incurramos-en-los-errores-de-las-anteriores/</guid>
      <description>Participé el otro día en una cena con gente friqui. Constaté con cierto desasosiego cómo han virado los sujetos pasivos de nuestra indignación profesional a lo largo de los años.
Antaño, fueron los viejos que seguían apegados a la paleoinformática. Hogaño, los primíparos que usan Python y desdeñan R.
Tengo sentimientos encontrados y no sé qué más añadir.</description>
    </item>
    
    <item>
      <title>&#34;Embeddings&#34; y análisis del carrito de la compra</title>
      <link>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</link>
      <pubDate>Thu, 04 Oct 2018 08:13:34 +0000</pubDate>
      
      <guid>/2018/10/04/embeddings-y-analisis-del-carrito-de-la-compra/</guid>
      <description>Escribiendo la entrada del otro día sobre embeddings, no se me pasó por alto que la fórmula
$latex \frac{P(W_i,C_i)}{P(W_i)P(C_i)}$
que escribí en ella es análoga al llamado lift (¿es el lift?) del llamado análisis del carrito de la compra, i.e., el estudio de productos que tienden a comprarse juntos (véase, por ejemplo, esto).
Lo cual me lleva a sugerir mas no escribir una entrada en la que se rehagan este tipo de análisis usando embeddings: los ítems como palabras, los carritos como textos, etc.</description>
    </item>
    
    <item>
      <title>Planes de búsqueda y rescate con R</title>
      <link>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</link>
      <pubDate>Tue, 02 Oct 2018 13:09:10 +0000</pubDate>
      
      <guid>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</guid>
      <description>Existe un paquete muy curioso en CRAN, [rSARP](https://cran.r-project.org/package=rSARP) para diseñar, optimizar y comunicar la evolución de planes de búsqueda y/o rescate (p.e., de un niño desaparecido en un monte).
Es particularmente interesante porque este tipo de problemas lo tienen todo: desde distribuciones a priori (sobre dónde es más probable encontrar lo que se busca) hasta la decisión final (explórese tanto aquí y tanto allá) teniendo en cuenta restricciones de tiempo y recursos.</description>
    </item>
    
    <item>
      <title>Disponible el fichero de datos abiertos más goloso de ambas castillas: las rutas de Bicimad</title>
      <link>/2018/09/25/disponible-el-fichero-de-datos-abiertos-mas-goloso-de-ambas-castillas-las-rutas-de-bicimad/</link>
      <pubDate>Tue, 25 Sep 2018 08:13:27 +0000</pubDate>
      
      <guid>/2018/09/25/disponible-el-fichero-de-datos-abiertos-mas-goloso-de-ambas-castillas-las-rutas-de-bicimad/</guid>
      <description>Albricias, el ayuntamiento de Madrid ha liberado el fichero más goloso de ambas castillas: el de las rutas de usuarios de Bicimad, viaje a viaje, con su estación de origen, estación de destino, tiempo de recorrido, etc. Tiempo os falta para echarle un vistazo y hacer cosas chulas con él.
Los datos están aquí.
Se puede leer con código no muy distinto de este:
library(RJSONIO) raw &amp;lt;- readLines(&amp;quot;201808_Usage_Bicimad.json&amp;quot;) dat &amp;lt;- iconv(raw, &amp;quot;latin1&amp;quot;, &amp;quot;utf8&amp;quot;) dat &amp;lt;- sapply(dat, fromJSON)  A bote pronto, se me ocurren algunas cosas que se pueden hacer con esos datos:</description>
    </item>
    
    <item>
      <title>X Jornadas de Usuarios de R: ¡abiertas las inscripciones!</title>
      <link>/2018/09/20/x-jornadas-de-usuarios-de-r-abiertas-las-inscripciones/</link>
      <pubDate>Thu, 20 Sep 2018 08:13:37 +0000</pubDate>
      
      <guid>/2018/09/20/x-jornadas-de-usuarios-de-r-abiertas-las-inscripciones/</guid>
      <description>Nada que añadir a:</description>
    </item>
    
    <item>
      <title>Los datos están histogramizados... ¿quién los deshisotogramizará?</title>
      <link>/2018/09/18/los-datos-estan-histogramizados-quien-los-deshisotogramizara/</link>
      <pubDate>Tue, 18 Sep 2018 08:13:51 +0000</pubDate>
      
      <guid>/2018/09/18/los-datos-estan-histogramizados-quien-los-deshisotogramizara/</guid>
      <description>Hace un tiempo quise hacer cosas malísimas con datos fiscales de España y Dinamarca. Pero los datos estaban histogramizados:
Gracias a Freakonometrics di con binequality. Adaptando su código, escribo
library(rvest) library(plyr) dk &amp;lt;- read_html(&amp;quot;http://www.skm.dk/english/facts-and-figures/progression-in-the-income-tax-system&amp;quot;) tmp &amp;lt;- html_nodes(dk, &amp;quot;table&amp;quot;) tmp &amp;lt;- html_table(tmp[[2]]) header &amp;lt;- tmp[1,] tmp &amp;lt;- tmp[-c(1, 2),] colnames(tmp) &amp;lt;- header # elimino declaraciones negativas tmp &amp;lt;- tmp[-1,] # elimino el total tmp &amp;lt;- tmp[-(nrow(tmp)),] colnames(tmp) &amp;lt;- c(&amp;quot;rango&amp;quot;, &amp;quot;contribuyentes&amp;quot;, &amp;quot;X1&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;tax1&amp;quot;, &amp;quot;tax2&amp;quot;, &amp;quot;pct&amp;quot;) irpf_dk &amp;lt;- tmp[, c(&amp;quot;rango&amp;quot;, &amp;quot;contribuyentes&amp;quot;, &amp;quot;income&amp;quot;, &amp;quot;tax1&amp;quot;, &amp;quot;tax2&amp;quot;)] irpf_dk$contribuyentes &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>Contraargumentando (materialmente) sobre la falacia del fiscal</title>
      <link>/2018/09/13/contraargumentando-materialmente-sobre-la-falacia-del-fiscal/</link>
      <pubDate>Thu, 13 Sep 2018 08:13:23 +0000</pubDate>
      
      <guid>/2018/09/13/contraargumentando-materialmente-sobre-la-falacia-del-fiscal/</guid>
      <description>Hace un par de días hablé de la falacia del fiscal y granos de arroz. La entrada iba acompañada de
y la lección era: es raro no encontrar ningún clúster cuando se tiran al azar granos de arroz sobre una superficie. De lo que se derivaban más cosas que es ocioso repetir aquí.
Pero el gráfico no es desconocido para los viejos del lugar: se parece mucho al de la página 319 de ESL.</description>
    </item>
    
    <item>
      <title>Series temporales y &#34;motifs&#34;</title>
      <link>/2018/09/10/series-temporales-y-motifs/</link>
      <pubDate>Mon, 10 Sep 2018 08:13:53 +0000</pubDate>
      
      <guid>/2018/09/10/series-temporales-y-motifs/</guid>
      <description>Un motif es un patrón que se repite en una serie temporal:
Para saber más sobre ellos, p.e., Finding Motif Sets in Time Series. Y para identificarlos con R, STMotif.</description>
    </item>
    
    <item>
      <title>¿Por que slt-ear si puedes stR-ear?</title>
      <link>/2018/07/25/por-que-slt-ear-si-puedes-str-ear/</link>
      <pubDate>Wed, 25 Jul 2018 08:13:42 +0000</pubDate>
      
      <guid>/2018/07/25/por-que-slt-ear-si-puedes-str-ear/</guid>
      <description>La función stl (véase aquí un ejemplo de uso). Pero tiene sus limitaciones.
El paquete stR la extiende y permite, entre otras cosas, introducir distintos tipos de estacionalidades (p.e., anuales y semanales).</description>
    </item>
    
    <item>
      <title>kamila: Clústering con variables categóricas</title>
      <link>/2018/07/20/kamila-clustering-con-variables-categoricas/</link>
      <pubDate>Fri, 20 Jul 2018 08:13:58 +0000</pubDate>
      
      <guid>/2018/07/20/kamila-clustering-con-variables-categoricas/</guid>
      <description>La codificación de las variables categóricas en problemas de clústering es la fuente de la mayor parte de los problemas con que se encuentran los desdichados que se ven forzados a aplicar este tipo de técnicas.
Existen algoritmos que tratan de resolver el problema sin necesidad de realizar codificaciones numéricas. kamila es un paquete de R que implementa uno de ellos. El artículo que lo acompaña, A semiparametric method for clustering mixed data aporta los detalles, que en resumen son:</description>
    </item>
    
    <item>
      <title>François Husson en las X Jornadas de Usuarios de R</title>
      <link>/2018/06/11/francois-husson-en-las-x-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 11 Jun 2018 08:13:04 +0000</pubDate>
      
      <guid>/2018/06/11/francois-husson-en-las-x-jornadas-de-usuarios-de-r/</guid>
      <description>Las X Jornadas de Usuarios de R siguen adelante. Ahora, el comité organizador ha anunciado que una de las charlas plenarias correrá a cargo de François Husson, conocido por FactoMineR.
Sirva esta entrada de recordatorio, además, para que vayas considerando acudir a las jornadas.
[Y sí, escribo poco este mes; desafortunadamente, no tanto por falta de motivos como del tiempo necesario.]</description>
    </item>
    
    <item>
      <title>Casos de uso de MicroDatosEs</title>
      <link>/2018/05/16/casos-de-uso-de-microdatoses/</link>
      <pubDate>Wed, 16 May 2018 08:13:42 +0000</pubDate>
      
      <guid>/2018/05/16/casos-de-uso-de-microdatoses/</guid>
      <description>[MicroDatosEs](https://github.com/rOpenSpain/MicroDatosEs) ha sufrido algunas modificaciones recientes. En particular, un nuevo colaborador, Jorge López Pérez ha reescrito la documentación usando [roxygen2](https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html).
Pero falta una cosa importante (sobre todo, para el usuario esporádico): casos de uso.
En la página del paquete (el README.md de Github) he añadido una sección de ejemplos de uso de funciones del paquete, que actualmente solo tiene un enlace. Pero si alguien ha hecho o conoce algún otro ejemplo, y me lo puede comunicar, lo añadiré muy gustosamente (y quedaré muy agradecido).</description>
    </item>
    
    <item>
      <title>gam/bam admiten efectos aleatorios</title>
      <link>/2018/05/10/gam-bam-admiten-efectos-aleatorios/</link>
      <pubDate>Thu, 10 May 2018 08:13:58 +0000</pubDate>
      
      <guid>/2018/05/10/gam-bam-admiten-efectos-aleatorios/</guid>
      <description>gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios gam/bam admiten efectos aleatorios
Y solo me enteré anoche (gracias a José Luis Cañadas).
(Para más detalles, esto o esto).</description>
    </item>
    
    <item>
      <title>Leaflet con capas WMS de Correos, Catastro, etc.</title>
      <link>/2018/05/04/leaflet-con-capas-wms-de-coreos-catastro-etc/</link>
      <pubDate>Fri, 04 May 2018 08:13:55 +0000</pubDate>
      
      <guid>/2018/05/04/leaflet-con-capas-wms-de-coreos-catastro-etc/</guid>
      <description>Esta entrada es un subproducto del trabajo que pocería que he realizado estos días en caRtociudad.
caRtociudad permite generar mapas estáticos al estilo de ggmap. Iba a poner algún ejemplo, pero los dejo para otro día.
La cosa es que mejorando caRtociudad::get_cartociudad_map, se me ha pasado por la cabeza la posibilidad de realizar la integración no ya con ggmap sino con leaflet. Y así (¡probadlos!), para los códigos postales,
library(leaflet) leaflet() %&amp;gt;% addTiles() %&amp;gt;% setView(-3.</description>
    </item>
    
    <item>
      <title>t y as.raster no conmutan; ¿por qué no conmutarán?</title>
      <link>/2018/05/03/t-y-as-raster-no-conmutan-por-que-no-conmutaran/</link>
      <pubDate>Thu, 03 May 2018 08:13:35 +0000</pubDate>
      
      <guid>/2018/05/03/t-y-as-raster-no-conmutan-por-que-no-conmutaran/</guid>
      <description>Creo una minimatriz, la convierto en un raster y la represento:
m &amp;lt;- matrix(c(0, 0, 0.33, 0.66, .9, .9), 2, 3) m # [,1] [,2] [,3] # [1,] 0 0.33 .9 # [2,] 0 0.66 .9 r &amp;lt;- as.raster(m) r # [,1] [,2] [,3] # [1,] &amp;quot;#000000&amp;quot; &amp;quot;#545454&amp;quot; &amp;quot;#FFFFFF&amp;quot; # [2,] &amp;quot;#000000&amp;quot; &amp;quot;#A8A8A8&amp;quot; &amp;quot;#FFFFFF&amp;quot; plot(r, interpolate = FALSE)  Ahora, con la matriz traspuesta,
r_t_1 &amp;lt;- as.raster(t(m)) r_t_1 # [,1] [,2] # [1,] &amp;quot;#000000&amp;quot; &amp;quot;#000000&amp;quot; # [2,] &amp;quot;#545454&amp;quot; &amp;quot;#A8A8A8&amp;quot; # [3,] &amp;quot;#E6E6E6&amp;quot; &amp;quot;#E6E6E6&amp;quot;  obtengo</description>
    </item>
    
    <item>
      <title>El malabarista de Amiga, con R (y rgl)</title>
      <link>/2018/04/24/el-malabarista-de-amiga-con-r-y-rgl/</link>
      <pubDate>Tue, 24 Apr 2018 08:11:30 +0000</pubDate>
      
      <guid>/2018/04/24/el-malabarista-de-amiga-con-r-y-rgl/</guid>
      <description>Un exalumno mío de unos cursos de R, Guillermo Luijk, ha creado
https://www.youtube.com/watch?v=U7ndveqX_H4
usando R (y el paquete rgl).
Toda la información relevante, (incluyendo la historia, el código, las ecuaciones, etc.) aquí. Infinitamente recomendable.
(La recomendación se extiende encarecidamente al resto de las entradas de su blog).</description>
    </item>
    
    <item>
      <title>La intrahistoria de mi libro de R</title>
      <link>/2018/04/09/la-intrahistoria-de-mi-libro-de-r/</link>
      <pubDate>Mon, 09 Apr 2018 08:13:44 +0000</pubDate>
      
      <guid>/2018/04/09/la-intrahistoria-de-mi-libro-de-r/</guid>
      <description>Una de las preguntas más fértiles que pueden formularse frente a algo es la del motivo de su existencia: ¿por qué existe en lugar de, simplemente, no existir?
El otro día anuncié públicamente la existencia de mi libro de R. No es el mejor ni el peor. Es hijo de las circunstancias que lo hicieron nacer. Que describo a continuación.
I
Corría el 2014. Yo tecleaba entonces en las oficinas de eBay en Zúrich.</description>
    </item>
    
    <item>
      <title>Un libro de R: mi libro de R</title>
      <link>/2018/04/05/un-libro-de-r-mi-libro-de-r/</link>
      <pubDate>Thu, 05 Apr 2018 08:13:12 +0000</pubDate>
      
      <guid>/2018/04/05/un-libro-de-r-mi-libro-de-r/</guid>
      <description>No quería hacerlo público aún pero alguien se ve que lo estaba leyendo por ahí. No sé si Google habrá levantado ya la pájara. Tampoco es que fuese un secreto: lo he usado para varios cursos y me consta que ha sido usado por terceros para tal fin.
Pero ya está, es oficial: mi libro de introducción a R (inacabado) está colgado (aquí).
Y no voy a añadir nada más al respecto porque está todo en la introducción.</description>
    </item>
    
    <item>
      <title>¿Un voluntario para aggiornar MicroDatosEs?</title>
      <link>/2018/03/26/un-voluntario-para-aggiornar-microdatoses/</link>
      <pubDate>Mon, 26 Mar 2018 08:13:29 +0000</pubDate>
      
      <guid>/2018/03/26/un-voluntario-para-aggiornar-microdatoses/</guid>
      <description>Mi paquete MicroDatosEs ya forma parte de rOpenSpain. Sin embargo, está falto de ciertas mejoras a las que aspiran los paquetes que forman parte de dicho repositorio.
Una de ellas es la de migrar la documentación del paquete a roxigen2. Lo podría hacer yo, pero es muy aburrido. Sin embargo, entiendo que puede ser entretenido (además de sencillo) para alguien que:
 * No sepa de qué va eso de `roxigen2` pero me tome la palabra en eso de que es importante.</description>
    </item>
    
    <item>
      <title>¿Podría ser la solución que almas caritativas creasen viñetas espontáneamente?</title>
      <link>/2018/03/08/podria-ser-la-solucion-que-almas-caritativas-creasen-vinetas-espontaneamente/</link>
      <pubDate>Thu, 08 Mar 2018 08:13:23 +0000</pubDate>
      
      <guid>/2018/03/08/podria-ser-la-solucion-que-almas-caritativas-creasen-vinetas-espontaneamente/</guid>
      <description>Uno de los modelos más útiles potencialmente y que menos atención recibe es el de los modelos de conteos autoexcitados. Es decir, aquellos en los que un evento incrementa durante cierto tiempo la probabilidad de que ocurra otro. Creedme, ocurre así muy a menudo en muchas aplicaciones.
Por eso se pone uno muy contento cuando descubre paquetes de R como este.
Pero el hecho de que unos académicos lo hayan creado y puesto ahí por mor de las neonormas (administrativas, morales o de señalamiento) de reproducibilidad, no significa que lo hayan desarrollado para los usuarios finales.</description>
    </item>
    
    <item>
      <title>Documentar como el culo, no pensar en el usuario final, ser incapaz de ponerte en su situación, etc.</title>
      <link>/2018/02/28/documentar-como-el-culo-no-pensar-en-el-usuario-final-ser-incapaz-de-ponerte-en-su-situacion-etc/</link>
      <pubDate>Wed, 28 Feb 2018 08:13:54 +0000</pubDate>
      
      <guid>/2018/02/28/documentar-como-el-culo-no-pensar-en-el-usuario-final-ser-incapaz-de-ponerte-en-su-situacion-etc/</guid>
      <description>De vez en cuando pruebo paquetes promisorios. No es infrecuente que cosas que he intentado hace años, algún ejemplo más o menos sencillo que he publicado aquí, acabe convirtiéndose en la piedra angular de algo facturable. Incluso de algo facturable por mí.
geozoning podía haber sido uno de esos. La promesa del paquete es que puede ayudarte a segmentar regiones del espacio de acuerdo con alguna variable, una especie de clústering para información de tipo espacial.</description>
    </item>
    
    <item>
      <title>Con tiempo: encuentro de usuarios de R de Latinoamérica en enero de 2019</title>
      <link>/2018/02/23/con-tiempo-encuentro-de-usuarios-de-r-de-latinoamerica-en-enero-de-2019/</link>
      <pubDate>Fri, 23 Feb 2018 08:13:39 +0000</pubDate>
      
      <guid>/2018/02/23/con-tiempo-encuentro-de-usuarios-de-r-de-latinoamerica-en-enero-de-2019/</guid>
      <description>Pues sí, acabo de enterarme de que se organiza la tal cosa. Toda la información, escasa de momento, aquí.</description>
    </item>
    
    <item>
      <title>mgm (no la de las pelis sino la de los modelos gráficos)</title>
      <link>/2018/01/25/mgm-no-la-de-las-pelis-sino-la-de-los-modelos-graficos/</link>
      <pubDate>Thu, 25 Jan 2018 08:13:12 +0000</pubDate>
      
      <guid>/2018/01/25/mgm-no-la-de-las-pelis-sino-la-de-los-modelos-graficos/</guid>
      <description>Cayeron en mis manos unos datos que no puedo publicar, pero me atreveré a presentar algunos resultados anonimizados. Se trata de una tabla de puntuaciones numéricas (18 en total, cada una en su columna) proporcionadas por unos cuantos centenares de sujetos (filas). Era de interés un estudio cualitativo de las posibles relaciones de dependencia entre las variables.
La manera más rápida de comenzar, un heatmap(cor(dat)), para obtener
Y luego PCA y todas esas cosas.</description>
    </item>
    
    <item>
      <title>Mortalidad en carretera (contada de una manera distinta)</title>
      <link>/2018/01/09/mortalidad-en-carretera-contada-de-una-manera-distinta/</link>
      <pubDate>Tue, 09 Jan 2018 08:13:17 +0000</pubDate>
      
      <guid>/2018/01/09/mortalidad-en-carretera-contada-de-una-manera-distinta/</guid>
      <description>Con motivo de fin de año se ha hablado de fallecidos en accidentes de tráfico como por ejemplo en El Mundo o en El País. Y sí, parece que el número observado de muertos ha aumentado.
Lo cual es mucho menos relevante de lo que se da a entender. Si tiras una moneda al aire 100 veces y sacas 48 caras y luego repites el experimento, podrías sacar 53 (y habría aumentado el número observado de caras) o 45 (y habría disminuido).</description>
    </item>
    
    <item>
      <title>La distribución de Poisson y la estabilización de la varianza</title>
      <link>/2017/12/15/la-poisson-y-la-estabilizacion-de-la-varianza/</link>
      <pubDate>Fri, 15 Dec 2017 20:07:25 +0000</pubDate>
      
      <guid>/2017/12/15/la-poisson-y-la-estabilizacion-de-la-varianza/</guid>
      <description>Imagínate que quieres estabilizar la varianza (¡para qué!) de una distribución de Poisson. Los libros viejunos te dirán que saques la raíz cuadrada de tus valores.
Si en lugar de mirar en libros viejunos prestas atención a tus propios ojos, harás algo parecido a:
lambdas &amp;lt;- -10:10 lambdas &amp;lt;- 2^lambdas res &amp;lt;- sapply(lambdas, function(lambda) sd(sqrt(rpois(1e5, lambda))))  para obtener
y averiguar dónde funciona y dónde no.
Si usas la transformación $latex f(x) = x^{2/3}$, como recomiendan en cierto artículo que no viene a cuento identificar, harás</description>
    </item>
    
    <item>
      <title>p-curvas</title>
      <link>/2017/12/12/p-curvas/</link>
      <pubDate>Tue, 12 Dec 2017 08:13:19 +0000</pubDate>
      
      <guid>/2017/12/12/p-curvas/</guid>
      <description>Primero, una simulación:
n &amp;lt;- 100 delta &amp;lt;- 0.2 n.iter &amp;lt;- 10000 p_valores &amp;lt;- function(n, delta){ tmp &amp;lt;- replicate(n.iter, { x &amp;lt;- rnorm(n) y &amp;lt;- rnorm(n, mean = delta) t.test(x, y)$p.value }) res &amp;lt;- tmp[tmp &amp;lt; 0.05] hist(res, freq = FALSE, xlab = &amp;quot;p value&amp;quot;, ylab = &amp;quot;&amp;quot;, col = &amp;quot;gray&amp;quot;, main = &amp;quot;histograma de p-valores publicables&amp;quot;) res } null_effect_p_values &amp;lt;- p_valores(n, 0) some_effect_p_values &amp;lt;- p_valores(n, delta)  Lo que simula son n.</description>
    </item>
    
    <item>
      <title>Cuidado con los $</title>
      <link>/2017/12/11/cuidado-con-los/</link>
      <pubDate>Mon, 11 Dec 2017 08:13:03 +0000</pubDate>
      
      <guid>/2017/12/11/cuidado-con-los/</guid>
      <description>El otro tropezamos con el siguiente artefacto:
a &amp;lt;- list(aa = 12, bb = 14) is.null(a$a) #[1] FALSE a$a #[1] 12  No es un bug de R, por que la documentación reza:
Y se pueden constrastar:
a[[&amp;quot;a&amp;quot;, exact = FALSE]] a[[&amp;quot;a&amp;quot;, exact = TRUE]]  Comentarios:
 * Odio muchísimo los _bugs_ que no son _bugs_ porque están documentados en el la nota ‡2.a.(c), párrafo §23.3 de la sección 14 de un manual oscuro.</description>
    </item>
    
    <item>
      <title>La magnitud de la sequía</title>
      <link>/2017/12/04/la-magnitud-de-la-sequia/</link>
      <pubDate>Mon, 04 Dec 2017 08:13:28 +0000</pubDate>
      
      <guid>/2017/12/04/la-magnitud-de-la-sequia/</guid>
      <description>Cuando tienes una serie temporal al uso (sin entrar a definir qué es eso), uno puede aplicar descomposiciones tmabién al uso, como stl, para extraer tendencia y estacionalidad, de la forma
como en esta entrada previa.
Lluvia.
La serie de la lluvia es otra cosa. Uno ve si llueve o no llueve (típicamente no). Lo que uno no ve es la probabilidad, que varía a lo largo del año, de que llueva.</description>
    </item>
    
    <item>
      <title>dbf · xlsx · pdf</title>
      <link>/2017/11/24/dbf-xlsx-pdf/</link>
      <pubDate>Fri, 24 Nov 2017 08:13:55 +0000</pubDate>
      
      <guid>/2017/11/24/dbf-xlsx-pdf/</guid>
      <description>Me escriben pidiendo consejo sobre cómo leer datos contenidos en (una serie larga de) ficheros en formatos .dbf, .xlsx (con un formato extraño) y .pdf.
.dbf
No tengo ni curiosidad por averiguar de dónde proceden. Simplemente,
 library(foreign) res &amp;lt;-read.dbf(&amp;quot;R0010.DBF&amp;quot;)  funciona de maravilla.
.xlsx
Estos sí que sé de dónde vienen (y me guardo la opinión). El problema aquí no era leer directamente tablas contenidas en hojas sino ir extrayendo celdas y rangos de hojas.</description>
    </item>
    
    <item>
      <title>Arqueólogos bayesianos</title>
      <link>/2017/11/23/arqueologos-bayesianos/</link>
      <pubDate>Thu, 23 Nov 2017 08:13:26 +0000</pubDate>
      
      <guid>/2017/11/23/arqueologos-bayesianos/</guid>
      <description>Se ve que hay arqueólogos bayesianos. Un problema con el que se encuentran es que tropiezan con cacharros antiguos y quieren estimar su antigüedad.
Así que prueban distintos métodos (¿químicos?), cada uno de los cuales con su precisión, y acaban recopilando una serie de estimaciones y errores. Obviamente, tienen que combinarlas de alguna manera.
El modelo más simple es
$latex M_i \sim N(\mu, \sigma_i)$
donde $latex \mu$ es la antigüedad (desconocida) del artefacto y los $latex \sigma_i$ son las varianzas distintas de los distintos métodos de medida, que arrojan las estimaciones $latex M_i$.</description>
    </item>
    
    <item>
      <title>&#34;Intervalos&#34; de confianza con forma de rosquilla</title>
      <link>/2017/11/07/intervalos-de-confianza-con-forma-de-rosquilla/</link>
      <pubDate>Tue, 07 Nov 2017 08:13:44 +0000</pubDate>
      
      <guid>/2017/11/07/intervalos-de-confianza-con-forma-de-rosquilla/</guid>
      <description>Envalentonado por el comentario de Iñaki Úcar a mi entrada del otro día, que me remitía a este artículo, decidí rizar el rizo y crear intervalos de confianza no ya discontinuos sino con otra propiedad topológica imposible: homeomorfos con un toro.
Y aquí está:
El modelo, el código y demás,
library(rstan) library(ggplot2) n &amp;lt;- 100 a1 &amp;lt;- 1 a2 &amp;lt;- 1 sigma &amp;lt;- 0.4 datos &amp;lt;- data.frame(x1 = rnorm(n, 2, 0.</description>
    </item>
    
    <item>
      <title>Distribuciones hiperbólicas</title>
      <link>/2017/10/31/distribuciones-hiperbolicas/</link>
      <pubDate>Tue, 31 Oct 2017 08:13:21 +0000</pubDate>
      
      <guid>/2017/10/31/distribuciones-hiperbolicas/</guid>
      <description>curve(-sqrt(x^2 + 1), -5, 5)  pinta una rama de hipérbola,
que, una vez exponenciada, i.e.,
curve(exp(-sqrt(x^2 + 1)), -5, 5)  da
Es decir, una curva algo menos esbelta que la normal pero que bien podemos dividir por su integral para obtener la llamada distribución hiperbólica.
Tres notas sobre ella:
 * Tiene una historia curiosa. Fue considerada por [Ralph Bagnold](https://en.wikipedia.org/wiki/Ralph_Alger_Bagnold) al estudiar la forma de las dunas y la sedimentación de la arena arrastrada por el viento.</description>
    </item>
    
    <item>
      <title>Modelos directos, inversos y en los que tanto da</title>
      <link>/2017/10/23/modelos-directos-inversos-y-en-los-que-tanto-da/</link>
      <pubDate>Mon, 23 Oct 2017 08:13:15 +0000</pubDate>
      
      <guid>/2017/10/23/modelos-directos-inversos-y-en-los-que-tanto-da/</guid>
      <description>Continúo con esto que concluí con una discusión que me negué a resolver sobre la geometría de los errores.
Que es la manera de entender que los problemas directos e inversos no son exactamente el mismo. Digamos que no es una medida invariante frente a reflexiones del plano (que es lo que hacemos realmente al considerar el modelo inverso).
¿Pero y si medimos la distancia (ortogonal) entre los puntos $latex (x,y)$ y la curva $latex y = f(x)$ (o, equivalentemente, $latex x = f^{-1}(x)$)?</description>
    </item>
    
    <item>
      <title>He tratado de contrastar una hipótesis sin éxito, así que solo publico el subproducto</title>
      <link>/2017/10/20/he-tratado-de-contrastar-una-hipotesis-sin-exito-asi-que-solo-publico-el-subproducto/</link>
      <pubDate>Fri, 20 Oct 2017 08:13:02 +0000</pubDate>
      
      <guid>/2017/10/20/he-tratado-de-contrastar-una-hipotesis-sin-exito-asi-que-solo-publico-el-subproducto/</guid>
      <description>Inspirado por esto he tratado de contrastar una hipótesis en otro contexto.
Las cosas, o se hacen bien, o no se hacen. Como mi análisis se ha complicado con casos y casitos particulares, aunque siga pensándo cierta (en caso de tener que apostar, como priori, claro) la hipótesis de partida, abandono su búsqueda.
Como subproducto, esto:
library(xml2) library(stringr) library(plyr) library(lubridate) periodos &amp;lt;- expand.grid(anno = 2010:2017, mes = 1:12) periodos$ind &amp;lt;- periodos$anno * 100 + periodos$mes periodos &amp;lt;- periodos[periodos$ind &amp;lt; 201711,] periodos &amp;lt;- paste(periodos$anno, str_pad(periodos$mes, 2, pad = &amp;quot;0&amp;quot;), sep = &amp;quot;_&amp;quot;) raw &amp;lt;- lapply(periodos, function(x){ url &amp;lt;- paste0(&amp;quot;http://www.</description>
    </item>
    
    <item>
      <title>Modelos no lineales directos e inversos</title>
      <link>/2017/10/16/modelos-no-lineales-directos-e-inversos/</link>
      <pubDate>Mon, 16 Oct 2017 08:13:41 +0000</pubDate>
      
      <guid>/2017/10/16/modelos-no-lineales-directos-e-inversos/</guid>
      <description>Las malandanzas de Circiter la han conducido al siguiente entuerto: estimar $latex \alpha$ donde
$latex y = f_\alpha(x) + \epsilon$
y $latex f_\alpha$ es una función no lineal horrible. Sin embargo, $latex f^{-1}_\alpha$ es mucho más manejable y podría plantearse el modelo
$latex x = f^{-1}_\alpha(y) + \epsilon$
(donde este nuevo $latex \epsilon$ no coincide con el anterior: piénsese en el método delta y léase la nota final).
Un ejemplo. Que arranca con unos datos autoexplicativos:</description>
    </item>
    
    <item>
      <title>rOpenSpain: ahí tiro el guante</title>
      <link>/2017/10/11/ropenspain-ahi-tiro-el-guante/</link>
      <pubDate>Wed, 11 Oct 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/10/11/ropenspain-ahi-tiro-el-guante/</guid>
      <description>La gente de rOpenSci hace cosas a las que merece la pena atento. Tanto por los objetivos como por medios y las formas. Recomiendo seguir sus últimas publicaciones acerca de la profesionalización del proceso de desarrollo de código.
Llevo unos meses jugando con una idea inspirada por rOpenSci: crear un respositorio y un consorcio más o menos formal que desarrolle, mantenga y mejore herramientas (en R) de interés para el procesamiento y análisis de datos ya no científicos sino españoles.</description>
    </item>
    
    <item>
      <title>Efectos secundarios (nota: que existan no significa que debas usarlos)</title>
      <link>/2017/10/10/efectos-secundarios-nota-que-existan-no-significa-que-debas-usarlos/</link>
      <pubDate>Tue, 10 Oct 2017 08:13:11 +0000</pubDate>
      
      <guid>/2017/10/10/efectos-secundarios-nota-que-existan-no-significa-que-debas-usarlos/</guid>
      <description>Una función no debería cambiar nada de cuanto la rodea. Debería devolver algo y ya. Se acepta barco como animal acuático cuando hay funciones que escriben en logs, guardan datos en disco o crean gráficos.
R deja que los usuarios se disparen en el pie permitiendo hacer cosas tan peligrosas como:
a &amp;lt;- new.env() a$1 # error foo &amp;lt;- function(){ a$a &amp;lt;- 1 } foo() a$a # [1] 1  De la misma manera, si le enseñas un cuchillo a una vieja, es posible que te dé su bolso con todo lo que contiene.</description>
    </item>
    
    <item>
      <title>Una comparación de lenguajes de programación en una esquinita pequeña de la economía</title>
      <link>/2017/10/06/una-comparacion-de-lenguajes-de-programacion-en-una-esquinita-pequena-de-la-economia/</link>
      <pubDate>Fri, 06 Oct 2017 08:13:55 +0000</pubDate>
      
      <guid>/2017/10/06/una-comparacion-de-lenguajes-de-programacion-en-una-esquinita-pequena-de-la-economia/</guid>
      <description>El título, no el de esta entrada sino el de A Comparison of Programming Languages in Economics, es una sinécdoque confusa.
Que nadie busque en él consejo sobre qué lenguaje estudiar si le interesa el mundo de la economía (en general). O fuera de ella (también en general).
Encontrará más bien la implementación de la solución a un único problema dentro de los muchos que supongo comprende esa disciplina. Uno, además, con el que no he visto (en persona) a economista alguno ganarse el pan ni en la academia ni fuera de ella.</description>
    </item>
    
    <item>
      <title>CatastRo, un paquete de R para consultar la API del Catastro</title>
      <link>/2017/10/02/catastro-un-paquete-de-r-para-consultar-la-api-del-catastro/</link>
      <pubDate>Mon, 02 Oct 2017 08:12:35 +0000</pubDate>
      
      <guid>/2017/10/02/catastro-un-paquete-de-r-para-consultar-la-api-del-catastro/</guid>
      <description>Informo de que está disponible en GitHub el paquete CatastRo para consultar la API pública del Catastro.
No es una API particularmente extensa, pero es de esperar que se amplíe el catálogo de servicios disponible cuando comencemos a machacarla (o no: a saber qué hay en la mente de esa gente).
El paquete es el trabajo de fin de máster de mi alumno Ángel Delgado Panadero en el máster de ciencia de datos de la UTAD.</description>
    </item>
    
    <item>
      <title>Geofacetas</title>
      <link>/2017/09/28/geofacetas/</link>
      <pubDate>Thu, 28 Sep 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/09/28/geofacetas/</guid>
      <description>Con geofacet se puede hacer</description>
    </item>
    
    <item>
      <title>Python y R: una perspectiva markoviana</title>
      <link>/2017/09/06/python-y-r-una-perspectiva-markoviana/</link>
      <pubDate>Wed, 06 Sep 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/09/06/python-y-r-una-perspectiva-markoviana/</guid>
      <description>Hoy he visto
aquí y he escrito
m &amp;lt;- matrix(c(74, 15, 10, 1, 11, 50, 38, 1, 5, 4, 90, 1, 17, 4, 19, 60), 4, 4, byrow = TRUE) m &amp;lt;- m / 100  luego
m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m%*% m%*% m%*% m%*% m%*% m%*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m %*% m%*% m%*% m%*% m%*% m%*% m%*% m # [,1] [,2] [,3] [,4] #[1,] 0.</description>
    </item>
    
    <item>
      <title>Gelmaneando</title>
      <link>/2017/07/13/gelmaneando/</link>
      <pubDate>Thu, 13 Jul 2017 08:13:00 +0000</pubDate>
      
      <guid>/2017/07/13/gelmaneando/</guid>
      <description>Hoy, gelmaneo así:
bar &amp;lt;- function(n, reps = 1e4){ foo &amp;lt;- function(n){ x &amp;lt;- rnorm(n) tmp &amp;lt;- t.test(x) c(tmp$p.value, abs(mean(x))) } res &amp;lt;- replicate(reps, foo(n)) tmp &amp;lt;- t(res) tmp &amp;lt;- tmp[tmp[,1] &amp;lt; 0.05,] tmp[,2] } res &amp;lt;- lapply(c(3, 10, 20, 50, 100), bar) sapply(res, mean) #[1] 0.8662636 0.6583157 0.4934551 0.3240322 0.2337086  Resumo:
 * Fabrico un montón de errores de tipo I. Recuérdese: error de tipo I implica artículo publicado.</description>
    </item>
    
    <item>
      <title>Micromapas</title>
      <link>/2017/07/07/micromapas/</link>
      <pubDate>Fri, 07 Jul 2017 08:13:27 +0000</pubDate>
      
      <guid>/2017/07/07/micromapas/</guid>
      <description>Vienen a ser la versión geo de las sparklines. Por ejemplo,
Notas:
 * El gráfico anterior no es mío. El [código (y datos) con el que se generó](https://www.datanalytics.com/uploads/micromap.zip) tampoco. Son de Susana Huedo, exalumna. * Está basado (todo hay que decirlo) en código de terceros y debería acordarme de cuál de ellos. Pero no es el caso.  </description>
    </item>
    
    <item>
      <title>Creo que darán que hablar (los GRF)</title>
      <link>/2017/07/06/creo-que-daran-que-hablar-los-grf/</link>
      <pubDate>Thu, 06 Jul 2017 08:13:52 +0000</pubDate>
      
      <guid>/2017/07/06/creo-que-daran-que-hablar-los-grf/</guid>
      <description>El artículo, el código y el paquete.</description>
    </item>
    
    <item>
      <title>Syberia tiene muy buena pinta [pero...]</title>
      <link>/2017/07/05/syberia-tiene-muy-buena-pinta-pero/</link>
      <pubDate>Wed, 05 Jul 2017 08:13:54 +0000</pubDate>
      
      <guid>/2017/07/05/syberia-tiene-muy-buena-pinta-pero/</guid>
      <description>Echadle un vistazo a Syberia (y me contáis qué tal os va). Tiene muy buena pinta y puede ser útil para produccionalizar código.
[Esto es casi todo; lo que sigue es omitible.]
Sin embargo y sin que necesariamente haga desmerecer a Syberia como tal, en la página arriba enlazada se lee:
Nada tengo contra que R sea (o deje de ser) azúcar sintáctico. Si lo fuese sobre LISP, tanto mejor. Pero lenguajes de programación hay cientos mientras que statistical tools que merezcan el nombre, solo una [¿es correcto concordar con la traducción más natural de tools?</description>
    </item>
    
    <item>
      <title>Hoy, como excepción, gritaré y justificaré: ¡Malditos logaritmos!</title>
      <link>/2017/06/29/hoy-como-excepcion-gritare-y-justificare-malditos-logaritmos/</link>
      <pubDate>Thu, 29 Jun 2017 08:13:36 +0000</pubDate>
      
      <guid>/2017/06/29/hoy-como-excepcion-gritare-y-justificare-malditos-logaritmos/</guid>
      <description>Dados unos números positivos hay que justificar por que no tomar logaritmos y no al revés. La carga de la prueba recae sobre quien no lo hace.
No obstante:
Tenía unos datos (para cada $latex t$) que siguen (me lo juran) un modelo teórico
$latex \log y \sim k \exp(-at)$
Existen dos opciones para encontrar los parámetros deseados $latex k$ y $latex a$. El primero, tomando logaritmos y aplicando lm. El segundo, ajustando un modelo no lineal con, p.</description>
    </item>
    
    <item>
      <title>¿Les dará un patatús a mis excolegas?</title>
      <link>/2017/06/28/les-dara-un-patatus-a-mis-excolegas/</link>
      <pubDate>Wed, 28 Jun 2017 08:13:28 +0000</pubDate>
      
      <guid>/2017/06/28/les-dara-un-patatus-a-mis-excolegas/</guid>
      <description>En Gaussianos publicaron este problema:
El gráfico, construido por uno de los respondedores, Ignacio Larrosa Cañestro, es este:Mi solución (puro uso del teorema del seno):
library(nleqslv) ab &amp;lt;- 11 ac &amp;lt;- 8 foo &amp;lt;- function(abc, print.answer = FALSE){ acb &amp;lt;- asin(sin(abc) * ab / ac) bac &amp;lt;- pi - acb - abc bc &amp;lt;- ab * sin(bac) / sin(acb) # lado opuesto bad &amp;lt;- bac / 2 adb &amp;lt;- pi - bad - abc base.</description>
    </item>
    
    <item>
      <title>¿Cómo preambuláis vuestros .Rmd?</title>
      <link>/2017/06/26/como-preambulais-vuestros-rmd/</link>
      <pubDate>Mon, 26 Jun 2017 08:13:12 +0000</pubDate>
      
      <guid>/2017/06/26/como-preambulais-vuestros-rmd/</guid>
      <description>Yo nunca me había preocupado demasiado de eso (salvo en las presentaciones, para la que uso revealjs y que son otra historia), pero el otro día me pasaron y vi el efecto de
--- title: &amp;quot;Mi título&amp;quot; author: &amp;quot;Yo Me Mí Conmigo&amp;quot; date: &#39;`r format(Sys.Date(), &amp;quot;%B %d, %Y&amp;quot;)`&#39; output: html_document: toc: true toc_float: collapsed: false smooth_scroll: false theme: united highlight: tango ---  y las cosas van a cambiar para siempre.</description>
    </item>
    
    <item>
      <title>La anticonferencia: una idea que me ronda la cabeza</title>
      <link>/2017/06/12/la-anticonferencia-una-idea-que-me-ronda-la-cabeza/</link>
      <pubDate>Mon, 12 Jun 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/06/12/la-anticonferencia-una-idea-que-me-ronda-la-cabeza/</guid>
      <description>La anticonferencia me ronda la cabeza.
No es una conferencia, (de ahí el prefijo), aunque se parezca a ella en lo de reunir a un grupillo de gente interesada en un asunto.
No es un jacatón. Los jacatones están, sobre el papel, bien; pero demasiado a menudo su producto se queda ahí, tiene poca (o nula) trayectoria o impacto. ¿Me dejáis que diga que son mayormente intranscendentes?
Pero creo que los de rOpenSci dieron en el clavo con su Unconference.</description>
    </item>
    
    <item>
      <title>Funcionalidades infravaloradas de R: los corchetes</title>
      <link>/2017/06/07/funcionalidades-infravaloradas-de-r-los-corchetes/</link>
      <pubDate>Wed, 07 Jun 2017 08:13:26 +0000</pubDate>
      
      <guid>/2017/06/07/funcionalidades-infravaloradas-de-r-los-corchetes/</guid>
      <description>[Ad]Mirad esta pequeña maravilla de código:
n &amp;lt;- 100 dat &amp;lt;- data.frame( y = rnorm(100), x = sample(letters[1:3], n, replace = T) ) medias &amp;lt;- tapply(dat$y, dat$x, mean) dat$x.trans &amp;lt;- medias[dat$x] head(dat)  El corchete está manifiestamente infravalorado.</description>
    </item>
    
    <item>
      <title>Que Magritte me perdone</title>
      <link>/2017/06/05/que-magritte-me-perdone/</link>
      <pubDate>Mon, 05 Jun 2017 08:13:51 +0000</pubDate>
      
      <guid>/2017/06/05/que-magritte-me-perdone/</guid>
      <description>¿Qué es %&amp;gt;%? ¿Para qué sirve? Hoy he hecho la presentación más sesgada y parcial del operador para neófitos en R:
library(magrittr) 8 %&amp;gt;% sin %&amp;gt;% exp exp(sin(8))  (Es que madrugar me pone de mal humor y saca mi más sincero yo de dentro de mí mismo).</description>
    </item>
    
    <item>
      <title>Dizque al sexto mes... pero ¿y los datos?</title>
      <link>/2017/05/31/dizque-al-sexto-mes-pero-y-los-datos/</link>
      <pubDate>Wed, 31 May 2017 08:13:29 +0000</pubDate>
      
      <guid>/2017/05/31/dizque-al-sexto-mes-pero-y-los-datos/</guid>
      <description>He leído esto, que trata de lo distinta que es
a la izquierda y a la derecha de la línea roja punteada.
La historia contada desde las posterioris basadas en datos difiere de la apriorística (recordad: ideología = priori). En concreto
Reconoceréis una aplicación de causalImpact y lo que significa el gráfico está comentado en todas partes.
Código y datos, por mor de la reproducibilidad, aquí.</description>
    </item>
    
    <item>
      <title>Aquellos que ignoran la estadística etcétera</title>
      <link>/2017/05/24/aquellos-que-ignoran-la-estadistica-etcetera/</link>
      <pubDate>Wed, 24 May 2017 08:13:13 +0000</pubDate>
      
      <guid>/2017/05/24/aquellos-que-ignoran-la-estadistica-etcetera/</guid>
      <description>Ayer asistí a una charla sobre errors. Brevemente (porque está estupendamente explicado, motivado y documentado por su autor, al que aprovecho la ocasión para saludar), hace esto:
library(errors) valores &amp;lt;- unlist(list(a = 1, b = 2, c = 3)) vars &amp;lt;- c(1, 1, 1) # varianzas de esos datos/medidas sds &amp;lt;- sqrt(vars) # errores x &amp;lt;- valores errors(x) &amp;lt;- sds format(x[1] * sin(x[2])^3, notation = &amp;quot;plus-minus&amp;quot;, digits = 3) #[1] &amp;quot;0.</description>
    </item>
    
    <item>
      <title>¿Soy un dinosauRio? Sobre las novedades de R</title>
      <link>/2017/05/16/soy-un-dinosaurio-sobre-las-novedades-de-r/</link>
      <pubDate>Tue, 16 May 2017 08:13:51 +0000</pubDate>
      
      <guid>/2017/05/16/soy-un-dinosaurio-sobre-las-novedades-de-r/</guid>
      <description>Trato de estar abierto a lo nuevo. Tantos años soportando dinosaurios me han vacunado contra el conservadurismo tecnológico. De hecho, me produce arcadas. La experiencia, no obstante, me ha hecho permeable al efecto Lindy, lo que me da ocasión de saludar a mis amigos emaqueros.
Las cosas cambian y en R estamos viviendo una especie de revolución. Mi argumento, para impacientes, es que:
 * Es más superficial que sustancial: es azúcar sintáctico.</description>
    </item>
    
    <item>
      <title>Me too, me too!</title>
      <link>/2017/05/12/me-too-me-too/</link>
      <pubDate>Fri, 12 May 2017 08:13:13 +0000</pubDate>
      
      <guid>/2017/05/12/me-too-me-too/</guid>
      <description>Las alturas corresponden a una cierta potencia de la población residente en la correspondiente rejilla. Los datos son del SEDAC (Socioeconomic Data and Applications Center, Universidad de Columbia) y se pueden bajar gratis si te registras y rellenas un cuestionario tontaina.
El código,
library(ggplot2) options(expressions = 10000) dat &amp;lt;- read.table(&amp;quot;dat/espp00ag.asc&amp;quot;, skip = 6) dat &amp;lt;- as.matrix(dat) dat &amp;lt;- data.frame(y = as.numeric(row(dat)), x = as.numeric(col(dat)), pop = as.numeric(dat)) peninsula &amp;lt;- dat[dat$x &amp;gt; 200,] peninsula &amp;lt;- peninsula[peninsula$y &amp;lt; 250,] res &amp;lt;- ggplot() for (i in 1:max(peninsula$y)){ tmp &amp;lt;- peninsula[peninsula$y == i,] tmp$pop &amp;lt;- tmp$pop^0.</description>
    </item>
    
    <item>
      <title>¿Cómo fue R antes de R?</title>
      <link>/2017/05/08/como-fue-r-antes-de-r/</link>
      <pubDate>Mon, 08 May 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/05/08/como-fue-r-antes-de-r/</guid>
      <description>La década le ha dejado nuevas sintaxis a R. Algunos, precarcas, fruncimos el entrecejo. Esta entrada nos administrará un poco de medicina histórica.
R es una reimplementación (libre, para más señas) de S. La sintaxis actual de S (que es la del R de toda la vida) es del año 88. Antes, durante los 80, era otra. Pero es difícil dar con ella en internet.
Pero no imposible. El libro S: An Interactive Environment for Data Analysis and Graphics, de Chambers y Becker, ha sido escaneado por Google y, aunque no completo, nos permite echar un vistazo a algunas páginas, las suficientes para no hacer carraspear desaprobatoriamente al copyright.</description>
    </item>
    
    <item>
      <title>Curso de introducción a R en Gijón</title>
      <link>/2017/05/02/curso-de-introduccion-a-r-en-gijon/</link>
      <pubDate>Tue, 02 May 2017 10:44:59 +0000</pubDate>
      
      <guid>/2017/05/02/curso-de-introduccion-a-r-en-gijon/</guid>
      <description>Tenía que haberlo publicado antes, pero&amp;hellip; ahí va:
Esta semana se va a impartir un curso de introducción a R en el que participo. Está organizado por la UNED y se puede asistir presencialmente (si estás en Gijón esos días) o en remoto desde cualquier parte.
La info, aquí.</description>
    </item>
    
    <item>
      <title>Experimentos con &#34;extremely small data&#34;: la media muestral de pocas betas</title>
      <link>/2017/04/12/experimentos-con-extremely-small-data-la-media-muestral-de-pocas-betas/</link>
      <pubDate>Wed, 12 Apr 2017 08:13:07 +0000</pubDate>
      
      <guid>/2017/04/12/experimentos-con-extremely-small-data-la-media-muestral-de-pocas-betas/</guid>
      <description>Aquí, contracorriente. Dejamos aparcado el big data y le damos a lo que nos da de comer. Entre otras cosas, este pequeño experimento con muy pequeños datos (¿tres?).
La aplicación es real. Y los datos pequeños porque son carísimos.
Se puede suponer que tienen distribución beta de parámetros desconocidos. Nos interesa la media muestral de unas pocas observaciones: dos, tres, cuatro,&amp;hellip; En particular, qué distribución tiene.
Si fuesen muchos, podríamos aplicar el teorema central del límite (que funciona estupendamente incluso con valores no muy grandes).</description>
    </item>
    
    <item>
      <title>Pues sí, puede fabricarse uno para España</title>
      <link>/2017/04/10/pues-si-puede-fabricarse-uno-para-espana/</link>
      <pubDate>Mon, 10 Apr 2017 08:13:28 +0000</pubDate>
      
      <guid>/2017/04/10/pues-si-puede-fabricarse-uno-para-espana/</guid>
      <description>Es
responde a mi entrada de la semana pasada y se lo debemos a la gentileza de Sergio J.
El código, con mínimas modificaciones mías (para automatizar la descarga de los datos) es
library(pxR) library(dplyr) library(tidyr) library(ggplot2) #---- Carga y transformacion de datos download.file(&amp;quot;http://www.datanalytics.com/uploads/3199.px&amp;quot;, &amp;quot;3199.px&amp;quot;) pob &amp;lt;- read.px(&amp;quot;3199.px&amp;quot;, encoding = &amp;quot;latin1&amp;quot;) pob &amp;lt;- as.data.frame(pob) pob$Sexo &amp;lt;- NULL pob$Periodo &amp;lt;- as.numeric(as.character(pob$Periodo)) pob &amp;lt;- separate(pob, Provincias, into = c(&amp;quot;id_provincia&amp;quot;, &amp;quot;provincia&amp;quot;), sep = 3) pob$fecha &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>¿Podría fabricarse uno para España?</title>
      <link>/2017/04/07/podria-fabricarse-uno-para-espana/</link>
      <pubDate>Fri, 07 Apr 2017 08:13:40 +0000</pubDate>
      
      <guid>/2017/04/07/podria-fabricarse-uno-para-espana/</guid>
      <description>Me refiero a algo similar a (referencia):
Lo ideal sería crear una función compatible con el sistema de facetas de ggplot2 con nombre, p.e., facet_spain que permitiese disponer cualquier tipo de gráfico en una retícula similar.
No particularmente difícil, pero sí, seguro, utilísimo.
¿A nadie le tienta el proyecto?
[Me encanta el impersonal de &amp;ldquo;podría fabricarse&amp;hellip;&amp;rdquo;. ¡Es como tan de tirar la piedra y esconder la mano!]</description>
    </item>
    
    <item>
      <title>Lo (mínimo) que hay que saber de series temporales: breve, conciso e indoloro</title>
      <link>/2017/04/06/lo-minimo-que-hay-que-saber-de-series-temporales-breve-conciso-e-indoloro/</link>
      <pubDate>Thu, 06 Apr 2017 08:13:28 +0000</pubDate>
      
      <guid>/2017/04/06/lo-minimo-que-hay-que-saber-de-series-temporales-breve-conciso-e-indoloro/</guid>
      <description>Es Forecasting: principles and practice, de Hyndman y Athana­sopou­los.</description>
    </item>
    
    <item>
      <title>Etsa es una edntara a pubrea de roreetcs cnctoaumes</title>
      <link>/2017/04/05/etsa-es-una-edntara-a-pubrea-de-roreetcs-cnctoaumes/</link>
      <pubDate>Wed, 05 Apr 2017 08:13:07 +0000</pubDate>
      
      <guid>/2017/04/05/etsa-es-una-edntara-a-pubrea-de-roreetcs-cnctoaumes/</guid>
      <description>Psandeno en cómo ebiisrcr a pbruea de roceetrs plaigoaris couetmacns rodecré esto y lo he idepmneatlmo en R.
No sé si ertéaiss o no de adeurco en que fncniuoa o no, es dicer, que los ttoexs son rloeincboecs si se faijn la pmirera y úmtila lerta de cada pabrala y se puertma el retso. Lo que sí que es ctireo es que añade a cdaa txeto una mcraa catstaícirerca que decnniua su pdcionereca.</description>
    </item>
    
    <item>
      <title>Tres grandes problemas que ocupan pero, según el CIS, no preocupan</title>
      <link>/2017/04/03/tres-grandes-problemas-que-ocupan-pero-segun-el-cis-no-preocupan/</link>
      <pubDate>Mon, 03 Apr 2017 08:13:33 +0000</pubDate>
      
      <guid>/2017/04/03/tres-grandes-problemas-que-ocupan-pero-segun-el-cis-no-preocupan/</guid>
      <description>Plañe el periodista porque dizque hay tres graves problemas que, a pesar de lo que ocupan (en los medios), a la hora del CIS, no preocupan.
Aggiorno una vieja entrada para ver, por ejemplo, cómo ha variado en los últimos años la preocupación de los encuestados por el CIS acerca de uno de los tres graves problemas:
De hecho, el porcentaje que se muestra indica la proporción de los encuestados que mencionaron el asunto como uno de los tres principales problemas de España.</description>
    </item>
    
    <item>
      <title>Evolución de la edad media de la población por provincias</title>
      <link>/2017/03/29/evolucion-de-la-edad-media-de-la-poblacion-por-provincias/</link>
      <pubDate>Wed, 29 Mar 2017 08:13:44 +0000</pubDate>
      
      <guid>/2017/03/29/evolucion-de-la-edad-media-de-la-poblacion-por-provincias/</guid>
      <description>Abundo en la entrada de ayer. Lo hago para mostrar
En el gráfico anterior se muestra la evolución de la edad media de la población de las provincias españolas como diferencia con respecto a una evolución media calculada como la regresión lineal de todas las edades medias con respecto al año. Es decir, algo así como evolución relativa.
Se aprecian claramente los rejuvenecimientos relativos de Guadalajara y, en menor medida, Toledo.</description>
    </item>
    
    <item>
      <title>Rejillas poblacionales con R (un borrador)</title>
      <link>/2017/03/28/rejillas-poblacionales-con-r-un-borrador/</link>
      <pubDate>Tue, 28 Mar 2017 08:13:06 +0000</pubDate>
      
      <guid>/2017/03/28/rejillas-poblacionales-con-r-un-borrador/</guid>
      <description>me llegó ayer por Twitter (vía @unnombrealazar). En el mapa aparece representada la edad media de la población por provincia (y hoy voy a dar las cloropetas por buenas). Salta a la vista Guadalajara: tiene una edad media ¿sorprendentemente? baja. Tanto que tuve que comprobarlo en el INE. La explicación (siempre a posteriori) más obvia es
¿Será cierto? A saber. Seguramente. Pero, ¿podemos comprobarlo?
Es complicado obtener datos de edades por municipio.</description>
    </item>
    
    <item>
      <title>EM (duro) a mano (y para humanos)</title>
      <link>/2017/03/20/em-duro-a-mano-y-para-humanos/</link>
      <pubDate>Mon, 20 Mar 2017 08:13:22 +0000</pubDate>
      
      <guid>/2017/03/20/em-duro-a-mano-y-para-humanos/</guid>
      <description>Dada una configuración de puntos tal como
puede pensarse que existen dos grupos (clústers los llaman casi todos menos el neotroll de estas páginas y algún otro purista) de puntos organizados alrededor de unas rectas que se adivinan.
Nos planteamos el problema de identificarlas y de asignar los puntos a su respectiva.
Una posible estrategia consiste en construir la verosimilitud asociada al problema y maximizarla. Esa verosimilitud dependería de muchos parámetros:</description>
    </item>
    
    <item>
      <title>Todo lo que sucede en R es una llamada a una función</title>
      <link>/2017/03/16/todo-lo-que-sucede-en-r-es-una-llamada-a-una-funcion/</link>
      <pubDate>Thu, 16 Mar 2017 15:44:30 +0000</pubDate>
      
      <guid>/2017/03/16/todo-lo-que-sucede-en-r-es-una-llamada-a-una-funcion/</guid>
      <description>En serio, es así. ¿También if? Pues también. De hecho,
`if`(1 == 3, print(&amp;quot;a&amp;quot;), print(&amp;quot;b&amp;quot;))  Y eso permite, por ejemplo, que funcionen expresiones tales como
a &amp;lt;- if (1 == 3) 4 else 5  tan útiles como poco empleadas en general. También son funciones (, { y otras que aparecen en la sección .Internal vs .Primitive del documento R Internals.</description>
    </item>
    
    <item>
      <title>qgraph para representar grafos que son correlaciones que son vinos</title>
      <link>/2017/03/15/qgraph-para-representar-grafos-que-son-correlaciones-que-son-vinos/</link>
      <pubDate>Wed, 15 Mar 2017 08:13:37 +0000</pubDate>
      
      <guid>/2017/03/15/qgraph-para-representar-grafos-que-son-correlaciones-que-son-vinos/</guid>
      <description>Me vais a permitir que escriba una entrada sin mayores pretensiones, inspirada en y adaptada de aquí y que sirva solo de que para representar correlaciones entre variables podemos recurrir a los grafos como en
library(qgraph) wine.quality &amp;lt;- read.csv(&amp;quot;https://goo.gl/0Fz1S8&amp;quot;, sep = &amp;quot;;&amp;quot;) qgraph(cor(wine.quality), shape= &amp;quot;circle&amp;quot;, posCol = &amp;quot;darkgreen&amp;quot;, negCol= &amp;quot;darkred&amp;quot;, layout = &amp;quot;groups&amp;quot;, vsize=13)  que pinta
mostrando resumidamente cómo se relacionan entre sí determinadas características de los vinos y cómo en última instancia influyen en su calidad (qlt).</description>
    </item>
    
    <item>
      <title>Reducción de la dimensionalidad con t-SNE</title>
      <link>/2017/03/08/reduccion-de-la-dimensionalidad-con-t-sne/</link>
      <pubDate>Wed, 08 Mar 2017 08:13:41 +0000</pubDate>
      
      <guid>/2017/03/08/reduccion-de-la-dimensionalidad-con-t-sne/</guid>
      <description>Voy a explicar aquí lo que he aprendido recientemente sobre t-SNE, una técnica para reducir la dimensionalidad de conjuntos de datos. Es una alternativa moderna a MDS o PCA.
Partimos de puntos $latex x_1, \dots, x_n$ y buscamos otros $latex y_1, \dots, y_n$ en un espacio de menor dimensión. Para ello construiremos primero $latex n$ distribuciones de probabilidad, $latex p_i$ sobre los enteros $latex 1, \dots, n$ de forma que</description>
    </item>
    
    <item>
      <title>Cuantiles, sí, pero ¿de qué tipo?</title>
      <link>/2017/03/06/cuantiles-si-pero-de-que-tipo/</link>
      <pubDate>Mon, 06 Mar 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/03/06/cuantiles-si-pero-de-que-tipo/</guid>
      <description>Porque resulta que los hay de varios tipos. En R, hasta nueve de ellos:
set.seed(1234) muestra &amp;lt;- sort(rt(100, 3)) mis.cuantiles &amp;lt;- sapply(1:9, function(tipo) quantile(muestra, 0.834, type = tipo)) mis.cuantiles # 83.4% 83.4% 83.4% 83.4% 83.4% 83.4% 83.4% 83.4% 83.4% #0.9065024 0.9065024 0.8951710 0.8997036 0.9053693 0.9331290 0.9015846 0.9077920 0.9063154  Las definiciones de todos ellos pueden consultarse en Sample Quantiles in Statistical Packages.
Las diferencias entre ellos, de todos modos, decrecen conforme aumenta el tamaño muestral:</description>
    </item>
    
    <item>
      <title>Wikipedia &#43; prophet</title>
      <link>/2017/03/03/wikipedia-prophet/</link>
      <pubDate>Fri, 03 Mar 2017 08:13:17 +0000</pubDate>
      
      <guid>/2017/03/03/wikipedia-prophet/</guid>
      <description>El otro día escribí sobre visitas a la Wikipedia. El otro día (posiblemente otro) oí hablar de prophet.
Hoy con
library(wikipediatrend) library(prophet) library(ggplot2) visitas &amp;lt;- wp_trend(&amp;quot;R_(lenguaje_de_programaci%C3%B3n)&amp;quot;, from = &amp;quot;2010-01-01&amp;quot;, to = Sys.Date(), lang = &amp;quot;es&amp;quot;) mis.visitas &amp;lt;- visitas[, c(&amp;quot;date&amp;quot;, &amp;quot;count&amp;quot;)] colnames(mis.visitas) &amp;lt;- c(&amp;quot;ds&amp;quot;, &amp;quot;y&amp;quot;) pasado &amp;lt;- mis.visitas[1:1500,] m &amp;lt;- prophet(pasado) futuro &amp;lt;- make_future_dataframe(m, periods = nrow(mis.visitas) - 1500) prediccion &amp;lt;- predict(m, futuro) pred.plot &amp;lt;- plot(m, prediccion) pred.plot + geom_line(data = mis.</description>
    </item>
    
    <item>
      <title>&#34;Todas&#34; las terrazas de Madrid</title>
      <link>/2017/03/02/todas-las-terrazas-de-madrid/</link>
      <pubDate>Thu, 02 Mar 2017 08:13:23 +0000</pubDate>
      
      <guid>/2017/03/02/todas-las-terrazas-de-madrid/</guid>
      <description>es un mapa en el que, en rojo, figuran todas (véase la coda) las terrazas de Madrid. Los datos están extraídos del censo de locales, sus actividades y terrazas de hostelería y restauración del ayuntamiento y están procesados con
terrazas &amp;lt;- fread(&amp;quot;http://datos.madrid.es/egob/catalogo/200085-17-censo-locales.txt&amp;quot;) terrazas$coordenada_x_local &amp;lt;- as.numeric(gsub(&amp;quot;,&amp;quot;, &amp;quot;.&amp;quot;, terrazas$coordenada_x_local)) terrazas$coordenada_y_local &amp;lt;- as.numeric(gsub(&amp;quot;,&amp;quot;, &amp;quot;.&amp;quot;, terrazas$coordenada_y_local)) tmp &amp;lt;- terrazas[terrazas$coordenada_x_local &amp;gt; 1000, ] tmp &amp;lt;- terrazas[terrazas$coordenada_y_local &amp;gt; 3e6,] # UTM a siglo XXI library(rgdal) terrazas.utm &amp;lt;- SpatialPoints(cbind(tmp$coordenada_x_local, tmp$coordenada_y_local), proj4string=CRS(&amp;quot;+proj=utm +zone=30&amp;quot;)) terrazas.</description>
    </item>
    
    <item>
      <title>Sobre una poco conocida y para nada menguante &#34;brecha de género&#34;</title>
      <link>/2017/03/01/sobre-una-poco-conocida-y-para-nada-menguante-brecha-de-genero/</link>
      <pubDate>Wed, 01 Mar 2017 08:13:51 +0000</pubDate>
      
      <guid>/2017/03/01/sobre-una-poco-conocida-y-para-nada-menguante-brecha-de-genero/</guid>
      <description>Con datos del INE sobre mortalidad he construido el gráfico
que muestra las tasas de mortalidad relativas (la de hombres entre la de mujeres) desde 1975 para cada edad. Como no se aprecia debidamente el efecto que da pie a esta entrada, reorganizo los ejes (y promedio, ¡glups!, las tasas de mortalidad por grupos quinquenales de edad):
Se observa una manifiesta tendencia creciente, uno de esos gender gaps, brechas de género o como quiera que se llamen a estas cosa en neolengua que, lejos de menguar, crece y crece.</description>
    </item>
    
    <item>
      <title>Consultando el número de visitas a páginas de la Wikipedia con R</title>
      <link>/2017/02/27/consultando-el-numero-de-visitas-a-paginas-de-la-wikipedia-con-r/</link>
      <pubDate>Mon, 27 Feb 2017 08:13:18 +0000</pubDate>
      
      <guid>/2017/02/27/consultando-el-numero-de-visitas-a-paginas-de-la-wikipedia-con-r/</guid>
      <description>Hace un tiempo probé el paquete wikipediatrend de R ya no recuerdo para qué. Desafortunadamente, el servicio que consulta debía de estar caído y no funcionó. Ahí quedó la cosa.
Una reciente entrada de Antonio Chinchón en su blog me ha invitado a revisitar la cuestión y ahora, al parecer, stats.grok.se vuelve a estar levantado. Por lo que se pueden hacer cosas como:
visitas &amp;lt;- wp_trend(&amp;quot;R_(lenguaje_de_programaci%C3%B3n)&amp;quot;, from = &amp;quot;2010-01-01&amp;quot;, to = Sys.</description>
    </item>
    
    <item>
      <title>Probando hunspell para el procesamiento de texto en español</title>
      <link>/2017/02/20/probando-hunspell-para-el-procesamiento-de-texto-en-espanol/</link>
      <pubDate>Mon, 20 Feb 2017 08:13:50 +0000</pubDate>
      
      <guid>/2017/02/20/probando-hunspell-para-el-procesamiento-de-texto-en-espanol/</guid>
      <description>El paquete hunspell de R permite procesar texto utilizando como soporte la infraestructura proporcionada por Hunspell, el corrector ortográfico que subyace a muchas aplicaciones en R.
Existe una viñeta que ilustra el uso del paquete pero, como siempre, en inglés. En español las cosas son parecidas pero, como siempre, nunca exactamente iguales. En esta entrada, por lo tanto, voy a repasar partes de la viñeta aplicándolas a nuestra tan frecuentemente maltratada mas por ello no menos querida por algunos como yo (pausa) lengua.</description>
    </item>
    
    <item>
      <title>Una mala manera de perder un par de horas</title>
      <link>/2017/02/07/una-mala-manera-de-perder-un-par-de-horas/</link>
      <pubDate>Tue, 07 Feb 2017 08:13:50 +0000</pubDate>
      
      <guid>/2017/02/07/una-mala-manera-de-perder-un-par-de-horas/</guid>
      <description>Es esta:
156.67 * 100 # 15667 as.integer(156.67 * 100) #15666  Claro, hay que leer ?as.integer para enterarte de que, en realidad, la función que quieres usar es round.
Una mala manera de perder un par de horas.</description>
    </item>
    
    <item>
      <title>El número efectivo de partidos</title>
      <link>/2017/01/25/el-numero-efectivo-de-partidos/</link>
      <pubDate>Wed, 25 Jan 2017 08:13:47 +0000</pubDate>
      
      <guid>/2017/01/25/el-numero-efectivo-de-partidos/</guid>
      <description>El número efectivo de partidos es el nombre de una página de la Wikipedia, que contiene la fórmula
$latex N = \frac{1}{\sum_i p_i^2}$
y excipiente alrededor.
Aplicada a España (usando datos del CIS como proxy),
Como casi siempre, el código:
library(rvest) library(rvest) library(reshape2) library(plyr) library(zoo) url &amp;lt;- &amp;quot;http://www.cis.es/cis/export/sites/default/-Archivos/Indicadores/documentos_html/sB606050010.html&amp;quot; raw &amp;lt;- read_html(url) tmp &amp;lt;- html_nodes(raw, &amp;quot;table&amp;quot;) tmp &amp;lt;- html_table(tmp[[2]], fill = TRUE) colnames(tmp)[1] &amp;lt;- &amp;quot;partido&amp;quot; tmp &amp;lt;- tmp[!is.na(tmp$partido),] tmp &amp;lt;- tmp[1:30,] tmp &amp;lt;- melt(tmp, id.</description>
    </item>
    
    <item>
      <title>Polinomios monótonos</title>
      <link>/2017/01/23/polinomios-monotonos/</link>
      <pubDate>Mon, 23 Jan 2017 08:13:44 +0000</pubDate>
      
      <guid>/2017/01/23/polinomios-monotonos/</guid>
      <description>Recibí un mensaje el otro día sobre polinomios monótonos. Mejor dicho, sobre el ajuste de datos usando polinomios monótonos. Frente a un modelo del tipo y ~ x (x e y reales) donde la relación entre las dos variables es
 * manifiestamente no lineal y * necesariamente monótina, p.e., creciente (por consideraciones previas),  cabe considerar ajustar un polinomio monótono, i.e., realizar una regresión polinómica con la restricción adicional de que el polinomio de ajuste resultante sea monótono.</description>
    </item>
    
    <item>
      <title>Va de si hay una o dos lambdas</title>
      <link>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</link>
      <pubDate>Wed, 18 Jan 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Vivimos en un mundo opaco e interconectado</title>
      <link>/2017/01/17/vivimos-en-un-mundo-opaco-e-interconectado/</link>
      <pubDate>Tue, 17 Jan 2017 11:40:51 +0000</pubDate>
      
      <guid>/2017/01/17/vivimos-en-un-mundo-opaco-e-interconectado/</guid>
      <description>Vivimos en un mundo opaco: como en los cuentecillos de Asimov, somos usuarios de tecnologías que ni conocemos ni controlamos. Parametrizamos nuestras máquinas y las echamos a correr. Poco más podemos hacer que fiarnos de quienes nos las proporcionan.
Luego pasan cosas como que, de repente, resulta que Stan, en las últimas versiones, ha estado produciendo muestras sesgadas. ¿Qué resultados condicionará eso río abajo?
Un caso mucho más famoso es el de la resonancia magnética (fMRI): un error en el software concomitante pone bajo sospecha hasta 40000 artículos sobre estudios del cerebro.</description>
    </item>
    
    <item>
      <title>Lo que pasa cuando omites la priori con variables categóricas</title>
      <link>/2017/01/12/lo-que-pasa-cuando-omites-la-priori-con-variables-categoricas/</link>
      <pubDate>Thu, 12 Jan 2017 08:13:32 +0000</pubDate>
      
      <guid>/2017/01/12/lo-que-pasa-cuando-omites-la-priori-con-variables-categoricas/</guid>
      <description>Stan. Modelo multinivel. Variable categórica. Codificación con ceros y unos. Matriz. Coeficiente vector[n_ccaa] Cccaa. Sin priori.
Catástrofe:
(Coeficientes hasta 15000. Sin tasa, con tiempo. Los valores desorbitados, en ceros de la dummy).
Priori.
for (i in 1:n_ccaa) Cccaa[i] ~ cauchy(0, 20);
¿Por qué no?
Tachán:
(¿Para qué verbos?)</description>
    </item>
    
    <item>
      <title>Las conexiones telefónicas de Vodafone España, visualizadas con R</title>
      <link>/2016/12/20/las-conexiones-telefonicas-de-vodafone-espana-visualizadas-con-r/</link>
      <pubDate>Tue, 20 Dec 2016 08:13:24 +0000</pubDate>
      
      <guid>/2016/12/20/las-conexiones-telefonicas-de-vodafone-espana-visualizadas-con-r/</guid>
      <description>Me pasa un exalumno (no os perdáis su blog y su otro blog, especialmente si os interesa la versión friqui de la fotografía) de mi curso de R de KSchool, un gráfico que ha realizado con R para su empresa:
Addenda: En los comentarios hay más enlaces relevantes (proporcionados por el autor de la imagen), que conducen al código, etc.</description>
    </item>
    
    <item>
      <title>Problemas navideños de/con R</title>
      <link>/2016/12/19/problemas-navidenos-decon-r/</link>
      <pubDate>Mon, 19 Dec 2016 08:13:22 +0000</pubDate>
      
      <guid>/2016/12/19/problemas-navidenos-decon-r/</guid>
      <description>Acabo de sugerir a mis alumnos de KSchool una lista de problemas después de sus 10 primeras horas de contacto con R.
Uno de ellos, advierto, y les he advertido (porque yo, no siendo rector de universidad pública alguna, no cuento el plagiar entre mis vicios) es una versión de otro publicado aquí.
Ejercicio Construye una matriz que dada una entrada del tipo
&amp;lt;code&amp;gt;a = c(&#39;NAME:Maria /COUNTRY:uruguay /EMAIL:mariaUY@gmail.com&#39;, &#39;NAME:Paul/COUNTRY:UK /EMAIL:PaulUK@gmail.com&#39;, &#39;NAME:Jhon /COUNTRY:USA /EMAIL:JhonUSA@gmail.</description>
    </item>
    
    <item>
      <title>Que la fuerza de R también te acompañe a ti (allá a donde haya datos)</title>
      <link>/2016/12/13/que-la-fuerza-de-r-tambien-te-acompane-a-ti-alla-a-donde-haya-datos/</link>
      <pubDate>Tue, 13 Dec 2016 08:13:05 +0000</pubDate>
      
      <guid>/2016/12/13/que-la-fuerza-de-r-tambien-te-acompane-a-ti-alla-a-donde-haya-datos/</guid>
      <description>La fuerza de R siepre me acompaña allá donde tengo datos. De ello da fe la siguiente captura de pantalla de mi móvil:
Si quieres que también te acompañe a ti:
 * [Instálate telegram](https://telegram.org/) * [Conecta con teleR](https://telegram.me/tele_R)  </description>
    </item>
    
    <item>
      <title>Un muy cuestionable análisis de lo de PISA</title>
      <link>/2016/12/12/un-muy-cuestinoable-analisis-de-lo-de-pisa/</link>
      <pubDate>Mon, 12 Dec 2016 08:13:00 +0000</pubDate>
      
      <guid>/2016/12/12/un-muy-cuestinoable-analisis-de-lo-de-pisa/</guid>
      <description>Voy a realizar un más que cuestionable (debajo desgranaré los caveats) de los resultados de las pruebas PISA del 2015 en España.
Primero, datos y métodos. Los primeros (y las descripciones de las variables) se pueden bajar de aquí. En cuanto a los segundos, he consultado esto (que me ha llevado a), esto y esto (donde está actualizado para los resultados de la última oleada). Hablaré más de métodos, y sus problemas, más abajo.</description>
    </item>
    
    <item>
      <title>Análisis de la supervivencia cuando ningún sujeto ha muerto</title>
      <link>/2016/11/28/analisis-de-la-supervivencia-cuando-ningun-sujeto-ha-muerto/</link>
      <pubDate>Mon, 28 Nov 2016 08:13:21 +0000</pubDate>
      
      <guid>/2016/11/28/analisis-de-la-supervivencia-cuando-ningun-sujeto-ha-muerto/</guid>
      <description>Me ha sobrevenido un problema de análisis de supervivencia curioso: ningún sujeto ha muerto. Dicho de otra manera, todas mis observaciones están censuradas por la derecha.
Los datos recogen la antigüedad de la cámara de fotos de los visitantes de cierto blog. Y debería uno poder estimar cada cuántos años renuevan la cámara, es decir, la vida promedio de esos aparatejos. Si embargo, no tenemos información de la edad de las cámaras en el momento de la renovación.</description>
    </item>
    
    <item>
      <title>Habiendo mónadas, ¿quién quiere callbacks?</title>
      <link>/2016/11/24/habiendo-monadas-quien-quiere-callbacks/</link>
      <pubDate>Thu, 24 Nov 2016 08:13:35 +0000</pubDate>
      
      <guid>/2016/11/24/habiendo-monadas-quien-quiere-callbacks/</guid>
      <description>Nunca me he visto en la tesitura de tener que usar callbacks porque no son mi guerra. Pero por lo que he oído de la gente que sabe mucho más que yo, son uno de esos infiernos de los que hay que huir con el mismo pavor que de los fors, los ifs, los elses (¡argggg! ¡he escrito else!) y los whiles.
Una pequeña maravilla teórica que me ha hecho replantearme la absoluta inutilidad de aquello que estudié en Álgebra III (funtores y demás) son las mónadas.</description>
    </item>
    
    <item>
      <title>Hoy no estaré donde debería: las VIII Jornadas de R</title>
      <link>/2016/11/17/hoy-no-estare-donde-deberia-las-viii-jornadas-de-r/</link>
      <pubDate>Thu, 17 Nov 2016 08:00:47 +0000</pubDate>
      
      <guid>/2016/11/17/hoy-no-estare-donde-deberia-las-viii-jornadas-de-r/</guid>
      <description>A la hora en que salga publicada esta entrada se estarán inaugurando las VIII Jornadas de Usuarios de R, las primeras a las que no asisto. Es por culpa de vaya uno saber qué tipo de microorganismos, que han decidido medir sus fuerzas con la Seguridad Social en algún recoveco de mis vías urinarias, y que me han obligado a cancelar el viaje a última hora.
Ha sido mi cita obligada del año durante los últimos ocho.</description>
    </item>
    
    <item>
      <title>Detrás de la detección de anomalías en series temporales</title>
      <link>/2016/11/16/detras-de-la-deteccion-de-anomalias-en-series-temporales/</link>
      <pubDate>Wed, 16 Nov 2016 08:13:02 +0000</pubDate>
      
      <guid>/2016/11/16/detras-de-la-deteccion-de-anomalias-en-series-temporales/</guid>
      <description>Por azares, me ha tocado lidiar con eso de la detección de anomalías. Que es un problema que tiene que ver con dónde colocar las marcas azules en
El anterior es el gráfico construido con los datos de ejemplo del paquete AnomalyDetection. De hecho, así:
library(AnomalyDetection) data(raw_data) res &amp;lt;- AnomalyDetectionTs(raw_data, max_anoms=0.02, direction=&#39;both&#39;, plot=TRUE) res$plot  Aparentemente, AnomalyDetectionTs hace lo que cabría sospechar. Primero, una descomposición de la serie temporal, tal como</description>
    </item>
    
    <item>
      <title>Una fina, tenue, somera capa de sintaxis</title>
      <link>/2016/11/15/una-fina-tenue-somera-capa-de-sintaxis/</link>
      <pubDate>Tue, 15 Nov 2016 08:13:18 +0000</pubDate>
      
      <guid>/2016/11/15/una-fina-tenue-somera-capa-de-sintaxis/</guid>
      <description>Estuve el otro día en una charla de José Luis Cañadas en el grupo de usuarios de R de Madrid sobre sparklyr. Hoy en otra de Juan Luis Rivero sobre, esencialmente, lo mismo, pero esta vez con Python. Y podría escribir &amp;ldquo;etc.&amp;rdquo;.
Me centraré en la de José Luis, aunque podría decir lo mismo de cualquiera de las otras. No había trabajado con sparklyr. No soy siquiera fan de dplyr (aunque no es que no se lo recomiende a otros; es simplemente, como tantas cosas, que soluciona problemas que no tengo).</description>
    </item>
    
    <item>
      <title>¿Cuánto tarda en ejecutarse este código?</title>
      <link>/2016/11/11/cuanto-tarda-en-ejecutarse-este-codigo/</link>
      <pubDate>Fri, 11 Nov 2016 08:13:49 +0000</pubDate>
      
      <guid>/2016/11/11/cuanto-tarda-en-ejecutarse-este-codigo/</guid>
      <description>Es:
library(future) plan(multiprocess, workers = 4) system.time({ a1 &amp;lt;- future({Sys.sleep(7); 1}) a2 &amp;lt;- future({Sys.sleep(1); 1}) a3 &amp;lt;- future({Sys.sleep(1); 1}) a4 &amp;lt;- future({Sys.sleep(1); 1}) a5 &amp;lt;- future({Sys.sleep(1); 1}) a6 &amp;lt;- future({Sys.sleep(1); 1}) a7 &amp;lt;- future({Sys.sleep(1); 1}) res &amp;lt;- sapply(list(a1, a2, a3, a4, a5, a6, a5), value) })  Piensa antes las posibles opciones:
 * ~8 segundos: ejecuta primero `a1`-`a4` en 7 segundos y luego `a5`-`a7` en un segundo adicional. * ~7 segundos: ejecuta primero `a1`-`a4`, pero cuando acaban `a2`-`a4`, lanza `a5`-`a7`, que terminan antes que `a1` * ¿Otras?</description>
    </item>
    
    <item>
      <title>R en paralelo (pero ahora, con futuros)</title>
      <link>/2016/11/04/r-en-paralelo-pero-ahora-con-futuros/</link>
      <pubDate>Fri, 04 Nov 2016 08:13:59 +0000</pubDate>
      
      <guid>/2016/11/04/r-en-paralelo-pero-ahora-con-futuros/</guid>
      <description>Esta entrada extiende y mejora una homónima de 2014.
El problema de entonces consistía en calcular por separado y en paralelo objetos A, B y C para combinarlos después. Cuando, por supuesto, el cálculo de A, B y C es pesado.
El muy reciente paquete future incorpora a R un mecanismo disponible en otros lenguajes de programación: un cierto tipo de datos, los futuros, que contienen promesas de valores que se calculan fuera del hilo principal del programa.</description>
    </item>
    
    <item>
      <title>Recordatorio: las VIII Jornadas de Usuarios de R</title>
      <link>/2016/10/07/recordatorio-las-viii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Fri, 07 Oct 2016 08:13:41 +0000</pubDate>
      
      <guid>/2016/10/07/recordatorio-las-viii-jornadas-de-usuarios-de-r/</guid>
      <description>Que tendrán lugar en Albacete los días 17 y 18 de noviembre de 2016. Más información (toda la información, de hecho), aquí.</description>
    </item>
    
    <item>
      <title>Barómetros del CIS con R</title>
      <link>/2016/10/05/barometros-del-cis-con-r/</link>
      <pubDate>Wed, 05 Oct 2016 08:13:46 +0000</pubDate>
      
      <guid>/2016/10/05/barometros-del-cis-con-r/</guid>
      <description>El CIS realiza barómetros todos los meses menos uno. Pasado un tiempo (es octubre y el último publicado es de julio) coloca los microdatos en su banco de datos.
Aparte de ficheros .pdf que lo explican todo (pero que no dejan de ser .pdf), publica dos ficheros. Uno de datos en ancho fijo (prefijo DA) y otro con código SPSS (prefijo ES) con los consabidos (¿lo son? ¡felicidades si no!) encabezados DATA LIST, VARIABLE LABELS, VALUE LABELS, y MISSING VALUES.</description>
    </item>
    
    <item>
      <title>Votos en la ONU con R</title>
      <link>/2016/09/21/votos-en-la-onu-con-r/</link>
      <pubDate>Wed, 21 Sep 2016 08:13:25 +0000</pubDate>
      
      <guid>/2016/09/21/votos-en-la-onu-con-r/</guid>
      <description>Inspirado por esto he generado
usando
library(unvotes) library(reshape2) library(gplots) dat &amp;lt;- un_votes levels(dat$vote) &amp;lt;- c(&amp;quot;0&amp;quot;, &amp;quot;-1&amp;quot;, &amp;quot;1&amp;quot;) dat$vote &amp;lt;- as.numeric(as.character(dat$vote)) dat &amp;lt;- dcast(dat, rcid ~ country, value.var = &amp;quot;vote&amp;quot;) dat$rcid &amp;lt;- NULL dat &amp;lt;- as.matrix(dat) res &amp;lt;- cov(dat, use = &amp;quot;pairwise.complete.obs&amp;quot;) heatmap(res)  Se me olvidaba: el gráfico se refiere a los votos de los distintos países en la ONU.
Tal vez alguien quiera poner la lupa en algún país concreto.</description>
    </item>
    
    <item>
      <title>Un curso de 15 horas de introducción a la programación</title>
      <link>/2016/09/19/un-curso-de-15-horas-de-introduccion-a-la-programacion/</link>
      <pubDate>Mon, 19 Sep 2016 08:13:31 +0000</pubDate>
      
      <guid>/2016/09/19/un-curso-de-15-horas-de-introduccion-a-la-programacion/</guid>
      <description>Hoy comienzo a enseñar un curso de introducción a la programación para recién graduados que comenzarán un máster de matemáticas aplicadas con incursiones en la llamada ciencia de datos. Serán 4 sesiones con el siguiente contenido:
 * Sesión 1, programación imperativa: variables, condicionales y bucles. * Sesión 2, programación orientada a objetos. * Sesión 3, colecciones: listas, tuplas, conjuntos, diccionarios, etc. * Sesión 4, programación funcional: _map_, _reduce_, _fold_, _foldLeft_, _scan_, _filter_, etc.</description>
    </item>
    
    <item>
      <title>Selección de variables con bosques aleatorios</title>
      <link>/2016/09/06/seleccion-de-variables-con-bosques-aleatorios/</link>
      <pubDate>Tue, 06 Sep 2016 08:13:39 +0000</pubDate>
      
      <guid>/2016/09/06/seleccion-de-variables-con-bosques-aleatorios/</guid>
      <description>Desde el principio de mis tiempos he seleccionado variables relevantes como subproducto de los árboles primero y de los bosques aleatorios después. Cierto que he hecho casi inconfesables incursiones en los métodos stepwise, pero han sido marginales y anecdóticas.
La idea es casi siempre la misma, se haga a mano o con ayuda de paquetes ad hoc: las variables importantes tienden a aparecer en el modelo (o submodelos), las otras no.</description>
    </item>
    
    <item>
      <title>Tod[rep(&#39;a&#39;, 831)]s y tod[rep(&#39;o&#39;, 6450)]s los autores de paquetes de R</title>
      <link>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</link>
      <pubDate>Wed, 31 Aug 2016 08:13:15 +0000</pubDate>
      
      <guid>/2016/08/31/todrepa-831s-y-todrepo-6450s-los-autores-de-paquetes-de-r/</guid>
      <description>En los últimos tiempos se ha puesto de moda un subgénero periodístico que es una manera de generar artículos de acuerdo con el siguiente algoritmo:
 1. Se toma una lista de personas. 2. Se cuenta en ella el número de mujeres (a) y de hombres (b). 3. Si a &amp;gt;= b, GOTO 1; si no, se copipega y se mutatismutandea un manido argumento.  No sabiéndome sustraer al encanto del último grito, he escrito y corrido</description>
    </item>
    
    <item>
      <title>La Consejería de Empleo de la Función General de la Comunidad Autónoma de Ordenación Provincia de la Audiencia Profesional</title>
      <link>/2016/08/29/la-consejeria-de-empleo-de-la-funcion-general-de-la-comunidad-autonoma-de-ordenacion-provincia-de-la-audiencia-profesional/</link>
      <pubDate>Mon, 29 Aug 2016 08:13:19 +0000</pubDate>
      
      <guid>/2016/08/29/la-consejeria-de-empleo-de-la-funcion-general-de-la-comunidad-autonoma-de-ordenacion-provincia-de-la-audiencia-profesional/</guid>
      <description>Ese es el nombre agramatical de una nueva consejería pergeñada por una red neuronal recurrente que he ajustado usando un año de BOEs.
El código, adaptado de aquí y sustancialmente mejorado, es
library(mxnet) batch.size &amp;lt;- 32 seq.len &amp;lt;- 64 num.hidden &amp;lt;- 128 num.embed &amp;lt;- 8 num.lstm.layer &amp;lt;- 1 num.round &amp;lt;- 1 learning.rate &amp;lt;- 0.1 wd &amp;lt;- 0.00001 clip_gradient &amp;lt;- 1 update.period &amp;lt;- 1 make.data &amp;lt;- function(dir.boe, seq.len = 32, max.vocab=10000, dic = NULL) { text &amp;lt;- lapply(dir(dir.</description>
    </item>
    
    <item>
      <title>Me voy a Gijón toda la semana</title>
      <link>/2016/07/18/me-voy-a-gijon-toda-la-semana/</link>
      <pubDate>Mon, 18 Jul 2016 08:13:40 +0000</pubDate>
      
      <guid>/2016/07/18/me-voy-a-gijon-toda-la-semana/</guid>
      <description>A esto:</description>
    </item>
    
    <item>
      <title>Rápido y frugal: una digresión en la dirección inhabitual</title>
      <link>/2016/07/13/rapido-y-frugal-una-digresion-en-la-direccion-inhabitual/</link>
      <pubDate>Wed, 13 Jul 2016 08:13:39 +0000</pubDate>
      
      <guid>/2016/07/13/rapido-y-frugal-una-digresion-en-la-direccion-inhabitual/</guid>
      <description>Siempre (aténganse los puristas al contexto) recomiendo comenzar con un árbol de decisión para, sobre esa base, ensayar métodos más potentes. Sobre todo si la precisión conviene más que la interpretabilidad.
En la dirección opuesta se sitúan los árboles rápidos y frugales. Un árbol rápido y frugal es un tipo de árbol de decisión tal como
La restricción que satisface (a diferencia de los árboles de decisión más habituales) es que:</description>
    </item>
    
    <item>
      <title>Dos nuevos tutoriales sobre data.table y dplyr</title>
      <link>/2016/07/12/dos-nuevos-tutoriales-sobre-data-table-y-dplyr/</link>
      <pubDate>Tue, 12 Jul 2016 08:13:34 +0000</pubDate>
      
      <guid>/2016/07/12/dos-nuevos-tutoriales-sobre-data-table-y-dplyr/</guid>
      <description>Los productos de Apple, aun admitiendo su calidad, resuelven problemas que yo hace años que no tenía. Tanto data.table como dplyr vinieron a resolver problemas a los que muchos nos enfrentábamos con sudor y lágrimas.
Ha aparecido recientemente una serie de tutoriales sobre ambos paquetes que recomiendo:
 * El de [`data.table`](https://rollingyours.wordpress.com/2016/06/14/fast-aggregation-of-large-data-with-the-data-table-package/) * El de `dplyr` ([parte I](https://rollingyours.wordpress.com/2016/06/29/express-intro-to-dplyr/), [parte II](https://rollingyours.wordpress.com/2016/07/07/express-dplyr-part-ii/))  Y mis comentarios:
 * Para el 99% de mis problemas de manipulación de datos, me sobra con, además de R base, `reshape2` y `plyr`.</description>
    </item>
    
    <item>
      <title>Una estupenda introducción intermedia a data.table</title>
      <link>/2016/07/08/una-estupenda-introduccion-intermedia-a-data-table/</link>
      <pubDate>Fri, 08 Jul 2016 08:13:05 +0000</pubDate>
      
      <guid>/2016/07/08/una-estupenda-introduccion-intermedia-a-data-table/</guid>
      <description>Jan Gorecki ha resumido las soluciones a las cincuenta preguntas más populares sobre el paquete data.table de R en Stack Overflow y las ha resumido en forma de tutorial aquí.
Muy recomendable. Muy recomendable también data.table.
Aunque me temo que el hadleyverse, y por razones que nada tienen que ver con la calidad de la cosa, no van a dejar de él, a medio plazo, ni las raspas.</description>
    </item>
    
    <item>
      <title>R I/O (o rio)</title>
      <link>/2016/07/07/r-io-o-rio/</link>
      <pubDate>Thu, 07 Jul 2016 08:13:53 +0000</pubDate>
      
      <guid>/2016/07/07/r-io-o-rio/</guid>
      <description>rio es otro de esos desasosegantes paquetes de R. rio contiene esencialmente tres funciones,
 * `import`, que lo lee _todo_ * `export`, que lo escribe _todo_ y * `convert`, que transforma un fichero de un formato a otro.  Según su documentación, uno puede hacer cosas como
export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.csv&amp;quot;) export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.rds&amp;quot;) export(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/mtcars&amp;quot;&amp;gt;mtcars, &amp;quot;mtcars.sav&amp;quot;)  para guardar mtcars en cualquiera de los formatos indicados por la extensión y luego</description>
    </item>
    
    <item>
      <title>GLMs con prioris (casi) a voluntad</title>
      <link>/2016/07/06/glms-con-prioris-casi-a-voluntad/</link>
      <pubDate>Wed, 06 Jul 2016 08:13:34 +0000</pubDate>
      
      <guid>/2016/07/06/glms-con-prioris-casi-a-voluntad/</guid>
      <description>Esto que cuento hoy puede ser muy útil: cómo mejorar los GLMs mediante la introducción de prioris (casi) a voluntad sobre los coeficientes. Usando el paquete arm de R, claro.
De momento y porque aún tengo sucios los datos sobre los que me gustaría aplicar el modelo, extraeré un ejemplo de la ayuda de la función principal del paquete, bayesglm.
Primero, preparo unos datos:
n &amp;lt;- 100 x1 &amp;lt;- rnorm (n) x2 &amp;lt;- rbinom (n, 1, .</description>
    </item>
    
    <item>
      <title>Gestión de la mendacidad encuestoelectoral: los números</title>
      <link>/2016/07/04/gestion-de-la-mendacidad-encuestoelectoral-los-numeros/</link>
      <pubDate>Mon, 04 Jul 2016 08:13:31 +0000</pubDate>
      
      <guid>/2016/07/04/gestion-de-la-mendacidad-encuestoelectoral-los-numeros/</guid>
      <description>Continuando con la entrada anterior, ahora, números.
Primero, el planteamiento (cuatro partidos, etc.):
probs &amp;lt;- c(4, 3, 2, 1) probs &amp;lt;- probs / sum(probs) partidos &amp;lt;- letters[1:length(probs)]  Nos hará falta más adelante
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) library(rstan) library(ggplot2) library(reshape2)  Sigo con el proceso de muestreo. Reitero: cada encuestador enseña al encuestado una tarjeta al azar donde aparece el nombre de dos partidos y le pregunta si ha votado (o piensa votar) a alguno de ellos.</description>
    </item>
    
    <item>
      <title>R es un vago</title>
      <link>/2016/06/27/r-es-un-vago/</link>
      <pubDate>Mon, 27 Jun 2016 08:13:56 +0000</pubDate>
      
      <guid>/2016/06/27/r-es-un-vago/</guid>
      <description>Si creo la función
foo &amp;lt;- function(a,b) a*a + b  y la llamo mediante
foo(1 + 1,3)  pueden ocurrir dos cosas: o bien que R precalcule 1+1 y la función ejecute 2 * 2 + 3 o bien que la función ejecute directamente (1+1)*(1+1)+3. Pero, ¿qué es lo que hace realmente? Si escribimos
f1 &amp;lt;- function(x){ print(&amp;quot;Soy f1&amp;quot;) x } f2 &amp;lt;- function(x){ print(&amp;quot;Soy f2&amp;quot;) x } foo(f1(2), f2(3))  obtenemos</description>
    </item>
    
    <item>
      <title>6602.767 km alrededor de España para visitar todas sus capitales de provincia</title>
      <link>/2016/06/20/6602-767-km-alrededor-de-espana-para-visitar-todas-sus-capitales-de-provincia/</link>
      <pubDate>Mon, 20 Jun 2016 08:13:30 +0000</pubDate>
      
      <guid>/2016/06/20/6602-767-km-alrededor-de-espana-para-visitar-todas-sus-capitales-de-provincia/</guid>
      <description>O tal dice lo que expongo a continuación.
Paquetes necesarios:
library(rvest) library(caRtociudad) library(reshape2) library(ggmap) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/TSP&amp;quot;&amp;gt;TSP)  Extracción de las provincias y sus capitales (de la Wikipedia):
capitales &amp;lt;- read_html(&amp;quot;https://es.wikipedia.org/wiki/Anexo:Capitales_de_provincia_de_Espa%C3%B1a_por_poblaci%C3%B3n&amp;quot;) capitales &amp;lt;- html_nodes(capitales, &amp;quot;table&amp;quot;) capitales &amp;lt;- html_table(capitales[[1]])$Ciudad capitales &amp;lt;- capitales[!capitales %in% c(&amp;quot;Las Palmas de Gran Canaria&amp;quot;, &amp;quot;Melilla&amp;quot;, &amp;quot;Ceuta&amp;quot;, &amp;quot;Mérida&amp;quot;, &amp;quot;Santa Cruz de Tenerife&amp;quot;, &amp;quot;Santiago de Compostela&amp;quot;, &amp;quot;Palma de Mallorca&amp;quot;)]  Y sus coordenadas:
coordenadas &amp;lt;- ldply(capitales, function(x) { tmp &amp;lt;- cartociudad_geocode(x)[1,] res &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>Censura a la izquierda en las universidades españolas</title>
      <link>/2016/06/13/censura-a-la-izquierda-en-las-universidades-espanolas/</link>
      <pubDate>Mon, 13 Jun 2016 08:13:39 +0000</pubDate>
      
      <guid>/2016/06/13/censura-a-la-izquierda-en-las-universidades-espanolas/</guid>
      <description>(Aviso: esta entrada podría competir dignamente en una competición de titulares engañosos. Es posible que si no sepas de qué hablo regularmente te interese más esto).
En España hay pruebas de acceso a la universidad que y en algunos sitios publican las notas de corte para acceder a determinados estudios. Las he bajado escrapeando El País así
library(rvest) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) library(rstan) library(reshape2) options(mc.cores = 2) url &amp;lt;- &amp;quot;http://elpais.com/especiales/universidades/&amp;quot; pagina &amp;lt;- read_html(url, encoding = &amp;quot;UTF8&amp;quot;) urls_provs &amp;lt;- html_nodes(pagina, &amp;quot;a&amp;quot;) urls_provs &amp;lt;- html_attr(urls_provs, &amp;quot;href&amp;quot;) urls_provs &amp;lt;- paste0(&amp;quot;http://elpais.</description>
    </item>
    
    <item>
      <title>Acceso a Google Analytcs desde R</title>
      <link>/2016/06/06/acceso-a-google-analytcs-desde-r/</link>
      <pubDate>Mon, 06 Jun 2016 08:13:46 +0000</pubDate>
      
      <guid>/2016/06/06/acceso-a-google-analytcs-desde-r/</guid>
      <description>Google Analytics puede usarse desde su consola o bien descargando datos y procesándolos por tu cuenta. Para lo cual, desde R,
require(RGoogleAnalytics) client.id &amp;lt;- &amp;quot;1415926535-u377en6un7lugar2de7lamancha0de1cuyo5nombre0m.apps.googleusercontent.com&amp;quot; client.secret &amp;lt;- &amp;quot;CEcI5nEst6pAs6Un2SecREt6-f8nt&amp;quot; token &amp;lt;- Auth(client.id,client.secret) #save(token,file=&amp;quot;~/.ga_token_file&amp;quot;)  Obviamente, para lo anterior:
 * Hay que instalar y cargar los paquetes relevantes * Tienes que usar tu propio id y secreto de cliente como indica [aquí](https://auth0.com/docs/connections/social/google) * Tienes que tener una cuenta en Google Analytics, claro  Además, puedes descomentar la última línea si quieres guardar tus credenciales para futuros usos (con las debidas medidas de seguridad).</description>
    </item>
    
    <item>
      <title>R sobre el EC2 de Amazon hace casi siete años: una concesión a la melancolía</title>
      <link>/2016/06/03/r-sobre-el-ec2-de-amazon-hace-casi-siete-anos-una-concesion-a-la-melancolia/</link>
      <pubDate>Fri, 03 Jun 2016 08:13:16 +0000</pubDate>
      
      <guid>/2016/06/03/r-sobre-el-ec2-de-amazon-hace-casi-siete-anos-una-concesion-a-la-melancolia/</guid>
      <description>Corría el año 2009 cuando comencé mi segunda aventura bloguera (nadie, yo incluido, quiere rememorar la segunda) cuando Raúl Vaquerizo tuvo la caridad de aceptarme como colaborador en Análisis y Decisión.
En diciembre de aquel año escribí cómo utilizar R en una cosa que entonces comenzaba a sonar: la nube y, en concreto, el servicio EC2 de Amazon.
El resultado, probablemente totalmente desfasado, fue este.
Material de hemeroteca, alimento de melancolías.</description>
    </item>
    
    <item>
      <title>Detección de &#34;outliers&#34; locales</title>
      <link>/2016/06/02/deteccion-de-outliers-locales/</link>
      <pubDate>Thu, 02 Jun 2016 08:13:19 +0000</pubDate>
      
      <guid>/2016/06/02/deteccion-de-outliers-locales/</guid>
      <description>Aunque outlier local parezca oxímoron, es un concepto que tiene sentido.
Un outlier es un punto dentro de un conjunto de datos tan alejado del resto que diríase generado por un mecanismo distinto que el resto. Por ejemplo, puedes tener las alturas de la gente y alguna observación que parece producto de otra cosa como, por ejemplo, errores mecanográficos en la transcripción. Un outlier está lejos del resto. Pero, ¿cuánto?</description>
    </item>
    
    <item>
      <title>¿Mis conciudadanos no tienen wifi?</title>
      <link>/2016/05/30/mis-conciudadanos-no-tienen-wifi/</link>
      <pubDate>Mon, 30 May 2016 08:13:01 +0000</pubDate>
      
      <guid>/2016/05/30/mis-conciudadanos-no-tienen-wifi/</guid>
      <description>A alguien leí el otro día que decía que en un bar de carretera habían colocado un cartel diciendo: &amp;ldquo;Hemos quitado el periódico y hemos puesto wifi&amp;rdquo;. Viene esto a cuento de
library(rvest) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/tm&amp;quot;&amp;gt;tm) library(wordcloud) res &amp;lt;- sapply(1:17, function(i){ url &amp;lt;- paste(&amp;quot;https://decide.madrid.es/participatory_budget/investment_projects?geozone=all&amp;amp;page=&amp;quot;, i, &amp;quot;&amp;amp;random_seed=0.28&amp;quot;, sep = &amp;quot;&amp;quot;) tmp &amp;lt;- html_nodes(read_html(url), xpath = &amp;quot;//div[starts-with(@id, &#39;spending_proposal&#39;)]/div/div/div[1]/div/h3/a/text()&amp;quot;) as.character(tmp) }) tmp &amp;lt;- unlist(res) tmp &amp;lt;- Corpus(VectorSource(tmp)) tmp &amp;lt;- tm_map(tmp, stripWhitespace) tmp &amp;lt;- tm_map(tmp, content_transformer(tolower)) tmp &amp;lt;- tm_map(tmp, removeWords, stopwords(&amp;quot;spanish&amp;quot;)) wordcloud(tmp, scale=c(5,0.</description>
    </item>
    
    <item>
      <title>Coordenadas polares por doquier</title>
      <link>/2016/05/27/coordenadas-polares-por-doquier/</link>
      <pubDate>Fri, 27 May 2016 08:13:49 +0000</pubDate>
      
      <guid>/2016/05/27/coordenadas-polares-por-doquier/</guid>
      <description>El otro día pasé por uno de esos sitios en los que exponen en las paredes obras de artistas medianos con el precio debajo. Me quedé mirando una muy&amp;hellip; concéntrica porque me recordaba a lo que nos regala a menudo Antonio Chinchón. Pregunté de qué trataba la cosa y tuvieron la paciencia de explicármelo: al lado había una foto enorme y, se conoce, las cosas concéntricas eran una reordenación de los píxels de la primera.</description>
    </item>
    
    <item>
      <title>Rmd2R: un conversor de lo que su propio nombre indica</title>
      <link>/2016/05/25/rmd2r-un-conversor-de-lo-que-su-propio-nombre-indica/</link>
      <pubDate>Wed, 25 May 2016 08:13:07 +0000</pubDate>
      
      <guid>/2016/05/25/rmd2r-un-conversor-de-lo-que-su-propio-nombre-indica/</guid>
      <description>Mis clases de/con R suelen consistir en un guión que es un programa en R con muchos comentarios y ejercicios. Con el tiempo, estos últimos tienden a crecer hasta el punto de que se convierte casi en un fichero de texto comentado con aspersión —en su acepción no-DRAE de efecto— de líneas de código.
Mejor, me he dicho recientemente, usar Rmarkdown.
Pero Rmarkdown sirve para lo que sirve: como fuente para compilar ficheros pensados para ser leídos por seres humanos.</description>
    </item>
    
    <item>
      <title>Descarga de datos del Ibex 35 (¿y otros?) minuto a minuto en tiempo (casi) real</title>
      <link>/2016/05/20/descarga-de-datos-del-ibex-35-y-otros-minuto-a-minuto-en-tiempo-casi-real/</link>
      <pubDate>Fri, 20 May 2016 08:13:54 +0000</pubDate>
      
      <guid>/2016/05/20/descarga-de-datos-del-ibex-35-y-otros-minuto-a-minuto-en-tiempo-casi-real/</guid>
      <description>El código es
library(httr) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) base.url &amp;lt;- &amp;quot;http://www.infobolsa.es/1/wtdb/ChartIntraday&amp;quot; res &amp;lt;- POST(base.url, body = list(mv = &amp;quot;M SAN&amp;quot;, date = &amp;quot;20160518&amp;quot;, compressionMult = 1, isSession = 1)) dat &amp;lt;- content(res, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/methods/as&amp;quot;&amp;gt;as = &amp;quot;parsed&amp;quot;, type = &amp;quot;application/json&amp;quot;) dat &amp;lt;- dat$answer$LST$TV$T09 dat &amp;lt;- ldply(dat, unlist)  Los mutatis mutandis, si alguien tiene la gentileza, en los comentarios.</description>
    </item>
    
    <item>
      <title>Mañana (2016-05-12), caRtociudad en la reunión de usuarios de R de Madrid</title>
      <link>/2016/05/11/manana-2016-05-12-cartociudad-en-la-reunion-de-usuarios-de-r-de-madrid/</link>
      <pubDate>Wed, 11 May 2016 08:13:25 +0000</pubDate>
      
      <guid>/2016/05/11/manana-2016-05-12-cartociudad-en-la-reunion-de-usuarios-de-r-de-madrid/</guid>
      <description>Mañana día 12 de mayo (de 2016) Luz Frías, mi coautora, hablará de caRtociudad en la reunión de usuarios de R de Madrid.
Es un paquete muy interesante para geolocalizar direcciones (¡sin las restricciones de los consabidos servicios!), identificar las secciones censales, distritos censales y códigos postales correspondientes a direcciones y ubicaciones, etc.</description>
    </item>
    
    <item>
      <title>Cartogramas rectangulares con R</title>
      <link>/2016/05/10/cartogramas-rectangulares-con-r/</link>
      <pubDate>Tue, 10 May 2016 08:13:22 +0000</pubDate>
      
      <guid>/2016/05/10/cartogramas-rectangulares-con-r/</guid>
      <description>* [Galería](http://cartodraw.science/recmap/gallery/) * [Paquete](https://cran.r-project.org/web/packages/recmap/index.html)  Y, lo siento, no tengo ejemplos míos. Pero si te animas, fabricas uno y lo enlazas en los comentarios, seguro que a alguien le sirve.</description>
    </item>
    
    <item>
      <title>Encuestas electorales: medios y sesgos (II)</title>
      <link>/2016/05/09/encuestas-electorales-medios-y-sesgos-ii/</link>
      <pubDate>Mon, 09 May 2016 08:13:27 +0000</pubDate>
      
      <guid>/2016/05/09/encuestas-electorales-medios-y-sesgos-ii/</guid>
      <description>Aquí quedó pendiente hablar de datos y métodos. Los primeros proceden de El Mundo. Solicité a Marta Ley, una coautora, los datos pero, antes de que contestase que sí (¡gracias!), me di cuenta de que podía obtenerlos solito: basta con capturar la llamada que el javascript local hace al servidor.
¿Métodos? Mejorables: se suaviza la intención de voto (con loess) y se estima la diferencia con un modelo de efectos mixtos, i.</description>
    </item>
    
    <item>
      <title>Un corpus de textos en español para NLP</title>
      <link>/2016/05/06/un-corpus-de-textos-en-espanol-para-nlp/</link>
      <pubDate>Fri, 06 May 2016 08:13:49 +0000</pubDate>
      
      <guid>/2016/05/06/un-corpus-de-textos-en-espanol-para-nlp/</guid>
      <description>Mañana doy clase de NLP en el máster de ciencia de datos de KSchool. Para lo que necesito un corpus decente. Los hay en inglés a tutiplén, pero las hordas de lingüistas hispanoparlantes que se pagan los vicios a costa de tajadas de mi IRPF han sido incapaces de colgar ninguno en español que pueda ubicar y reutilizar.
Necesito una colección de textos en español con ciertas características:
 * Tener un cierto tamaño (¿unas cuantas centenas de ellos?</description>
    </item>
    
    <item>
      <title>Encuestas electorales: medios y sesgos (I)</title>
      <link>/2016/05/05/encuestas-electorales-medios-y-sesgos-i/</link>
      <pubDate>Thu, 05 May 2016 08:13:07 +0000</pubDate>
      
      <guid>/2016/05/05/encuestas-electorales-medios-y-sesgos-i/</guid>
      <description>Existen las encuestas electorales. Las publican medios. Algunos, se dice, tienen sesgos. Lo he estudiado y a continuación muestro resultados.
Para el PP:
Para el PSOE:
Para Podemos y cía:
Para Ciudadanos:
Para IU:
En otra entrada, datos y métodos. Hoy solo adelanto que el eje horizontal mide puntos porcentuales y que las encuestas se remontan a enero de 2015.</description>
    </item>
    
    <item>
      <title>Cómo ir de Regumiel de la Sierra a Montejo de la Vega de la Serrezuela</title>
      <link>/2016/04/29/como-ir-de-regumiel-de-la-sierra-a-montejo-de-la-vega-de-la-serrezuela/</link>
      <pubDate>Fri, 29 Apr 2016 08:13:11 +0000</pubDate>
      
      <guid>/2016/04/29/como-ir-de-regumiel-de-la-sierra-a-montejo-de-la-vega-de-la-serrezuela/</guid>
      <description>Pues así:
 * Continúe por CALLE SAN JUAN DE RABANERA * Gire justo a la izquierda por CALLE DIPUTACION * Gire justo a la derecha por CALLE CABALLEROS * Gire ligeramente a la izquierda por PLAZA RAMON Y CAJAL * Gire a la izquierda por PLAZA MARIANO GRANADOS * Gire a la izquierda por PASEO ESPOLON (EL) * Gire ligeramente a la izquierda por AVENIDA VALLADOLID * Gire ligeramente a la izquierda por N-122 * Continúe por A-11 * Continúe por N-122 * Gire ligeramente a la izquierda por CARRETERA SIN NOMBRE * Continúe por N-122 * Gire a la izquierda por BU-924 * Continúe por N-122 * Continúe por BU-930 * Gire a la derecha por BU-940 * Continúe por CALLE FELIPE GARCIA * Continúe por BU-940 * Gire ligeramente a la derecha por BU-932 * Gire a la izquierda por CALLE PAJARES * Continúe por BU-V-9321 * Continúe por SG-V-9321 * Continúe por road * Continúe por SG-V-9321 * Gire a la derecha por CALLE BAÑUELOS  O al menos, eso dice la novísima función caRtociudad::get_cartociudad_route.</description>
    </item>
    
    <item>
      <title>El impacto causal del óbito del Sr. Botín en la cotización bursátil del benemérito Banco de Santander</title>
      <link>/2016/04/20/el-impacto-causal-del-obito-del-sr-botin-en-la-cotizacion-bursatil-del-benemerito-banco-de-santander/</link>
      <pubDate>Wed, 20 Apr 2016 09:13:32 +0000</pubDate>
      
      <guid>/2016/04/20/el-impacto-causal-del-obito-del-sr-botin-en-la-cotizacion-bursatil-del-benemerito-banco-de-santander/</guid>
      <description>El Sr. Botín, presidente que fue del Banco de Santander, falleció el 2014-09-10. Cabe preguntarse por el impacto causal à la Google de no continuidad de su gestión a cargo de dicha institución.
Comienzo pues.
Primero los datos:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/tseries&amp;quot;&amp;gt;tseries) library(CausalImpact) santander &amp;lt;- get.hist.quote(instrument=&amp;quot;san.mc&amp;quot;, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/start&amp;quot;&amp;gt;start= &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.Date&amp;quot;&amp;gt;Sys.Date() - 365*3, end= &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.Date&amp;quot;&amp;gt;Sys.Date(), quote=&amp;quot;AdjClose&amp;quot;, provider=&amp;quot;yahoo&amp;quot;, origin=&amp;quot;1970-01-01&amp;quot;, compression=&amp;quot;d&amp;quot;, retclass=&amp;quot;zoo&amp;quot;) bbva &amp;lt;- get.hist.quote(instrument=&amp;quot;bbva.mc&amp;quot;, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/start&amp;quot;&amp;gt;start= &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.Date&amp;quot;&amp;gt;Sys.Date() - 365*3, end= &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.Date&amp;quot;&amp;gt;Sys.Date(), quote=&amp;quot;AdjClose&amp;quot;, provider=&amp;quot;yahoo&amp;quot;, origin=&amp;quot;1970-01-01&amp;quot;, compression=&amp;quot;d&amp;quot;, retclass=&amp;quot;zoo&amp;quot;) ibex &amp;lt;- get.</description>
    </item>
    
    <item>
      <title>Diapositivas de mi charla sobre feather</title>
      <link>/2016/04/19/diapositivas-de-mi-charla-sobre-feather/</link>
      <pubDate>Tue, 19 Apr 2016 09:13:44 +0000</pubDate>
      
      <guid>/2016/04/19/diapositivas-de-mi-charla-sobre-feather/</guid>
      <description>Las diapositivas de mi charla Birds of the same feather&amp;hellip; en el grupo de usuarios de R de Madrid pueden verse/bajarse de aquí.</description>
    </item>
    
    <item>
      <title>Ahora caRtociudad encuentra información administrativa relativa a un punto</title>
      <link>/2016/04/15/ahora-cartociudad-encuentra-informacion-administrativa-relativa-a-un-punto/</link>
      <pubDate>Fri, 15 Apr 2016 09:13:20 +0000</pubDate>
      
      <guid>/2016/04/15/ahora-cartociudad-encuentra-informacion-administrativa-relativa-a-un-punto/</guid>
      <description>Y lo hace así:
library(caRtociudad) get_cartociudad_location_info(40.473219,-3.7227241, year = 2015) # $seccion # [1] &amp;quot;2807908148&amp;quot; # # $distrito # [1] &amp;quot;2807908&amp;quot; # # $provincia # [1] &amp;quot;Madrid&amp;quot; # # $municipio # [1] &amp;quot;Madrid&amp;quot;  Esto da respuesta a una pregunta de Rubén.
La función es en su mayor parte (salvo algunos retoques más estéticos que otra cosa míos) de Luz Frías, que hizo omiso caso de la inexistente docuentación del INE sobre su servicio de mapas y capturó directamente la petición que el portal de Cartociudad hace al servicio.</description>
    </item>
    
    <item>
      <title>Diapositivas de mi charla &#34;Datos, modelos y parámetros&#34;</title>
      <link>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</link>
      <pubDate>Thu, 14 Apr 2016 09:13:35 +0000</pubDate>
      
      <guid>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</guid>
      <description>Las diapositivas de mi charla Datos, modelos y parámetros en el grupo Machine Learning Spain pueden verse/bajarse de aquí.</description>
    </item>
    
    <item>
      <title>¿Quieres aprender R? ¡Matricúlate en mi curso en KSchool!</title>
      <link>/2016/04/13/quieres-aprender-r-matriculate-en-mi-curso-en-kschool/</link>
      <pubDate>Wed, 13 Apr 2016 09:13:01 +0000</pubDate>
      
      <guid>/2016/04/13/quieres-aprender-r-matriculate-en-mi-curso-en-kschool/</guid>
      <description>Si quieres aprender R, bien puedes matricularte en el curso que voy a impartir en KSchool. Es un programa de iniciación a R centrado en aquellos aspectos de R que más usan en la práctica diaria quienes trabajan con datos (y no son estadísticos duros). ¡Y ya vamos por la tercera edición!
Tendrá lugar durante el mes de junio (y un poco de julio). Son diez sesiones de tres horas. Los detalles están aquí.</description>
    </item>
    
    <item>
      <title>Este jueves, Feather en la reunión de usuarios de R de Madrid</title>
      <link>/2016/04/12/este-jueves-feather-en-la-reunion-de-usuarios-de-r-de-madrid/</link>
      <pubDate>Tue, 12 Apr 2016 09:13:01 +0000</pubDate>
      
      <guid>/2016/04/12/este-jueves-feather-en-la-reunion-de-usuarios-de-r-de-madrid/</guid>
      <description>Sí, hablaré de feather.
Los detalles, aquí.</description>
    </item>
    
    <item>
      <title>Clústers de trayectorias con la distancia de Fréchet</title>
      <link>/2016/04/08/clusters-de-trayectorias-con-la-distancia-de-frechet/</link>
      <pubDate>Fri, 08 Apr 2016 09:13:23 +0000</pubDate>
      
      <guid>/2016/04/08/clusters-de-trayectorias-con-la-distancia-de-frechet/</guid>
      <description>Los viejos del lugar recordarán esto, donde agrupo trayectorias usando k-medias a pelo.
El paquete kmlShape usa la distancia de Fréchet para hacer algo parecido: buscar trayectorias geométricamente similares.
El código es
library(kmlShape) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/tseries&amp;quot;&amp;gt;tseries) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/zoo&amp;quot;&amp;gt;zoo) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/XML&amp;quot;&amp;gt;XML) library(reshape) library(ggplot2) foo &amp;lt;- function( simbolo, final = &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.time&amp;quot;&amp;gt;Sys.time(), profundidad = 30 * 24 * 3600 ){ precios &amp;lt;- get.hist.quote(instrument= simbolo, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/start&amp;quot;&amp;gt;start = final - profundidad, end = final, quote=c(&amp;quot;AdjClose&amp;quot;), provider=&amp;quot;yahoo&amp;quot;, origin=&amp;quot;1970-01-01&amp;quot;, compression=&amp;quot;d&amp;quot;, retclass=&amp;quot;zoo&amp;quot;) colnames(precios) &amp;lt;- simbolo return(precios) } # lista de símbolos del ibex tmp &amp;lt;- readHTMLTable(&amp;quot;http://finance.</description>
    </item>
    
    <item>
      <title>¿Un libro recomendable de estadística básica?</title>
      <link>/2016/04/07/un-libro-recomendable-de-estadistica-basica/</link>
      <pubDate>Thu, 07 Apr 2016 09:13:36 +0000</pubDate>
      
      <guid>/2016/04/07/un-libro-recomendable-de-estadistica-basica/</guid>
      <description>Me piden bibliografía para unos cursos de ciencia de datos. En particular, de estadística básica. Un texto que reúna los conceptos fundamentales de la cosa para quienes o no los aprendieron en su día o los olvidaron por el camino. Tiene que cumplir algunos requisitos mínimos:
 * Que presente los gráficos estadísticos básicos y que no estén construidos con Excel (en 3D). * Que, a lo más, incluya un único gráfico de tarta.</description>
    </item>
    
    <item>
      <title>rPython &#43; feather</title>
      <link>/2016/04/06/rpython-feather/</link>
      <pubDate>Wed, 06 Apr 2016 09:13:28 +0000</pubDate>
      
      <guid>/2016/04/06/rpython-feather/</guid>
      <description>Supongo que a estas alturas todos conoceréis feather y rPython. Hoy los vais a ver trabajar juntos.
Primero solo en R:
library(feather) path &amp;lt;- &amp;quot;/tmp/my_data.feather&amp;quot; write_feather(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/cars&amp;quot;&amp;gt;cars, path) my_cars &amp;lt;- read_feather(path)  Ahora, para pasarle datos a Python:
library(rPython) python.exec(&amp;quot;import feather&amp;quot;) python.exec(&amp;quot;a = feather.read_dataframe(&#39;/tmp/my_data.feather&#39;)&amp;quot;) python.exec(&amp;quot;print a&amp;quot;)  Y, finalmente, para crear datos grandes en Python y devolvéselos a R:
python.exec(&amp;quot;import numpy as np&amp;quot;) python.exec(&amp;quot;import pandas as pd&amp;quot;) python.exec(&amp;quot;arr = np.random.randn(10000000)&amp;quot;) python.</description>
    </item>
    
    <item>
      <title>¿Nos vemos en el Machine Learning Spain XII?</title>
      <link>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</link>
      <pubDate>Tue, 05 Apr 2016 09:13:58 +0000</pubDate>
      
      <guid>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</guid>
      <description>Porque voy a dar una charla en él. Es este jueves, por la tarde, en el Campus de Google de Madrid (los detalles).
Se tratará de una introducción a y justificación de aproximaciones más bayesianas de lo habitual a problemas reales del análisis de datos. Que comenzará con una explicación sobre cuándo 100% no significa 100% para terminar con lo que viene siéndome habitual últimamente: un ejemplo en rstan con su discusión.</description>
    </item>
    
    <item>
      <title>Túneles ssh para conectarse de manera segura con RStudio Server</title>
      <link>/2016/04/04/tuneles-ssh-para-conectarse-de-manera-segura-con-rstudio-server/</link>
      <pubDate>Mon, 04 Apr 2016 09:13:39 +0000</pubDate>
      
      <guid>/2016/04/04/tuneles-ssh-para-conectarse-de-manera-segura-con-rstudio-server/</guid>
      <description>La solución que presenté el otro día para resolver el problema en cuestión, tal como indicó Iñaki Úcar, es demasiado aparatosa. La alternativa a mi propuesta
ssh -ND 2001 miusuario@datanalytics.com
y todo lo que sigue es crear un túnel ssh mediante
ssh -NL 2001:localhost:8787 miusuario@datanalytics.com
y conectarse a la sesión remota de RStudio apuntando en cualquier navegador a http://localhost:2001.
El comando anterior exige la debida exégesis, que nunca había tenido del todo clara.</description>
    </item>
    
    <item>
      <title>Redirección dinámica de puertos para conectarse de manera segura con RStudio Server</title>
      <link>/2016/04/01/redireccion-dinamica-de-puertos-para-conectarse-de-manera-segura-con-rstudio-server/</link>
      <pubDate>Fri, 01 Apr 2016 09:13:32 +0000</pubDate>
      
      <guid>/2016/04/01/redireccion-dinamica-de-puertos-para-conectarse-de-manera-segura-con-rstudio-server/</guid>
      <description>Finalmente, instalé RStudio Server en la máquina que está sirviéndote esta página. Pero no dejo abierto el puerto 8787 al exterior ni jarto de vino.
(De hecho, veréis que desde hace un tiempo a este blog escucha en el puerto 443 y, aunque esa es otra historia, utiliza HTTP/2).
Así que lo he configurado para que solo se pueda acceder a él desde localhost, i.e., que no admita conexiones remotas, añadiendo la línea</description>
    </item>
    
    <item>
      <title>Cartociudad</title>
      <link>/2016/03/31/cartociudad/</link>
      <pubDate>Thu, 31 Mar 2016 09:13:48 +0000</pubDate>
      
      <guid>/2016/03/31/cartociudad/</guid>
      <description>caRtociudad es esto.
Más noticias habrá.</description>
    </item>
    
    <item>
      <title>Caret y rejillas: ¿es necesario utilizar fuerza bruta?</title>
      <link>/2016/03/21/caret-y-rejillas-es-necesario-utilizar-fuerza-bruta/</link>
      <pubDate>Mon, 21 Mar 2016 09:13:25 +0000</pubDate>
      
      <guid>/2016/03/21/caret-y-rejillas-es-necesario-utilizar-fuerza-bruta/</guid>
      <description>Durante la charla de Carlos Ortega del pasado jueves sobre el paquete caret y sus concomitancias, se planteó el asunto de la optimización de los parámetros de un modelo usando rejillas (grids) de búsqueda.
Cuando un determinado algoritmo depende de, p.e., cuatro parámetros, se puede definir una rejilla como en
gbmGrid &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/expand.grid&amp;quot;&amp;gt;expand.grid(interaction.depth = c(1, 5, 9), n.trees = (1:30)*50, shrinkage = 0.1, n.minobsinnode = 20)  y caret se encarga de ajustar el modelo bajo todas esas combinaciones de parámetros (90 en el ejemplo) para ver cuál de ellas es, con las debidas salvedades, óptima.</description>
    </item>
    
    <item>
      <title>Modelos mixtos para preprocesar datos en un sistema de recomendación de drogas</title>
      <link>/2016/03/18/modelos-mixtos-para-preprocesar-de-datos-en-un-sistema-de-recomendacion-de-drogas/</link>
      <pubDate>Fri, 18 Mar 2016 09:13:34 +0000</pubDate>
      
      <guid>/2016/03/18/modelos-mixtos-para-preprocesar-de-datos-en-un-sistema-de-recomendacion-de-drogas/</guid>
      <description>Sí, de drogas de las que mantienen despierto al lumpenazgo. Porque he encontrado (aquí) un conjunto datos muy interesante sobre la valoración que una serie de personas, unas 900, da a una serie de drogas más o menos legales que se llaman —me acabo de enterar— nootrópicos.
El gráfico
extraído de la página enlazada más arriba resume parte de los resultados. No obstante, es sabido entre los que se dedican a los sistemas de recomendación que hay usuarios que tienden a valorar sistemáticamente por encima de la media y otros, por debajo.</description>
    </item>
    
    <item>
      <title>¿Se puede explicar la predicción de un modelo de caja negra?</title>
      <link>/2016/03/15/se-puede-explicar-la-prediccion-de-un-modelo-de-caja-negra/</link>
      <pubDate>Tue, 15 Mar 2016 09:13:51 +0000</pubDate>
      
      <guid>/2016/03/15/se-puede-explicar-la-prediccion-de-un-modelo-de-caja-negra/</guid>
      <description>Imaginemos un banco que construye modelos para determinar si se concede o no un crédito. Este banco tiene varias opciones para crear el modelo. Sin embargo, en algunos países el regulador exige que el banco pueda explicar el motivo de la denegación de un crédito cuando un cliente lo solicite.
Esa restricción impediría potencialmente usar modelos de caja negra como el que construyo a continuación:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/randomForest&amp;quot;&amp;gt;randomForest) raw &amp;lt;- read.table(&amp;quot;http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data&amp;quot;, sep = &amp;quot;,&amp;quot;, na.</description>
    </item>
    
    <item>
      <title>Sutilezas de las licencias libres</title>
      <link>/2016/03/07/sutilezas-de-las-licencias-libres/</link>
      <pubDate>Mon, 07 Mar 2016 09:13:12 +0000</pubDate>
      
      <guid>/2016/03/07/sutilezas-de-las-licencias-libres/</guid>
      <description>Leyendo por ahí, he encontrado un comentario sobre el paquete RJSONIO de R en el que se recomendaba no usarlo por no ser libre.
El paquete, aparentemente, está liberado bajo una licencia BSD. Pero su pecado es que dentro de uno de los ficheros que contiene, src/JSON_parser.c, dice
Más información, aquí.
No sé qué pensar sobre toda esta historia.</description>
    </item>
    
    <item>
      <title>¿Quieres presentar algo en las Jornadas de Usuarios de R?</title>
      <link>/2016/03/04/quieres-presentar-algo-en-las-jornadas-de-usuarios-de-r/</link>
      <pubDate>Fri, 04 Mar 2016 09:13:44 +0000</pubDate>
      
      <guid>/2016/03/04/quieres-presentar-algo-en-las-jornadas-de-usuarios-de-r/</guid>
      <description>En varias de las ediciones de las Jornadas de Usuarios de R he formado parte del comité organizador, que se encarga, fundamentalmente, de la logística de la cosa. Este año, para variar, estoy en el comité científico.
Como integrante del cual, es labor mía tratar de animaros a que enviéis alguna propuesta de participación, que puede tener alguno de los siguientes formatos:
 * Una presentación de unos 20 minutos, mostrando alguna aplicación de R.</description>
    </item>
    
    <item>
      <title>Mezclas de distribuciones con rstan</title>
      <link>/2016/03/03/mezclas-de-distribuciones-con-rstan/</link>
      <pubDate>Thu, 03 Mar 2016 09:13:13 +0000</pubDate>
      
      <guid>/2016/03/03/mezclas-de-distribuciones-con-rstan/</guid>
      <description>y &amp;lt;- c(rnorm(1000), rnorm(2000, 1, 0.5))
es una mezcla de dos normales (N(0, 1) y N(1, 0.5)) con pesos 1/3 y 2/3 respectivamente. Pero, ¿cómo podríamos estimar los parámetros a partir de esos datos?
Se puede usar, p.e., flexmix, que implementa eso del EM. Pero en el librillo de este maestrillo dice
library(rstan) y &amp;lt;- c(rnorm(1000), rnorm(2000, 1, 0.5)) codigo &amp;lt;- &amp;quot; data { int&amp;lt;lower=1&amp;gt; K; // number of mixture components int&amp;lt;lower=1&amp;gt; N; // number of data points real y[N]; // observations } parameters { simplex[K] theta; // mixing proportions real mu[K]; // locations of mixture components real&amp;lt;lower=0&amp;gt; sigma[K]; // scales of mixture components } model { real ps[K]; // temp for log component densities sigma ~ cauchy(0,2.</description>
    </item>
    
    <item>
      <title>Pequeño bug en ggmap: no pinta el último tramo de una ruta</title>
      <link>/2016/03/02/pequeno-bug-en-ggmap-no-pinta-el-ultimo-tramo-de-una-ruta/</link>
      <pubDate>Wed, 02 Mar 2016 09:13:04 +0000</pubDate>
      
      <guid>/2016/03/02/pequeno-bug-en-ggmap-no-pinta-el-ultimo-tramo-de-una-ruta/</guid>
      <description>Supongo que no debería escribirlo aquí sino comunicárselo a quien mantiene ggmap. Pero ya tuve una experiencia mejorable con él y dos no serán. Así que lo cuento por acá.
La mayor parte del mérito en el descubrimiento, en cualquier caso, es de una alumna de la clase de R que he dado hoy (en el momento en el que escribo, no en el que lees) en el Banco de Santander.</description>
    </item>
    
    <item>
      <title>Ficheros KML con R y ggmap</title>
      <link>/2016/03/01/ficheros-kml-con-r-y-ggmap/</link>
      <pubDate>Tue, 01 Mar 2016 09:13:25 +0000</pubDate>
      
      <guid>/2016/03/01/ficheros-kml-con-r-y-ggmap/</guid>
      <description>Fácil:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/maptools&amp;quot;&amp;gt;maptools) library(ggmap) # un fichero bajado el Ayto. de Madrid # (catálogo de datos abiertos) rutas &amp;lt;- getKMLcoordinates(&amp;quot;dat/130111_vias_ciclistas.kml&amp;quot;) # procesando el fichero kml rutas &amp;lt;- lapply(1:length(rutas), function(x) data.frame(rutas[[x]], id = x)) rutas &amp;lt;- do.call(rbind, rutas) # mapa de Madrid mapa &amp;lt;- get_map(&amp;quot;Madrid&amp;quot;, source = &amp;quot;stamen&amp;quot;, maptype = &amp;quot;toner&amp;quot;, zoom = 12) # pintando los tramos sobre el mapa ggmap(mapa) + geom_path(aes(x = X1, y = X2, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/grDevices/group&amp;quot;&amp;gt;group = id), data = rutas, colour = &amp;quot;red&amp;quot;)  produce</description>
    </item>
    
    <item>
      <title>Las VIII Jornadas de Usuarios de R, en Albacete</title>
      <link>/2016/02/25/las-viii-jornadas-de-usuarios-de-r-en-albacete/</link>
      <pubDate>Thu, 25 Feb 2016 07:13:12 +0000</pubDate>
      
      <guid>/2016/02/25/las-viii-jornadas-de-usuarios-de-r-en-albacete/</guid>
      <description>Por si alguien aún no lo sabe: estamos todos citados en Albacete los días 17 y 18 de noviembre de 2016 en las VIII Jornadas de Usuarios de R.
Los detalles, aquí.</description>
    </item>
    
    <item>
      <title>Validación cruzada en R</title>
      <link>/2016/02/23/validacion-cruzada-en-r/</link>
      <pubDate>Tue, 23 Feb 2016 09:13:34 +0000</pubDate>
      
      <guid>/2016/02/23/validacion-cruzada-en-r/</guid>
      <description>Está de moda usar caret para estas cosas, pero yo estoy todavía acostumbrado a hacerlas a mano. Creo, además, que es poco instructivo ocultar estas cuestiones detrás de funciones de tipo caja-negra-maravillosa a quienes se inician en el mundo de la construcción y comparación de modelos. Muestro, por tanto, código bastante simple para la validación cruzada de un modelo con R:
# genero ids ids &amp;lt;- rep(1:10, length.out = nrow(&amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Hoy se ha anunciado la propuesta de nueva página de la Comunidad R Hispano</title>
      <link>/2016/02/18/hoy-se-ha-anunciado-la-propuesta-de-nueva-pagina-de-la-comunidad-r-hispano/</link>
      <pubDate>Thu, 18 Feb 2016 09:13:08 +0000</pubDate>
      
      <guid>/2016/02/18/hoy-se-ha-anunciado-la-propuesta-de-nueva-pagina-de-la-comunidad-r-hispano/</guid>
      <description>Acabo de escribir a los socios de la Comunidad R Hispano acerca de la existencia de una propuesta para renovar la página de la asociación. Podéis ver la versión actual y la propuesta.
(Y agradezco muchísimo el trabajo de Paula López Casado, responsable de que la nueva página tenga un aspecto infinitamente más atractivo que la que lees).
(Además, esta entrada incluye el que será el nuevo logo de la Comunidad R Hispano).</description>
    </item>
    
    <item>
      <title>Diapositivas (y código fuente) de mi charla sobre rstan</title>
      <link>/2016/02/12/diapositivas-y-codigo-fuente-de-mi-charla-sobre-rstan/</link>
      <pubDate>Fri, 12 Feb 2016 09:13:23 +0000</pubDate>
      
      <guid>/2016/02/12/diapositivas-y-codigo-fuente-de-mi-charla-sobre-rstan/</guid>
      <description>Las diapositivas de mi charla sobre rstan en el grupo de usuarios de R de Madrid del 2016-02-11 están aquí.
(Y los vídeos).</description>
    </item>
    
    <item>
      <title>storr: como Redis, pero con R</title>
      <link>/2016/02/09/storr-como-redis-pero-con-r/</link>
      <pubDate>Tue, 09 Feb 2016 09:13:43 +0000</pubDate>
      
      <guid>/2016/02/09/storr-como-redis-pero-con-r/</guid>
      <description>Probablemente no habéis utilizado nunca Redis. Redis es un sistema de almacenamiento basado en parejas clave-valor. Es similar a un diccionario de Python o a un entorno en R. Salvo que el almacenamiento es externo al proceso: los datos se guardan en un sistema distribuido y potencialmente ilimitado en cuanto a capacidad.
Si queréis probar algo parecido, además de los diccionarios y los entornos, podéis probar con storr , un paquete reciente de R.</description>
    </item>
    
    <item>
      <title>Premoniciones de Tirole sobre sobre el R Consortium</title>
      <link>/2016/02/01/premoniciones-de-tirole-sobre-sobre-el-r-consortium/</link>
      <pubDate>Mon, 01 Feb 2016 09:13:28 +0000</pubDate>
      
      <guid>/2016/02/01/premoniciones-de-tirole-sobre-sobre-el-r-consortium/</guid>
      <description>A J. Tirole tiene Nobel de economía. En 2002 escribió un artículo, Some Simple Economics of Open Source, en el que trataba de explicar desde un punto de vista económico y de organización industrial el porqué de esa rareza. Aparte de cuestiones como si sería extrapolable a otros sectores distintos del del desarrollo de software.
En la sección sobre la reacción de las compañías de software frente al fenómeno del software libre tiene un apartado titulado viviendo simbióticamente de [no con] un proyecto de código abierto que termina con la frase (mi traducción):</description>
    </item>
    
    <item>
      <title>Comparaciones de tres grupos: pruebas vs modelos</title>
      <link>/2016/01/25/comparaciones-de-tres-grupos-pruebas-vs-modelos/</link>
      <pubDate>Mon, 25 Jan 2016 09:13:59 +0000</pubDate>
      
      <guid>/2016/01/25/comparaciones-de-tres-grupos-pruebas-vs-modelos/</guid>
      <description>Una pregunta reciente en r-help-es se refería a la comparación en R de las proporciones en tres grupos. Obviando algunas pequeñas complicaciones en el problema, la respuesta canónica podría ser esta:
total &amp;lt;- c(56, 49,51) positivos &amp;lt;- c(14, 10, 17) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/prop.test&amp;quot;&amp;gt;prop.test(tmp$positivos, tmp$positivos + tmp$negativos) # 3-sample test for equality of proportions without continuity correction # # data: tmp$positivos out of tmp$positivos + tmp$negativos # X-squared = 2.2289, df = 2, p-value = 0.</description>
    </item>
    
    <item>
      <title>Análisis estadístico de respuestas ocultas en encuestas</title>
      <link>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</link>
      <pubDate>Fri, 22 Jan 2016 08:13:24 +0000</pubDate>
      
      <guid>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</guid>
      <description>A veces se hacen encuestas sobre temas sobre los que los encuestados son reticentes a revelar la verdad (p.e., ¿es Vd. un zombi?). Un procedimiento conocido para recabar tal tipo de información es el siguiente:
 * Se le invita al encuestado a tirar al aire una _moneda_ con las caras etiquetadas con _sí_ y _no_; la _moneda_ no es una moneda porque tiene una probabidad conocida (y distinta del 50%) de caer en _sí_.</description>
    </item>
    
    <item>
      <title>Por si os interesa el tema de la energía, las centrales, las emisiones, etc.</title>
      <link>/2016/01/20/por-si-os-interesa-el-tema-de-la-energia-las-centrales-las-emisiones-etc/</link>
      <pubDate>Wed, 20 Jan 2016 08:13:51 +0000</pubDate>
      
      <guid>/2016/01/20/por-si-os-interesa-el-tema-de-la-energia-las-centrales-las-emisiones-etc/</guid>
      <description>Esta entrada será del interés de a quien le atraigan dos temas bastante independientes entre sí:
 * La energía, las centrales eléctricas, sus emisiones, etc. * [SPARQL](https://en.wikipedia.org/wiki/SPARQL)  Allá va el código
library(SPARQL) library(ggplot2) queryString = &amp;quot;PREFIX a: &amp;lt;http://enipedia.tudelft.nl/wiki/&amp;gt; PREFIX prop: &amp;lt;http://enipedia.tudelft.nl/wiki/Property:&amp;gt; PREFIX rdfs: &amp;lt;http://www.w3.org/2000/01/rdf-schema#&amp;gt; select ?plant ?name ?elec_capacity_MW ?lat ?lon ?operator where { ?plant prop:Country a:Spain . #get the name #?plant rdfs:label ?name . ?plant prop:Generation_capacity_electrical_MW ?elec_capacity_MW . #?</description>
    </item>
    
    <item>
      <title>¿En qué año era la el almacenamiento en disco tan caro como hoy en memoria?</title>
      <link>/2016/01/13/en-que-ano-era-la-el-almacenamiento-en-disco-tan-caro-como-hoy-en-memoria/</link>
      <pubDate>Wed, 13 Jan 2016 08:13:07 +0000</pubDate>
      
      <guid>/2016/01/13/en-que-ano-era-la-el-almacenamiento-en-disco-tan-caro-como-hoy-en-memoria/</guid>
      <description>La respuesta a sea pregunta, y siempre de acuerdo con los datos de John C. McCallum la da

que hace corresponder a cada año del eje horizontal el correspondiente (en el vertical) aquel en el que el almacenamiento en disco venía a costar lo mismo (euros por MB) que el memoria en el primero.
Hoy vamos casi por 2000.
Me llama la atención que el crecimiento se esté ralentizando.</description>
    </item>
    
    <item>
      <title>Un poco más sobre el índice de poder de Banzhaf</title>
      <link>/2015/12/23/un-poco-mas-sobre-el-indice-de-poder-de-banzhaf/</link>
      <pubDate>Wed, 23 Dec 2015 08:13:51 +0000</pubDate>
      
      <guid>/2015/12/23/un-poco-mas-sobre-el-indice-de-poder-de-banzhaf/</guid>
      <description>En el año 2012 escribí esto, que incluye
Ni idea de dónde saqué eso. Ni siquiera descarto que fuese una malinterpretación de algo donde se decía otra cosa. De hecho, en el enlace que acompaña al párrafo, efectivamente, dice otra cosa.
Merecido es que reimplemente la función teniendo encuenta la que parece ser la verdadera definición del índice. Es la siguiente:
banzhaf &amp;lt;- function(x, mayoria = sum(x) / 2){ tmp &amp;lt;- rep(list(c(TRUE, FALSE)), length(x)) tmp &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Coaliciones de Banzhaf en el 20D</title>
      <link>/2015/12/22/coaliciones-de-banzhaf-en-el-20d/</link>
      <pubDate>Tue, 22 Dec 2015 08:13:22 +0000</pubDate>
      
      <guid>/2015/12/22/coaliciones-de-banzhaf-en-el-20d/</guid>
      <description>Usando código de una entrada anterior voy a medir el poder de cada partido político de acuerdo con Banzhaf tras las elecciones de diciembre de 2015.
escannos &amp;lt;- c(123, 90, 69, 40, 9, 8, 6, 2, 2, 1) names(escannos) &amp;lt;- c( &amp;quot;pp&amp;quot;, &amp;quot;psoe&amp;quot;, &amp;quot;pod&amp;quot;, &amp;quot;c&#39;s&amp;quot;, &amp;quot;erc&amp;quot;, &amp;quot;dl&amp;quot;, &amp;quot;pnv&amp;quot;, &amp;quot;iu&amp;quot;, &amp;quot;bildu&amp;quot;, &amp;quot;cc&amp;quot;) banzhaf(escannos)  da 14 coaliciones mínimas, pp psoe pp pod pp c&#39;s erc dl pp c&#39;s erc pnv pp c&#39;s erc iu bildu pp c&#39;s dl pnv pp c&#39;s dl iu bildu cc psoe pod c&#39;s psoe pod erc dl psoe pod erc pnv iu psoe pod erc pnv bildu psoe pod dl pnv iu bildu psoe pod dl pnv iu cc psoe pod dl pnv bildu cc y un reparto de poder que queda de esta manera: psoe pod pp pnv dl erc c&#39;s iu bildu cc 57.</description>
    </item>
    
    <item>
      <title>CRAN, r-devel, GitHub, Travis CI, pruebas automáticas y todo eso</title>
      <link>/2015/12/17/cran-r-devel-github-travis-ci-pruebas-automaticas-y-todo-eso/</link>
      <pubDate>Thu, 17 Dec 2015 08:13:13 +0000</pubDate>
      
      <guid>/2015/12/17/cran-r-devel-github-travis-ci-pruebas-automaticas-y-todo-eso/</guid>
      <description>Estoy harto. La gente de CRAN me devolvió (con errores) un paquete que trataba de subir. Había hecho el prescriptivo
R CMD check --as-cran etc.
y el log era una patena. Pero había un par de NOTES al pasar el test sobre la versión de desarrollo de R, r-devel. No solo hay que probar los paquetes en la versión que hay sino también en la que vendrá (tal y como está docuentado).</description>
    </item>
    
    <item>
      <title>Pasando data.frames de R como tablas de pandas en Python usando rPython</title>
      <link>/2015/12/11/pasando-data-frames-de-r-como-tablas-de-pandas-en-python-usando-rpython/</link>
      <pubDate>Fri, 11 Dec 2015 08:13:41 +0000</pubDate>
      
      <guid>/2015/12/11/pasando-data-frames-de-r-como-tablas-de-pandas-en-python-usando-rpython/</guid>
      <description>Un usuario de rPython, David González Knowles, me ha facilitado su código para pasar una tabla, iris en este caso, de R a una tabla de pandas en Python usando mi paquete.
En R hay tablas de serie. En Python no. La librería pandas de Python implementa algo parecido a los data.frames. Solo que nada garantiza que un usuario de Python la tenga instalada. Por eso no hay un formato de destino claro y universal para las tablas de R a través de rPython.</description>
    </item>
    
    <item>
      <title>Una revisita a &#34;¿Cuántos peces hay en un lago?&#34;</title>
      <link>/2015/12/10/una-revisita-a-cuantos-peces-hay-en-un-lago/</link>
      <pubDate>Thu, 10 Dec 2015 08:13:09 +0000</pubDate>
      
      <guid>/2015/12/10/una-revisita-a-cuantos-peces-hay-en-un-lago/</guid>
      <description>Hace ya dos años escribí ¿Cuántos peces hay en un lago? La rescato ahora que se ha publicado el paquete multimark de R, que permite realizar los mismos análisis básicos que hice entonces más muchos otros más sofisticados para resolver variantes del problema.</description>
    </item>
    
    <item>
      <title>Cambio de logo en la Comunidad R Hispano</title>
      <link>/2015/12/02/cambio-de-logo-en-la-comunidad-r-hispano/</link>
      <pubDate>Wed, 02 Dec 2015 08:13:27 +0000</pubDate>
      
      <guid>/2015/12/02/cambio-de-logo-en-la-comunidad-r-hispano/</guid>
      <description>Hace años, al comienzo de los tiempos de la Comunidad R Hispano, se propusieron ciertos logos y se votó el actual,

que tiene su gracia pero, también, dos inconvenientes graves:
 * Está diseñado para ser utilizado sobre fondo oscuro. Pero un logo tiene que quedar bien sobre fondo blanco (papel, cartelería, etc.). * El autor solo proporcionó un par de imágenes (no vectoriales, por supuesto) del logo antes de desaparecer (no, no falleció: vive feliz en otro país y dejó de usar R).</description>
    </item>
    
    <item>
      <title>Mi otra debilidad: procesos de Poisson &#34;autoexcitados&#34;</title>
      <link>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</link>
      <pubDate>Thu, 19 Nov 2015 08:13:18 +0000</pubDate>
      
      <guid>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</guid>
      <description>La primera es la factorización positiva de matrices positivas. La otra, como bien titula la entrada, los procesos de Poisson autoexcitados.
Por eso no podía dejar de traer a la atención de mis lectores seismic. Aunque lo de Twitter ya huela.</description>
    </item>
    
    <item>
      <title>agate: análisis de datos optimizado para humanos (y no para máquinas)</title>
      <link>/2015/11/17/agate-analisis-de-datos-optimizado-para-humanos-y-no-para-maquinas/</link>
      <pubDate>Tue, 17 Nov 2015 08:13:11 +0000</pubDate>
      
      <guid>/2015/11/17/agate-analisis-de-datos-optimizado-para-humanos-y-no-para-maquinas/</guid>
      <description>Una de las cosas que menos me canso de repetir es que R no es (solo) un lenguaje de programación. R es un entorno para el análisis de datos. Los informáticos se horrorizan con él: no entienden por qué es como es. Pero, fundamentalmente, su problema es que no conciben que pueda haber sido diseñado para el REPL y no (solamente) para crear programas.
Casi todo el tiempo que paso con R abierto lo consumo trabajando interactivamente, no programando.</description>
    </item>
    
    <item>
      <title>Lo poco y lo mucho; lo malo, lo regular y lo bueno</title>
      <link>/2015/11/16/lo-poco-y-lo-mucho-lo-malo-lo-regular-y-lo-bueno/</link>
      <pubDate>Mon, 16 Nov 2015 08:13:53 +0000</pubDate>
      
      <guid>/2015/11/16/lo-poco-y-lo-mucho-lo-malo-lo-regular-y-lo-bueno/</guid>
      <description>Estos días pasados ha habido un hilo en la lista de correo de ayuda de R en español (¿todavía no te has dado de alta en ella?) en la que alguien preguntaba cómo crear paquetes y dónde encontrar documentación al respecto.
La buena intención de quienes han tratado de ayudarle, me temo, ha sido contraproducente. Lo han empapelado con una lista (casi con aspiraciones de exhaustividad) de recursos y más recursos en los que se indica cómo resolver el problema.</description>
    </item>
    
    <item>
      <title>GAM</title>
      <link>/2015/11/13/gam/</link>
      <pubDate>Fri, 13 Nov 2015 08:13:53 +0000</pubDate>
      
      <guid>/2015/11/13/gam/</guid>
      <description>Hoy he dado una charla en la Carlos III. En la comida me han preguntado, algo extrañados, por un ejemplo que había enseñado en el que ajustaba un modelo usando GAMs.
El motivo era que quienes preguntaban —que trabajan con ese tipo de modelos— encuentran muy difícil, se ve, convencer a otros usuarios de los métodos estadísticos (economistas, etc.) de adoptarlos. Yo he contestado que hace unos pocos días a unos primíparos que acababan de ajustar sus tres primeros lms con R les invité a probar GAMs con sus datos.</description>
    </item>
    
    <item>
      <title>Asignación en R: ¿flecha o lo innombrable?</title>
      <link>/2015/11/10/asignacion-en-r-flecha-o-lo-innombrable/</link>
      <pubDate>Tue, 10 Nov 2015 08:13:55 +0000</pubDate>
      
      <guid>/2015/11/10/asignacion-en-r-flecha-o-lo-innombrable/</guid>
      <description>Alguien que no quiero nombrar (pero que sabe de sobra quién es) me comentaba el otro día algo que no sabía de la asignación en R: las presuntas diferencias entre &amp;lt;- e =. Que en resumen eran:
 * ambos asignan * pero `=` hace una copia del objeto asignado * mientras que `&amp;lt;-` no.  Como consecuencia, &amp;lt;- es más eficiente desde el punto de vista de la gestión de la memoria.</description>
    </item>
    
    <item>
      <title>El g-test para tablas de contingencia</title>
      <link>/2015/11/02/el-g-test-para-tablas-de-contingencia/</link>
      <pubDate>Mon, 02 Nov 2015 08:13:26 +0000</pubDate>
      
      <guid>/2015/11/02/el-g-test-para-tablas-de-contingencia/</guid>
      <description>Hace unos días recibí una consulta de una vieja amiga lingüista. Ella trabaja en algo que creo que se llama cocolocación: el estudio de palabras que aparecen o que tiendan a aparecer juntas en textos. Digamos que es algo así como una correlación o una regla de asociación.
Los lingüistas están muy interesados en ese tipo de fenómenos. Tradicionalmente (cada gremio tiene su librillo) usan la información mutua. Pero, al final, lo que tienen es una tabla de contingencia: situaciones en que aparece una, la otra, ambas o ninguna de las palabras.</description>
    </item>
    
    <item>
      <title>Madrid decide, propone, vota, etc.</title>
      <link>/2015/10/09/madrid-decide-propone-vota-etc/</link>
      <pubDate>Fri, 09 Oct 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/10/09/madrid-decide-propone-vota-etc/</guid>
      <description>De siempre, no sé por qué motivo, me interesaron esas cosas relacionadas con la democracia directa. En la feria del libro del año nosecuántos compré un libro al respecto (que presté y no me han devuelto). He seguido de cerca del desarrollo de plataformas como Agora y conozco a alguno de sus desarrolladores. Di guerrita en Suiza a los locales para que me explicasen pros, contras y funcionamientos de lo que allí tienen instalado.</description>
    </item>
    
    <item>
      <title>Programa Profesional de Iniciación a R II</title>
      <link>/2015/10/05/programa-profesional-de-iniciacion-a-r-ii/</link>
      <pubDate>Mon, 05 Oct 2015 08:13:46 +0000</pubDate>
      
      <guid>/2015/10/05/programa-profesional-de-iniciacion-a-r-ii/</guid>
      <description>Del 10 de noviembre al 17 de diciembre impartiré la segunda edición de mi Programa Profesional de Iniciación a R. Los detalles pueden consultarse en el enlace anterior.
Es la segunda edición. De la primera hablé aquí.
El programa es esencialmente el mismo: presentar y trabajar con aquellas herramientas que hacen de R una herramienta útil dentro de BBVA, Santander, Mapfre, etc. Para trascender Excel y, entre otros,
 * manipular datos como un _pro_, * crear gráficos estadísticos complejos de calidad, * crear informes automáticos que combinan análisis de datos, gráficos, texto, etc.</description>
    </item>
    
    <item>
      <title>purrr: otro dialecto para la programación funcional en R</title>
      <link>/2015/10/02/purrr-otro-dialecto-para-la-programacion-funcional-en-r/</link>
      <pubDate>Fri, 02 Oct 2015 08:13:54 +0000</pubDate>
      
      <guid>/2015/10/02/purrr-otro-dialecto-para-la-programacion-funcional-en-r/</guid>
      <description>Acaba de publicarse purrr. Es un paquete del universo Wickham que ofrece funciones para desarrollar otro dialecto funcional sobre R.
R es un lenguaje oportunista: ni del todo funcional, ni del todo orientado a objetos, ni del todo procedural. Es como es porque nació con un objetivo muy concreto y fue adoptando cosas de aquí y de allá como cuando uno recorre el supermercado. Merece la pena traer a colación cómo el primerísimo R (cuando era S), durante los ochenta, antes de adoptar la forma actual a través de los diversos libros de colores de Chambers y compañía, estaba fuertemente inspirado por Lisp.</description>
    </item>
    
    <item>
      <title>Anunciado el programa de las VII Jornadas de Usuarios de R</title>
      <link>/2015/09/28/anunciado-el-programa-de-las-vii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 28 Sep 2015 08:13:03 +0000</pubDate>
      
      <guid>/2015/09/28/anunciado-el-programa-de-las-vii-jornadas-de-usuarios-de-r/</guid>
      <description>Se acercan las VII Jornadas de Usuarios de R. Y se acaba de actualizar la página con la siguiente información:
 * El programa, en el que, además de charlas, hay varios talleres muy atractivos. * La cena social (para la que es bueno que reserves: ¡necesitamos una buena estimación de cuántos acabaremos siendo!) * El anuncio de una visita guiada gratuita a la ciudad de Salamanca. * Como novedad con respecto a otras jornadas, el anuncio de una excursión durante el sábado a la [sierra de Francia](https://es.</description>
    </item>
    
    <item>
      <title>Un problema &#34;sencillo&#34;: posiciones y ruido</title>
      <link>/2015/09/18/un-problema-sencillo-posiciones-y-ruido/</link>
      <pubDate>Fri, 18 Sep 2015 08:13:23 +0000</pubDate>
      
      <guid>/2015/09/18/un-problema-sencillo-posiciones-y-ruido/</guid>
      <description>Voy a describir la solución un problema sencillo. Se trata de un objeto que se mueve a una velocidad no necesariamente constante en línea recta. Este objeto emite su posición y velocidad periódicamente (p.e., cada segundo). Por centrar ideas, su posición y velocidad reales en esos momentos es
n &amp;lt;- 100 v.real &amp;lt;- rnorm(n, 1, 0.2) x.real &amp;lt;- cumsum(v.real)  (Perdóneseme lo gañán de la física que aplico para calcular las posiciones: prometo que se puede y que sé hacerlo mejor; pero para el presente caso, vale).</description>
    </item>
    
    <item>
      <title>NMF: una técnica mergente de análisis no supervisado</title>
      <link>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</link>
      <pubDate>Mon, 14 Sep 2015 08:13:50 +0000</pubDate>
      
      <guid>/2015/09/14/nmf-una-tecnica-mergente-de-analisis-no-supervisado/</guid>
      <description>[N]NMF (se encuentra con una o dos enes) es una técnica de análisis no supervisado emergente. Se cuenta entre mis favoritas.
[N]NMF significa non negative matrix factorization y, como SVD, descompone una matriz M como UDV&#39;. Solo que, en este caso, las entradas de M son todas positivas. Y la descomposición es UV&#39;, donde las entradas de ambas matrices son también positivas.
¿Qué tipo de matrices tienen entradas estrictamente positivas?</description>
    </item>
    
    <item>
      <title>Cosas de R (¿que tal vez alguien sabrá explicar?)</title>
      <link>/2015/09/09/cosas-de-r-que-tal-vez-alguien-sabra-explicar/</link>
      <pubDate>Wed, 09 Sep 2015 08:13:14 +0000</pubDate>
      
      <guid>/2015/09/09/cosas-de-r-que-tal-vez-alguien-sabra-explicar/</guid>
      <description>En Twitter, leo
 sum(c(1, 2), na.r=F) [1] 3 sum(c(1, 2), na.r=T) [1] 4
&amp;ndash; John Myles White (@johnmyleswhite) September 8, 2015 ¿Alguien puede explicar lo que ocurre? ¿Es tan grade como parece indicar sorna el autor del tuit?</description>
    </item>
    
    <item>
      <title>Voronois con distintas distancias</title>
      <link>/2015/09/08/voronois-con-distintas-distancias/</link>
      <pubDate>Tue, 08 Sep 2015 08:13:57 +0000</pubDate>
      
      <guid>/2015/09/08/voronois-con-distintas-distancias/</guid>
      <description>Especulando sobre la diferencia en la práctica entre distintas métricas ($latex l_1$, $latex l_2$, $latex l_\infty$, etc.), construi una serie de diagramas de Voronoi usado métricas arbitrarias.
En la Wikipedia se comparan gráficamente $latex l_1$, $latex l_2$ (o euclídea y Manhattan). Mi código,
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/data.table&amp;quot;&amp;gt;data.table) library(reshape2) library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/graphics/grid&amp;quot;&amp;gt;grid) n &amp;lt;- 20 dim.image &amp;lt;- 1000 puntos &amp;lt;- data.frame(id = 1:n, x0 = runif(n) * dim.image, y0 = runif(n) * dim.image) colores &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Guías de estilo para programar en R</title>
      <link>/2015/09/04/guias-de-estilo-para-programar-en-r/</link>
      <pubDate>Fri, 04 Sep 2015 08:13:38 +0000</pubDate>
      
      <guid>/2015/09/04/guias-de-estilo-para-programar-en-r/</guid>
      <description>Frans van Dunné me ha hecho llegar su guía de estilo de programación en R. Abunda en otra creada por Google hace un tiempo y que traduje y adapté aquí.
Tiene como novedad, dice, su adaptación a las formas y maneras de Hadley Wickham, aún no tan conocido entonces. Coinciden, no obstante, en lo más.
Ninguna de las dos trata el uso las tuberías (operador %&amp;gt;%). Pero es un asunto que se nos puede ir de las manos: de hecho, hoy he conocido el paquete [backpipe](https://github.</description>
    </item>
    
    <item>
      <title>Estar en racha (y promediar promedios)</title>
      <link>/2015/08/10/estar-en-racha-y-promediar-promedios/</link>
      <pubDate>Mon, 10 Aug 2015 08:13:27 +0000</pubDate>
      
      <guid>/2015/08/10/estar-en-racha-y-promediar-promedios/</guid>
      <description>Suponemos que observamos rachas de longitud 2 + rpois(1, 10) de un juego en el que se tiene éxito (1) o se fracasa (0) con probabilidad 1/2. Nos interesa saber si existe eso de las rachas de suerte, es decir, si es más probable que a un éxito le suceda otro o lo contrario.
El observador ve rachas y calcula el número de veces que a un éxito le sigue un éxito y el número de veces que a un éxito le sigue un fracaso así:</description>
    </item>
    
    <item>
      <title>Ajuste de probabilidades en regresiones logísticas bajo sobremuestreo ( y otros)</title>
      <link>/2015/08/03/ajuste-de-probabilidades-en-regresiones-logisticas-bajo-sobremuestreo-y-otros/</link>
      <pubDate>Mon, 03 Aug 2015 08:13:17 +0000</pubDate>
      
      <guid>/2015/08/03/ajuste-de-probabilidades-en-regresiones-logisticas-bajo-sobremuestreo-y-otros/</guid>
      <description>En ocasiones el conjunto de datos sobre el que se ajusta una regresión logística está desequilibrado con respecto a la población subyacente. Por ejemplo, puede suceder que la tasa de casos positivos en los datos sea del 20% mientras que en la población general es del 5%.
Esto puede suceder por varios motivos. El sobremuestreo uno de ellos: se sobremuestrea cuando se toman, por ejemplo, todos los casos positivos y solo un subconjunto de los negativos.</description>
    </item>
    
    <item>
      <title>Estrategias escalables con R</title>
      <link>/2015/07/22/estrategias-escalables-con-r-2/</link>
      <pubDate>Wed, 22 Jul 2015 08:13:34 +0000</pubDate>
      
      <guid>/2015/07/22/estrategias-escalables-con-r-2/</guid>
      <description>Recomiendo leer Scalable Strategies for Computing with Massive Data, un artículo que trata dos de los problemas de escalabilidad con que tropezamos los usuarios de R:
 * Los de memoria, para los que proponen e ilustran el uso del paquete [`bigmemory`](https://cran.r-project.org/web/packages/bigmemory/index.html). * Los de velocidad de ejecución, a los que se enfrentan paralelizando el código, tanto en una única máquina como en un clúster, con [`foreach`](https://cran.r-project.org/web/packages/foreach/index.html).  En el artículo no solo discute los dos paquetes por separado sino que ilustra, además, cómo usarlos conjuntamente en su propuesta de estrategia escalable con R.</description>
    </item>
    
    <item>
      <title>Un modelo jerárquico para lo de Casillas</title>
      <link>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</link>
      <pubDate>Wed, 15 Jul 2015 08:13:42 +0000</pubDate>
      
      <guid>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</guid>
      <description>Vuelvo a lo de Casillas inspirándome en el primer ejemplo de este artículo de Gelman et al.
El planteamiento es el siguiente: el número de paradas, $latex n_i$ que realiza el $latex i$-ésimo portero tiene una distribución binomial
$latex n_i \sim B(N_i, p_i)$
donde $latex N_i$ es el número de disparos entre los palos y $latex p_i$ es la habilidad innata del portero. Estas habilidades innatas siguen una distribución dada, la de habilidades innatas de los porteros de primera división, que podemos suponer que sigue una distribución beta</description>
    </item>
    
    <item>
      <title>Efectos en regresiones logísticas</title>
      <link>/2015/07/14/efectos-en-regresiones-logisticas/</link>
      <pubDate>Tue, 14 Jul 2015 08:13:54 +0000</pubDate>
      
      <guid>/2015/07/14/efectos-en-regresiones-logisticas/</guid>
      <description>Rescato y reconvierto un comentario de mi buen amigo José Luis Cañadas en una entrada mía reciente en la de hoy.
Sugiere José Luis el uso del paquete effects de R para estudiar el efecto de (que el caso concreto de interés, aunque hay otros) las variables de un modelo logístico.
Nos copia el código
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/effects&amp;quot;&amp;gt;effects) mod.cowles &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/glm&amp;quot;&amp;gt;glm(volunteer ~ sex + neuroticism*extraversion, data = Cowles, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/family&amp;quot;&amp;gt;family = &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>¿Son normales las alturas (de los individuos)?</title>
      <link>/2015/07/09/son-normales-las-alturas-de-los-individuos/</link>
      <pubDate>Thu, 09 Jul 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/07/09/son-normales-las-alturas-de-los-individuos/</guid>
      <description>Diríase que sí. La altura de un individuo está sujeta a multitud de factores que suman y restan. Está la genética (que es el resultado de la suma y resta del impacto de muchos genes individuales). Está la dieta, está&amp;hellip; Diríase, insisto, que la altura es el promedio de muchos efectos pequeños y no demasiado dependientes entre ellos.
Y en efecto, (una vez descargados los microdatos de la Encuesta Nacional de Salud de 2011),</description>
    </item>
    
    <item>
      <title>Una interpretación (rápida y sucia) de los coeficientes de la regresión logística</title>
      <link>/2015/07/06/una-interpretacion-rapida-y-sucia-de-los-coeficientes-de-la-regresion-logistica/</link>
      <pubDate>Mon, 06 Jul 2015 08:13:15 +0000</pubDate>
      
      <guid>/2015/07/06/una-interpretacion-rapida-y-sucia-de-los-coeficientes-de-la-regresion-logistica/</guid>
      <description>Los coeficientes de la regresión logística tienen una interpretación recta en términos de odds ratio. Que es un concepto sobre el que puede que alguien tenga algún tipo de intuición. Pero yo no.
¿Cómo podemos interpretar, aunque sea de manera rápida y grosera, los coeficientes? En términos de la variación de la probabilidad cuando la variable correspondiente cambia de valor (p.e., en una unidad). El problema es que la probabilidad depende del valor del resto de las variables: la relación no es lineal.</description>
    </item>
    
    <item>
      <title>R Consortium</title>
      <link>/2015/07/03/r-consortium/</link>
      <pubDate>Fri, 03 Jul 2015 10:40:34 +0000</pubDate>
      
      <guid>/2015/07/03/r-consortium/</guid>
      <description>Acaba de nacer el R Consortium con no sé qué objetivos. Los declarados son
Vamos, nada que la R Foundation no viniese haciendo ya de oficio.
Solo que es probable que lo quieran hacer de otra manera. R se está volviendo demasiado importante, pensarán, como para que su desarrollo siga en manos de unos amateurs. Uso aquí el término en el sentido literal y no despectivo del término: estos amateurs son académicos de reconocido prestigio que hacen en su tiempo libre y con equipos informáticos que vete tú a saber a quién pertenecerán y dónde se alojarán las cosas que pretende hacer el consorcio.</description>
    </item>
    
    <item>
      <title>Mejores mensajes de error con deparse &#43; substitute</title>
      <link>/2015/07/02/mejores-mensajes-de-error-con-deparse-substitute/</link>
      <pubDate>Thu, 02 Jul 2015 08:13:54 +0000</pubDate>
      
      <guid>/2015/07/02/mejores-mensajes-de-error-con-deparse-substitute/</guid>
      <description>foo &amp;lt;- function(df, column.name){ if (!column.name %in% colnames(df)) stop(&amp;ldquo;Column &amp;ldquo;, column.name, &amp;quot; not found in &amp;ldquo;, deparse(substitute(df)))
 mean(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/df&amp;quot;&amp;gt;df$column.name) # por ejemplo } foo(iris, &amp;quot;petal.area&amp;quot;)  Lanza el error
Error in foo(iris, &amp;quot;petal.area&amp;quot;) : Column petal.area not found in iris
mucho más informativo gracias a deparse + substitute.</description>
    </item>
    
    <item>
      <title>Diferencia de medias a la bayesiana con salsa de stan</title>
      <link>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</link>
      <pubDate>Thu, 25 Jun 2015 08:13:35 +0000</pubDate>
      
      <guid>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</guid>
      <description>El habitual problema de la diferencia de medias suele formularse de la siguiente manera: hay observaciones $latex y_{1i}$ e $latex y_{2i}$ donde
$latex y_{ji} \sim N(\mu_j, \sigma)$
e interesa saber si $latex \mu_1 = \mu_2$. Obviamente, se desconoce $latex \sigma$. De cómo resolvió Gosset el problema están los libros de estadística llenos. En R,
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) N1 &amp;lt;- 50 N2 &amp;lt;- 50 mu1 &amp;lt;- 1 mu2 &amp;lt;- -0.5 sig1 &amp;lt;- 1 sig2 &amp;lt;- 1 y1 &amp;lt;- rnorm(N1, mu1, sig1) y2 &amp;lt;- rnorm(N2, mu2, sig2) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Busco viñetista (para MicroDatosEs)</title>
      <link>/2015/06/24/busco-vinetista-para-microdatoses/</link>
      <pubDate>Wed, 24 Jun 2015 08:13:18 +0000</pubDate>
      
      <guid>/2015/06/24/busco-vinetista-para-microdatoses/</guid>
      <description>Las viñetas son complementos importantes para un paquete, para que un usuario circunstancial pruebe y use un paquete. Uno de los míos, MicroDatosEs carece de ellas.
Me gustaría poder añadirle una o más que ilustraran cómo usarlo. Por ejemplo, para reproducir algunos de los números que ofrece el INE en sus notas de prensa.
Por eso te ofrezco la posibilidad de que te conviertas en viñetista. Eso te convertiría en colaborador del paquete (que es algo que cabe en un currículo).</description>
    </item>
    
    <item>
      <title>SparkR 1.4: carga de ficheros CSV</title>
      <link>/2015/06/23/sparkr-1-4-carga-de-ficheros-csv/</link>
      <pubDate>Tue, 23 Jun 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/06/23/sparkr-1-4-carga-de-ficheros-csv/</guid>
      <description>He instalado Spark 1.4 recientemente y he comenzado a cacharrear. Antes de nada, quiero cargar datos.
Advierto que ha cambiado sustancialmente la API de SparkR. Entre otras novedades, desapareció (o más bien, se escondió) la función textFile, que permitía leer ficheros línea a línea. Ahora está pero no se exporta. La verás solo si haces SparkR:::textFile. ¿Signo de deprecación?
Se pueden crear un DataFrame (tablas distribuidas de Spark) a partir de un data.</description>
    </item>
    
    <item>
      <title>rPython &amp; Anaconda</title>
      <link>/2015/06/22/rpython-anaconda/</link>
      <pubDate>Mon, 22 Jun 2015 08:13:28 +0000</pubDate>
      
      <guid>/2015/06/22/rpython-anaconda/</guid>
      <description>Nota: publico hoy en inglés en atención al público potencial de la entrada.
rPython lets R users call Python code. Anaconda  is a completely free enterprise-ready Python distribution for large-scale data processing, predictive analytics, and scientific computing. Not surprisingly, some users want to call Anaconda Python rather than their system&amp;rsquo;s default Python.
However, Anaconda is a very particular package: unlike most other packages, whose files are scattered in a diversity of locations, it is self contained in a single directory.</description>
    </item>
    
    <item>
      <title>La encuesta de presupuestos familiares, en MicroDatosEs</title>
      <link>/2015/06/18/la-encuesta-de-presupuestos-familiares-en-microdatoses/</link>
      <pubDate>Thu, 18 Jun 2015 08:13:10 +0000</pubDate>
      
      <guid>/2015/06/18/la-encuesta-de-presupuestos-familiares-en-microdatoses/</guid>
      <description>Hoy he subido una nueva versión del paquete MicroDatosEs a r-forge que incluye herramientas para cargar los datos de la Encuesta de Presupuestos Familiares.
Aún no está en CRAN, pero estáis invitados a probarla instalando la versión de desarrollo mediante
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/install.packages&amp;quot;&amp;gt;install.packages(&amp;quot;MicroDatosEs&amp;quot;, repos=&amp;quot;http://R-Forge.R-project.org&amp;quot;)  La parte del paquete que se encarga de la EPF es obra de Diego Paniagua, que es uno de los estudiantes del Experto en Data Science de la UTAD.</description>
    </item>
    
    <item>
      <title>Liberado Spark 1.4</title>
      <link>/2015/06/17/liberado-spark-1-4/</link>
      <pubDate>Wed, 17 Jun 2015 08:13:15 +0000</pubDate>
      
      <guid>/2015/06/17/liberado-spark-1-4/</guid>
      <description>El anuncio de la liberación de la versión 1.4 de Spark se ha materializado. Está aquí.
¿Qué trae de novedad la versión 1.4? La integración con SparkR —antes había que instalarlo con algo de dolor independientemente— y, aparentemente, data.frames distribuidos y, cuentan, una sintaxis similar a la de dplyr —honestamente, hubiera preferido otra— para manipularlos.
Iré desgranando por aquí novedades. Y estoy pensando organizar una install &amp;amp; tutorial party un día de estos en Madrid.</description>
    </item>
    
    <item>
      <title>Paralelismo en R: memo[rándum]</title>
      <link>/2015/06/15/paralelismo-en-r-memorandum/</link>
      <pubDate>Mon, 15 Jun 2015 08:13:30 +0000</pubDate>
      
      <guid>/2015/06/15/paralelismo-en-r-memorandum/</guid>
      <description>Esta es una nota que me dejo a mí mismo sobre paralelización en R para no tener que ir buscándola en otras partes:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/lattice/parallel&amp;quot;&amp;gt;parallel) foo &amp;lt;- function(i){ &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.sleep&amp;quot;&amp;gt;Sys.sleep(i) } cl &amp;lt;- makeCluster(4) system.time(parSapply(cl, 1:4, foo)) # user system elapsed # 0.025 0.006 4.007 system.time(sapply(1:4, foo)) # user system elapsed # 0.039 0.033 10.001 stopCluster(cl)  </description>
    </item>
    
    <item>
      <title>Ver 53000 filas</title>
      <link>/2015/06/10/ver-53000-filas/</link>
      <pubDate>Wed, 10 Jun 2015 08:13:15 +0000</pubDate>
      
      <guid>/2015/06/10/ver-53000-filas/</guid>
      <description>Me preguntaban cómo ver con R una tabla con 53000 filas. Mi yo menos diplomático quiso contestar: define ver. Lo reformulé más amablemente y se me contestó: como en Excel.
La pregunta es: ¿permite Excel ver 53000 registros? De hecho, ¿se pueden ver 53000 registros? Impresos a razón de línea por centímetro, ocuparían 530 metros y andar a paso vivo del primero al último costaría cinco minutos.
Con 53000 registros, ver (como trasunto de entender) es una cosa distinta de tener delante.</description>
    </item>
    
    <item>
      <title>Oh, no, ¡datastepr!</title>
      <link>/2015/06/09/oh-no-datastepr/</link>
      <pubDate>Tue, 09 Jun 2015 08:12:02 +0000</pubDate>
      
      <guid>/2015/06/09/oh-no-datastepr/</guid>
      <description>Hoy no estoy de humor. He tratado de completar mi primer anillo en dos años y ha resultado un total fracaso. Mi bici buena estaba pinchada: me he enterado a un kilómetro de casa. He tenido que salir en otra, una de esas viejas de Decathlon, que no sé bien cómo apareció una vez en mi casa, que pesa un quintal y que cambia de marchas cuando y como quiere.</description>
    </item>
    
    <item>
      <title>Una de las cosas que me irritan de R</title>
      <link>/2015/06/08/una-de-las-cosas-que-me-irritan-de-r/</link>
      <pubDate>Mon, 08 Jun 2015 08:13:34 +0000</pubDate>
      
      <guid>/2015/06/08/una-de-las-cosas-que-me-irritan-de-r/</guid>
      <description>R (y su comunidad) es en ocasiones irritante. Os cuento por qué.
El otro día quise pintar un grafo sobre un mapa. No quería usar ninguno de los layouts al uso porque cada nodo estaba georeferenciado. Me interesaba, además, pintar el grafo sobre una capa (de Google Maps u OSM) para contextualizarlo (¿conterrenizarlo?) mejor.
No es demasiado complicado escribir una función que haga lo anterior. Pero es razonable pensar que alguien pudiera haberlo hecho antes.</description>
    </item>
    
    <item>
      <title>Grafos por vecindad en mapas</title>
      <link>/2015/05/27/grafos-por-vecindad-en-mapas/</link>
      <pubDate>Wed, 27 May 2015 08:13:53 +0000</pubDate>
      
      <guid>/2015/05/27/grafos-por-vecindad-en-mapas/</guid>
      <description>Dando vueltas (infructuosas) al asunto de los cartogramas he dado con un subproducto con el que, por hoy, me conformo: crear un grafo a partir de relaciones de vecindad entre polígonos. La magia, obra de [spdep::poly2nb](http://www.inside-r.org/packages/cran/spdep/docs/poly2nb); el código,
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/maptools&amp;quot;&amp;gt;maptools) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/spdep&amp;quot;&amp;gt;spdep) library(igraph) # fichero descargado del INE aragon &amp;lt;- readShapePoly(&amp;quot;ccaa00c02.shp&amp;quot;) plot(aragon)  
aragon.nb &amp;lt;- poly2nb(aragon) # vértices vertices &amp;lt;- aragon@data vertices$id &amp;lt;- 1:nrow(aragon@data) vertices &amp;lt;- vertices[, c(&amp;quot;id&amp;quot;, setdiff(colnames(vertices), &amp;quot;id&amp;quot;))] # coordenadas aproximadas de los vértices my.</description>
    </item>
    
    <item>
      <title>Grafos sobre mapas</title>
      <link>/2015/05/18/grafos-sobre-mapas/</link>
      <pubDate>Mon, 18 May 2015 08:13:03 +0000</pubDate>
      
      <guid>/2015/05/18/grafos-sobre-mapas/</guid>
      <description>He escrito de grafos, he escrito de mapas; hoy hablaré de la combinación de ambas cosas.
Tengo un grafo cuyos nodos están geoposicionados. Lo quiero estudiar utilizando herramientas de grafos (vía [igraph](http://igraph.org/r/)) pero después representarlos sobre una capa con información geográfica (una foto satelital de Google Maps, vamos).
La red va a ser la de guifi.net en los derredores de Barcelona. guifi.net es un proyecto para crear una red de telecomunicaciones mancomunada, abierta, libre y neutral.</description>
    </item>
    
    <item>
      <title>Premio al mejor trabajo presentado por un joven en las VII Jornadas de Usuarios de R</title>
      <link>/2015/05/12/premio-al-mejor-trabajo-presentado-por-un-joven-en-las-vii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Tue, 12 May 2015 08:13:32 +0000</pubDate>
      
      <guid>/2015/05/12/premio-al-mejor-trabajo-presentado-por-un-joven-en-las-vii-jornadas-de-usuarios-de-r/</guid>
      <description>Ha pasado un poco desapercibido pero estamos organizando un premio para el mejor trabajo presentado por un ponente nacido después del 1 de enero de 1985 dentro de las VII Jornadas de Usuarios de R.
Las bases están aquí.
Finalmente, si alguien conoce a alguien que pueda conocer a alguien que quiera dotar el premio, ¡que avise! (Y que lea previamente esto también).</description>
    </item>
    
    <item>
      <title>Intervalos de credibilidad para la beta: una alternativa</title>
      <link>/2015/05/05/intervalos-de-credibilidad-para-la-beta-una-alternativa/</link>
      <pubDate>Tue, 05 May 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/05/05/intervalos-de-credibilidad-para-la-beta-una-alternativa/</guid>
      <description>A partir de los comentarios de Olivier Núñez a mi entrada anterior casi homónima, se nos ha ocurrido a ambos de forma independiente y simultánea una manera alternativa de calcular el intervalo: minimizando su longitud.
a &amp;lt;- 3 b &amp;lt;- 5 alfa &amp;lt;- 0.05 # versión de la entrada anterior: f &amp;lt;- function(x){ (dbeta(x[2], a, b) - dbeta(x[1], a, b))^2 + (&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/pbeta&amp;quot;&amp;gt;pbeta(x[2], a, b) - &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/pbeta&amp;quot;&amp;gt;pbeta(x[1], a, b) -1 + alfa)^2 } res &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Las VII Jornadas de Usuarios de R buscan patrocinadores</title>
      <link>/2015/05/05/las-vii-jornadas-de-usuarios-de-r-buscan-patrocinadores/</link>
      <pubDate>Tue, 05 May 2015 08:13:16 +0000</pubDate>
      
      <guid>/2015/05/05/las-vii-jornadas-de-usuarios-de-r-buscan-patrocinadores/</guid>
      <description>Las VII Jornadas de Usuarios de R buscan patrocinadores. Los organizadores hemos redactado un documento en el que se especifican las modalidades y el mecanismo para que tú o la empresa o institución donde trabajas podáis convertiros en patrocinadores de las Jornadas.
Esencialmente, hemos establecido tres categorías —oro, 300 €; plata, 200 € y bronce, 100 €— para empresas e instituciones y una aportación personal y voluntaria de 10 € para participantes y entusiastas.</description>
    </item>
    
    <item>
      <title>Una curiosa trasposición legal (hecha, manifiestamente, a malagana)</title>
      <link>/2015/04/29/una-curiosa-trasposicion-legal-hecha-manifiestamente-a-malagana/</link>
      <pubDate>Wed, 29 Apr 2015 08:13:04 +0000</pubDate>
      
      <guid>/2015/04/29/una-curiosa-trasposicion-legal-hecha-manifiestamente-a-malagana/</guid>
      <description>El parlamento de la Unión Europea aprueba directivas. Los parlamentos nacionales las trasponen, es decir, las convierten en leyes nacionales (véase el enlace anterior).
No sé hasta qué punto la trasposición tiene que ser literal. La única experiencia seria que tengo es con esta y sus trasposiciones nacionales a España y el RU. Y era notorio cómo cada país, aprovechando las ambigüedades del texto original, arrimaba el ascua a su sardina.</description>
    </item>
    
    <item>
      <title>Intervalos de credibilidad para la distribución beta</title>
      <link>/2015/04/27/intervalos-de-credibilidad-para-la-distribucion-beta/</link>
      <pubDate>Mon, 27 Apr 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/04/27/intervalos-de-credibilidad-para-la-distribucion-beta/</guid>
      <description>Tengo un parámetro, la p de una binomial, que supongo distribuido según una beta. Me da igual para el caso si la distribución a priori es o no informativa. Solo digo que la distribución a posteriori es otra beta con parámetros a y b.
Quiero construir un intervalo de credibilidad para p, es decir, encontrar un subintervalo de [0,1]
 * dentro del cual la densidad de la beta sea mayor que fuera y que * capture $latex 1-\alpha$ de la probabilidad total.</description>
    </item>
    
    <item>
      <title>Programa Profesional de Iniciación a R</title>
      <link>/2015/04/21/programa-profesional-de-iniciacion-a-r/</link>
      <pubDate>Tue, 21 Apr 2015 08:13:04 +0000</pubDate>
      
      <guid>/2015/04/21/programa-profesional-de-iniciacion-a-r/</guid>
      <description>Del 9 de junio al 9 de julio impartiré un curso de iniciación a R.
Se trata de una versión extendida de mi curso de introducción a R que, como novedad fundamental, pasa de 12 a 30 horas de duración. El programa, sin embargo, es esencialmente el mismo: aquello, todo ello y no más que aquello que de R podría usarse en Endesa, el Banco de Santander, Deloitte o el Ministerio de Sanidad.</description>
    </item>
    
    <item>
      <title>Todo por no RTFM (o cómo usar matplotlib con R)</title>
      <link>/2015/04/16/todo-por-no-rtfm-o-como-usar-matplotlib-con-r/</link>
      <pubDate>Thu, 16 Apr 2015 08:13:26 +0000</pubDate>
      
      <guid>/2015/04/16/todo-por-no-rtfm-o-como-usar-matplotlib-con-r/</guid>
      <description>Quien escribió Call matplotlib from R podía haberse ahorrado bastante trabajo de la peor especie (programación de bajo nivel con C++) leyendo los benditos manuales (de [rPython](http://cran.r-project.org/web/packages/rPython/index.html), en este caso).
Le bastaba hacer
library(rPython) x &amp;lt;- seq(0, 2*pi, length = 100) sx &amp;lt;- sin(x) cx &amp;lt;- cos(x) python.assign(&amp;quot;x&amp;quot;, x) python.assign(&amp;quot;sx&amp;quot;, sx) python.assign(&amp;quot;cx&amp;quot;, cx) python.exec(&amp;quot;import matplotlib.pyplot as plt&amp;quot;) python.exec(&amp;quot;plt.rcParams.update({&#39;figure.figsize&#39; : (7,4)})&amp;quot;) python.exec(&amp;quot;plt.plot(x, sx)&amp;quot;) python.exec(&amp;quot;plt.plot(x, cx, &#39;--r&#39;, linewidth=2) &amp;quot;) python.exec(&amp;quot;plt.legend((&#39;sin(x)&#39;, &#39;cos(x)&#39;))&amp;quot;) python.exec(&amp;quot;plt.savefig(&#39;2015-04-02-pyplot.png&#39;)&amp;quot;)  para obtener</description>
    </item>
    
    <item>
      <title>Spark ha muerto, ¡larga vida (y buena migración) a Shinyapps!</title>
      <link>/2015/04/15/spark-ha-muerto-larga-vida-y-buena-migracion-a-shinyapps/</link>
      <pubDate>Wed, 15 Apr 2015 08:13:48 +0000</pubDate>
      
      <guid>/2015/04/15/spark-ha-muerto-larga-vida-y-buena-migracion-a-shinyapps/</guid>
      <description>Primero, y por evitar confusiones, este no es el Spark que se nos muere. Se muere un servidor de RStudio donde se colgaban aplicaciones desarrolladas en shiny, spark.rstudio.com.
El nuevo servicio se llama shinyapps.io. Que viene a ser lo mismo pero más formal, con sus tokens, sus claves, su modelo freemium y sus servicios pro de pago.
Migrar aplicaciones, como mi vetusto detector de idiomas, viene a ser equivalente a colgarlas modo ex novo en shinyapps.</description>
    </item>
    
    <item>
      <title>Las VII Jornadas de Usuarios de R, en Salamanca este noviembre</title>
      <link>/2015/04/13/las-vii-jornadas-de-usuarios-de-r-en-salamanca-este-noviembre/</link>
      <pubDate>Mon, 13 Apr 2015 08:13:12 +0000</pubDate>
      
      <guid>/2015/04/13/las-vii-jornadas-de-usuarios-de-r-en-salamanca-este-noviembre/</guid>
      <description>Pues eso, que arrancan. Los detalles, aquí.
Nota: Si encontráis algún error, avisad. La mejor manera es abrir un issue en Github.</description>
    </item>
    
    <item>
      <title>TelegRam[.]me!</title>
      <link>/2015/04/07/telegram-me/</link>
      <pubDate>Tue, 07 Apr 2015 08:13:09 +0000</pubDate>
      
      <guid>/2015/04/07/telegram-me/</guid>
      <description>Telegram es un sistema de mensajería por internet similar a Whatsapp, aunque con algunas diferencias notables:
 * No es de Facebook * Una vez tienes una cuenta, puedes usarla desde distintos dispositivos (Linux incluido) * Tiene menos usuarios * Es programable  De lo último es ilustración esta &amp;ldquo;conversación&amp;rdquo; que tuve con la cuenta @TeleR:

Los detalles, aquí. Y el crédito, para Rubén Tobalina.</description>
    </item>
    
    <item>
      <title>Taller de mapas con R el 14 de abril en Madrid</title>
      <link>/2015/04/06/taller-de-mapas-con-r-el-14-de-abril-en-madrid/</link>
      <pubDate>Mon, 06 Apr 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/04/06/taller-de-mapas-con-r-el-14-de-abril-en-madrid/</guid>
      <description>Mi entrada de hoy es para anunciar un taller de mapas con R que tendrá lugar el día 14 de abril de 18 a 21 horas en Martina Cocina (cómo llegar).
Lo impartirá Beatriz Martínez, socióloga dedicada a la investigación social y de mercados, que ha trabajado en numerosos proyectos: desde investigación digital al desarrollo rural o programas de inclusión social. Está especializada en la la visualización de datos. Algunos de sus trabajos pueden verse en visualizados.</description>
    </item>
    
    <item>
      <title>Pues sí: un curso de redes sociales con R</title>
      <link>/2015/03/25/pues-si-un-curso-de-redes-sociales-con-r/</link>
      <pubDate>Wed, 25 Mar 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/03/25/pues-si-un-curso-de-redes-sociales-con-r/</guid>
      <description>Debido a la positiva acogida de la propuesta para organizar un curso de redes sociales con R&amp;hellip; pues se va a hacer.
 * **Cuándo:** Los días 9 (jueves), 15 y 22 (miércoles ambos) de abril, de 18:00 a 20:30-21:00 horas. * **Lugar:** Las cuevas de [MartinaCocina](http://www.martinacocina.es) (Cascorro 11, 28005 Madrid). * **Programa:** Las partes 1-6 de [este tutorial](http://sna.stanford.edu/rlabs.php). Se completará en modo taller resolviendo por el camino las dudas que surjan y discutiendo los conceptos que aparecen en él.</description>
    </item>
    
    <item>
      <title>Compresión con SVD</title>
      <link>/2015/03/24/compresion-con-svd/</link>
      <pubDate>Tue, 24 Mar 2015 08:13:19 +0000</pubDate>
      
      <guid>/2015/03/24/compresion-con-svd/</guid>
      <description>lo he creado con
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/grDevices/png&amp;quot;&amp;gt;png) tmp.file &amp;lt;- tempfile() &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/download.file&amp;quot;&amp;gt;download.file(&amp;quot;http://datanalytics.com/uploads/greco.png&amp;quot;, tmp.file) m &amp;lt;- readPNG(tmp.file) svd.m &amp;lt;- svd(m) filtra.svd &amp;lt;- function(svd, k){ tmp &amp;lt;- svd tmp$d[(k+1):length(tmp$d)] &amp;lt;- 0 res &amp;lt;- tmp$u %*% diag(tmp$d) %*% t(tmp$v) res[res &amp;gt; 1] &amp;lt;- 1 res[res &amp;lt; 0] &amp;lt;- 0 plot(1:2, type=&#39;n&#39;, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;&amp;quot;, xaxt = &amp;quot;n&amp;quot;, yaxt = &amp;quot;n&amp;quot;, main = paste(k, &amp;quot;primeras componentes&amp;quot;, sep = &amp;quot; &amp;quot;)) rasterImage(res, 1, 1, 2, 2) } &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>¿Un curso de redes sociales con R?</title>
      <link>/2015/03/19/un-curso-de-redes-sociales-con-r/</link>
      <pubDate>Thu, 19 Mar 2015 08:13:03 +0000</pubDate>
      
      <guid>/2015/03/19/un-curso-de-redes-sociales-con-r/</guid>
      <description>Se me ha propuesto organizar un curso, taller o similar de redes sociales y su análisis con R. De nuevo, presencial.

Mi propuesta —dado que soy lego en el asunto— es organizar un taller basado en este. Ahí va mi propuesta: en una serie de sesiones en MartinaCocina plantamos un proyector y una pizarra y entre todos vamos avanzando en el tutorial y resolviendo las dudas colaborativamente.
Por supuesto, el asunto no estaría planteado como clase unidireccional en el que alguien habla y explica y los demás asienten.</description>
    </item>
    
    <item>
      <title>Datos en formato largo y melt</title>
      <link>/2015/03/12/datos-en-formato-largo-y-melt/</link>
      <pubDate>Thu, 12 Mar 2015 08:13:21 +0000</pubDate>
      
      <guid>/2015/03/12/datos-en-formato-largo-y-melt/</guid>
      <description>En ocasiones uno recibe datos no muy distintos de
aragon &amp;lt;- read.table(&amp;quot;http://datanalytics.com/uploads/pob_aragon&amp;quot;, header = T, sep = &amp;quot;\t&amp;quot;) aragon # Provincias Periodo Hombres Mujeres # 1 Huesca 2014 113840 111069 # 2 Huesca 2004 107961 104940 # 3 Teruel 2014 71449 68916 # 4 Teruel 2004 71073 68260 # 5 Zaragoza 2014 471675 488436 # 6 Zaragoza 2004 441840 455510  Los mismos datos en formato largo son:
library(reshape2) aragon.largo &amp;lt;- melt(aragon, id.</description>
    </item>
    
    <item>
      <title>format( &#34;www.R-project.org&#34;, year = 2015)</title>
      <link>/2015/03/11/format-www-r-project-org-year-2015/</link>
      <pubDate>Wed, 11 Mar 2015 08:13:51 +0000</pubDate>
      
      <guid>/2015/03/11/format-www-r-project-org-year-2015/</guid>
      <description>Tal fue el asunto del correo en el que Martin Maechler anunció el lavado de cara de la página de R acontecido hace unos pocos días. Es muy revelador el argumento year = 2015: los usuarios de hoy en día ya no toleramos caóticas yuxtaposiciones de cualquier cosa que algunos llaman páginas de internet.
Los usuarios de hoy en día no tenemos tiempo de buscar y rebuscar. Nos molestan los tropezones.</description>
    </item>
    
    <item>
      <title>¿Cuál es la &#34;mejor&#34; manera de ordenar un dataframe?</title>
      <link>/2015/03/06/cual-es-la-mejor-manera-de-ordenar-un-dataframe/</link>
      <pubDate>Fri, 06 Mar 2015 08:13:04 +0000</pubDate>
      
      <guid>/2015/03/06/cual-es-la-mejor-manera-de-ordenar-un-dataframe/</guid>
      <description>El título de esta entrada es una pregunta honesta. Yo siempre he utilizado order así:
iris[order(iris$Petal.Length),]  Y para ordenar por dos (o más columnas), así:
iris[order(iris$Petal.Length, iris$Petal.Width),]  Es a lo que estoy acostumbrado. Sin embargo, la construcción anterior desconcierta a quienes dan sus primeros pasos en R. dplyr dispone de la función arrange con una sintaxis un tanto más natural:
library(dplyr) arrange(iris, Petal.Length, Petal.Width)  pero, de nuevo, puede resultar desconcertante tener que recurrir a paquetes avanzados: ¿es conveniente introducir a los principiantes en el proceloso mundo de los paquetes para la simple y muy natural operación de ordenar un dataframe?</description>
    </item>
    
    <item>
      <title>Todos contra todos</title>
      <link>/2015/02/25/todos-contra-todos/</link>
      <pubDate>Wed, 25 Feb 2015 08:13:35 +0000</pubDate>
      
      <guid>/2015/02/25/todos-contra-todos/</guid>
      <description>¿Cómo se suman los cuadrados de un vector de números en un paradigma tradicional de programación? Se crea un bucle que lo recorre y que guarda las sumas parciales en un acumulador. Sumamente económico en términos de memoria: apenas consume unos pocos bytes en la pila. La versión funcional de la cosa se parece más a sum(x^2), que implica generar un vector de cuadrados y dilapidar memoria.
Así las cosas, en C uno tiende a recorrer y construir resultados parciales.</description>
    </item>
    
    <item>
      <title>Curso de presencial y gratuito en Madrid (mío, para más señas)</title>
      <link>/2015/02/16/curso-de-presencial-y-gratuito-en-madrid-mio-para-mas-senas/</link>
      <pubDate>Mon, 16 Feb 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/02/16/curso-de-presencial-y-gratuito-en-madrid-mio-para-mas-senas/</guid>
      <description>Voy a impartir un curso básico de R en Madrid. El curso es
 * presencial (no habrá vídeo, retransmisión en _streaming_ ni similares), * gratuito (aunque mira las letra pequeña del final) * no reglado, por lo que no se experidirán certificados, ANECAs o papeles de ningún tipo.  Se trata de un curso de introducción a R desde cero en cuatro sesiones de tres horas los martes (24 de febrero y 3, 10 y 17 de marzo) de 18:00 a 21:00.</description>
    </item>
    
    <item>
      <title>Recurrencia recurrente</title>
      <link>/2015/02/11/recurrencia-recurrente/</link>
      <pubDate>Wed, 11 Feb 2015 08:13:50 +0000</pubDate>
      
      <guid>/2015/02/11/recurrencia-recurrente/</guid>
      <description>Pregunta Antonio Sánchez Chinchón cómo mejorar la parte menos vistosa e imaginativa de esto, es decir, el código. Él, y muchos diríamos que correctamente, autocritica el uso de eval + parse para plagar el namespace de funciones.
La respuesta está en la recurrencia. He aquí mi versión del código:
library(ggplot2) library(gridExtra) nrows &amp;lt;- 6 coefs.a &amp;lt;- runif(min=1, max=50, nrows) coefs.b &amp;lt;- runif(min=1, max=50, nrows) foo.a &amp;lt;- sample(c(sin, cos), nrows, replace = TRUE) foo.</description>
    </item>
    
    <item>
      <title>Ejercicios de mi clase de R</title>
      <link>/2015/02/09/ejercicios-de-mi-clase-de-r/</link>
      <pubDate>Mon, 09 Feb 2015 07:13:30 +0000</pubDate>
      
      <guid>/2015/02/09/ejercicios-de-mi-clase-de-r/</guid>
      <description>Ya conté que participo (como profesor) en el Experto en Data Science de la U-tad. Voy a copiar aquí los ejercicios que propuse en la asignatura de preparación de datos con R. Por si alguien les quiere hincar el diente. En lo que sigue he eliminado algunos detalles que no vienen a cuento. He dejado el resto.
Son así:
Los ejercicios tienen que resolverse individualmente. No son sencillos: parte de ellos están inspirados en problemas prácticos reales.</description>
    </item>
    
    <item>
      <title>Romain François (y Francisco Viciana) en el grupo de usuarios de R de Sevilla</title>
      <link>/2015/02/06/romain-francois-y-francisco-viciana-en-el-grupo-de-usuarios-de-r-de-sevilla/</link>
      <pubDate>Fri, 06 Feb 2015 07:13:17 +0000</pubDate>
      
      <guid>/2015/02/06/romain-francois-y-francisco-viciana-en-el-grupo-de-usuarios-de-r-de-sevilla/</guid>
      <description>Me entero en la página del grupo de usuarios de R de Sevilla de dos cosas:
 * de que Romain François hablará sobre `dplyr` y de lo que esconde bajo el capó y * que Francisco Viciana demostrará el uso del [paquete `pxR`](http://cran.r-project.org/web/packages/pxR/index.html)  en la próxima reunión del grupo. ¡Quién pudiera asistir!</description>
    </item>
    
    <item>
      <title>Parametrización para vagos muy, muy vagos</title>
      <link>/2015/02/05/parametrizacion-para-vagos-muy-muy-vagos/</link>
      <pubDate>Thu, 05 Feb 2015 07:13:14 +0000</pubDate>
      
      <guid>/2015/02/05/parametrizacion-para-vagos-muy-muy-vagos/</guid>
      <description>Un ejemplo sencillo. Tengo un programa que contiene, por ejemplo, una consulta tal que
query &amp;lt;- &amp;quot;select * from mitabla where country = 24 and year = 2014&amp;quot;  Hay gente sumamente diligente, con una enorme capacidad de trabajo y con vocación de hormiguita que en mil ejecuciones distintas (distinto país, distinto año) del código anterior sería capaz de editar la consulta a mano. Probablemente usando el block de notas. Esa gente, que además suele madrugar mucho, siempre me ha dado cierta envidia.</description>
    </item>
    
    <item>
      <title>Entrevista en Principio de Incertidumbre: &#34;big data&#34; sin artificio</title>
      <link>/2015/02/04/entrevista-en-principio-de-incertidumbre-big-data-sin-artificio/</link>
      <pubDate>Wed, 04 Feb 2015 07:13:40 +0000</pubDate>
      
      <guid>/2015/02/04/entrevista-en-principio-de-incertidumbre-big-data-sin-artificio/</guid>
      <description>El jueves pasado y durante un breve receso de mi gripe, me entrevistaron en Canal Extremadura Radio. Durante una hora larga (que luego hubo que recortar a los 30 minutos que dura el programa de divulgación científica Principio de Incertidumbre) hablé de estadística, big data y R con Jorge Solís Bejarano.
A quien tengo que agradecer, primero, que contase conmigo; pero además y sobre todo, lo bien documentado que estuvo (lo cual me lleva a pensar que habrá que estar atentos a otras grabaciones de su programa).</description>
    </item>
    
    <item>
      <title>La profesionalización de R</title>
      <link>/2015/01/28/la-profesionalizacion-de-r/</link>
      <pubDate>Wed, 28 Jan 2015 07:13:08 +0000</pubDate>
      
      <guid>/2015/01/28/la-profesionalizacion-de-r/</guid>
      <description>Tenía en mente escribir estas líneas desde hace un tiempo. La reciente noticia de la adquisición de Revolution Analytics por parte de Microsoft la ha adelantado, como mucho, unos pocos días.
S, el lenguaje del que R es una implementación libre, vivió su ciclo propietario completo: nació en los laboratorios Bell, creció con Insightful, se reprodujo (R fue su vástago) y creo que ha muerto sin pena ni gloria en manos de Tibco.</description>
    </item>
    
    <item>
      <title>Grandes datos, máquinas pequeñas (y regresiones logísticas con variables categóricas)</title>
      <link>/2015/01/27/grandes-datos-maquinas-pequenas-y-regresiones-logisticas-con-variables-categoricas/</link>
      <pubDate>Tue, 27 Jan 2015 07:13:49 +0000</pubDate>
      
      <guid>/2015/01/27/grandes-datos-maquinas-pequenas-y-regresiones-logisticas-con-variables-categoricas/</guid>
      <description>Preguntaba el otro día Emilio Torres esto en R-help-es. Resumo la pregunta. Se trata de una simulación de unos datos y su ajuste mediante una regresión logística para ver si los coeficientes obtenidos son o no los esperados (teóricamente y por construcción).
El código de Emilio (cuyos resultados no podemos reproducir porque no nos ha contado qué similla usa) es
logisticsimulation &amp;lt;- function(n){ dat &amp;lt;- data.frame(x1=sample(0:1, n,replace=TRUE), x2=sample(0:1, n,replace=TRUE)) odds &amp;lt;- exp(-1 - 4 * dat$x1 + 7*dat$x2 - 1 *dat$x1* dat$x2 ) pr &amp;lt;- odds/(1+odds) res &amp;lt;- replicate(100, { dat$y &amp;lt;- rbinom(n,1,pr) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Dónde guardar los paquetes de R (en Linux, al menos)</title>
      <link>/2015/01/21/donde-guardar-los-paquetes-de-r-en-linux-al-menos/</link>
      <pubDate>Wed, 21 Jan 2015 07:13:02 +0000</pubDate>
      
      <guid>/2015/01/21/donde-guardar-los-paquetes-de-r-en-linux-al-menos/</guid>
      <description>En todos mis Linux, desde el principio de los tiempos, R guardaba los paquetes en
 * `/usr/lib/R/library` * `/usr/lib/R/site-library` (¡a veces y no sé por qué!) * `/usr/local/lib/R/site-library`  Bajo /usr/lib deberían instalarse solo aquellos que vienen de serie con la instalación de R (o que se instalan usando el sistema de actualización de paquetes de la distribución de Linux) mientras que bajo /usr/local vivirían los instalados posteriormente por el usuario (véase esto).</description>
    </item>
    
    <item>
      <title>No me ha salido, pero lo cuento igual</title>
      <link>/2015/01/20/no-me-ha-salido-pero-lo-cuento-igual/</link>
      <pubDate>Tue, 20 Jan 2015 07:13:54 +0000</pubDate>
      
      <guid>/2015/01/20/no-me-ha-salido-pero-lo-cuento-igual/</guid>
      <description>Creo que todos sabéis la historia de las admisiones de la Universidad de Berkeley y la paradoja de Simpson. Con palabras, muchas palabras, está contado, por ejemplo, aquí. Y si buscáis ubc admissions simpson en Google la encontraréis también en modo --verbose en muchos más sitios.
En R puede resumirse en
library(reshape2) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) data(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/UCBAdmissions&amp;quot;&amp;gt;UCBAdmissions) raw &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/as.data.frame&amp;quot;&amp;gt;as.data.frame(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/datasets/UCBAdmissions&amp;quot;&amp;gt;UCBAdmissions) dat &amp;lt;- dcast(raw, Gender + Dept ~ &amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/AdMit&amp;quot;&amp;gt;Admit) mod.</description>
    </item>
    
    <item>
      <title>Huele a bicho (en plyr)</title>
      <link>/2015/01/19/huele-a-bicho-en-plyr/</link>
      <pubDate>Mon, 19 Jan 2015 07:13:36 +0000</pubDate>
      
      <guid>/2015/01/19/huele-a-bicho-en-plyr/</guid>
      <description>library(plyr)
dat &amp;lt;- data.frame( a = sample(c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), 100, replace = T), b = sample(c(TRUE, FALSE), 100, replace = T)) ddply(dat, .(a), summarize, b = sum(b), no.b = sum(!b)) ddply(dat, .(a), summarize, no.b = sum(!b), b = sum(b))  Huele a bicho, ¿verdad?</description>
    </item>
    
    <item>
      <title>evtree: árboles globales</title>
      <link>/2015/01/12/evtree-arboles-globales/</link>
      <pubDate>Mon, 12 Jan 2015 07:13:44 +0000</pubDate>
      
      <guid>/2015/01/12/evtree-arboles-globales/</guid>
      <description>Tengo por delante otro proyecto que tiene mucho de análisis exploratorio de datos. Sospecho que más de un árbol construiré. Los árboles son como la Wikipedia: prácticamente nunca el último pero casi siempre el primer recurso.
Esta vez, además, por entretenerme un poco, probaré el paquete [evtree](http://cran.r-project.org/web/packages/evtree/index.html). Aunque no porque espere sorprendentes mejoras con respecto a los tradicionales, ctree y rpart.
¿Qué tiene aquél que los diferencie de los otros dos?</description>
    </item>
    
    <item>
      <title>Cómo no nació el &#34;big data&#34;</title>
      <link>/2014/12/30/como-no-nacio-el-big-data/</link>
      <pubDate>Tue, 30 Dec 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/12/30/como-no-nacio-el-big-data/</guid>
      <description>En julio anuncié en mi cuenta de Twitter (léase de abajo a arriba):

Ya está disponible.</description>
    </item>
    
    <item>
      <title>R Markdown a la Tufte</title>
      <link>/2014/12/05/r-markdown-a-la-tufte/</link>
      <pubDate>Fri, 05 Dec 2014 07:13:44 +0000</pubDate>
      
      <guid>/2014/12/05/r-markdown-a-la-tufte/</guid>
      <description>El Sr. Tufte debiera ser un conocido de los habituales de estas páginas. Los desavisados siempre pueden ponerse al día aquí.
El Sr. Tufte escribe libros. Los escribe, los edita, los publica y creo que hasta los vende él solo. No puede ser de otra manera. Mensaje, texto, tipografía, maquetación, gráficos, los elementos todos de sus libros, en cada una de sus páginas, están combinados y medidos hasta el menor de los detalles.</description>
    </item>
    
    <item>
      <title>Paralelización en R con snow</title>
      <link>/2014/12/03/paralelizacion-en-r-con-snow/</link>
      <pubDate>Wed, 03 Dec 2014 07:13:13 +0000</pubDate>
      
      <guid>/2014/12/03/paralelizacion-en-r-con-snow/</guid>
      <description>Suelo trabajar un servidor con ocho CPUs. Cuando quiero paralelizar código en R, suelo utilizar [parallel::mclapply](https://stat.ethz.ch/R-manual/R-devel/library/parallel/html/mclapply.html) (como aquí). Pero no tengo una máquina. Tengo varias. Y antes, de hecho, muchas.
¿Cómo paralelizar en distintas máquinas?
Se puede usar Spark (y SparkR), por ejemplo. Pero una ruta que no había ensayado jamás es la de la vieja escuela, i.e., MPI, snow y demás.
Pero si
 * tienes varios servidores corriendo un sistema operativo decente, * instalas R y `snow` (y todo lo que necesites) en todos ellos y * configuras los servidores para poder acceder a través de [ssh sin contraseña](http://www.</description>
    </item>
    
    <item>
      <title>Me muerdo la lengua... por no contarlo todo</title>
      <link>/2014/12/02/me-muerdo-la-lengua-por-no-contarlo-todo/</link>
      <pubDate>Tue, 02 Dec 2014 07:13:59 +0000</pubDate>
      
      <guid>/2014/12/02/me-muerdo-la-lengua-por-no-contarlo-todo/</guid>
      <description>Me tengo que morder la lengua por no contarlo todo. Escribiré hasta donde pueda hacerlo. Que es casi nada. La cosa es que ha llegado a mis oídos que una muy importante empresa española con muchos, muchos empleados planea una migración muy seria de SAS a R.
Lo cual no deja de ser un cotilleo empresarial más. Que, como tal, no tendría cabida aquí. Salvo por el hecho de que me consta que me leen muchos estudiantes, muchos profesionales que se replantean sus carreras, muchos desempleados que se están formando de cara a su reincorporación.</description>
    </item>
    
    <item>
      <title>Sevilla: otro grupo local de usuarios de R</title>
      <link>/2014/11/18/sevilla-otro-grupo-local-de-usuarios-de-r/</link>
      <pubDate>Tue, 18 Nov 2014 07:13:32 +0000</pubDate>
      
      <guid>/2014/11/18/sevilla-otro-grupo-local-de-usuarios-de-r/</guid>
      <description>Me acabo de enterar que nuestros colegas de Sevilla están organizando la primera reunión de su grupo local de usuarios de R. Además, el tema es muy, muy relevante y de interés general: R Markdown.
Los detalles, aquí.
Sevillanos que seguís esta bitácora: ¡que no me entere yo que faltáis!</description>
    </item>
    
    <item>
      <title>Descargar ficheros .gz detrás de HTTPS con R</title>
      <link>/2014/11/12/descargar-ficheros-gz-detras-de-https-con-r/</link>
      <pubDate>Wed, 12 Nov 2014 07:13:22 +0000</pubDate>
      
      <guid>/2014/11/12/descargar-ficheros-gz-detras-de-https-con-r/</guid>
      <description>El problema consiste en leer, por ejemplo, [https://stat.ethz.ch/pipermail/r-help-es/2012-August.txt.gz](https://stat.ethz.ch/pipermail/r-help-es/2012-August.txt.gz).
Desde Windows, por algún motivo, es sencillo: se puede usar download.file y luego, readLines directamente (porque no sé si sabéis que esta y otras funciones similares saben leer directamente ficheros comprimidos con gzip).
En Linux parece algo más complicado: download.file se niega a bajar ficheros usando el protocolo [https](http://en.wikipedia.org/wiki/HTTP_Secure). Lo mejor que he sabido hacer es
library(httr) x &amp;lt;- GET(&amp;quot;https://stat.ethz.ch/pipermail/r-help-es/2012-August.txt.gz&amp;quot;) tmp &amp;lt;- tempfile() writeBin(content(x, &amp;quot;raw&amp;quot;), tmp) res &amp;lt;- readLines(tmp) unlink(tmp)  que es feo, feo, feo.</description>
    </item>
    
    <item>
      <title>Remuestreos y tests de hipótesis</title>
      <link>/2014/11/10/remuestreos-y-tests-de-hipotesis/</link>
      <pubDate>Mon, 10 Nov 2014 07:13:58 +0000</pubDate>
      
      <guid>/2014/11/10/remuestreos-y-tests-de-hipotesis/</guid>
      <description>No sé si visteis el vídeo que colgué el otro día. Trataba el problema de determinar si dos poblaciones
beer &amp;lt;- c(27, 20, 21, 26, 27, 31, 24, 21, 20, 19, 23, 24, 18, 19, 24, 29, 18, 20, 17, 31, 20, 25, 28, 21, 27) water &amp;lt;- c(21, 22, 15, 12, 21, 16, 19, 15, 22, 24, 19, 23, 13, 22, 20, 24, 18, 20)  tienen o no la misma media.</description>
    </item>
    
    <item>
      <title>Disponibles los vídeos y presentaciones de las VI Jornadas de Usuarios de R</title>
      <link>/2014/11/05/disponibles-los-videos-y-presentaciones-de-las-vi-jornadas-de-usuarios-de-r/</link>
      <pubDate>Wed, 05 Nov 2014 07:13:37 +0000</pubDate>
      
      <guid>/2014/11/05/disponibles-los-videos-y-presentaciones-de-las-vi-jornadas-de-usuarios-de-r/</guid>
      <description>Ya están disponibles las diapositivas y vídeos de las charlas de las VI Jornadas de Usuarios de R. Entre ellos, las diapositivas y el

de la charla de quien suscribe.
(Y gracias, de nuevo, al equipo local (en Santiago) del Comité Organizador de las Jornadas por su estupendo trabajo).</description>
    </item>
    
    <item>
      <title>Noticia de las VI Jornadas de Usuarios de R</title>
      <link>/2014/10/27/noticia-de-las-vi-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 27 Oct 2014 07:13:34 +0000</pubDate>
      
      <guid>/2014/10/27/noticia-de-las-vi-jornadas-de-usuarios-de-r/</guid>
      <description>Regreso de las VI Jornadas de Usuarios de R y, como otros años he hecho (véase esto, esto y esto), al volver a casa, quiero escribir sobre este par de días estupendos que he pasado en Santiago.
Antes de ello quiero agradecer a los miembros de los comités científico y organizador su esfuerzo. Muy especialmente a los miembros locales de este último que —quien lo probó bien lo sabe— hicieron un gran e impagable trabajo.</description>
    </item>
    
    <item>
      <title>Parto para las VI Jornadas de Usuarios de R</title>
      <link>/2014/10/22/vi-jornadas-de-usuarios-de-r/</link>
      <pubDate>Wed, 22 Oct 2014 07:13:43 +0000</pubDate>
      
      <guid>/2014/10/22/vi-jornadas-de-usuarios-de-r/</guid>
      <description>Esta noche, mochila al hombro, parto para Santiago. Me esperan allá las VI Jornadas de Usuarios de R.
Algo contaré este año. Es lo de menos. Lo de más, que volveré a ver a viejos amigos.
¿Nos vemos en Santiago?</description>
    </item>
    
    <item>
      <title>Aprende R con swirl</title>
      <link>/2014/10/16/aprende-r-con-swirl/</link>
      <pubDate>Thu, 16 Oct 2014 07:13:08 +0000</pubDate>
      
      <guid>/2014/10/16/aprende-r-con-swirl/</guid>
      <description>Me pasó el otro día Federico Castanedo un enlace a swirl que quiero compartir con mis lectores y, en particular, aquellos que quieren aprender (¡o enseñar!) R.

¿Cómo funciona? Sencillo:
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/install.packages&amp;quot;&amp;gt;install.packages(&amp;quot;swirl&amp;quot;) library(&amp;quot;swirl&amp;quot;) swirl()  (idealmente en RStudio) y luego, click, click, click hasta saber todo lo que merece ser sabido en R.</description>
    </item>
    
    <item>
      <title>Amanece, me cuentan, que no es poco</title>
      <link>/2014/10/14/amanece-me-cuenta-que-no-es-poco/</link>
      <pubDate>Tue, 14 Oct 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/10/14/amanece-me-cuenta-que-no-es-poco/</guid>
      <description>El amanecer es una cosa que ocurre a diario, me cuentan, pero que yo apenas he visto. Casi hablo de lo que no sé. Por otra parte, la discusión de los horarios, de si deberíamos tener la hora de Londres y no la de Berlín, me parece puro nominalismo. Unos llaman a la hora a la que se levantan sechs, otros seven, otros huit y yo diez y veinte. Y no pasa nada.</description>
    </item>
    
    <item>
      <title>Bootstrap bayesiano</title>
      <link>/2014/10/10/bootstrap-bayesiano/</link>
      <pubDate>Fri, 10 Oct 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/10/10/bootstrap-bayesiano/</guid>
      <description>Hoy voy a hablar de esa especie de oxímoron que es el el bootstrap bayesiano. Comenzaré planteando un pequeño problema bien conocido: tenemos números $latex x_1, \dots, x_n$ y hemos calculado su media. Pero nos preguntamos cómo podría variar dicha media (de realizarse otras muestras).
La respuesta de Efron (1979) es esta:
replicate(n, mean(sample(x, length(x), replace = TRUE)))  Es decir, crear muestras de $latex x_i$ con reemplazamiento y hacer la media de cada una de ellas para obtener su presunta distribución (o una muestra de la presunta distribución de esa media).</description>
    </item>
    
    <item>
      <title>Experto en Data Science en la U-tad</title>
      <link>/2014/10/09/experto-en-data-science-en-la-u-tad/</link>
      <pubDate>Thu, 09 Oct 2014 07:13:40 +0000</pubDate>
      
      <guid>/2014/10/09/experto-en-data-science-en-la-u-tad/</guid>
      <description>Se me ha ido pasando y nunca he llegado a escribir aquí que seré uno de los profesores del Experto en Data Science de la U-tad que comienza&amp;hellip; de hecho este viernes.

El escribir tan tarde me permite, al menos, presumir de que todo lo bueno que tengo que decir sobre el programa y el claustro no tiene finalidad comercial/propagandística.
Y sí, lo habéis adivinado: la parte del programa que me corresponde tiene que ver con R y algunos de los paquetes que me sacan de apuros a diario (p.</description>
    </item>
    
    <item>
      <title>¿Dónde he estado (según Google)?</title>
      <link>/2014/10/01/donde-he-estado-segun-google/</link>
      <pubDate>Wed, 01 Oct 2014 07:13:47 +0000</pubDate>
      
      <guid>/2014/10/01/donde-he-estado-segun-google/</guid>
      <description>Leí esto el otro día. Lo voy a replicar con mis datos.
Contexto
Google guarda datos de tus ubicaciones: tu tableta, tu ordenador, tu teléfono Android son espías a su servicio. Los datos los guarda en aquí (creo que necesitarás que en tu navegador haya una sesión abierta con tus credenciales del universo Google). Pulsando en administrar archivos y luego en crear archivos puedes seleccionar el tipo de información sobre ti que posee Google y que quieres descargarte.</description>
    </item>
    
    <item>
      <title>plyr, dplyr, data.table: ¿qué opinas?</title>
      <link>/2014/09/24/plyr-dplyr-data-table-que-opinas/</link>
      <pubDate>Wed, 24 Sep 2014 07:13:27 +0000</pubDate>
      
      <guid>/2014/09/24/plyr-dplyr-data-table-que-opinas/</guid>
      <description>Fui un pájaro mañanero con [plyr](http://cran.r-project.org/web/packages/plyr/index.html).
Probé una vez [data.table](http://cran.r-project.org/web/packages/data.table/index.html) y no me convenció. Volví a él cuando realmente lo necesitaba y ahora es la prolongación de mis dedos.
Aún no me he puesto con [dplyr](http://cran.r-project.org/web/packages/dplyr/index.html) aunque he visto el suficiente código escrito con él que no creo que me cueste mucho comenzar a usarlo.
Pero tengo la sensación de que tenemos un cisma como el de vi contra emacs en ciernes.</description>
    </item>
    
    <item>
      <title>El impacto (causal) de Google</title>
      <link>/2014/09/23/el-impacto-causal-de-google/</link>
      <pubDate>Tue, 23 Sep 2014 07:13:07 +0000</pubDate>
      
      <guid>/2014/09/23/el-impacto-causal-de-google/</guid>
      <description>Voy a escribir sobre un artículo como no debe hacerse: sin haberlo leído. Los bayesianos dirían que esta opinión que aquí voy a vertir es mi prior para cuando encuentre el tiempo y bajo la cual matizaré lo que en el se diga. Lo advierto, en todo caso, para que quien me lea no renuncie al sanísimo escepticismo.
Voy a hablar de Inferring causal impact using Bayesian structural time-series models y del paquete de R que lo acompaña, CausalImpact, cuyos autores trabajan en Google.</description>
    </item>
    
    <item>
      <title>La diapositiva perdida, versión algo más extendida</title>
      <link>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</link>
      <pubDate>Mon, 22 Sep 2014 07:13:49 +0000</pubDate>
      
      <guid>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</guid>
      <description>Tuve que saltarme una diapositiva en el DataBeers de Madrid del pasado jueves.
(A propósito, aquí están las 1+20 diapositivas).
La decimonona, de la que trata la entrada, viene a hablar de lo siguiente. Tenemos una base de datos con sujetos (ids) que hacen cosas en determinados momentos. No es inhabitual calcular la frecuencia de esos sujetos así:
&amp;lt;code&amp;gt;select id, count(*) as freq from mytabla where fecha between current_date - 7 and current_date group by id ; &amp;lt;/code&amp;gt;  Esa variable se utiliza frecuentemente ya sea como descriptor de los sujetos o como alimento de otros modelos.</description>
    </item>
    
    <item>
      <title>Primer elemento de un grupo dentro de un dataframe de R</title>
      <link>/2014/09/19/primer-elemento-de-un-grupo-dentro-de-un-dataframe-de-r/</link>
      <pubDate>Fri, 19 Sep 2014 07:13:31 +0000</pubDate>
      
      <guid>/2014/09/19/primer-elemento-de-un-grupo-dentro-de-un-dataframe-de-r/</guid>
      <description>Hoy he encontrado una solución decente a un problema que venía arrastrando desde hace un tiempo en R. Tengo una tabla muy grande (decenas de millones de registros) con su id. Me interesa quedarme con el subconjunto de la tabla original en que para cada id el valor de una determinada variable es mínimo.
Un caso de uso: esa variable adicional mide la distancia de la observación a los centroides de unos clústers.</description>
    </item>
    
    <item>
      <title>R en Nada Es Gratis</title>
      <link>/2014/09/16/r-en-nada-es-gratis/</link>
      <pubDate>Tue, 16 Sep 2014 07:13:33 +0000</pubDate>
      
      <guid>/2014/09/16/r-en-nada-es-gratis/</guid>
      <description>Jesús Fernández Villaverde escribió en Nada es Gratis sobre R el otro día. Publicó cuatro vídeos:
 * Una [entrevista a Hadley Wickham](https://www.youtube.com/watch?v=JxwxefRAu70) * La [conferencia plenaria de John Chambers](https://www.youtube.com/watch?v=_hcpuRB5nGs) en la useR! 2014 * Una [entrevista a Yihui Xie](https://www.youtube.com/watch?v=LussVnrLZKU), el creador de `knitr` * La conferencia plenaria de Martin Mächler en la useR! 2014, _[Good Practices in R Programming](https://www.youtube.com/watch?v=ytbX-T1A8wE)_  Todos muy interesantes.
Pero todavía lo es más que desde unas páginas del impacto de Nada es Gratis tengan a bien contribuir al conocimiento (¡y al uso!</description>
    </item>
    
    <item>
      <title>Bajo el capó del particionamiento recursivo basado en modelos</title>
      <link>/2014/09/12/bajo-el-capo-del-particionamiento-recursivo-basado-en-modelos/</link>
      <pubDate>Fri, 12 Sep 2014 07:13:31 +0000</pubDate>
      
      <guid>/2014/09/12/bajo-el-capo-del-particionamiento-recursivo-basado-en-modelos/</guid>
      <description>Una de las mayores contrariedades de estar sentado cerca de alguien que es más matemático que un servidor (de Vds., no de silicio) es que oye siempre preguntar por qué. Una letanía de preguntas me condujo a leer papelotes que ahora resumo.
Primero, unos datos:
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) n &amp;lt;- 100 x1 &amp;lt;- rnorm(n) x2 &amp;lt;- rnorm(n) x3 &amp;lt;- rnorm(n) y &amp;lt;- 0.3 + 0.2 * x1 + 0.5 * (x2 &amp;gt; 0) + 0.</description>
    </item>
    
    <item>
      <title>Missing</title>
      <link>/2014/09/11/missing/</link>
      <pubDate>Thu, 11 Sep 2014 07:13:20 +0000</pubDate>
      
      <guid>/2014/09/11/missing/</guid>
      <description>Dos motivos me han tenido missing estas últimas semanas. Uno es una estancia en la Universidad de Santa Catalina del Burgo de Osma. Oportunamente ubicada en las estribaciones de la muy generosa en caldos de calidad Ribera del Duero, ha sido reconvertida a la sazón en un hotel propicio para la evasión y la agrafía.

El segundo es que en horas intempestivas he estado purgando de missings unas matrices enormes y de la, se conoce, mayor trascendencia.</description>
    </item>
    
    <item>
      <title>Factorización de enteros con grid</title>
      <link>/2014/09/09/factorizacion-de-enteros-con-grid/</link>
      <pubDate>Tue, 09 Sep 2014 07:13:03 +0000</pubDate>
      
      <guid>/2014/09/09/factorizacion-de-enteros-con-grid/</guid>
      <description>Vi esto y me dije: yo también quiero. Así que dicho y hecho:

Por si acaso, cada diagrama representa la descomposición en números primos de un número del 1 al 100.
El código (que no he adecentado lo que suelo) es un pequeño ejercicio con el paquete grid y unos elementos de recursividad (como en Grid, Scala y arbolitos fractales):
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/graphics/grid&amp;quot;&amp;gt;grid) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/gmp&amp;quot;&amp;gt;gmp) plot.factors &amp;lt;- function(n, new.plot = TRUE){ if(new.</description>
    </item>
    
    <item>
      <title>(Mis) procesos puntuales con glm</title>
      <link>/2014/08/13/mis-procesos-puntuales-con-glm/</link>
      <pubDate>Wed, 13 Aug 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/08/13/mis-procesos-puntuales-con-glm/</guid>
      <description>Lo que escribí hace un par de días sobre procesos puntuales, ahora me doy cuenta, podía haberse resuelto con nuestro viejo amigo glm.
Ejecuto el código del otro día y obtengo (para un caso nuevo)
&amp;lt;code&amp;gt; mu alfa verosimilitud delta 1 0.4493158 0.50000000 340.6141 1 2 0.2675349 0.40457418 307.3939 2 3 0.1894562 0.28917407 293.4696 3 4 0.1495654 0.22237707 287.0784 4 5 0.1243791 0.18079703 281.3900 5 6 0.1142837 0.14913172 284.9227 6 7 0.</description>
    </item>
    
    <item>
      <title>Procesos puntuales: una primera aproximación</title>
      <link>/2014/08/11/procesos-puntuales-una-primera-aproximacion/</link>
      <pubDate>Mon, 11 Aug 2014 07:13:21 +0000</pubDate>
      
      <guid>/2014/08/11/procesos-puntuales-una-primera-aproximacion/</guid>
      <description>Tengo una serie de datos que se parecen a lo que cierta gente llama procesos puntuales y que se parecen a los que se introducen (muuuuy prolijamente) aquí. Gráficamente, tienen este aspecto:

Sobre un determinado periodo de tiempo (eje horizontal) suceden eventos y los cuento por fecha. Pero no suceden independientemente (como si generados por un proceso de Poisson) sino que tienden a agruparse: el que suceda un evento tiende a incrementar la probabilidad de que suceda otro poco después.</description>
    </item>
    
    <item>
      <title>Procesos de Poisson no homogéneos: la historia de un fracaso</title>
      <link>/2014/08/08/procesos-de-poisson-no-homogeneos-la-historia-de-un-fracaso/</link>
      <pubDate>Fri, 08 Aug 2014 07:13:03 +0000</pubDate>
      
      <guid>/2014/08/08/procesos-de-poisson-no-homogeneos-la-historia-de-un-fracaso/</guid>
      <description>Partamos el tiempo en, p.e., días y contemos una serie de eventos que suceden en ellos. Es posible que esos recuentos se distribuyan según un proceso de Poisson de parámetro $latex \lambda$, que es un valor que regula la intensidad.
Si los días son homogéneos, i.e., no hay variaciones de intensidad diaria, estimar $latex \lambda$ (por máxima verosimilitud), es tan fácil como calcular la media de los sucesos por día. Pero puede suceder que la intensidad varíe en el tiempo (p.</description>
    </item>
    
    <item>
      <title>Coclustering con blockcluster</title>
      <link>/2014/08/01/coclustering-con-blockcluster/</link>
      <pubDate>Fri, 01 Aug 2014 07:13:18 +0000</pubDate>
      
      <guid>/2014/08/01/coclustering-con-blockcluster/</guid>
      <description>Guardo desde hace un tiempo el enlace al paquete blockcluster de R que igual puede ser del interés de alguno de mis lectores.
No lo he probado pero sospecho que cualquier día me puede sacar de un apuro. Implementa lo que dice, el coclústering, concepto que se explica mejor, como el efecto de las dietas milagrosas, con la foto del antes y el después:

Esto es: la entrada es una matriz y la salida es una matriz reorganizada tanto en sus filas como en sus columnas en la que se han detectado bloques homogéneos.</description>
    </item>
    
    <item>
      <title>Incrementalidad via particionamiento recursivo basado en modelos</title>
      <link>/2014/07/30/incrementalidad-via-particionamiento-recursivo-basado-en-modelos/</link>
      <pubDate>Wed, 30 Jul 2014 07:13:24 +0000</pubDate>
      
      <guid>/2014/07/30/incrementalidad-via-particionamiento-recursivo-basado-en-modelos/</guid>
      <description>Planteas un modelo tal como resp ~ treat y no encuentras diferencia significativa. O incluso puede ser negativa. Globalmente.
La pregunta es, con el permiso del Sr. Simpson (o tal vez inspirados por él), ¿existirá alguna región del espacio en la que el tratamiento tiene un efecto beneficioso? Puede que sí. Y de haberla, ¿cómo identificarla?
De eso hablo hoy aquí. E incluyo una protorespuesta.
Primero, genero datos:
n &amp;lt;- 20000 v1 &amp;lt;- sample(0:1, n, replace = T) v2 &amp;lt;- sample(0:1, n, replace = T) v3 &amp;lt;- sample(0:1, n, replace = T) treat &amp;lt;- sample(0:1, n, replace = T) y &amp;lt;- v1 + treat * v1 * v2 y &amp;lt;- exp(y) / (1 + exp(y)) y &amp;lt;- sapply(y, function(x) rbinom(1,1,x)) dat &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>Estrategias escalables (con R)</title>
      <link>/2014/07/09/estrategias-escalables-con-r/</link>
      <pubDate>Wed, 09 Jul 2014 07:13:41 +0000</pubDate>
      
      <guid>/2014/07/09/estrategias-escalables-con-r/</guid>
      <description>Hay quienes preguntan cómo cargar con R un csv de 8GB en un portátil de 4GB de RAM. La verdad, he leído respuestas la mar de extravagantes a este tipo de cuestiones: p.e., recomendar SQLite.
Yo recomendaría Scalable Strategies for Computing with Massive Data. Entre otras cosas, porque para eso lo escribieron sus autores: para que se lea. Y porque está cargado de razón y buenos consejos.
Una cosa con la que tropezará enseguida quien lo hojee es:</description>
    </item>
    
    <item>
      <title>Vectorización en R: un contraejemplo</title>
      <link>/2014/07/04/vectorizacion-en-r-un-contraejemplo/</link>
      <pubDate>Fri, 04 Jul 2014 07:13:15 +0000</pubDate>
      
      <guid>/2014/07/04/vectorizacion-en-r-un-contraejemplo/</guid>
      <description>No hay regla sin excepción, dicen. Para la recomendación casi única para quienes se quejan de la lentitud de R, es decir, ¡vectoriza!, he encontrado hoy una.
Sí, el artículo deja R por los suelos. En el fondo, no tanto, porque viene a decir que R es malo para lo que la documentación de R dice que es malo: véase cómo en Writing R Extensions nos advierten que la convolución is hard to do fast in interpreted R code, but easy in C code.</description>
    </item>
    
    <item>
      <title>Disponible una nueva versión de MicroDatosEs</title>
      <link>/2014/06/27/disponible-una-nueva-version-de-microdatoses/</link>
      <pubDate>Fri, 27 Jun 2014 07:46:29 +0000</pubDate>
      
      <guid>/2014/06/27/disponible-una-nueva-version-de-microdatoses/</guid>
      <description>Acabo de subir a CRAN una nueva versión de MicroDatosEs, un paquete para procesar automáticamente en R ficheros de microdatos públicos españoles.
A los cambios y mejoras a los que me referí el otro día, esta nueva versión añade otras, obra de Carlos Neira, que es ahora contribuidor oficial del paquete.
Carlos también contribuyó a detectar y corregir un error inducido por el INE, que cambió el formato del fichero introduciendo una nueva variable sin aviso previo.</description>
    </item>
    
    <item>
      <title>Grupo de usuarios de R de Portugal</title>
      <link>/2014/06/23/grupo-de-usuarios-de-r-de-portugal/</link>
      <pubDate>Mon, 23 Jun 2014 07:00:39 +0000</pubDate>
      
      <guid>/2014/06/23/grupo-de-usuarios-de-r-de-portugal/</guid>
      <description>Nuestros vecinos portugueses acaban de abrir un foro para sus usuarios de R un poco al estilo de nuestro r-help-es (¿todavía no estás dado de alta en él?).

Espero que les sirva de base para organizar una comunidad vibrante de usuarios. Y que algún día podamos organizar unas Jornadas Ibéricas de Usuarios de R.</description>
    </item>
    
    <item>
      <title>Agrupación de grafos por topología</title>
      <link>/2014/06/13/agrupacion-de-grafos-por-topologia/</link>
      <pubDate>Fri, 13 Jun 2014 07:26:00 +0000</pubDate>
      
      <guid>/2014/06/13/agrupacion-de-grafos-por-topologia/</guid>
      <description>Anuncio algo que no he conseguido hacer: agrupar grafos por topología. Pero no me he quedado lejos. Y espero que si alguien tiene alguna idea al respecto, nos lo haga saber al resto en la coda.
Contexto (disfrazado). Hay usuarios que tienen correos electrónicos. La relación esperada es de uno a uno. Pero la realidad es, como siempre, mucho más compleja: hay usuarios que tienen varios correos y correos compartidos por varios usuarios.</description>
    </item>
    
    <item>
      <title>A vueltas con el t-test</title>
      <link>/2014/06/10/a-vueltas-con-el-t-test/</link>
      <pubDate>Tue, 10 Jun 2014 07:28:17 +0000</pubDate>
      
      <guid>/2014/06/10/a-vueltas-con-el-t-test/</guid>
      <description>Me gustaría no tener que hacer más t-tests en la vida, pero no va a ser el caso.
El problema al que me refiero le surgió a alguien en una galaxia lejana y, de alguna manera, me salpicó y me involucró. Es, simplificándolo mucho, el siguiente.
Tiene una muestra $latex X = x_1, \dots, x_n$ y quiere ver si la media es o no cero. ¿Solución de libro? El t-test. Pero le salen cosas raras e inesperadas.</description>
    </item>
    
    <item>
      <title>Validación cruzada en paralelo</title>
      <link>/2014/06/06/validacion-cruzada-en-paralelo/</link>
      <pubDate>Fri, 06 Jun 2014 07:12:30 +0000</pubDate>
      
      <guid>/2014/06/06/validacion-cruzada-en-paralelo/</guid>
      <description>Estoy sin tiempo, así que os suelto el código y me largo a casa a no cenar. Es así:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/lattice/parallel&amp;quot;&amp;gt;parallel) cl &amp;lt;- makeCluster(8) # solo si hay aleatorización # clusterSetRNGStream(cl, 123) clusterEvalQ(cl, { # las librerías necesarias tienen que cargarse # en cada esclavo library(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/rpart/rpart&amp;quot;&amp;gt;rpart) # en la práctica, hay que cargar los datos # (¿desde fichero?) en cada esclavo my.data &amp;lt;- iris # lo mismo con las funciones necesarias foo &amp;lt;- function(x, dat){ train &amp;lt;- 1:nrow(dat) %% 10 !</description>
    </item>
    
    <item>
      <title>Mínimos cuadrados con restricciones</title>
      <link>/2014/06/05/minimos-cuadrados-con-restricciones/</link>
      <pubDate>Thu, 05 Jun 2014 07:09:02 +0000</pubDate>
      
      <guid>/2014/06/05/minimos-cuadrados-con-restricciones/</guid>
      <description>Sí, había restricciones. No me preguntéis por qué, pero los coeficientes tenían que ser positivos y sumar uno. Es decir, buscaba la combinación convexa de cuatro vectores que más se aproximase a y en alguna métrica razonable. Y lo resolví así:
# prepare constrained optimization y &amp;lt;- dat.clean$actual x &amp;lt;- t(dat.clean[,2:5]) # target function: L2 first, then other metrics L2 &amp;lt;- function(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/coef&amp;quot;&amp;gt;coef){ sum(abs((y - colSums(x * &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/coef&amp;quot;&amp;gt;coef)))^1.5) } # restrictions: coefs &amp;gt; 0, sum(coefs) ~ 1 ui &amp;lt;- rbind(diag(4), c(-1,-1,-1,-1), c(1,1,1,1)) ci &amp;lt;- c(0,0,0,0,-1.</description>
    </item>
    
    <item>
      <title>Nuevo curso: &#34;Big &amp; open data: análisis y programación con R&#34;</title>
      <link>/2014/06/02/nuevo-curso-big-open-data-analisis-y-programacion-con-r/</link>
      <pubDate>Mon, 02 Jun 2014 07:30:28 +0000</pubDate>
      
      <guid>/2014/06/02/nuevo-curso-big-open-data-analisis-y-programacion-con-r/</guid>
      <description>Este verano, la Escuela Complutense de Verano ofrece el curso Big &amp;amp; open data: análisis y programación con R.

Lo anuncio por aquí por tres motivos:
 * Por su interés intrínseco. * Por si alguno de los lectores de estas páginas estuviese interesado. * Porque yo participo/participaría en el programa contando cosas de lo más jugosas.  </description>
    </item>
    
    <item>
      <title>Inserción eficiente (?) de datos vía RJDBC</title>
      <link>/2014/05/27/insercion-eficiente-de-datos-via-rjdbc/</link>
      <pubDate>Tue, 27 May 2014 07:27:54 +0000</pubDate>
      
      <guid>/2014/05/27/insercion-eficiente-de-datos-via-rjdbc/</guid>
      <description>Las bases de datos son instrumentos magníficos con dos defectos fundamentales: es difícil meter datos en ellas y es difícil sacar datos de ellas. Pero guardarlos&amp;hellip; los guardan estupendamente.
Estos días me ha tocado subir a una base de datos tablas bastante grandes y las herramientas proporcionadas por RJDBC para ello, esencialmente dbWriteTable han fallado. Internet no se pone de acuerdo sobre si es un bug de RJDBC o si la culpa la tiene el driver de la base de datos que estoy obligado a utilizar.</description>
    </item>
    
    <item>
      <title>plot.ly: visualización de datos multilenguaje</title>
      <link>/2014/05/23/plot-ly-visualizacion-de-datos-multilenguaje/</link>
      <pubDate>Fri, 23 May 2014 07:16:16 +0000</pubDate>
      
      <guid>/2014/05/23/plot-ly-visualizacion-de-datos-multilenguaje/</guid>
      <description>He recibido hoy un correo sobre plot.ly, que es, según sus autores, una herramienta colaborativa para en análisis y la visualización de datos. Gustará seguramente a los interesados en las APIs: en el fondo, el software reside en la nube.
Permite, por ejemplo, [integrar gráficos interactivos en IPython](http://nbviewer.ipython.org/gist/msund/61cdbd5b22c103fffb84). Aunque no he visto ejemplos de cómo integrarlo con [knitr](http://yihui.name/knitr/). A ver si saco algo de tiempo&amp;hellip;</description>
    </item>
    
    <item>
      <title>V Jornadas de la Enseñanza y Aprendizaje de la Estadística y la Investigación Operativa</title>
      <link>/2014/05/20/v-jornadas-de-la-ensenanza-y-aprendizaje-de-la-estadistica-y-la-investigacion-operativa-2/</link>
      <pubDate>Tue, 20 May 2014 07:42:50 +0000</pubDate>
      
      <guid>/2014/05/20/v-jornadas-de-la-ensenanza-y-aprendizaje-de-la-estadistica-y-la-investigacion-operativa-2/</guid>
      <description>Los días 16 y 17 de junio tendrán lugar en Madrid las V Jornadas de la Enseñanza y Aprendizaje de la Estadística y la Investigación Operativa. Cosa de la que tal vez no hubiese llegado a tener constancia de no haber sido por la gentileza de la organización, que me ha invitado a impartir un taller introductorio al big data.
Serán cuatro horas y media en la mañana del 17 organizadas de la siguiente manera:</description>
    </item>
    
    <item>
      <title>R en paralelo</title>
      <link>/2014/05/15/r-en-paralelo/</link>
      <pubDate>Thu, 15 May 2014 07:13:59 +0000</pubDate>
      
      <guid>/2014/05/15/r-en-paralelo/</guid>
      <description>Trabajo sobre una máquina de 8 núcleos y 24 GB de RAM. Y que conste que se me ha llegado a quedar chica.
Algunos programas que ejecuto tienen (o contienen pedazos de) la forma
 1. calcula A 2. calcula B 3. calcula C 4. combina A, B y C  Obviamente, se me ocurre ejecutarlos así:
 1. calcula A, B y C en paralelo 2. cuando acabe el paso anterior, combina A, B y C  Y aún me sobrarían 5 núcleos y bastante RAM.</description>
    </item>
    
    <item>
      <title>Y sin embargo, te quiero</title>
      <link>/2014/05/14/y-sin-embargo-te-quiero/</link>
      <pubDate>Wed, 14 May 2014 07:20:53 +0000</pubDate>
      
      <guid>/2014/05/14/y-sin-embargo-te-quiero/</guid>
      <description>Copio aquí unas líneas:
Pertenecen al resumen de un artículo que enlazo aquí por si a alguien le intrigan el nudo y el desenlaza de ese planteamiento.</description>
    </item>
    
    <item>
      <title>Nueva versión de MicroDatosEs: héroes, villanos y mejoras</title>
      <link>/2014/05/14/nueva-version-de-microdatoses-heroes-villanos-y-mejoras/</link>
      <pubDate>Wed, 14 May 2014 07:00:28 +0000</pubDate>
      
      <guid>/2014/05/14/nueva-version-de-microdatoses-heroes-villanos-y-mejoras/</guid>
      <description>Ayer odié mucho a José Luis Cañadas —que sigue no obstante siendo amigo: véase más abajo— por esto:
Hubiera preferido reservarme la primicia para todos sus usuarios y simpatizantes de la nueva versión del paquete MicroDatosEs recién subida a CRAN pero&amp;hellip; en fin.
De todos modos José Luis no es el villano de la historia. El villano es el INE, que parió en la mañana del 29 de abril los nuevos resultados de la EPA con un cambio retroactivo de formato en los ficheros de microdatos que rompió mis funciones justo cuando más falta hacían.</description>
    </item>
    
    <item>
      <title>Grid, Scala y arbolitos fractales</title>
      <link>/2014/05/12/grid-scala-y-arbolitos/</link>
      <pubDate>Mon, 12 May 2014 07:39:06 +0000</pubDate>
      
      <guid>/2014/05/12/grid-scala-y-arbolitos/</guid>
      <description>Inspirado por
 * los arbolitos que he visto esta mañana en mi semivuelta al lago de Zúrich, * las cosas que estoy leyendo últimamente sobre el paquete grid de R (p.e., [_grid graphics_](http://stat.ethz.ch/R-manual/R-devel/library/grid/doc/grid.pdf), de Murrell) * mi curso de scala y * [este enlace](http://aschinchon.wordpress.com/2014/04/10/the-pythagorean-tree-is-in-bloom/)  me he decidido a reescribirlo como Dios manda (y no como de primeras se le ocurriría a un neoingeniero al que solo le han enseñado MatLab y que, por lo tanto, tiene vetado el acceso a cualquier tipo de empresa tecnológica puntera).</description>
    </item>
    
    <item>
      <title>Las VI Jornadas de Usuarios de R, en Santiago</title>
      <link>/2014/05/05/las-vi-jornadas-de-usuarios-de-r-en-santiago/</link>
      <pubDate>Mon, 05 May 2014 09:20:17 +0000</pubDate>
      
      <guid>/2014/05/05/las-vi-jornadas-de-usuarios-de-r-en-santiago/</guid>
      <description>Escribo para anunciar públicamente que están en marcha las VI Jornadas de Usuarios de R. Se celebrarán este año en Santiago, los días 23 y 24 de octubre de 2014.
Esta nueva edición debe mucho a la colaboración de Miguel Ángel Rodríguez Muiños, al Centro de Novas Texnologías de Galicia y otras asociaciones gallegas vinculadas al software libre.
Todavía no está disponible el programa (que, en cierto modo, es responsabilidad de vosotros: estáis invitados a enviar propuestas de ponencias y talleres).</description>
    </item>
    
    <item>
      <title>Embalses en España: otro ejercicio inconcluso de &#34;web scraping&#34;</title>
      <link>/2014/04/30/embalses-en-espana-otro-ejercicio-inconcluso-de-web-scraping/</link>
      <pubDate>Wed, 30 Apr 2014 06:51:55 +0000</pubDate>
      
      <guid>/2014/04/30/embalses-en-espana-otro-ejercicio-inconcluso-de-web-scraping/</guid>
      <description>Vi el otro día que alguien había conseguido datos de la entrada en funcionamiento de las presas de EE.UU. y me picó la curiosidad: ¿se podrán conseguir también para España?
La respuesta es afirmativa.
El código para bajarse (y adecentar un poco) la base de datos es:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/XML&amp;quot;&amp;gt;XML) ## bajada de datos tmp &amp;lt;- lapply(1:47, function(x) readLines(paste(&amp;quot;http://www.seprem.es/presases.php?p=&amp;quot;, x, sep = &amp;quot;&amp;quot;))) tmp2 &amp;lt;- lapply(tmp, readHTMLTable) ## limpieza de datos res &amp;lt;- lapply(tmp2, function(x) x[[1]]) res &amp;lt;- do.</description>
    </item>
    
    <item>
      <title>Una de gráficos casi artísticos con R</title>
      <link>/2014/04/25/una-de-graficos-casi-artisticos-con-r/</link>
      <pubDate>Fri, 25 Apr 2014 07:38:35 +0000</pubDate>
      
      <guid>/2014/04/25/una-de-graficos-casi-artisticos-con-r/</guid>
      <description>Hoy traigo una selección a cuatro páginas en que podréis encontrar gráficos casi artísticos creados con R. En la primera de ellas se construye el fractal de Collatz.
En las dos siguientes, los autores construyen animaciones. Una de ellas para ilustrar el mecanismo de la regresión local y el segundo para crear figuras en 3D.

Y el último, trata de mapas. En particular, de cómo sobreimponer sobre ellos datos de rutas.</description>
    </item>
    
    <item>
      <title>Aventuras de &#34;web scraping&#34;: cómo bajarse todo el BOE</title>
      <link>/2014/04/24/aventuras-de-web-scraping-como-bajarse-todo-el-boe/</link>
      <pubDate>Thu, 24 Apr 2014 07:47:56 +0000</pubDate>
      
      <guid>/2014/04/24/aventuras-de-web-scraping-como-bajarse-todo-el-boe/</guid>
      <description>Rescato aquí para futura o ajena referencia un pedazo de código que utilicé un día para un proyecto que se abortó y que tenía que ver con el análisis del texto del BOE. Reza así:
setwd(&amp;quot;~/boe/boes&amp;quot;) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/RCurl&amp;quot;&amp;gt;RCurl) h = getCurlHandle() for( i in 1:3231){ mi.url &amp;lt;- paste(&amp;quot;http://www.boe.es/diario_boe/xml.php?id=BOE-A-2013-&amp;quot;, i, sep = &amp;quot;&amp;quot;) nom.fich &amp;lt;- paste(&amp;quot;2013-A-&amp;quot;, formatC(i, width = 6, format = &amp;quot;d&amp;quot;, flag = &amp;quot;0&amp;quot;), &amp;quot;.xml&amp;quot;, sep = &amp;quot;&amp;quot;) res &amp;lt;- getURI(mi.</description>
    </item>
    
    <item>
      <title>Reponderación de componentes: un ejemplo</title>
      <link>/2014/04/22/reponderacion-de-componentes-un-ejemplo/</link>
      <pubDate>Tue, 22 Apr 2014 07:09:56 +0000</pubDate>
      
      <guid>/2014/04/22/reponderacion-de-componentes-un-ejemplo/</guid>
      <description>Esta entrada es la continuación de La escala natural de la varianza. En ella vimos cómo los componentes de un PCA pueden tener un peso que pudiera no guardar relación con su importancia práctica.
Si uno quiere trabajar con las principales componentes de un PCA sobre unos datos, puede que la escala sea irrelevante (p.e., si quiere utilizar modelos lineales). Pero hay casos egregios en los que no sucede así.</description>
    </item>
    
    <item>
      <title>@R_Hisp, la cuenta oficial de la Comunidad R Hispano</title>
      <link>/2014/04/14/r_hips-la-cuenta-oficial-de-la-comunidad-r-hispano/</link>
      <pubDate>Mon, 14 Apr 2014 07:10:57 +0000</pubDate>
      
      <guid>/2014/04/14/r_hips-la-cuenta-oficial-de-la-comunidad-r-hispano/</guid>
      <description>Finalmente, la Comunidad R Hispano dispone de una cuenta oficial en Twitter.
El anuncio público lo realizó Emilio López Cano, miembro de la junta de la asociación y que va a coordinar la cuenta con ayuda de otros voluntarios.
Os animo a seguir esa cuenta para estar al tanto de las novedades de la asociación en la que, como dice Emilio (en el enlace anterior), hay y va a seguir habiendo movimiento.</description>
    </item>
    
    <item>
      <title>No hay motivo para no actualizar tu R a la última versión</title>
      <link>/2014/04/11/no-hay-motivo-para-no-actualizar-tu-r-a-la-ultima-version/</link>
      <pubDate>Fri, 11 Apr 2014 21:00:59 +0000</pubDate>
      
      <guid>/2014/04/11/no-hay-motivo-para-no-actualizar-tu-r-a-la-ultima-version/</guid>
      <description>Ayer se publicó la versión 3.1.0 de R. No es gran noticia: aparecen nuevas versiones cada no muchos meses.
No hay motivo para no actualizar. Pero sí para hacerlo: las nuevas versiones corrigen errores en las anteriores y, además, encontrarás poco soporte en los foros para ese R 2.1.5 viejuno que aún mantienes por pereza.
Para quienes usen R en plataformas donde el software no se actualiza automágicamente, existe el paquete installr que permite actualizar la versión de R con menos esfuerzo que antaño haciendo</description>
    </item>
    
    <item>
      <title>Mapas: cosas casi increíbles que pueden hacerse con R</title>
      <link>/2014/03/27/mapas-cosas-casi-increibles-que-pueden-hacerse-con-r/</link>
      <pubDate>Thu, 27 Mar 2014 07:23:26 +0000</pubDate>
      
      <guid>/2014/03/27/mapas-cosas-casi-increibles-que-pueden-hacerse-con-r/</guid>
      <description>Nunca pude ser un erizo. Lo intenté durante años y acabé en el sicólogo. Si el cuerpo me hubiese dado, ahora, tal vez, como algunos compañeros de promoción, sería un experto en un área diminuta del conocimiento y corregiría exámenes los fines de semana. Descubrí con tiempo y muchas sesiones de a 60 euros la hora que había nacido para ser un zorro, un merodeador que olisquea aquí y allá.</description>
    </item>
    
    <item>
      <title>Totales agregados por bloques en tablas</title>
      <link>/2014/03/25/totales-agregados-por-bloques-en-tablas/</link>
      <pubDate>Tue, 25 Mar 2014 07:45:50 +0000</pubDate>
      
      <guid>/2014/03/25/totales-agregados-por-bloques-en-tablas/</guid>
      <description>En ocasiones uno quiere añadir un total calculado en ciertos bloques a una tabla. Por ejemplo, en la tabla
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) ventas.orig &amp;lt;- data.frame(cliente = rep(1:10, each = 5), producto = rep(letters[1:5], times = 10), importe = &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/rlnorm&amp;quot;&amp;gt;rlnorm(50))  tenemos clientes, productos e importes. Y nos preguntamos por el porcentaje en términos de importe que cada producto supone para cada cliente.
Una manera natural pero torpe de realizar este cálculo consiste en usar un objeto intermedio y merge:</description>
    </item>
    
    <item>
      <title>Cuatro enlaces sobre R: Excel, C&#43;&#43;, CSV y paralelización</title>
      <link>/2014/03/21/cuatro-enlaces-sobre-r-excel-c-csv-y-paralelizacion/</link>
      <pubDate>Fri, 21 Mar 2014 07:44:31 +0000</pubDate>
      
      <guid>/2014/03/21/cuatro-enlaces-sobre-r-excel-c-csv-y-paralelizacion/</guid>
      <description>Hoy traigo a mis páginas cuatro enlaces que apuntan a recetarios y tutoriales sobre la solución a cuatro problemas que pueden encontrar los usuarios de R:
 * [Conectar R y Excel](http://www.thertrader.com/2014/02/11/a-million-ways-to-connect-r-and-excel/) * [Importar grandes ficheros CSV](http://statcompute.wordpress.com/2014/02/11/efficiency-of-importing-large-csv-files-in-r/) (y falta [`LaF`](http://cran.fhcrc.org/web/packages/LaF/index.html)) * [Integrar R con C/C++](http://anythingbutrbitrary.blogspot.ch/2014/02/three-ways-to-call-cc-from-r.html) * [Paralelizar código con `snow`](http://hernanresnizky.com/2014/01/10/quick-guide-to-parallel-r-with-snow/)  ¡Espero que os resulten útiles!</description>
    </item>
    
    <item>
      <title>Los sospechosos habituales y Python</title>
      <link>/2014/03/20/los-sospechosos-habituales-y-python/</link>
      <pubDate>Thu, 20 Mar 2014 08:44:17 +0000</pubDate>
      
      <guid>/2014/03/20/los-sospechosos-habituales-y-python/</guid>
      <description>Llamo sospechosos habituales a esos programas y lenguajes para el análisis de datos distintos de R cuya decreciente popularidad nos parece tan natural a los partidarios de este último. Abundan los análisis de cuotas de mercado tales como What Analytic Software are People Discussing?
¿Cuáles son estos sospechosos habituales? Pues SAS, SPSS y algún otro: Stata, Statistica, Minitab,&amp;hellip;
Sin embargo, R tiene competidores más serios a medio plazo. Uno de ellos, el más importante, es Python.</description>
    </item>
    
    <item>
      <title>Series temporales, datos espaciales y espacio-temporales con R</title>
      <link>/2014/03/19/series-temporales-datos-espaciales-y-espacio-temporales-con-r/</link>
      <pubDate>Wed, 19 Mar 2014 07:59:05 +0000</pubDate>
      
      <guid>/2014/03/19/series-temporales-datos-espaciales-y-espacio-temporales-con-r/</guid>
      <description>Acaba de publicarse Displaying Time Series, Spatial, and Space-Time Data with R, un libro de Óscar Perpiñán que, conociéndolo como lo conozco, me atrevo a recomendar sin haberlo hojeado siquiera.

Además, Óscar nos ha regalado una guía sobre cómo escribir un libro técnico con Emacs y otras herramientas libres.</description>
    </item>
    
    <item>
      <title>Selección de enlaces: censos, el Titanic, periodistas y mapas</title>
      <link>/2014/03/14/seleccion-de-enlaces-censos-el-titanic-periodistas-y-mapas/</link>
      <pubDate>Fri, 14 Mar 2014 08:58:31 +0000</pubDate>
      
      <guid>/2014/03/14/seleccion-de-enlaces-censos-el-titanic-periodistas-y-mapas/</guid>
      <description>El primer enlace de la selección de esta semana es The evolution of the modern census. Todos sabemos que lo que llevó a José y María a Belén hace más de 2000 años fue dizque tenían que censarse. Hay noticias de censos anteriores. Desde entonces hasta ahora ha habido muchos, muchísimos censos, pero su mismo concepto y finalidad ha ido cambiando a lo largo de la historia: ya no se trata solamente de contar, medir la riqueza o el poderío militar.</description>
    </item>
    
    <item>
      <title>El escritor exemplar</title>
      <link>/2014/03/13/el-escritor-exemplar/</link>
      <pubDate>Thu, 13 Mar 2014 07:45:27 +0000</pubDate>
      
      <guid>/2014/03/13/el-escritor-exemplar/</guid>
      <description>Eso reza el pie de página de El escritor exemplar un artilugio que a veces crea frases tales como

que debieran ser aleatorias, no muy distintas en estilo de las Novelas Ejemplares y, con muchísima suerte, inspiradoras.
Hay más detalles sobre el proyecto aquí.
El motor que las genera, que es producto de mi cacumen —por lo que a él y solo a él cabe culpar de los deméritos de la cosa—, muestrea una cadena de Markov de segundo orden construida a partir de secuencias de palabras que figuran en las Novelas Ejemplares.</description>
    </item>
    
    <item>
      <title>Veinte paquetes de R para científicos de datos</title>
      <link>/2014/03/12/veinte-paquetes-de-r-para-cientificos-de-datos/</link>
      <pubDate>Wed, 12 Mar 2014 07:11:28 +0000</pubDate>
      
      <guid>/2014/03/12/veinte-paquetes-de-r-para-cientificos-de-datos/</guid>
      <description>Me llegó recientemente un artículo con una lista de veinte paquetes de R para data scientists. Y no la encuentro afortunada. Voy a agrupar esos veinte paquetes en algunas categorías y añadiré comentarios. La primera de ellas es la de manipulación de datos, tal vez la más amplia, que recoge los siguientes: sqldf, plyr, stringr (para procesar texto), lubridate (para procesar fechas),reshape2 y los paquetes de acceso a bases de datos.</description>
    </item>
    
    <item>
      <title>Guarjolización de fotos con R</title>
      <link>/2014/03/10/guarjolizacion-de-fotos-con-r/</link>
      <pubDate>Mon, 10 Mar 2014 07:07:47 +0000</pubDate>
      
      <guid>/2014/03/10/guarjolizacion-de-fotos-con-r/</guid>
      <description>Inspirado en esto aunque con la intención de mejorar el horrible código adjunto, escribí el otro día esto:
library(&amp;quot;biOps&amp;quot;) library(&amp;quot;cluster&amp;quot;) # leo una foto usando readJpeg de biOps # el objeto devuelto es un array mxnx3 dimensional # la última dimensión es el rgb de cada pixel tmp &amp;lt;- tempfile() &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/download.file&amp;quot;&amp;gt;download.file(&amp;quot;http://blog.guiasenior.com/images/Retrato_Garber.jpg&amp;quot;, tmp) x &amp;lt;- readJpeg(tmp) # si quieres mostrar la foto como un gráfico... #plot(x) # convertimos el array 3D nxmx3 en uno 2D (nm)x3 # luego buscamos 5 clústers # esencialmente, buscamos 7 &amp;quot;píxels representativos&amp;quot; d &amp;lt;- dim(x) clarax &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Victoria o diferencia de puntos, ahora con &#34;random forests&#34;</title>
      <link>/2014/03/07/victoria-o-diferencia-de-puntos-ahora-con-random-forests/</link>
      <pubDate>Fri, 07 Mar 2014 07:35:05 +0000</pubDate>
      
      <guid>/2014/03/07/victoria-o-diferencia-de-puntos-ahora-con-random-forests/</guid>
      <description>Después de hablar con tirios y troyanos sobre mi entrada sobre los efectos de binarizar una variable objetivo continua, he decidido tomarme la justicia por mi mano y llamar a la caballería. Es decir, utilizar random forests.
Aquí va el código:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/randomForest&amp;quot;&amp;gt;randomForest) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) my.coefs &amp;lt;- -2:2 n &amp;lt;- 200 train.n &amp;lt;- floor(2*n/3) test.error &amp;lt;- function(){ X &amp;lt;- matrix(rnorm(n*5), n, 5) Y &amp;lt;- 0.2 + X %*% my.coefs + rnorm(n) Y.</description>
    </item>
    
    <item>
      <title>¿Victoria o diferencia de puntos? ¿lm o glm?</title>
      <link>/2014/03/04/victoria-o-diferencia-de-puntos-lm-o-glm/</link>
      <pubDate>Tue, 04 Mar 2014 07:08:18 +0000</pubDate>
      
      <guid>/2014/03/04/victoria-o-diferencia-de-puntos-lm-o-glm/</guid>
      <description>Supongamos que queremos construir un modelo para predecir quién ganará un determinado partido de baloncesto basándonos en datos diversos. Y en un histórico, por supuesto.
Podemos utilizar una regresión logística así:
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) my.coefs &amp;lt;- -2:2 n &amp;lt;- 200 train.n &amp;lt;- floor(2*n/3) test.error.glm &amp;lt;- function(){ X &amp;lt;- matrix(rnorm(n*5), n, 5) Y &amp;lt;- (0.2 + X %*% my.coefs + rnorm(n)) &amp;gt; 0 train &amp;lt;- sample(1:n, train.n) X &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/as.data.frame&amp;quot;&amp;gt;as.data.frame(X) X$Y &amp;lt;- Y mod.</description>
    </item>
    
    <item>
      <title>Selección de enlaces: redes sociales, gráficos con R, ofertas de trabajo y p-valores</title>
      <link>/2014/02/28/seleccion-de-enlaces-redes-sociales-graficos-con-r-ofertas-de-trabajo-y-p-valores/</link>
      <pubDate>Fri, 28 Feb 2014 08:21:09 +0000</pubDate>
      
      <guid>/2014/02/28/seleccion-de-enlaces-redes-sociales-graficos-con-r-ofertas-de-trabajo-y-p-valores/</guid>
      <description>Acá va otra selección de cuatro enlaces relevantes –que no necesariamente nuevos— de la semana. El primero, Using Metadata to find Paul Revere recoge a modo de historia, que algunos encontrarán amena, una aplicación de rudimentos del álgebra lineal al análisis de redes sociales. Dada una matriz de incidencia A (personas que pertenecen a clubes) es posible calcular índices de proximidad entre personas (o entre clubes) calculando no más AA&#39;. El resto hasta ganar el premio de Netflix es pura heurística.</description>
    </item>
    
    <item>
      <title>Curso de análisis de datos &#39;ómicos&#39; con R</title>
      <link>/2014/02/26/curso-de-analisis-de-datos-omicos-con-r/</link>
      <pubDate>Wed, 26 Feb 2014 07:37:40 +0000</pubDate>
      
      <guid>/2014/02/26/curso-de-analisis-de-datos-omicos-con-r/</guid>
      <description>Copio aquí el anuncio de un nuevo curso de análisis de datos (ómicos en este caso) con R:
 Nos complace anunciaros que el CREAL organiza la segunda edición del &amp;ldquo;Curso de análisis de estadístico de datos ómicos&amp;rdquo; que va a celebrarse los días 8, 9 y 10 de abril de 2014. AdjuntoDebajo podréis encontrar cómo hacer la inscripción que se llevará a cabo por estricto orden de petición y sólo será posible para los primeros 16 pre-inscritos.</description>
    </item>
    
    <item>
      <title>Cuatro enlaces: sanidad, correos electrónicos, leyes y errores de programación</title>
      <link>/2014/02/21/cuatro-enlaces-sanidad-correos-electronicos-leyes-y-errores-de-programacion/</link>
      <pubDate>Fri, 21 Feb 2014 08:42:59 +0000</pubDate>
      
      <guid>/2014/02/21/cuatro-enlaces-sanidad-correos-electronicos-leyes-y-errores-de-programacion/</guid>
      <description>El primero es Freer trade in European and Spanish health care services y trata sobre los efectos en el sistema sanitario español de una directiva europea que liberaliza el acceso a los ciudadanos de al unión a los servicios de salud de otros países.
En concreto, el artículo argumenta cómo España podría ser uno de los países más afectados por dos razones:
 1. El flujo de extranjeros que atrae el país.</description>
    </item>
    
    <item>
      <title>La bolsa intradía y bolsa interdía</title>
      <link>/2014/02/20/la-bolsa-intradia-y-bolsa-interdia/</link>
      <pubDate>Thu, 20 Feb 2014 08:29:43 +0000</pubDate>
      
      <guid>/2014/02/20/la-bolsa-intradia-y-bolsa-interdia/</guid>
      <description>El IBEX 35 abre todas las mañanas a un precio y cierra a otro. El precio de apertura de un día no es necesariamente igual al del cierre del siguiente. Por lo tanto, la variación del índice en una jornada completa de 24 horas es igual a la suma de las variaciones dentro y fuera del horario de cotización.
Dicho lo cual:
 * Juan _compra el IBEX_ todos los días a primera hora y lo vende en el último minuto.</description>
    </item>
    
    <item>
      <title>Ofertón: tarifa plana de GasNaturalFenosa</title>
      <link>/2014/02/19/oferton-tarifa-plana-de-gasnaturalfenosa/</link>
      <pubDate>Wed, 19 Feb 2014 08:34:17 +0000</pubDate>
      
      <guid>/2014/02/19/oferton-tarifa-plana-de-gasnaturalfenosa/</guid>
      <description>En medio del fragor mediático sobre el precio de la electricidad, me ha llegado un ofertón de GasNaturalFenosa: la posibilidad de contratar una tarifa plana para la electricidad.
La entrada de hoy es el debido ejercicio acerca de si me conviene o no contratarla. En R, por supuesto.
Primero, el código:
library(ggplot2) # tramos tarifas planas tarifas &amp;lt;- c(&amp;quot;micro&amp;quot;, &amp;quot;mini&amp;quot;, &amp;quot;media&amp;quot;, &amp;quot;maxi&amp;quot;, &amp;quot;extra&amp;quot;) dat &amp;lt;- data.frame( tarifas = factor(tarifas, levels = tarifas), hasta = c(1500, 2500, 4000, 5500, 7000), tarifa.</description>
    </item>
    
    <item>
      <title>El yuyuplot en perspectiva</title>
      <link>/2014/02/18/el-yuyuplot-en-perspectiva/</link>
      <pubDate>Tue, 18 Feb 2014 08:41:17 +0000</pubDate>
      
      <guid>/2014/02/18/el-yuyuplot-en-perspectiva/</guid>
      <description>El yuyuplot al que me refiero es

un gráfico ha circulado por internet y que ha causado cierto pánico, se ve (y de ahí el nombre). En algunos sitios —véase este como ejemplo de los menos acertados— se ha intentado de explicar al público sus deméritos.
El mundo de las finanzas debiera ser la envidia de otros ámbitos por el volumen, variedad y velocidad de los datos disponibles en él.</description>
    </item>
    
    <item>
      <title>Mi solución al otro problema del cumpleaños</title>
      <link>/2014/02/13/mi-solucion-al-otro-problema-del-cumpleanos/</link>
      <pubDate>Thu, 13 Feb 2014 07:23:19 +0000</pubDate>
      
      <guid>/2014/02/13/mi-solucion-al-otro-problema-del-cumpleanos/</guid>
      <description>Pues eso, que me piqué —y parte de la culpa la tiene este sujeto— con el otro problema del cumpleaños y he aquí el código —exacto salvo redondeos, no mediante simulaciones— que he usado para resolverlo:
f &amp;lt;- function(n, k = 365, v = NULL){ if(&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/is.null&amp;quot;&amp;gt;is.null(v)) v &amp;lt;- c(1, rep(NA, k)) res &amp;lt;- 1 for(j in (k-1):1){ v[k-j] &amp;lt;- ifelse( is.na(v[k-j]), f(n, k-j, v), v[k-j]) res &amp;lt;- res - choose(k,j) * ((k-j)/k)^n * v[k-j] } res } f(2287) #0.</description>
    </item>
    
    <item>
      <title>De ratios, apuestas y riesgos</title>
      <link>/2014/02/12/de-ratios-apuestas-y-riesgos/</link>
      <pubDate>Wed, 12 Feb 2014 07:49:19 +0000</pubDate>
      
      <guid>/2014/02/12/de-ratios-apuestas-y-riesgos/</guid>
      <description>Nunca he entendido eso de los odds. Me refiero a eso que mencionan las películas: ocho contra uno a favor de tal, cinco contra tres a favor de cual. Y no creo que sea el único al que le son ajenos. De hecho, la página de la Wikipedia en español correspondiente a la inglesa para odds se refiere a ellas como cuotas, término que jamás hasta hoy había visto así usado.</description>
    </item>
    
    <item>
      <title>Guía de estilo de R (de Google)</title>
      <link>/2014/01/27/guia-de-estilo-de-r-de-google/</link>
      <pubDate>Mon, 27 Jan 2014 08:21:42 +0000</pubDate>
      
      <guid>/2014/01/27/guia-de-estilo-de-r-de-google/</guid>
      <description>R es un lenguaje de programación de alto nivel que se usa principalmente en aplicaciones estadísticas y para la generación de gráficos. El objetivo de esta guía de estilo es que nuestro código sea más fácil de leer, compartir y analizar. Las reglas de esta guía fueron consensuadas con la comunidad de usuarios de R en Google.
 * **Resumen de las reglas de estilo** 1. Nombres de ficheros: tienen la extensión `.</description>
    </item>
    
    <item>
      <title>Macros sintácticas con R</title>
      <link>/2014/01/16/macros-sintacticas-con-r/</link>
      <pubDate>Thu, 16 Jan 2014 08:31:50 +0000</pubDate>
      
      <guid>/2014/01/16/macros-sintacticas-con-r/</guid>
      <description>Creo que muchos hemos tropezado con las macros alguna vez. Yo conocía las del preprocesador de C o el tinglado que tiene SAS. Y nunca fui muy amigo de ellas.
Pero el otro día leí Stop Writing JavaScript Compilers! Make Macros Instead y se me alargaron los dientes. Así que he buscado información adicional hasta hacerme una idea de la diferencia entre una macro que se limita a reemplazar texto, una macro procedural —como las del lenguaje PL/I, antecesor e inspirador de SAS— y las sintácticas, como las que tiene Lisp (¿cuándo tendré tiempo para aprenderlo en condiciones?</description>
    </item>
    
    <item>
      <title>Curso de estadística y R de Hastie y Tibshirani</title>
      <link>/2014/01/15/curso-de-estadistica-y-r-de-hastie-y-tibshirani/</link>
      <pubDate>Wed, 15 Jan 2014 08:28:07 +0000</pubDate>
      
      <guid>/2014/01/15/curso-de-estadistica-y-r-de-hastie-y-tibshirani/</guid>
      <description>Los profesores Hastie y Tibshirani, coautores de Elements of Statistical Learning, de muchas técnicas predictivas y, todo hay que decirlo, ídolos intelectuales míos, organizan un MOOC gratuito, Statistical Learning entre el 21 de enero y el 22 de marzo.
Si estás leyendo esto (es decir, si has aterrizado en mi bitácora), te interesa. Si no te apuntas, te aviso, te arrepentirás.
Dicho lo cual, yo estaré ahí. Y se cuenta que podrían organizarse grupos locales de participantes —p.</description>
    </item>
    
    <item>
      <title>Nueva edición de mi taller de R y Hadoop en Zaragoza</title>
      <link>/2014/01/13/nueva-edicion-de-mi-taller-de-r-y-hadoop-en-zaragoza/</link>
      <pubDate>Mon, 13 Jan 2014 08:03:37 +0000</pubDate>
      
      <guid>/2014/01/13/nueva-edicion-de-mi-taller-de-r-y-hadoop-en-zaragoza/</guid>
      <description>Los días 17 y 18 de enero impartiré una versión extendida (¡siete horas!) de mi taller de R y Hadoop en Zaragoza. Para los interesados:
 * [Información adicional](http://www.zaragoza.es/ciudad/centros/detalle_Agenda?id=113212) (fechas, horas, lugar) * [Requisitos de hardware y software para el taller](http://www.datanalytics.com/blog/2013/12/02/requisitos-para-mi-taller-de-hadoop-r-en-las-v-jornadas-de-usuarios-de-r/)  El temario será el mismo que en las ediciones anteriores aunque en esta ocasión habrá más tiempo para profundizar en algunos conceptos, realizar ejercicios adicionales, etc.</description>
    </item>
    
    <item>
      <title>Tres artículos curiosos sobre gráficos </title>
      <link>/2013/12/27/tres-articulos-curiosos-sobre-graficos/</link>
      <pubDate>Fri, 27 Dec 2013 07:50:07 +0000</pubDate>
      
      <guid>/2013/12/27/tres-articulos-curiosos-sobre-graficos/</guid>
      <description>El primero es How to display data badly, de H. Wainer. Es un poco viejo, de 1984; pero, desgraciadamente, tan vigente si no más. Trata, como puede preverse, del mismo y ya algo manido tema: cómo crear gráficos que representen datos clara y eficazmente. Se agradece que el autor, no sin ironía, lo haya planteado a modo de recetario para conseguir justo lo contrario.
El segundo, Visualizing the Law: Using Charts, Diagrams, and Other Images to Improve Legal Briefs, de A.</description>
    </item>
    
    <item>
      <title>Muestreos aleatorios sobre la península Ibérica, por ejemplo</title>
      <link>/2013/12/26/muestreos-aleatorios-sobre-la-peninsula-iberica-por-ejemplo/</link>
      <pubDate>Thu, 26 Dec 2013 07:10:39 +0000</pubDate>
      
      <guid>/2013/12/26/muestreos-aleatorios-sobre-la-peninsula-iberica-por-ejemplo/</guid>
      <description>El problema fue sugerido por Eloy Ortiz en un mensaje a r-help-es. Quería saber cómo muestrear aleatoriamente (i.e., uniformemente) puntos sobre una región de la superficie terrestre delimitada por su bounding box (i.e., las coordenadas que definen un rectángulo sobre la esfera).
Obviamente, no vale con muestrear latitud y longitud uniformemente: el área comprendida entre dos meridianos cerca del ecuador es mayor que la comprendida entre otros dos más próximos al polo.</description>
    </item>
    
    <item>
      <title>¿Cuánta gente usará R (vs Python vs otros) dentro de 1000 años?</title>
      <link>/2013/12/18/cuanta-gente-usara-r-vs-python-vs-otros-dentro-de-1000-anos/</link>
      <pubDate>Wed, 18 Dec 2013 07:23:00 +0000</pubDate>
      
      <guid>/2013/12/18/cuanta-gente-usara-r-vs-python-vs-otros-dentro-de-1000-anos/</guid>
      <description>Pues no lo sé. Seguramente, nadie. Pero como he visto esto (que no es otra forma que una representación palabrera de una matriz de transiciones de Markov) y el debate R vs Python para el análisis de datos ha resonado estos últimos días con cierta fuerza, voy a ensayar un pequeño divertimento matemático que me traslada a una clase práctica de Álgebra I en mis años de estudiante.
Es el siguiente:</description>
    </item>
    
    <item>
      <title>¿Te queda lejos el aeropuerto?</title>
      <link>/2013/12/10/te-queda-lejos-el-aeropuerto/</link>
      <pubDate>Tue, 10 Dec 2013 07:39:16 +0000</pubDate>
      
      <guid>/2013/12/10/te-queda-lejos-el-aeropuerto/</guid>
      <description>He construido el mapa

porque, a pesar de sus innegables deméritos gráficos, como la profusión de topos rojigualdas, pudiera resultar de interés. No tanto por lo que representa, la distancia de los puntos de la península Ibérica a una lista obsoleta de aeropuertos (en la que no consta, p.e., el de Logroño), sino por el procedimiento que tal vez alguien pueda en su día reaprovechar para un mejor fin.</description>
    </item>
    
    <item>
      <title>¿Cuántos peces hay en un lago?</title>
      <link>/2013/12/05/cuantos-peces-hay-en-un-lago/</link>
      <pubDate>Thu, 05 Dec 2013 07:14:48 +0000</pubDate>
      
      <guid>/2013/12/05/cuantos-peces-hay-en-un-lago/</guid>
      <description>Quien haya estudiado estadística o probabilidad en algún tipo de institución que ofrece educación reglada se habrá topado con el problema de estimar el número de peces de un lago.
Esencialmente, lo que puede hacerse (dado que es imposible realizar un censo completo) es lo siguiente:
 * Pescar cierto número de peces, p1, marcarlos y devolverlos al lago. * Pescar cierto número de peces, p2, y contar cuántos de ellos fueron marcados el día anterior, n.</description>
    </item>
    
    <item>
      <title>Ayuda de R en español</title>
      <link>/2013/12/04/ayuda-de-r-en-espanol/</link>
      <pubDate>Wed, 04 Dec 2013 07:43:34 +0000</pubDate>
      
      <guid>/2013/12/04/ayuda-de-r-en-espanol/</guid>
      <description>He ejecutado hoy tres ficheros secuencialmente:
&amp;lt;code&amp;gt;#!/bin/bash wget -nd -r -l1 --accept gz https://stat.ethz.ch/pipermail/r-help-es/ zcat *.gz &amp;gt; all_mails rm *.gz&amp;lt;/code&amp;gt;  en sh,
&amp;lt;code&amp;gt;#!/usr/bin/python import mailbox from email.utils import parsedate from time import mktime for message in mailbox.mbox(&#39;all_mails&#39;): fecha = parsedate(message[&amp;quot;date&amp;quot;]) print str(fecha[0]) + &amp;quot;-&amp;quot; + str(fecha[1])&amp;lt;/code&amp;gt;  en Python y finalmente
&amp;lt;code&amp;gt;#!/usr/bin/Rscript library(zoo) meses &amp;lt;- read.table(&amp;quot;horas.txt&amp;quot;)[,1] meses &amp;lt;- paste(meses, &amp;quot;-1&amp;quot;, sep = &amp;quot;&amp;quot;) meses &amp;lt;- table(meses) meses &amp;lt;- zoo(meses, order.</description>
    </item>
    
    <item>
      <title>Requisitos para mi taller de Hadoop &#43; R en las V Jornadas de Usuarios de R</title>
      <link>/2013/12/02/requisitos-para-mi-taller-de-hadoop-r-en-las-v-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 02 Dec 2013 07:18:55 +0000</pubDate>
      
      <guid>/2013/12/02/requisitos-para-mi-taller-de-hadoop-r-en-las-v-jornadas-de-usuarios-de-r/</guid>
      <description>El jueves 12 de diciembre impartiré un taller titulado Big data analytics: R + Hadoop en las V Jornadas de Usuarios de R.
Va a ser un taller práctico y eso exige de los asistentes que quieran aprovecharlo disponer de una plataforma (¡no trivial!) sobre la que seguirlo y poder realizar los ejercicios. Además de poder seguir ahondando en el asunto después y por su cuenta.
Los requisitos son los siguientes:</description>
    </item>
    
    <item>
      <title>Óscar Perpiñán sobre gráficos base vs. lattice vs ggplot2</title>
      <link>/2013/11/29/oscar-perpinan-sobre-graficos-base-vs-lattice-vs-ggplot2/</link>
      <pubDate>Fri, 29 Nov 2013 06:58:02 +0000</pubDate>
      
      <guid>/2013/11/29/oscar-perpinan-sobre-graficos-base-vs-lattice-vs-ggplot2/</guid>
      <description>Óscar Perpiñán es alguien a quien tenéis que conocer necesariamente si os interesan, entre otras cosas, temas como la visualización de datos espaciotemporales. Y tiene un blog muy recomendable.
Recientemente me ha dado permiso para reproducir aquí una respuesta suya en un hilo planteado en r-help-es sobre los distintos mecanismos existentes en R para generar gráficos. Lo hago a continuación con mínimos retoques tipográficos:
La ventaja esencial de los gráficos grid (lattice y ggplot2) frente a los gráficos base es su mayor flexibilidad para añadir o modificar el contenido.</description>
    </item>
    
    <item>
      <title>Un pequeño problema de probabilidad</title>
      <link>/2013/11/22/un-pequeno-problema-de-probabilidad/</link>
      <pubDate>Fri, 22 Nov 2013 07:14:13 +0000</pubDate>
      
      <guid>/2013/11/22/un-pequeno-problema-de-probabilidad/</guid>
      <description>El tuit

de John Allen Paulos me indujo a escribir
number.numbers &amp;lt;- function(n){ sum(cumsum(sample(0:n)) &amp;lt; n) + 1 } res &amp;lt;- replicate(10000, number.numbers(1000))  código con el que, efectivamente, puede comprobarse que la media es, efectivamente, e.
Ahora bien, ¿alguien se atreve a explicar por qué?
(No leas esta pista: (s??)?s??).</description>
    </item>
    
    <item>
      <title>rPython, ya en Windows</title>
      <link>/2013/11/21/rpython-ya-en-windows/</link>
      <pubDate>Wed, 20 Nov 2013 22:43:56 +0000</pubDate>
      
      <guid>/2013/11/21/rpython-ya-en-windows/</guid>
      <description>Aprovechando que por un lado las circunstancias han querido que ahora disfrute de más tiempo libre; que, por otro, mi paquete rPython parece ir ganando aceptación y, finalmente, que tengo varios correos pendientes clamando por una versión en Windows, he pasado unos ratos tratando de hacer el proceso de instalación lo menos pesado y manual que me ha sido posible.
Y el resultado ha sido este.
Así que si alguien todavía sigue usando Windows y tiene interés en interactuar con Python desde R (aunque solo sea por aburrimiento), que lo pruebe.</description>
    </item>
    
    <item>
      <title>La red Asia</title>
      <link>/2013/11/19/la-red-asia/</link>
      <pubDate>Tue, 19 Nov 2013 07:33:28 +0000</pubDate>
      
      <guid>/2013/11/19/la-red-asia/</guid>
      <description>La red Asia es esto:

Es decir, una red bayesiana. Una red bayesiana clásica sobre la que los interesados podrán saber más leyendo lo que Lauritzen y Spiegelhalter dejaron escrito sobre ella en 1988.
Pero la idea básica es la siguiente:
 * Los nodos superiores (visita a Asia, fumador) son variables observables sobre el comportamiento de unos pacientes. * Los nodos inferiores (rayos X, [disnea](http://es.wikipedia.org/wiki/Disnea)) son variables también observables, síntomas de esos pacientes.</description>
    </item>
    
    <item>
      <title>5000 paquetes de R en CRAN</title>
      <link>/2013/11/11/5000-paquetes-de-r-en-cran/</link>
      <pubDate>Sun, 10 Nov 2013 23:10:02 +0000</pubDate>
      
      <guid>/2013/11/11/5000-paquetes-de-r-en-cran/</guid>
      <description>CRAN (el Comprehensive R Archive Network) acaba de superar la barrera de los 5000 paquetes. Reproduzco (y traduzco) un mensaje de Henrik Bengtsson en la lista de desarrollo de R que ofrece más información al respecto:
Pasar de los 4000 a los 5000 paquetes tardó 14.5 meses, un paquete nuevo cada 10.5 horas. Detrás de cada paquete hay gente real. En total, 2900 personas mantienen paquetes, de los que 350 son nuevos, y muchos más que contribuyen a ellos.</description>
    </item>
    
    <item>
      <title>Importancia de variables en árboles</title>
      <link>/2013/11/06/importancia-de-variables-en-arboles/</link>
      <pubDate>Wed, 06 Nov 2013 07:49:59 +0000</pubDate>
      
      <guid>/2013/11/06/importancia-de-variables-en-arboles/</guid>
      <description>Los árboles (o árboles de inferencia condicional) valen fundamentalmente para hacerse una idea de cómo y en qué grado opera una variable en un modelo controlando por el efecto del resto. Su valor reside fundamentalmente en la interpretabilidad.
No obstante lo cual, no es infrecuente construir árboles muy grandes. Y el tamaño dificulta censar qué variables y en qué manera aparecen. Por eso me vi obligado recientemente a crear un pequeño prototipo para extraer el peso de las variables de un árbol.</description>
    </item>
    
    <item>
      <title>Un récord personal</title>
      <link>/2013/11/04/un-record-personal/</link>
      <pubDate>Mon, 04 Nov 2013 07:05:09 +0000</pubDate>
      
      <guid>/2013/11/04/un-record-personal/</guid>
      <description>El otro día, casi por error, cargué este dataframe en R:
&amp;lt;code&amp;gt;&amp;gt; dim(raw) [1] 115318140 4 &amp;lt;/code&amp;gt;  Es todo un récord personal logrado en un servidor con 24GB de RAM bastante caro.
El anterior estaba en otro de algo así como 20 millones de filas y unas 6 o siete columnas. Eso sí, logrado en tiramisu, mi ordenador personal de 8GB de RAM de 400 euros (monitor incluido).
Os preguntaréis si pude hacer algo con ese monstruo.</description>
    </item>
    
    <item>
      <title>Contando hexágonos en paralelo</title>
      <link>/2013/10/28/contando-hexagonos-en-paralelo/</link>
      <pubDate>Mon, 28 Oct 2013 07:51:25 +0000</pubDate>
      
      <guid>/2013/10/28/contando-hexagonos-en-paralelo/</guid>
      <description>Dicen que para realizar gráficos de dispersión con muchos datos no es desaconsejable usar celosías hexagonales. Por motivos que no vienen al caso, me interesa poder realizarlas en paralelo.
El código disponible en R (hexBinning de fMultivar o el de geom_hex de ggplot2) es feo, ininteligible y, en particular, no es paralelizable (o mapreducible). No lo es porque cada hilo, por diseño del algoritmo, crea hexágonos excéntricos.
Así que he desarrollado un algoritmo para crear celosías hexagonales paralelizable.</description>
    </item>
    
    <item>
      <title>Sexo, deporte y la cantidad de información mutua</title>
      <link>/2013/10/08/sexo-deporte-y-la-cantidad-de-informacion-mutua/</link>
      <pubDate>Tue, 08 Oct 2013 07:46:13 +0000</pubDate>
      
      <guid>/2013/10/08/sexo-deporte-y-la-cantidad-de-informacion-mutua/</guid>
      <description>Perdón por el titular. No soy inasequible a las modas.
La cuestión del día de hoy es la siguiente: tenemos una variable X inobservable y otra variable Y potencialmente correlacionada con X. ¿Cuánto podemos decir de X de conocida Y?
Supongamos que ambas son binarias. Si conozco Y poseo 1 bit de información. Si solo conozco X (que me da pistas sobre Y) conoceré una fracción de un bit de información (sobre Y).</description>
    </item>
    
    <item>
      <title>Recordatorio: V Jornadas de Usuarios de R, diciembre 2013, Zaragoza</title>
      <link>/2013/09/23/recordatorio-v-jornadas-de-usuarios-de-r-diciembre-2013-zaragoza/</link>
      <pubDate>Mon, 23 Sep 2013 07:19:46 +0000</pubDate>
      
      <guid>/2013/09/23/recordatorio-v-jornadas-de-usuarios-de-r-diciembre-2013-zaragoza/</guid>
      <description>Que sirva esta entrada de recordatorio de que la comunidad de usuarios de R va a celebrar sus V Jornadas en Zaragoza este mes de diciembre.

Este año, como aliciente adicional, contamos con no uno sino tres concursos con el patrocinio de Synergic Partners y Telefónica Digital.
Como miembro del comité organizador de las jornadas, reitero mi invitación a quienes siguen estas páginas a que acudan, participen y, en el peor de los casos, ayuden a difundirlas entre quienes consideren interesados en ellas.</description>
    </item>
    
    <item>
      <title>El cuarteto de Anscombe</title>
      <link>/2013/08/30/el-cuarteto-de-anscombe/</link>
      <pubDate>Fri, 30 Aug 2013 07:54:47 +0000</pubDate>
      
      <guid>/2013/08/30/el-cuarteto-de-anscombe/</guid>
      <description>F. Anscombe escribió en 1973 el artículo Graphs in Statistical Analysis para subrayar la importancia de los gráficos en el análisis estadístico.
Esencialmente, el artículo se limita a presentar cuatro conjuntos de datos distintos con la misma media, varianza, correlación y recta de regresión (excúsenseme los abusos del lenguaje). Sin embargo tienen aspectos muy distintos:

¿Os interesa saber más al respecto? Pues tenéis esto para satisfacer el apetito de culturilla y esto otro para jugar con el cuarteto en R.</description>
    </item>
    
    <item>
      <title>Medianas ponderadas en R</title>
      <link>/2013/08/05/medianas-ponderadas/</link>
      <pubDate>Mon, 05 Aug 2013 07:57:34 +0000</pubDate>
      
      <guid>/2013/08/05/medianas-ponderadas/</guid>
      <description>La mediana de 1:3 es 2. Pero puede ser que queramos dar a 1:3 los pesos 2, 1, 2. En ese caso, el cálculo de la mediana sigue siendo sencillo (y sigue siendo 2). Pero la situación puede complicarse más.
Mientras los pesos sean enteros, todavía pueden usarse trucos:
x &amp;lt;- 1:3 pesos &amp;lt;- c(2,1,2) median(rep(x, times = pesos ))  ¿Pero qué hacemos cuando hay pesos fraccionarios? Bueno, en realidad, podemos ordenar:</description>
    </item>
    
    <item>
      <title>Las V Jornadas de Usuarios de R, en Zaragoza</title>
      <link>/2013/07/15/las-v-jornadas-de-usuarios-de-r-en-zaragoza/</link>
      <pubDate>Mon, 15 Jul 2013 07:34:08 +0000</pubDate>
      
      <guid>/2013/07/15/las-v-jornadas-de-usuarios-de-r-en-zaragoza/</guid>
      <description>Escribo para anunciar públicamente que están en marcha las V Jornadas de Usuarios de R. Se celebrarán este año en Zaragoza, los días 12 y 13 de diciembre.
Todavía no está disponible el programa (que, en cierto modo, es responsabilidad de vosotros: estáis invitados a enviar propuestas de ponencias y talleres). Tenemos un concurso cuyas bases podrían todavía modificarse si un generoso patrocinador asumiese su financiación.
Y eso, que estáis todos invitados a esta nueva edición de las jornadas.</description>
    </item>
    
    <item>
      <title>¿Nos ayudáis a mejorar r-es.org?</title>
      <link>/2013/06/27/nos-ayudais-a-mejorar-r-es-org/</link>
      <pubDate>Thu, 27 Jun 2013 07:36:56 +0000</pubDate>
      
      <guid>/2013/06/27/nos-ayudais-a-mejorar-r-es-org/</guid>
      <description>Hora es cumplida, creo yo, de repensar el portal de la Comunidad R Hispano. Así que he pensado en pulsar el criterio —que estimo sobremanera— de mis visitantes y solicitar de ellos (vía comentario a esta entrada) sugerencias. Por acotar el tema, sugiero que vayan encaminadas a dirimir estas dos cuestiones:
 1. ¿Cuál debería ser el objetivo de un portal de esas características? 2. ¿Cómo debería organizarse para alcanzar mejor esos objetivos?</description>
    </item>
    
    <item>
      <title>Vídeo de la charla sobre la EPA (y más cosas) en Medialab Prado</title>
      <link>/2013/06/26/video-de-la-charla-sobre-la-epa-y-mas-cosas-en-medialab-prado/</link>
      <pubDate>Wed, 26 Jun 2013 07:04:33 +0000</pubDate>
      
      <guid>/2013/06/26/video-de-la-charla-sobre-la-epa-y-mas-cosas-en-medialab-prado/</guid>
      <description>Ya ha salido publicado el vídeo de la charla sobre la EPA (y más cosas) que anuncié el otro día.</description>
    </item>
    
    <item>
      <title>pqR: un R más rápido</title>
      <link>/2013/06/24/pqr-un-r-mas-rapido/</link>
      <pubDate>Mon, 24 Jun 2013 07:27:52 +0000</pubDate>
      
      <guid>/2013/06/24/pqr-un-r-mas-rapido/</guid>
      <description>Hace no mucho, Radford Neal publicó pqR, una versión de R más rápida. Y algunos os preguntaréis qué es y de dónde salió esa reimplementación.
La respuesta breve es la siguiente: no hace tanto, cuando R iba por la versión 2.13, Neal sugirió una serie de modificaciones (patches) para mejorar el rendimiento de R en algunos aspectos. Creo recordar que eran catorce, aunque bien pudo haber habido otros posteriores. Los desarolladores de R, sin embargo, rechazaron algunos (si no todos) de ellos por motivos de diversa índole pero que se resumen en lo siguiente:</description>
    </item>
    
    <item>
      <title>Hablaré de la EPA (y más cosas) en Medialab Prado</title>
      <link>/2013/06/17/hablare-de-la-epa-y-mas-cosas-en-medialab-prado/</link>
      <pubDate>Mon, 17 Jun 2013 07:47:13 +0000</pubDate>
      
      <guid>/2013/06/17/hablare-de-la-epa-y-mas-cosas-en-medialab-prado/</guid>
      <description>Este miércoles (2013-06-19 en formato ISO 8601: a ver si os vais acostumbrando a él de una bendita vez) hablaré en MediaLab Prado sobre la EPA y más cosas.
Va a ser una charla enteramente antiinstitucional y subversiva. Voy a tratar de abrir varias cajas de Pandora y liberar los correspondientes demonios. Y no voy a tener piedad con las neuronas de los asistentes: quienes acudan, que traigan unos sudokus hechos de casa a modo de calentamiento.</description>
    </item>
    
    <item>
      <title>La cosa más friqui que he visto en...</title>
      <link>/2013/06/13/la-cosa-mas-friqui-que-he-visto-en/</link>
      <pubDate>Thu, 13 Jun 2013 07:00:19 +0000</pubDate>
      
      <guid>/2013/06/13/la-cosa-mas-friqui-que-he-visto-en/</guid>
      <description>Es la cosa más friqui que he visto en tiempos. &amp;ldquo;Esto va intravenoso al blog&amp;rdquo;, me he dicho. Es esto.
Se trata de un paquete de R de Emilio Torres Manzanera con el que se pueden construir gráficos como

al más puro estilo xkcd. Para probarlo,
library(xkcd) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/vignette&amp;quot;&amp;gt;vignette(“xkcd-intro”)  ¡Disfrutad!</description>
    </item>
    
    <item>
      <title>APIdays Mediterranea, la semana que viene</title>
      <link>/2013/05/24/apidays-mediterranea-la-semana-que-viene/</link>
      <pubDate>Fri, 24 May 2013 07:15:18 +0000</pubDate>
      
      <guid>/2013/05/24/apidays-mediterranea-la-semana-que-viene/</guid>
      <description>La semana que viene y con el lema
se celebrará en Madrid APIdays Mediterranea, un encuentro de entusiastas de las APIs.

Y dentro del programa, el sábado día 1, a la una menos cuarto —una hora compatible con mis poco matutinos hábitos—, tengo asignado el taller Rapidays: Quick introduction to R &amp;amp; APIs al que están, por supuesto, invitados los lectores de estas páginas (y para los que podría llegar a tener descuentos para el evento completo y entradas gratuitas para mi taller en particular).</description>
    </item>
    
    <item>
      <title>Mi charla sobre un lematizador probabilístico con R (vídeo y diapositivas)</title>
      <link>/2013/05/23/diapositivas-de-mi-charla-sobre-un-lematizador-desambiguado-con-r/</link>
      <pubDate>Thu, 23 May 2013 07:18:17 +0000</pubDate>
      
      <guid>/2013/05/23/diapositivas-de-mi-charla-sobre-un-lematizador-desambiguado-con-r/</guid>
      <description>Acabo de subir a mi servidor las diapositivas de la charla describiendo un lematizador desambiguado que anuncié el otro día. Gracias a Carlos Ortega y Pedro Concejero, el vídeo de la charla está disponible en Vímeo. Por su parte, las transparencias pueden descargarse aquí.
Quiero agradecer a los asistentes a la charla su interés y, muy particularmente, su participación en el debate que se abrió al final de la sesión. Fue muy enriquecedor.</description>
    </item>
    
    <item>
      <title>Charla: un lematizador probabilístico con R</title>
      <link>/2013/05/13/charla-un-lematizador-probabilistico-con-r/</link>
      <pubDate>Mon, 13 May 2013 07:18:08 +0000</pubDate>
      
      <guid>/2013/05/13/charla-un-lematizador-probabilistico-con-r/</guid>
      <description>El jueves 16 de mayo hablaré en el Grupo de Interés Local de Madrid de R sobre lematizadores probabilísticos.
Hablaré sobre el proceso de lematizacion y trataré de mostrar su importancia dentro del mundo del llamado procesamiento del lenguaje natural (NLP). La lematización es un proceso humilde dentro del NLP del que apenas nadie habla: su ejercicio solo ha hecho famoso a Martin Porter. Lo eclipsan otras aplicaciones más vistosas, como el siempre sobrevalorado análisis del sentimiento.</description>
    </item>
    
    <item>
      <title>data.table (II): agregaciones</title>
      <link>/2013/05/09/data-table-ii-agregaciones/</link>
      <pubDate>Thu, 09 May 2013 07:52:45 +0000</pubDate>
      
      <guid>/2013/05/09/data-table-ii-agregaciones/</guid>
      <description>Sigo con mi lacónica serie sobre data.table.
La protagonista:
frases[sample(1:nrow(frases), 3),] #pos.es pos.en length.es length.en en es frase tfe qjilm num #1: 15 43 72 72 i de 2632 4.881416e-02 0.01369863 6.686871e-04 #2: 33 48 46 48 X países 5321 2.726146e-06 0.02040816 5.563563e-08 #3: 2 35 53 66 in preguntar 4582 2.424379e-08 0.01492537 3.618476e-10 dim(frases) #[1] 6340091 10  El tiempo:
system.time({ setkey(frases, &amp;quot;frase&amp;quot;, &amp;quot;es&amp;quot;) denominadores &amp;lt;- frases[, sum(num), by = key(frases)] setnames(denominadores, c(&amp;quot;frase&amp;quot;, &amp;quot;es&amp;quot;, &amp;quot;den&amp;quot;) ) frases &amp;lt;- merge(frases, denominadores) frases$delta &amp;lt;- frases$num / frases$den }) #user system elapsed #5.</description>
    </item>
    
    <item>
      <title>Dependencias funcionales en R con foodweb</title>
      <link>/2013/05/08/dependencias-funcionales-en-r-con-foodweb/</link>
      <pubDate>Wed, 08 May 2013 07:17:59 +0000</pubDate>
      
      <guid>/2013/05/08/dependencias-funcionales-en-r-con-foodweb/</guid>
      <description>El otro día tropecé con un problema de rendimiento con R y al utilizar Rprof() encontré muchas llamadas a funciones que yo no hacía directamente.
La principal sospechosa era la función daply (del paquete plyr) que parecía depender de bastantes otras. Uno puede navegar el código de las funciones para identificar esas dependencias, pero, mirad qué maravilla:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/mvbutils&amp;quot;&amp;gt;mvbutils) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/plyr&amp;quot;&amp;gt;plyr) foodweb(find.funs(&amp;quot;package:plyr&amp;quot;), &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/rpart/prune&amp;quot;&amp;gt;prune = &amp;quot;laply&amp;quot;)  genera

Ahí se ve la dependencia de daply con respecto a laply.</description>
    </item>
    
    <item>
      <title>Mi primera aplicacion en Shiny: un detector de idiomas</title>
      <link>/2013/05/06/mi-primera-aplicacion-en-shiny-un-detector-de-idiomas/</link>
      <pubDate>Mon, 06 May 2013 07:49:12 +0000</pubDate>
      
      <guid>/2013/05/06/mi-primera-aplicacion-en-shiny-un-detector-de-idiomas/</guid>
      <description>Motivado por los experimentos de Gregorio Serrano con shiny e ilustrado por la charla que dio en el Grupo de Usuarios de R de Madrid, decidí colgar el otro día un entretenimiento que ocupó la mañana de un domingo —y las mañanas de mis domingos son proverbialmente breves— en la red.
Se trata de una aplicación que distingue el idioma en que está escrito un texto dentro de una selección de ellos: español, italiano, latín, francés, portugués y catalán.</description>
    </item>
    
    <item>
      <title>Más sobre la ley de Benford (II): la distribución de la parte fraccionaria</title>
      <link>/2013/05/03/mas-sobre-la-ley-de-benford-ii-la-distribucion-de-la-parte-fraccionaria/</link>
      <pubDate>Fri, 03 May 2013 07:21:09 +0000</pubDate>
      
      <guid>/2013/05/03/mas-sobre-la-ley-de-benford-ii-la-distribucion-de-la-parte-fraccionaria/</guid>
      <description>Continuamos hoy nuestra serie sobre la llamada ley de Benford discutiendo la distribución de la parte fraccionaria de las muestras de una distribución.
La parte fraccionaria de un número es, para entendernos, lo que va detrás de la coma. Técnicamente, x - floor(x). ¿Le sorprendería a alguien la parte fraccionaria de una secuencia aleatoria de números no tenga una distribución uniforme sobre [0,1)?
Obviamente, si los números son enteros no. ¿Pero si siguen la distribución normal?</description>
    </item>
    
    <item>
      <title>data.table (I): cruces</title>
      <link>/2013/05/02/data-table-i-cruces/</link>
      <pubDate>Thu, 02 May 2013 07:16:30 +0000</pubDate>
      
      <guid>/2013/05/02/data-table-i-cruces/</guid>
      <description>Los protagonistas (tres tablas grandecitas):
dim(qjilm) # [1] 3218575 5 dim(tf) # [1] 6340091 7 dim(tfe) #[1] 1493772 3 &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/head&amp;quot;&amp;gt;head(qjilm, 2) #pos.es length.en length.es pos.en qjilm #1 1 2 1 1 0.8890203 #2 1 2 1 2 0.1109797 &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/head&amp;quot;&amp;gt;head(tf, 2) #frase es pos.es length.es en pos.en length.en #1 996 ! 42 42 ! 43 44 #2 1231 ! 37 37 ! 37 38 &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/head&amp;quot;&amp;gt;head(tfe, 2) #en es tfe #1 !</description>
    </item>
    
    <item>
      <title>¿Leemos &#34;Analyzing Linguistic Data&#34; juntos?</title>
      <link>/2013/04/24/leemos-analyzing-linguistic-data-juntos/</link>
      <pubDate>Wed, 24 Apr 2013 07:48:34 +0000</pubDate>
      
      <guid>/2013/04/24/leemos-analyzing-linguistic-data-juntos/</guid>
      <description>Victor Peinado y yo estamos organizando un grupo de lectura. Junto con quienes se nos sumen, vamos a ir leyendo el libro Analyzing Linguistic Data: A practical introduction to Statistics&amp;quot;, que trata de:
 * R (instalación, gráficos, etc.) * Métodos estadísticos con R (modelos lineales, clústering, * clasificación, modelos mixtos) * Lingüística (que es el contexto en el que se aplica lo anterior).  La participación en este grupo está indicada para quienes tengan interés en las aplicaciones lingüísticas de la estadística (y de R, por supuesto).</description>
    </item>
    
    <item>
      <title>Más sobre la ley de Benford (I): una condición suficiente</title>
      <link>/2013/04/16/mas-sobre-la-ley-de-benford-i-una-condicion-suficiente/</link>
      <pubDate>Tue, 16 Apr 2013 07:44:50 +0000</pubDate>
      
      <guid>/2013/04/16/mas-sobre-la-ley-de-benford-i-una-condicion-suficiente/</guid>
      <description>Las circunstancias —frente a las que soy dócil como el que más— me conducen a escribir de nuevo sobre la Ley de Benford. En concreto, voy a traer a la atención de mis lectores una condición suficiente para que se cumpla. Y de ella extraeremos conclusiones tal vez sorprendentes en sucesivas entradas de la serie que con esta inicio.
Dado un número (p.e., 1234), lo podemos descomponer en dos: una potencia de 10 y otro entre 0 y 10:</description>
    </item>
    
    <item>
      <title>Mapa de los terremotos en la península ibérica</title>
      <link>/2013/04/08/mapa-de-los-terremotos-en-la-peninsula-iberica/</link>
      <pubDate>Mon, 08 Apr 2013 07:27:21 +0000</pubDate>
      
      <guid>/2013/04/08/mapa-de-los-terremotos-en-la-peninsula-iberica/</guid>
      <description>Me sorprendió hace un tiempo averiguar que en la península ibérica hubiese tantos terremotos (aunque mis amigos chilenos los llamarían de otra manera).
En esta entrada voy a mostrar el siguiente mapa de actividad sísmica durante los últimos años,

que he construido con el siguiente código en R:
library(ggmap) url &amp;lt;- &amp;quot;http://comcat.cr.usgs.gov/earthquakes/feed/search.php?maxEventLatitude=45&amp;amp;minEventLatitude=35&amp;amp;minEventLongitude=-10&amp;amp;maxEventLongitude=5&amp;amp;minEventTime=953683200000&amp;amp;maxEventTime=1364688000000&amp;amp;minEventMagnitude=-1.0&amp;amp;maxEventMagnitude=10&amp;amp;minEventDepth=0.0&amp;amp;maxEventDepth=800.0&amp;amp;format=csv&amp;quot; terremotos &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/read.csv&amp;quot;&amp;gt;read.csv(url) # obtengo un mapa pen.iber &amp;lt;- get_map( location = c(-9.5, 36, 3.5, 44), color = &amp;quot;color&amp;quot;, maptype = &amp;quot;roadmap&amp;quot;) # le añado puntos ggmap(pen.</description>
    </item>
    
    <item>
      <title>textConnection y ficheros anónimos: cuestión de rendimiento</title>
      <link>/2013/04/04/textconnection-y-ficheros-anonimos/</link>
      <pubDate>Thu, 04 Apr 2013 07:48:59 +0000</pubDate>
      
      <guid>/2013/04/04/textconnection-y-ficheros-anonimos/</guid>
      <description>La función textConnection de R es útil para leer el contenido de una variable como si fuese un fichero de texto. Verbigracia,
zz &amp;lt;- textConnection(LETTERS) readLines(zz, 2)  Pero cuando uno hace
?textConnection  y lee con detenimiento, encuentra la siguiente nota:
Vamos, que desaconseja usar dicha función por motivos de rendimiento cuando no vayan a usarse todas las sus características de las que file carece. Pero, ¿será cierto que el rendimiento es tan malo?</description>
    </item>
    
    <item>
      <title>rPython ya está en CRAN</title>
      <link>/2013/04/01/rpython-ya-esta-en-cran/</link>
      <pubDate>Mon, 01 Apr 2013 07:08:19 +0000</pubDate>
      
      <guid>/2013/04/01/rpython-ya-esta-en-cran/</guid>
      <description>Después de bastante trabajo, rPython ya está disponible en CRAN, ya es un paquete oficial de R.
Se trata de un paquete del que ya nos hemos ocupado antes (véase esto y esto) y que permite llamar a Python desde R.
Por el momento, está disponible únicamente para plataformas UNIX (Linux, Mac) aunque estoy tratando de crear una versión que funcione en Windows.
Además, estoy buscando aplicaciones de rPython (al estilo de esta).</description>
    </item>
    
    <item>
      <title>Datos LIDAR en R</title>
      <link>/2013/03/06/datos-lidar-en-r/</link>
      <pubDate>Wed, 06 Mar 2013 07:13:58 +0000</pubDate>
      
      <guid>/2013/03/06/datos-lidar-en-r/</guid>
      <description>En la reunión del grupo de interés local (GIL) de R de Madrid, Francisco Mauro habló de aplicaciones de R a conjuntos de datos LIDAR.
En efecto, uno quiere estimar la cantidad de madera que hay en un monte. Uno entonces la calcula en unas pequeñas zonas y luego, barriendo el monte con pulsos de láser desde un avión toma medidas (x,y,z) (es decir, longitud, latitud y altura) en una malla fina de puntos.</description>
    </item>
    
    <item>
      <title>ggmap: mapas con R</title>
      <link>/2013/03/05/ggmap-mapas-con-r/</link>
      <pubDate>Tue, 05 Mar 2013 11:09:53 +0000</pubDate>
      
      <guid>/2013/03/05/ggmap-mapas-con-r/</guid>
      <description>Me mandó Alberto González Paje código para representar información en mapas usando R que hoy he dejado en su mínima expresión para que los lectores de esta bitácora puedan extender para crear sus propios mapas.
Es el siguiente:
library(ggmap) # ubico mi alma mater unizar &amp;lt;- geocode(&#39;Universidad de Zaragoza, Zaragoza, España&#39;) # obtengo un mapa map.unizar &amp;lt;- get_map( location = as.numeric(unizar), color = &amp;quot;color&amp;quot;, maptype = &amp;quot;roadmap&amp;quot;, scale = 2, zoom = 16) # lo represento ggmap(map.</description>
    </item>
    
    <item>
      <title>Cortar una cadena por un caracter solo cuando no forme parte de una subcadena entrecomillada</title>
      <link>/2013/03/04/cortar-una-cadena-por-un-caracter-solo-cuando-no-forme-parte-de-una-subcadena-entrecomillada/</link>
      <pubDate>Mon, 04 Mar 2013 07:31:46 +0000</pubDate>
      
      <guid>/2013/03/04/cortar-una-cadena-por-un-caracter-solo-cuando-no-forme-parte-de-una-subcadena-entrecomillada/</guid>
      <description>Algunos usuarios del paquete pxR han avisado de un error de implementación. Según las especificaciones del formato de datos PC-Axis, las líneas de ese tipo de ficheros acaban en punto y coma (y no necesariamente en un salto de línea).
Así que era natural leer los ficheros íntegramente, concatenar sus líneas físicas y luego partirlas usando strsplit para obtener las líneas lógicas.
Sin embargo, ciertos ficheros contienen descripciones (entrecomilladas) que contienen puntos y comas.</description>
    </item>
    
    <item>
      <title>Addenda: ¿qué ha pasado en el Ibex durante el último mes? </title>
      <link>/2013/02/28/addenda-que-ha-pasado-en-el-ibex-durante-el-ultimo-mes/</link>
      <pubDate>Thu, 28 Feb 2013 07:03:53 +0000</pubDate>
      
      <guid>/2013/02/28/addenda-que-ha-pasado-en-el-ibex-durante-el-ultimo-mes/</guid>
      <description>Abundando en el tema de ayer, ahora, los mismos datos representados con mapas de calor:

Para obtenerlo, a lo que ya teníamos basta añadirle:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/gplots&amp;quot;&amp;gt;gplots) heatmap.2(as.matrix(ibex.scaled), Rowv=F, Colv=T, key=F, trace=&amp;quot;none&amp;quot;, col=redgreen, xlab=&amp;quot;valor&amp;quot;, ylab=&amp;quot;&amp;quot;, margins=c(5,10))  </description>
    </item>
    
    <item>
      <title>¿Qué ha pasado en el Ibex durante el último mes?</title>
      <link>/2013/02/27/que-ha-pasado-en-el-ibex-durante-el-ultimo-mes/</link>
      <pubDate>Wed, 27 Feb 2013 07:07:38 +0000</pubDate>
      
      <guid>/2013/02/27/que-ha-pasado-en-el-ibex-durante-el-ultimo-mes/</guid>
      <description>Pues esencialmente esto:

Es decir, un grupo numeroso de valores ha bajado de precio mientras que otros dos grupos han tenido una evolución en U y ha recuperado, con creces incluso, el valor que tenían hace un mes.
Y, como siempre, el código:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/tseries&amp;quot;&amp;gt;tseries) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/zoo&amp;quot;&amp;gt;zoo) library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/XML&amp;quot;&amp;gt;XML) library(reshape) library(ggplot2) foo &amp;lt;- function( simbolo, final = &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/Sys.time&amp;quot;&amp;gt;Sys.time(), profundidad = 30 * 24 * 3600 ){ precios &amp;lt;- get.</description>
    </item>
    
    <item>
      <title>Descarga de ficheros con R a través de sftp</title>
      <link>/2013/02/18/descarga-de-ficheros-con-r-a-traves-de-sftp/</link>
      <pubDate>Mon, 18 Feb 2013 07:34:27 +0000</pubDate>
      
      <guid>/2013/02/18/descarga-de-ficheros-con-r-a-traves-de-sftp/</guid>
      <description>Llevo lo que parece un siglo sin escribir en estas páginas. Y es que, en gran parte, el nuevo curso de R me consume. Y también otros asuntos jugosos y relacionados con R que iré, sin duda, desgranando en futuras, aunque previsiblemente más esporádicas, entradas.
Lo que me ocupa hoy es esto:
fichero &amp;lt;- getURL(&amp;quot;sftp://usuario:contraseña@máquina/home/bla/bla/bla/fichero.txt&amp;quot;)  ¿Qué es? Es la manera de descargar directamente a R un fichero a través del protocolo SFTP (FTP seguro).</description>
    </item>
    
    <item>
      <title>¡Reeditamos el curso básico de R!</title>
      <link>/2013/02/04/reeditamos-el-curso-basico-de-r/</link>
      <pubDate>Mon, 04 Feb 2013 07:37:07 +0000</pubDate>
      
      <guid>/2013/02/04/reeditamos-el-curso-basico-de-r/</guid>
      <description>El año pasado, Juanjo Gibaja y yo organizamos nuestro primer Curso Básico de R. En esta entrada quiero anunciar su inminente reedición: ¡comienza el 11 de febrero!
Las características del curso van a seguir siendo, esencialmente, las mismas:
 * Es **gratuito**. * No da derecho a diplomas o certificados de ningún tipo. * No es presencial. * **Plazas ilimitadas**. * Está basado en el **autoestudio**: cada participante tendrá que leer y trabajar por su cuenta.</description>
    </item>
    
    <item>
      <title>Tu tasa de paro personal</title>
      <link>/2013/01/24/tu-tasa-de-paro-personal/</link>
      <pubDate>Thu, 24 Jan 2013 13:50:39 +0000</pubDate>
      
      <guid>/2013/01/24/tu-tasa-de-paro-personal/</guid>
      <description>En el pasado nos hemos ocupado en estas páginas del desempleo. Hoy, día en el que se han anunciado los datos de la EPA del último trimestre de 2012, sale a la luz TTParo.es, un proyecto en el que he colaborado (aunque en el que todo lo que se ve es obra de Kaleidos) y que permite calcular tu tasa de paro personal.
Por ejemplo, en

puedo ver la evolución de la tasa de paro de aquellos que son como yo desde el 2005 y compararla con la general.</description>
    </item>
    
    <item>
      <title>Arte con R: tres enlaces</title>
      <link>/2013/01/11/arte-con-r-tres-enlaces/</link>
      <pubDate>Fri, 11 Jan 2013 07:20:25 +0000</pubDate>
      
      <guid>/2013/01/11/arte-con-r-tres-enlaces/</guid>
      <description>Traigo hoy a mi bitácora tres enlaces sobre la creación de artefactos gráficos con R.
En el primero (¡en japonés!) puede uno aprender a construir cosas como

El segundo reproduce con R la siguiente obra de Bridget Riley:

Y el tercero es una elaboración sobre el anterior que permite generar gráficos tales como</description>
    </item>
    
    <item>
      <title>Una aplicación SEO con R</title>
      <link>/2013/01/10/una-aplicacion-seo-con-r/</link>
      <pubDate>Thu, 10 Jan 2013 07:29:36 +0000</pubDate>
      
      <guid>/2013/01/10/una-aplicacion-seo-con-r/</guid>
      <description>Leyendo Bad Data vine a saber que Google deja en los logs de Apache información muy relevante sobre la optimización del sitio. En efecto, cuando alguien encuentra tu página en Google, Apache deja (casi siempre) en los logs una línea similar a
188.77.154.135 - - [30/Dec/2012:09:35:28 +0000] &amp;quot;GET /blog/page/33/?p=... HTTP/1.1&amp;quot; 200 15348 &amp;quot;http://www.google.es/url?sa=t&amp;amp;rct=j&amp;amp;q=breiman%20dos%20culturas%20estadistica&amp;amp;source=web&amp;amp;cd=21&amp;amp;cad=rja&amp;amp;ved=0CDIQFjAAOBQ&amp;amp;url=http%3A%2F%2Fwww.datanalytics.com%2Fblog%2Fpage%2F33%2F%3Fp%3D...&amp;amp;ei=1QrgULj7E6qk0QXRwYHgCQ&amp;amp;usg=AFQjCNHpdZUVD15sC7CdOvUOppdcXAjweQ&amp;amp;sig2=hKh3vCnCrvublGxQXoojyg&amp;amp;bvm=bv.1355534169,d.d2k&amp;quot; &amp;quot;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; ca-es) AppleWebKit/533.21.1 (KHTML, like Gecko) Version/5.0.5 Safari/533.21.1&amp;quot;
La parte</description>
    </item>
    
    <item>
      <title>El Ibex 35 al estilo GapMinder</title>
      <link>/2013/01/09/el-ibex-35-estilo-gapminder/</link>
      <pubDate>Wed, 09 Jan 2013 07:07:31 +0000</pubDate>
      
      <guid>/2013/01/09/el-ibex-35-estilo-gapminder/</guid>
      <description>Quiero representar hoy la evolución del Ibex 35 a lo largo del año pasado al estilo GapMinder. En concreto, usando un MotionChart de Google.
Primero, bajo los símbolos de los activos del Ibex de Yahoo! Finance:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/XML&amp;quot;&amp;gt;XML) simbolos &amp;lt;- readHTMLTable(htmlParse(&amp;quot;http://finance.yahoo.com/q/cp?s=%5EIBEX+Components&amp;quot;)) simbolos &amp;lt;- as.character(simbolos[[9]]$Symbol) simbolos &amp;lt;- gsub(&amp;quot;-P&amp;quot;, &amp;quot;&amp;quot;, simbolos)  Luego, creo una pequeña función y se la aplico a cada símbolo:
library(&amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/tseries&amp;quot;&amp;gt;tseries) foo &amp;lt;- function( simbolo, final = &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Prueba R, gentileza de code school.com</title>
      <link>/2012/12/11/prueba-r-gentileza-de-code-school-com/</link>
      <pubDate>Tue, 11 Dec 2012 07:35:30 +0000</pubDate>
      
      <guid>/2012/12/11/prueba-r-gentileza-de-code-school-com/</guid>
      <description>¿Has oído hablar de R y quieres probarlo? ¿Sabes de alguien que esté pensando en hacer sus pinitos con él y que no sepa por dónde empezar?

Codeschool.com (en colaboración con O&amp;rsquo;Reilly) han creado un microcurso, Try R, que permite familiarizarse con lo básico de R sin instalar nada, desde el navegador.
¿Quieres probar R? No tienes excusa.</description>
    </item>
    
    <item>
      <title>¿... coma cero dos por ciento? ¡Anda ya!</title>
      <link>/2012/11/28/coma-cero-dos-por-ciento-anda-ya/</link>
      <pubDate>Wed, 28 Nov 2012 06:52:41 +0000</pubDate>
      
      <guid>/2012/11/28/coma-cero-dos-por-ciento-anda-ya/</guid>
      <description>Hoy hablo en la reunión del grupo de usuarios de R de Madrid. Voy a reciclar la charla que di en las IV Jornadas de Usuarios de R sobre mi paquete MicroDatosEs y voy a aprovechar para criticar, en mi estilo, enunciados como
que pueden encontrarse en la nota de prensa del INE que resume los resultados de la última encuesta de población activa, la del tercer trimestre de 2012.</description>
    </item>
    
    <item>
      <title>Lo normal: sumar doce, restar seis</title>
      <link>/2012/11/20/lo-normal-sumar-doce-restar-seis/</link>
      <pubDate>Tue, 20 Nov 2012 07:40:45 +0000</pubDate>
      
      <guid>/2012/11/20/lo-normal-sumar-doce-restar-seis/</guid>
      <description>Un truco para generar variables aleatorias normales: sumar doce uniformes y restar seis.
En efecto,
x &amp;lt;- replicate(1000, sum( runif(12) - 6 )) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/qqnorm&amp;quot;&amp;gt;qqnorm(x) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/qqline&amp;quot;&amp;gt;qqline(x, col=2)  produce

Ayuda a entender el motivo que la varianza de la distribución uniforme es 1/12 y que su media es 1/2.</description>
    </item>
    
    <item>
      <title>Presentación del libro &#34;Six Sigma with R&#34;</title>
      <link>/2012/11/19/presentacion-del-libro-six-sigma-with-r/</link>
      <pubDate>Mon, 19 Nov 2012 07:38:58 +0000</pubDate>
      
      <guid>/2012/11/19/presentacion-del-libro-six-sigma-with-r/</guid>
      <description>El martes 20 de noviembre, a las 17:00h, tendrá lugar la presentación del libro Six Sigma with R: Statistical Engineering for Process Improvement&amp;quot; en la sala Juan Béjar de la E.U. de Estadística de la U. Complutense por parte de Emilio López Cano.

Existe además un paquete de R, SixSigma, desarrollado por los autores y disponible en CRAN.
El mundo del control de la calidad (en ingeniería) está dominado por software propietario, particularmente, Minitab.</description>
    </item>
    
    <item>
      <title>Entrevista en el portal del RUG Barcelona</title>
      <link>/2012/11/13/entrevista-en-el-portal-del-rug-barcelona/</link>
      <pubDate>Tue, 13 Nov 2012 07:00:05 +0000</pubDate>
      
      <guid>/2012/11/13/entrevista-en-el-portal-del-rug-barcelona/</guid>
      <description>Ayer salió publicada una entrevista que me hicieron Aleix Ruiz de Villa y Lluís Ramón, del RUG Barcelona (grupo de usuarios de R de Barcelona). Puede leerse íntegramente en este enlace.</description>
    </item>
    
    <item>
      <title>Liberado BioStatFLOSS, una colección de recursos libres para la bioestadística y la epidemiología </title>
      <link>/2012/10/29/liberado-biostatfloss-una-coleccion-de-recursos-libres-para-la-bioestadistica-y-la-epidemiologia/</link>
      <pubDate>Mon, 29 Oct 2012 07:50:38 +0000</pubDate>
      
      <guid>/2012/10/29/liberado-biostatfloss-una-coleccion-de-recursos-libres-para-la-bioestadistica-y-la-epidemiologia/</guid>
      <description>Quiero publicitar hoy BioStatFLOSS, una recopilación de software (libre, como el propio nombre indica) para Windows, especialmente indicado a la hora de realizar trabajos en el campo de la bioestadística y la epidemiología (pero que también se puede utilizar para la realización de estudios estadísticos más generales).
El software (que incluye R como programa estrella) ha sido portabilizado —si no existía ya una versión portable, es decir, que no necesite instalación— y se ha creado un lanzador común desde donde se puedan llamar a todos esos programas (véase la captura adjunta).</description>
    </item>
    
    <item>
      <title>HHH, HHT y el comando &#34;yield&#34; de Python</title>
      <link>/2012/10/26/hhh-hht-y-el-comando-yield-de-python/</link>
      <pubDate>Fri, 26 Oct 2012 07:18:38 +0000</pubDate>
      
      <guid>/2012/10/26/hhh-hht-y-el-comando-yield-de-python/</guid>
      <description>Variable aleatoria X: tiramos una moneda al aire sucesivamente y contamos el número de veces que lo hacemos hasta obtener el patrón HHH (tres caras) en las tres últimas tiradas.
Variable aleatoria Y: lo mismo, pero hasta que salga el patrón HHT.
Entonces las medias de X e Y son iguales, ¿verdad? Pues no. (¿Alguien sabría decirme cuál de las combinaciones, HHH o HHT, tiende, en promedio, a aparecer antes? Pueden darse explicaciones muy complejas, pero existe una muy simple e intuitiva).</description>
    </item>
    
    <item>
      <title>Veinte herramientas de visualización</title>
      <link>/2012/10/24/veinte-herramientas-de-visualizacion/</link>
      <pubDate>Wed, 24 Oct 2012 07:54:41 +0000</pubDate>
      
      <guid>/2012/10/24/veinte-herramientas-de-visualizacion/</guid>
      <description>Este es un listado de 20 herramientas de visualización que he extraído de aquí. Están divididas en varios grupos:
 * Básicas: Excel y, extrañamente, CSV y JSON (que aun sin ser herramientas de visualización, son formatos usuales para el intercambio de información usados por ellas). * Visualización en línea: * [Google Chart API](https://developers.google.com/chart/) * [Flot](http://www.flotcharts.org/), [Raphaël](http://raphaeljs.com/) y [D3](http://d3js.org/), librerías de JavaScript. * [visual.ly](http://visual.ly/), que sirve para crear esas configuraciones rectangulares de números y símbolos no siempre útiles que algunos llaman infografías.</description>
    </item>
    
    <item>
      <title>Nuevo curso (gratuito) de estadística con R</title>
      <link>/2012/10/22/nuevo-curso-gratuito-de-estadistica-con-r/</link>
      <pubDate>Mon, 22 Oct 2012 07:18:23 +0000</pubDate>
      
      <guid>/2012/10/22/nuevo-curso-gratuito-de-estadistica-con-r/</guid>
      <description>Hace unos meses, Juanjo Gibaja y yo lanzamos el un curso básico de R. Animados por el éxito de crítica y público, volvemos a la carga con uno nuevo. Esta vez el curso se titula Introducción a la estadística moderna con R. Y su presentación es:
Sin embargo, pese a su juventud, hay quienes piensan que nació demasiado pronto. Algunos estadísticos modernos, de hecho, se han planteado la siguiente pregunta: ¿cómo sería la estadística si hubiese nacido después que los ordenadores?</description>
    </item>
    
    <item>
      <title>Reunión del Grupo de Usuarios de R de Madrid</title>
      <link>/2012/10/19/reunion-del-grupo-de-usuarios-de-r-de-madrid/</link>
      <pubDate>Fri, 19 Oct 2012 07:07:48 +0000</pubDate>
      
      <guid>/2012/10/19/reunion-del-grupo-de-usuarios-de-r-de-madrid/</guid>
      <description>El día 31 de octubre (de 2012) se reunirá de nuevo el Grupo de Usuarios de R de Madrid. La reunión tendrá lugar en el Matadero (metro Legazpi) y el programa y otros detalles pueden consultarse, como siempre, en la página del grupo. Y también en la página de Medialab Prado.
Entre otras cosas, casi seguro, se discutirá el plan de reuniones para el curso actual, los temas que se discutirán en las siguientes, etc.</description>
    </item>
    
    <item>
      <title>Algunos gráficos de información bursátil</title>
      <link>/2012/10/18/algunos-graficos-de-informacion-bursatil/</link>
      <pubDate>Thu, 18 Oct 2012 07:07:41 +0000</pubDate>
      
      <guid>/2012/10/18/algunos-graficos-de-informacion-bursatil/</guid>
      <description>Hoy voy a presentar algunos gráficos de información bursátil adaptados a partir de código de Eric Zivot, el instructor del curso Introduction to Computational Finance and Financial Econometrics que estoy siguiendo (un poco como puta por rastrojo: siempre me las arreglo para resolver los ejercicios en el último minuto y antes de haber revisado la teoría) en Coursera.
Por si pueden servir de algo a otros, los reproduzco y comento aquí.</description>
    </item>
    
    <item>
      <title>R como herramienta de captura de datos</title>
      <link>/2012/10/16/r-como-herramienta-de-captura-de-datos/</link>
      <pubDate>Tue, 16 Oct 2012 07:12:17 +0000</pubDate>
      
      <guid>/2012/10/16/r-como-herramienta-de-captura-de-datos/</guid>
      <description>Seré breve hoy porque estoy desinspirado. Y también porque estoy trabajando en dos o tres proyectos importantes de los que se hablará por aquí pronto. Así que hoy me dedicaré a divulgar una presentación de Jeffrey Breen que tiene un título engañoso: Tapping the Data Deluge with R.
En realidad, es un repaso (y el código está disponible) de las posibilidades que ofrece R para capturar datos disponibles en línea en diversos repositorios: Banco Mundial, Yahoo, Twitter.</description>
    </item>
    
    <item>
      <title>Gráficos en R a la xkcd</title>
      <link>/2012/10/10/graficos-en-r-a-la-xkcd/</link>
      <pubDate>Wed, 10 Oct 2012 07:08:20 +0000</pubDate>
      
      <guid>/2012/10/10/graficos-en-r-a-la-xkcd/</guid>
      <description>Esto fue un reto en toda regla: un megafriqui publicó código en LaTeX para reproducir en dicho entorno gráficos como los que aparecen en xkcd.com, es decir, del tipo de

con el siguiente resultado:

La respuesta por parte de la comunidad de usuarios de R, obviamente, no podía demorarse. Y es

El código puede encontrarse aquí. Y más información sobre el asunto, recomiendo este otro enlace.</description>
    </item>
    
    <item>
      <title>Tutorial: cómo analizar datos de Twitter con R</title>
      <link>/2012/09/28/tutorial-como-analizar-datos-de-twitter-con-r/</link>
      <pubDate>Fri, 28 Sep 2012 07:14:39 +0000</pubDate>
      
      <guid>/2012/09/28/tutorial-como-analizar-datos-de-twitter-con-r/</guid>
      <description>No es mío, pero sí una pequeña joya que merece la pena dar a conocer. Además de tener aquí, en mi bitácora-vademécum para futura referencia. Es este tutorial para el análisis de datos de Twitter realizado por Gastón Sánchez.</description>
    </item>
    
    <item>
      <title>Ejemplos sobre cómo usar R desde SAS a través de IML</title>
      <link>/2012/09/27/ejemplos-sobre-como-usar-r-desde-sas-a-traves-de-iml/</link>
      <pubDate>Thu, 27 Sep 2012 06:55:36 +0000</pubDate>
      
      <guid>/2012/09/27/ejemplos-sobre-como-usar-r-desde-sas-a-traves-de-iml/</guid>
      <description>Quiero dar a conocer hoy un vídeo de SAS sobre cómo integrarlo con R a través de SAS/IML. SAS/IML es un lenguaje de programación que apenas tiene que ver con lo que normalmente se conoce como el lenguaje de programación SAS y que tiene un aspecto similar a Matlab o, incluso, salvando las distancias, R. Debido a esa afinidad, es el producto a través del cual SAS ha querido establecer la interconexión de sus productos con R.</description>
    </item>
    
    <item>
      <title>Predicciones de series temporales a gran escala y en paralelo con R</title>
      <link>/2012/09/25/predicciones-de-series-temporales-a-gran-escala-y-en-paralelo-con-r/</link>
      <pubDate>Tue, 25 Sep 2012 07:50:49 +0000</pubDate>
      
      <guid>/2012/09/25/predicciones-de-series-temporales-a-gran-escala-y-en-paralelo-con-r/</guid>
      <description>En el artículo Large-Scale Parallel Statistical Forecasting Computations in R encontrarán los interesados información sobre cómo está usando Google R para realizar predicciones de series temporales a gran escala usando cálculos en paralelo.
El artículo tiene dos partes diferenciadas. Por un lado está la que describe los métodos que usan para realizar predicciones sobre series temporales. Parecen sentir cierto desdén por la teoría clásica, comprensible dado el gran número de series temporales que tratan de predecir y el mimo —entiéndase como uso de materia gris— que exige aquella.</description>
    </item>
    
    <item>
      <title>RDataMining, un paquete para minería de datos con R</title>
      <link>/2012/09/18/rdatamining-un-paquete-para-mineria-de-datos-con-r/</link>
      <pubDate>Tue, 18 Sep 2012 07:02:55 +0000</pubDate>
      
      <guid>/2012/09/18/rdatamining-un-paquete-para-mineria-de-datos-con-r/</guid>
      <description>Comparto con mis lectores la noticia que he recibido del paquete (aún en ciernes) RDataMining. El objetivo de sus promotores es construirlo colaborativamente (¡se buscan programadores!) e incluir en él algoritmos publicados que no tengan todavía implementación en R.

Existen en R muchos paquetes útiles para la minería de datos. De todos ellos, me atrevería a recomendar el paquete [caret](http://cran.r-project.org/web/packages/caret/index.html) que, más allá de integrar diversos algoritmos, incluye funciones auxiliares útiles para seleccionar modelos, comparar la importancia de funciones, realizar validaciones cruzadas, etc.</description>
    </item>
    
    <item>
      <title>&#34;Gráficos estadísticos y mapas con R&#34;, un análisis</title>
      <link>/2012/09/10/graficos-estadisticos-y-mapas-con-r-un-analisis/</link>
      <pubDate>Mon, 10 Sep 2012 06:44:37 +0000</pubDate>
      
      <guid>/2012/09/10/graficos-estadisticos-y-mapas-con-r-un-analisis/</guid>
      <description>Me dispongo hoy a analizar el libro Gráficos estadísticos y mapas con R que anuncié hace unos días, aun sin haber tenido oportunidad de hojearlo.
Es un libro relativamente extenso, de casi cuatrocientas páginas a todo color. Y es poco perdonable que una editorial técnica como Díaz de Santos haya permitido que el código que aparece en el libro esté en Times New Roman. Pero bueno.
La estructura general del libro tiene forma de recetario: cómo hacer para construir un determinado tipo de gráfico.</description>
    </item>
    
    <item>
      <title>Limpieza de cartera: tres artículos</title>
      <link>/2012/09/06/limpieza-de-cartera-tres-articulos/</link>
      <pubDate>Thu, 06 Sep 2012 07:36:24 +0000</pubDate>
      
      <guid>/2012/09/06/limpieza-de-cartera-tres-articulos/</guid>
      <description>Estoy limpiando mi cartera y antes de mandar unos cuantos legajos al archivador (o al contenedor de reciclaje) quiero dejar nota de sus contenidos para referencia mía y, quién sabe, si inspiración de otros.
El primer artículo es Tackling the Poor Assumptions of Naive Bayes Text Classifiers. Tiene esencialmente dos partes. La primera analiza críticamente el método de clasificación bayesiano ingenuo (naive Bayes) en el contexto de la minería de textos identificando una serie de deficiencias.</description>
    </item>
    
    <item>
      <title>p-valores bajo la hipótesis nula tras múltiples comparaciones</title>
      <link>/2012/08/24/p-valores-bajo-la-hipotesis-nula-tras-multiples-comparaciones/</link>
      <pubDate>Fri, 24 Aug 2012 06:50:08 +0000</pubDate>
      
      <guid>/2012/08/24/p-valores-bajo-la-hipotesis-nula-tras-multiples-comparaciones/</guid>
      <description>Imagina que trabajas en lo que Ionnidis, en su artículo Why Most Published Research Findings Are False, llama un null field; es decir, un área de investigación (tipo homeopatía o percepción extrasensorial) en la que no hay resultados ciertos, en la que las relaciones causa-efecto no pasan de ser presuntas. O tienes un conjunto de datos en un campo no nulo pero que, por algún motivo, no recoge las variables necesarias para explicar un cierto fenómeno.</description>
    </item>
    
    <item>
      <title>R en el Software Developer&#39;s Journal</title>
      <link>/2012/08/22/r-en-el-software-developers-journal/</link>
      <pubDate>Wed, 22 Aug 2012 07:44:56 +0000</pubDate>
      
      <guid>/2012/08/22/r-en-el-software-developers-journal/</guid>
      <description>El Software Developer&amp;rsquo;s Journal ha publicado estos días un número dedicado exclusivamente a R. Dicen que sus 260 páginas hacen de este número el más extenso que ha publicado jamás la revista.

Incluye, además, un artículo mío, Rpython, a package for calling Python from R.
Creo que es necesario registrarse (y probablemente de forma no gratuita) para hojear el volumen. De todos modos tal vez sería posible que pudiese pasarle el número completo a aquellos que deseen echarle un vistazo&amp;hellip;</description>
    </item>
    
    <item>
      <title>Fallecimientos y microdatos</title>
      <link>/2012/08/13/fallecimientos-y-microdatos/</link>
      <pubDate>Mon, 13 Aug 2012 08:57:36 +0000</pubDate>
      
      <guid>/2012/08/13/fallecimientos-y-microdatos/</guid>
      <description>Hace un tiempo, un amigo me dijo que si en verano tiende a crecer la tasa de fallecimientos. Como de eso no sé y no hay manera de preguntarle a Google cuándo se muere más la gente, acudí a quienes se encargan de recopilar ese tipo de datos. Y construí en relativamente poco rato un gráfico parecido a

que echaba por tierra su hipótesis.
Ahora quiero retomar el asunto aprovechando que he anunciado el paquete MicroDatosEs para indicar cómo se pueden crear los tres ficheros de metadatos necesarios para leer ficheros de microdatos.</description>
    </item>
    
    <item>
      <title>SAS, R, grandes datos y falta de afabilidad</title>
      <link>/2012/08/07/sas-r-grandes-datos-y-falta-de-afabilidad/</link>
      <pubDate>Tue, 07 Aug 2012 07:18:58 +0000</pubDate>
      
      <guid>/2012/08/07/sas-r-grandes-datos-y-falta-de-afabilidad/</guid>
      <description>El otro día hice un comentario a esta entrada de una bitácora de SAS. Esencialmente, decía dos cosas:
 * Que 10000 observaciones no hacen grandes datos (_big data_); 10000 observaciones son muy pocas observaciones. * Que el código original, la idea de la entrada, etc., proceden de [este otro enlace](http://yihui.name/en/2008/09/to-see-a-circle-in-a-pile-of-sand/) de una página de [Yihui Xie](http://yihui.name/) (conocido por ser el autor de [`knitr`](http://yihui.name/knitr/)) en la que el problema se planteaba y resolvía con R.</description>
    </item>
    
    <item>
      <title>Un paseo por el paquete MicroDatosEs (y la EPA, de nuevo)</title>
      <link>/2012/08/06/un-paseo-por-el-paquete-microdatoses-y-la-epa-de-nuevo/</link>
      <pubDate>Mon, 06 Aug 2012 07:31:47 +0000</pubDate>
      
      <guid>/2012/08/06/un-paseo-por-el-paquete-microdatoses-y-la-epa-de-nuevo/</guid>
      <description>En esta entrada voy a ilustrar el uso del paquete MicroDatosEs que anuncié el otro día. Como indiqué entonces, de momento sólo permite leer microdatos de la EPA con el formato que tiene desde el año 2005, la fecha del último cambio metodológico.
Como todavía no están disponibles los del segundo trimestre del 2012, utilizaré los del primero. Para ello, hay que ir a las páginas del INE y seleccionar el fichero correspondiente al primer trimestre de 2012 (que los impacientes pueden descargar directamente de su enlace directo).</description>
    </item>
    
    <item>
      <title>El paquete MicroDatosEs para microdatos públicos</title>
      <link>/2012/08/03/el-paquete-microdataes-para-microdatos-publicos/</link>
      <pubDate>Fri, 03 Aug 2012 07:38:41 +0000</pubDate>
      
      <guid>/2012/08/03/el-paquete-microdataes-para-microdatos-publicos/</guid>
      <description>Comencé hace un tiempo un pequeño paquete de R, MicroDataEs, para importar automáticamente a R ficheros de microdatos distribuidos por los diversos organismos estadísticos (españoles, por acotar el ámbito). El objetivo es facilitar el análisis de este tipo de datos a los usuarios de R y como consecuencia:
 * fomentar el uso de R entre aquellos que utilicen frecuentemente este tipo de información y * hacer más accesibles estos datos a los usuarios de R.</description>
    </item>
    
    <item>
      <title>Reetiquetar factores en R</title>
      <link>/2012/08/01/reetiquetar-factores-en-r/</link>
      <pubDate>Wed, 01 Aug 2012 07:11:51 +0000</pubDate>
      
      <guid>/2012/08/01/reetiquetar-factores-en-r/</guid>
      <description>La operación que voy a discutir hoy es una que plantea problemas a muchos programadores nuevos en R: cómo renombrar niveles de un factor. Un caso típico ocurre al leer una tabla que contiene datos no normalizados. Por ejemplo,
mi.factor &amp;lt;- factor( c(&amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;) )  donde se entiende que a y A, b y B son la misma cosa. Otro caso similar ocurre cuando se quieren agrupar niveles poco frecuentes como en</description>
    </item>
    
    <item>
      <title>Hemos cerrado el curso básico de R</title>
      <link>/2012/07/26/hemos-cerrado-el-curso-basico-de-r/</link>
      <pubDate>Thu, 26 Jul 2012 07:07:07 +0000</pubDate>
      
      <guid>/2012/07/26/hemos-cerrado-el-curso-basico-de-r/</guid>
      <description>El curso básico de R ha concluido. Hemos tenido 904 inscritos (aunque de ellos sólo un porcentaje pequeño ha tenido una participación activa) que a lo largo de 5 semanas han seguido el programa que planteamos Juanjo Gibaja y yo.
Quiero dar las gracias a los participantes en el curso y muy particularmente a quienes han contribuido más activamente en nuestra plataforma de preguntas y aprendizaje.
Al acabar hemos hecho una pequeña encuesta entre quienes lo han seguido con los resultados siguientes:</description>
    </item>
    
    <item>
      <title>Las IV Jornadas de Usuarios de R están aquí</title>
      <link>/2012/07/19/las-iv-jornadas-de-usuarios-de-r-estan-aqui/</link>
      <pubDate>Thu, 19 Jul 2012 07:01:59 +0000</pubDate>
      
      <guid>/2012/07/19/las-iv-jornadas-de-usuarios-de-r-estan-aqui/</guid>
      <description>Como imagino que ya sabréis, las IV Jornadas de Usuarios de R están aquí. El anuncio oficial, reproducido debajo, se hizo ayer:
Tendrán lugar los días 15 y 16 de noviembre en el CREAL, Barcelona y está coorganizadas por el CREAL, el Grupo de Usuarios de R de Barcelona y la Comunidad R Hispano.
Toda la información necesaria para participar y registrarse está disponible en
http://www.r-es.org/IV+Jornadas
Quiero invitar a todos a acudir, participar y difundir la noticia de esta nueva edición de las Jornadas de Usuarios de R.</description>
    </item>
    
    <item>
      <title>Dos cursos de R en la U. de Murcia</title>
      <link>/2012/07/17/dos-cursos-de-r-en-la-u-de-murcia/</link>
      <pubDate>Tue, 17 Jul 2012 07:15:02 +0000</pubDate>
      
      <guid>/2012/07/17/dos-cursos-de-r-en-la-u-de-murcia/</guid>
      <description>La Universidad de Murcia ha organizado dos talleres sobre R:
 * [Iniciación a los gráficos estadísticos con R](http://www.caldum.org/?p=5266), es el día 19 de julio de 2012, de 10:00 a 13:00h. * [Creación automática de informes con R: markdown + knitr](http://www.caldum.org/?p=5285), tendrá lugar el 24 julio a la misma hora.  Ambos tienen un enfoque eminentemente práctico y podrán seguirse por videoconferencia (entrando como invitado).</description>
    </item>
    
    <item>
      <title>¿Afectó el fraude de Barclays al Libor?</title>
      <link>/2012/07/05/afecto-el-fraude-de-barclays-al-libor/</link>
      <pubDate>Thu, 05 Jul 2012 06:02:59 +0000</pubDate>
      
      <guid>/2012/07/05/afecto-el-fraude-de-barclays-al-libor/</guid>
      <description>Después de la entrada de ayer y de

he decidido mirar a ver qué impacto puede haber tenido el fraude de Barclays, uno de los 16 bancos que aportan datos para calcular el índice, sobre su valor diario.
El procedimiento por el que se calcula el Libor lo describí ayer. Y también indiqué de dónde descargar los datos históricos que proporciona The Guardian. Así que puedo comenzar cargando los datos en R,</description>
    </item>
    
    <item>
      <title>Libor, líbor, Fundéu y Barclays, claro</title>
      <link>/2012/07/04/libor-libor-fundeu-y-barclays-claro/</link>
      <pubDate>Wed, 04 Jul 2012 07:10:22 +0000</pubDate>
      
      <guid>/2012/07/04/libor-libor-fundeu-y-barclays-claro/</guid>
      <description>Hace un tiempo pregunté a la Fundéu cómo traducir la expresión over the counter. Pobres, tienen mucho trabajo en esta península asperjada de anglicismos. La respuesta, sinceramente, no me sirvió de mucho: me impedía hacerme entender con mis semejantes.
Hace poco se le planteó también si escribir Euribor o euríbor. Optaron por la segunda por considerar el término como común.
Yo solo estoy de acuerdo con ellos a medias. Por un lado, existe el euríbor (nombre común y propiamente españolizado, con su tilde) que se refiere a cierto precio del dinero (o tipo de interés).</description>
    </item>
    
    <item>
      <title>Gráficos estadísticos y mapas con R</title>
      <link>/2012/07/02/graficos-estadisticos-y-mapas-con-r/</link>
      <pubDate>Mon, 02 Jul 2012 06:55:03 +0000</pubDate>
      
      <guid>/2012/07/02/graficos-estadisticos-y-mapas-con-r/</guid>
      <description>Me ha llegado noticia de un nuevo libro sobre R, Gráficos estadísticos y mapas con R recién publicado.

Los autores son Cástor Guisande y Antonio Vaamonde, ambos de la Universidad de Vigo. Y de la ficha del libro extraigo:
En la segunda parte del libro se revisan de forma sistemática los principales gráficos, desde los más básicos y habituales (dispersión, histograma, diagrama de barras, de cajas, etc.) hasta los más complejos (vilote, curvas de nivel, gráficos de control, gráficos para meta-análisis, árboles de clasificación, mapas, etc.</description>
    </item>
    
    <item>
      <title>useR2013, en Albacete</title>
      <link>/2012/06/20/user2013-en-albacete/</link>
      <pubDate>Wed, 20 Jun 2012 07:18:00 +0000</pubDate>
      
      <guid>/2012/06/20/user2013-en-albacete/</guid>
      <description>Aunque la noticia ya se sabe desde hace algunos días (y de hecho, la conocía desde antes de que se hiciese oficialmente pública), quiero dejar constancia aquí de ella: el congreso internacional de usuarios de R del año 2013, useR2013!, tendrán lugar en Albacete, en el mes de julio.
Los interesados pueden consultar la página del congreso o seguir su cuenta en Twitter.

Quiero, por un lado agradecer a quienes han hecho posible que esto suceda y muy particularmente a Virgilio Gómez Rubio, a Emilio López Cano —que son, de entre ellos, los que conozco personalmente— su trabajo y desearles mucho éxito.</description>
    </item>
    
    <item>
      <title>Hoy ha comenzado el curso básico de R</title>
      <link>/2012/06/11/hoy-ha-comenzado-el-curso-basico-de-r/</link>
      <pubDate>Mon, 11 Jun 2012 06:23:40 +0000</pubDate>
      
      <guid>/2012/06/11/hoy-ha-comenzado-el-curso-basico-de-r/</guid>
      <description>Hoy ha comenzado el curso básico de R. A Juanjo Gibaja y a mí nos ha sorprendido (muy agradablemente, por cierto) el espectacular recibimiento que ha merecido el curso: tenemos prácticamente 700 usuarios registrados.
El programa de la primera semana cubre:
 Los capítulos 1 a 6 de icebreakeR Los capitulos 1 a 6 de An Introduction to R El minitutorial de RStudio que he colgado de r-es.org y que es editable y mejorable por todos.</description>
    </item>
    
    <item>
      <title>Las IV Jornadas de Usuarios de R están en marcha</title>
      <link>/2012/06/08/las-iv-jornadas-de-usuarios-de-r-estan-en-marcha/</link>
      <pubDate>Fri, 08 Jun 2012 06:57:44 +0000</pubDate>
      
      <guid>/2012/06/08/las-iv-jornadas-de-usuarios-de-r-estan-en-marcha/</guid>
      <description>Entusiastas de R todos, regocijémonos: las IV Jornadas de Usuarios de R están en marcha. Aunque el anuncio oficial todavía no se ha hecho, estoy en condiciones de adelantar que este invierno, como viene siendo tradicional y si no se tuercen las cosas, nos veremos todos de nuevo en Barcelona.
Y&amp;hellip; hasta ahí puedo leer.
P.D.: También es inminente el anuncio otra gran noticia para la comunidad de usuarios de R&amp;hellip;</description>
    </item>
    
    <item>
      <title>Hoy hablaremos de r-es.org</title>
      <link>/2012/06/07/hoy-hablaremos-de-r-es-org/</link>
      <pubDate>Thu, 07 Jun 2012 06:40:17 +0000</pubDate>
      
      <guid>/2012/06/07/hoy-hablaremos-de-r-es-org/</guid>
      <description>Hoy voy a hablar del portal de la Comunidad R Hispano, r-es.org. Quiero aprovechar la inusitada popularidad de mi bitácora desde que se anunció el curso básico de R para hacerlo.
Y hacerlo para invitar a todo el mundo a conocerlo, a visitarlo, a participar en él y a mejorarlo.

Porque es posible. Xavier de Pedro lo ha diseñado utilizando Tiki, un gestor documental, que brinda a la comunidad de usuarios la posibilidad, otorga el derecho y, en cierto modo, según se mire, le impone la obligación de enriquecerlo con aportaciones.</description>
    </item>
    
    <item>
      <title>La prehistoria de R, según Patrick Burns</title>
      <link>/2012/06/04/la-prehistoria-de-r-segun-patrick-burns/</link>
      <pubDate>Mon, 04 Jun 2012 07:29:16 +0000</pubDate>
      
      <guid>/2012/06/04/la-prehistoria-de-r-segun-patrick-burns/</guid>
      <description>Para muchos de nosotros, R es algo del siglo XXI. Patrick Burns, sin embargo, es capaz de estirar la memoria hasta hace casi 30 años, 1984, momento en el que S, que era entonces un proyecto experimental de los laboratorios Bell, salió al mundo.
S evolucionó hacia S+ entre 1984 y 1992. Al aparecer R, la situación era aproximadamente así:

Y, de hecho, en las primeras versiones de R, el código (extraído del artículo R: Lessons Learned, Directions for the Future de Ross Ihaka) tenía esta pinta:</description>
    </item>
    
    <item>
      <title>Curso de R gratuito no presencial</title>
      <link>/2012/06/01/curso-de-r-gratuito-no-presencial/</link>
      <pubDate>Fri, 01 Jun 2012 07:21:44 +0000</pubDate>
      
      <guid>/2012/06/01/curso-de-r-gratuito-no-presencial/</guid>
      <description>Hace unos diez años aprendí R por mi solo y por mi cuenta. Entoces era una rareza y no me constaba que en mi universidad hubiese nadie trabajando con él.
Diez años después, R ha cobrado tal importancia que son muchos los interesados en aprenderlo. Para subvenir a esta demanda, Juanjo Gibaja y yo hemos diseñado un curso de R básico con las siguientes características:
 * Es **gratuito**. * No da derecho a diplomas o certificados de ningún tipo.</description>
    </item>
    
    <item>
      <title>SAP, HANA, RHANA y R</title>
      <link>/2012/05/29/sap-hana-rhana-y-r/</link>
      <pubDate>Tue, 29 May 2012 06:52:15 +0000</pubDate>
      
      <guid>/2012/05/29/sap-hana-rhana-y-r/</guid>
      <description>SAP es tal vez la mayor empresa europea de software. Aunque es principalmente conocida por sus programas de gestión empresarial, ha hecho sus pinitos en el mundo de los gestores de bases de datos con HANA. Una de sus principales peculiaridades es que almacena la información en memoria, beneficiándose, por un lado, del abaratamiento del hardware y, por el otro, de la velocidad de acceso.

Otra, de mucho más interés para quienes siguen esta bitácora, es la posibilidad de conectarlo con R.</description>
    </item>
    
    <item>
      <title>Desencriptando (II): la avaricia es mala</title>
      <link>/2012/05/28/desencriptando-ii-la-avaricia-es-mala/</link>
      <pubDate>Mon, 28 May 2012 07:07:51 +0000</pubDate>
      
      <guid>/2012/05/28/desencriptando-ii-la-avaricia-es-mala/</guid>
      <description>El otro día propuse y resolví un problema de encriptación con R. Utilizaba uno de los llamados métodos avariciosos (o greedy) para hallar el máximo de una función (que era, en esencia, la función de verosimilitud de una determinada permutación de caracteres dentro del espacio probabilístico de todas ellas).
Este método funcionó con una cadena relativamente larga para desencriptar pero falla con otras más cortas. Por ejemplo, con
cadena &amp;lt;-c(&amp;quot;u&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;i&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;g&amp;quot;,&amp;quot;m&amp;quot;,&amp;quot;h&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;y&amp;quot;, &amp;quot;b&amp;quot;,&amp;quot;g&amp;quot;,&amp;quot;m&amp;quot;,&amp;quot;a&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;p&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;m&amp;quot;,&amp;quot;d&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;h&amp;quot;,&amp;quot;z&amp;quot;,&amp;quot;y&amp;quot;, &amp;quot;r&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;i&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;l&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;i&amp;quot;,&amp;quot;n&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;t&amp;quot;,&amp;quot;d&amp;quot;,&amp;quot;t&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;z&amp;quot;, &amp;quot;c&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;v&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;o&amp;quot;,&amp;quot;d&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;s&amp;quot;,&amp;quot;e&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;q&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;c&amp;quot;, &amp;quot;n&amp;quot;,&amp;quot;g&amp;quot;,&amp;quot;q&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;i&amp;quot;,&amp;quot;g&amp;quot;,&amp;quot;m&amp;quot;,&amp;quot;r&amp;quot;,&amp;quot;y&amp;quot;,&amp;quot;d&amp;quot;,&amp;quot;i&amp;quot;,&amp;quot;v&amp;quot;,&amp;quot;r&amp;quot;)  Si ejecuto el código que presenté el otro día,</description>
    </item>
    
    <item>
      <title>Patrones hexagonales con R</title>
      <link>/2012/05/23/patrones-hexagonales-con-r/</link>
      <pubDate>Wed, 23 May 2012 07:25:13 +0000</pubDate>
      
      <guid>/2012/05/23/patrones-hexagonales-con-r/</guid>
      <description>Navegando por internet di con el gráfico

(que puede encontrarse aquí) además de un enlace al código en Matlab usado para generarlo.
Diríase que lo programó un contable. Tratad de seguirlo y veréis por qué lo digo.
Y por entretenerme, traté de generarlo con R. Y creo que de una manera algo más intuitiva:
 1. Creo una función que sabe pintar un hexágono en una posición dada. 2. Creo una retícula de centros de hexágonos del tamaño adecuado.</description>
    </item>
    
    <item>
      <title>España, ¿radial? (II)</title>
      <link>/2012/04/26/espana-%c2%bfradial-ii/</link>
      <pubDate>Thu, 26 Apr 2012 06:44:51 +0000</pubDate>
      
      <guid>/2012/04/26/espana-%c2%bfradial-ii/</guid>
      <description>Una de las principales objeciones que se le pueden hacer a mi entrada de ayer es que puede estar confundiendo la causa con efecto: puede que parte de la radialidad de la red que obtuve tenga que ver con el tamaño desproporcionado de Madrid que, a su vez, podría haber sido causado por la radialidad de la red tradicional de las comunicaciones españolas.
Así que enviemos una partida de pescado en malas condiciones a Mercamadrid, convidemos a toda la provincia, veámosla fenecer víctima de contumaces diarreas y rehagamos la simulación suponiendo que</description>
    </item>
    
    <item>
      <title>España, ¿radial? (I)</title>
      <link>/2012/04/25/espana-%c2%bfradial-i/</link>
      <pubDate>Wed, 25 Apr 2012 07:05:16 +0000</pubDate>
      
      <guid>/2012/04/25/espana-%c2%bfradial-i/</guid>
      <description>Me propuse hace un tiempo combinar lo que aprendí creando rutas callejeras por Zaragoza con una entrada que escribí sobre la estructura radial de las vías de transporte de España. El problema que me planteo es si tiene sentido que la red de carreteras Española tenga estructura radial habida cuenta de la geometría peninsular bajo ciertas hipótesis, siempre discutibles y mejorables, de partida.
Así que, en primer lugar, cargué los paquetes de R necesarios, un fichero que creé que contenía las capitales de provincia, su latitud, su longitud y la población de las respectivas provincias y fabriqué una red de carreteras muy ineficiente que unía todos los nodos entre sí:</description>
    </item>
    
    <item>
      <title>Segunda reunión de usuarios de R de Madrid: recordatorio</title>
      <link>/2012/04/24/segunda-reunion-de-usuarios-de-r-de-madrid-recordatorio/</link>
      <pubDate>Tue, 24 Apr 2012 06:54:32 +0000</pubDate>
      
      <guid>/2012/04/24/segunda-reunion-de-usuarios-de-r-de-madrid-recordatorio/</guid>
      <description>Aprovecho para recordar a los usuarios de R de Madrid que el jueves 26 de abril, a las siete de la tarde, tendrá lugar la segunda reunión del grupo de usuarios de R de Madrid en la sala Metrópolis de La Tabacalera (glorieta de Embajadores).
El programa, como siempre, puede consultarse en la página del grupo.</description>
    </item>
    
    <item>
      <title>Variables instrumentales con R</title>
      <link>/2012/04/19/variables-instrumentales-con-r/</link>
      <pubDate>Thu, 19 Apr 2012 07:30:54 +0000</pubDate>
      
      <guid>/2012/04/19/variables-instrumentales-con-r/</guid>
      <description>Los economistas usan unas cosas a las que llaman variables instrumentales con las que uno apenas se tropieza fuera de contextos econométricos. El problema se plantea en el contexto de la regresión
$$y_i = \beta x_i + \varepsilon_i,$$
cuando existe correlación entre X y $latex \varepsilon$. En tales casos, el estimador por mínimos cuadrados es
$$\hat{\beta} =\frac{x&amp;rsquo;y}{x&amp;rsquo;x}=\frac{x&#39;(x\beta+\varepsilon)}{x&amp;rsquo;x}=\beta+\frac{x&#39;\varepsilon}{x&amp;rsquo;x}$$
y debido a la correlación entre X y $latex \varepsilon$, está sesgado.
La solución que se plantea en ocasiones es el de usar variables instrumentales, es decir, variables correlacionadas con X pero no con $latex \varepsilon$.</description>
    </item>
    
    <item>
      <title>Rutas por Zaragoza con R</title>
      <link>/2012/04/16/rutas-por-zaragoza-con-r/</link>
      <pubDate>Mon, 16 Apr 2012 07:17:15 +0000</pubDate>
      
      <guid>/2012/04/16/rutas-por-zaragoza-con-r/</guid>
      <description>Óscar Perpiñán me puso el otro día al tanto del paquete osmar de R, que
Hoy voy a ilustrar el uso de este paquete adaptando un ejemplo de sus autores para encontrar la ruta óptima entre dos puntos de Zaragoza, la mercería Bell y el colegio La Salle Montemolín, ambos lugares muy vinculados a mi prehistoria. Comenzaré cargando los paquetes necesarios y los datos de OpenStreetMap correspondientes a Zaragoza:
library( igraph ) library( osmar ) api &amp;lt;- osmsource_api(url = &amp;quot;http://api.</description>
    </item>
    
    <item>
      <title>Corrección por exposición del modelo logístico</title>
      <link>/2012/04/11/correccion-por-exposicion-del-modelo-logistico/</link>
      <pubDate>Wed, 11 Apr 2012 06:52:19 +0000</pubDate>
      
      <guid>/2012/04/11/correccion-por-exposicion-del-modelo-logistico/</guid>
      <description>He tropezado con una extensión curiosa y que no conocía del modelo logístico que lo emparenta un tanto con los modelos de supervivencia. Es un problema que aparece en los modelos de los actuarios, por ejemplo, y en la supervivencia de nidos (sí, nidos de bichos alados), parece.
Es el siguiente: supongamos que unos sujetos están expuestos a un cierto suceso cuya probabilidad, $latex p_i$, depende del sujeto a través del esquema habitual de la regresión logística (es decir, depende de algunas variables como el sexo, etc.</description>
    </item>
    
    <item>
      <title>Un intérprete alternativo de R</title>
      <link>/2012/04/10/un-interprete-alternativo-de-r/</link>
      <pubDate>Tue, 10 Apr 2012 06:56:04 +0000</pubDate>
      
      <guid>/2012/04/10/un-interprete-alternativo-de-r/</guid>
      <description>Java es un lenguaje de programación que puede ejecutarse sobre muchas máquinas virtuales distintas: la de Sun, la de IBM, etc. Algo parecido pasa con SAS, que puede ejecutarse sobre el intérprete de SAS Institute o sobre el de WPS.
El código escrito en R puede ejecutarse, en principio, en dos plataformas distintas:
 * La creada por el _R Development Core Team_ y que todos, más o menos, conocemos. * La desarrollada por Tibco (y, previamente, por Insightful) para S-Plus, el dialecto propietario de R (o S).</description>
    </item>
    
    <item>
      <title>De D&#39;Hondt a Banzhaf</title>
      <link>/2012/04/04/de-dhondt-a-banzhaf/</link>
      <pubDate>Wed, 04 Apr 2012 07:15:23 +0000</pubDate>
      
      <guid>/2012/04/04/de-dhondt-a-banzhaf/</guid>
      <description>Hablé el otro día con Emilio Torres y comentamos de pasada la situación política en Asturias, donde vive, después de las últimas elecciones. El escaño obtenido por UPyD otorgaba a tal partido un poder en exceso del tamaño de su representación porque era clave para formar el futuro gobierno del principado. Pero, ¿cuánto poder realmente supone ese escaño en esas condiciones? ¿Puede cuantificarse?
Porque se habla mucho en periodo electoral de la ley D&amp;rsquo;Hondt pero, una vez asignados los escaños, cambia el juego.</description>
    </item>
    
    <item>
      <title>Otra de huelgas</title>
      <link>/2012/03/29/otra-de-huelgas/</link>
      <pubDate>Thu, 29 Mar 2012 07:41:32 +0000</pubDate>
      
      <guid>/2012/03/29/otra-de-huelgas/</guid>
      <description>Hoy, por motivos evidentes, e igual que en septiembre de 2010, voy a hablar de huelgas. De la misma fuente que entonces he descargado este fichero. Y he ejecutado
library( pxR ) library( reshape ) library( ggplot2 ) dat &amp;lt;- read.px( &amp;quot;pcaxis-623612450.px&amp;quot; ) dat &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/as.data.frame&amp;quot;&amp;gt;as.data.frame( dat ) dat.mes &amp;lt;- cast( dat, Periodo ~ series ) colnames(dat.mes) &amp;lt;- c( &amp;quot;mes&amp;quot;, &amp;quot;n.huelgas&amp;quot;, &amp;quot;n.trabajadores&amp;quot;, &amp;quot;n.jornadas&amp;quot; ) p &amp;lt;- ggplot( data = dat.</description>
    </item>
    
    <item>
      <title>R y la distribución de Rayleigh</title>
      <link>/2012/03/23/r-y-la-distribucion-de-rayleigh/</link>
      <pubDate>Fri, 23 Mar 2012 07:26:24 +0000</pubDate>
      
      <guid>/2012/03/23/r-y-la-distribucion-de-rayleigh/</guid>
      <description>En la reunión de usuarios de R de Madrid de ayer, Carlos Ortega estudió la distribución en el tiempo del número de bugs que aparecen en el código de R en cada versión. Indicó que es plausible que sigan una distribución de Rayleigh, relativamente frecuente en ese tipo de contextos. E indicó que esta distribución, no tan conocida, tiene que ver (he olvidado lo que dijo exactamente) con dos normales independientes.</description>
    </item>
    
    <item>
      <title>Noticia de la primera reunión del grupo de usuarios de R de Madrid</title>
      <link>/2012/03/22/primera-reunion-del-grupo-de-usuarios-de-r-de-madrid-ii/</link>
      <pubDate>Thu, 22 Mar 2012 08:05:49 +0000</pubDate>
      
      <guid>/2012/03/22/primera-reunion-del-grupo-de-usuarios-de-r-de-madrid-ii/</guid>
      <description>Acaba de terminar la primera reunión del grupo de usuarios de R de Madrid. No hemos disfrutado de la más primaveral de las tardes. Y la ubicación era un tanto excéntrica. Pero hemos tenido tres charlas muy interesantes (y luego, la mía, claro), nueve asistentes (¡espero haber contado bien!) y, sobre todo, unos intercambio de ideas sumamente provechosos.
Los enlaces a las presentaciones estarán pronto disponibles en la página del grupo.</description>
    </item>
    
    <item>
      <title>Un articulillo de Tukey</title>
      <link>/2012/03/21/un-articulillo-de-tukey/</link>
      <pubDate>Wed, 21 Mar 2012 07:31:13 +0000</pubDate>
      
      <guid>/2012/03/21/un-articulillo-de-tukey/</guid>
      <description>Hoy ando demasiado ocupado para escribir. Y como es posible que alguno de mis lectores no lo esté tanto como para no leer, le dejo un artículo de Tukey (abajo del todo en el enlace anterior) para que conozca al personaje, si no ha tenido el gusto previo, disfrute en cualquer caso y, en todos, sepa de dónde vienen los rootograms que implementa el paquete latticeExtra de R.</description>
    </item>
    
    <item>
      <title>Primera reunión del grupo de usuarios de R de Madrid</title>
      <link>/2012/03/20/primera-reunion-del-grupo-de-usuarios-de-r-de-madrid/</link>
      <pubDate>Tue, 20 Mar 2012 08:11:56 +0000</pubDate>
      
      <guid>/2012/03/20/primera-reunion-del-grupo-de-usuarios-de-r-de-madrid/</guid>
      <description>El miércoles 21 de marzo de 2012, en el aula N-130 del edificio de primer curso (también conocido como Prefabricado) de la facultad de CC. Económicas de la UCM (Somosaguas) tendrá lugar la primera reunión del grupo de usuarios de R de Madrid.
Contamos con tres charlas muy interesantes y una mía. Esta última trata de una función que aún no existe sino en forma de bosquejo en mi cabeza. Espero que esté presentable el miércoles.</description>
    </item>
    
    <item>
      <title>¡Maño qué mapa!</title>
      <link>/2012/03/14/%c2%a1mano-que-mapa/</link>
      <pubDate>Wed, 14 Mar 2012 08:35:49 +0000</pubDate>
      
      <guid>/2012/03/14/%c2%a1mano-que-mapa/</guid>
      <description>Esta mañana casi me da esa tontería de sentirme orgulloso de ser de donde soy, Zaragoza. Al fin y al cabo, podría haber sido de cualquier otro lugar. Pero es que Zaragoza tiene uno de los portales de datos públicos municipales más avanzados. En eso es una ciudad pionera.
(Se lo hemos de agradecer a nuestro alcalde, Belloch, que, dicen las malas lenguas, además de socialista y barbudo, es linuxero).</description>
    </item>
    
    <item>
      <title>Esperanzador no: varianzador</title>
      <link>/2012/03/07/esperanzador-no-varianzador/</link>
      <pubDate>Wed, 07 Mar 2012 07:51:04 +0000</pubDate>
      
      <guid>/2012/03/07/esperanzador-no-varianzador/</guid>
      <description>Que conste que soy un partidario de los adjetivos. Supongo que por sentimentalismo. Me caen simpáticos excepto
 * cuando se abusa de ellos y se dice, por ejemplo, analítica en lugar de análisis o normativa en lugar de norma o * los usan estadísticos en horario laboral.  Y si trabajan en el INE, aún más: se les paga por estadísticos, no por guionistas de opereta.
Viene esto al siguiente párrafo (con mi subrayado):</description>
    </item>
    
    <item>
      <title>Más sobre Julia (II): mi primer programa</title>
      <link>/2012/03/06/mas-sobre-julia-ii-mi-primer-programa/</link>
      <pubDate>Tue, 06 Mar 2012 08:37:57 +0000</pubDate>
      
      <guid>/2012/03/06/mas-sobre-julia-ii-mi-primer-programa/</guid>
      <description>A las entradas que he hecho sobre Julia estos últimos días, quiero añadir esta en la que publico mi primer programa en dicho lenguaje.
Me ha dado por reimplementar el programa para realizar un muestreo de Gibbs que aparece en Gibbs sampler in various languages.
Lo primero ha sido instalar Julia, para lo que basta con seguir las instrucciones que aparecen en su página de github. Y aviso: tarda bastante en descargar y compilar todas sus dependencias.</description>
    </item>
    
    <item>
      <title>Julia, un nuevo lenguaje para la programación científica</title>
      <link>/2012/02/28/3327/</link>
      <pubDate>Tue, 28 Feb 2012 08:02:29 +0000</pubDate>
      
      <guid>/2012/02/28/3327/</guid>
      <description>No sé si conocéis Julia, un lenguaje de programación orientado al cálculo científico. Os dejaré echarle un vistazo a su página.
¿Ya?
Bueno, pues estoy un poco enfadado con ellos. Me pasa un poco como a los catalanes que se quejaban de que en las fotos de ABC siempre sacaban a Jordi Pujol (todavía más) feo (de lo que por sí era): en las comparaciones no le hacen excesiva justicia a R.</description>
    </item>
    
    <item>
      <title>Entrevista con los promotores de RUGBCN</title>
      <link>/2012/02/20/entrevista-con-los-promotores-de-rugbcn/</link>
      <pubDate>Mon, 20 Feb 2012 07:19:25 +0000</pubDate>
      
      <guid>/2012/02/20/entrevista-con-los-promotores-de-rugbcn/</guid>
      <description>La serendipia me llevó a toparme con el RUGBCN, es decir, el grupo de usuarios de R de Barcelona. Me puse en contacto con ellos y Lluis Ramon ha tenido la gentileza de ofrecerse a responder una serie de preguntas mías que espero que, por un lado, animen a los usuarios de R de BCN a acercarse a las reuniones y, por otro, sirvan de estímulo para la creación de grupos de usuarios similares en otros lugares.</description>
    </item>
    
    <item>
      <title>Virguería con R</title>
      <link>/2012/02/16/virgueria-con-r/</link>
      <pubDate>Thu, 16 Feb 2012 07:50:40 +0000</pubDate>
      
      <guid>/2012/02/16/virgueria-con-r/</guid>
      <description>A la pregunta, tal vez con una formulación mejorable de un usuario de la lista de R, sobre cómo representar una distribución normal bivariada con correlación 0.5 en 3D di ayer esta solución:
library( &amp;lt;a href=&amp;quot;http://inside-r.org/packages/cran/mvtnorm&amp;quot;&amp;gt;mvtnorm ) x &amp;lt;- y &amp;lt;- -20:20 / 10 z &amp;lt;- matrix( 0, length( x ), length( y ) ) m &amp;lt;- c(0,0) sigma &amp;lt;- matrix( c(1, 0.5, 0.5, 1 ), 2 ) for( i in 1: length( x ) ) for( j in 1:length( y ) ) z[i,j] &amp;lt;- dmvnorm( c( x[i], y[j] ), c(0,0), sigma ) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Curso de Estadística Aplicada a la Investigación Biomédica con R en el CNIO</title>
      <link>/2012/02/15/curso-de-estadistica-aplicada-a-la-investigacion-biomedica-con-r-en-el-cnio/</link>
      <pubDate>Wed, 15 Feb 2012 15:34:22 +0000</pubDate>
      
      <guid>/2012/02/15/curso-de-estadistica-aplicada-a-la-investigacion-biomedica-con-r-en-el-cnio/</guid>
      <description>Me acaba de llegar la noticia de que el Centro Nacional de Investigaciones Oncológicas (CNIO) va a organizar en Madrid los días 25, 26 y 27 de Abril de 2012 el curso Estadística Aplicada a la Investigación Biomédica con R.

El objetivo del curso es cubrir las técnicas más utilizadas en la aplicación de la estadística a las ciencias de la salud, a la práctica clínica y epidemiológica y a la investigación biomédica en general.</description>
    </item>
    
    <item>
      <title>Guía de econometría básica con R</title>
      <link>/2012/02/14/guia-de-econometria-basica-con-r/</link>
      <pubDate>Tue, 14 Feb 2012 21:24:09 +0000</pubDate>
      
      <guid>/2012/02/14/guia-de-econometria-basica-con-r/</guid>
      <description>Aunque muchos de mis lectores ya estarán al corriente de la noticia, la reitero aquí: Gregorio Serrano ha comenzado una serie de artículos en su bitácora sobre econometría básica con R.
Puede seguirse por RSS (incluso usando mi agregador de noticias sobre R en RSS o HTML) y en su cuenta de Twitter.</description>
    </item>
    
    <item>
      <title>R y alRededoRes en MediaLab Prado</title>
      <link>/2012/02/13/r-y-alrededores-en-medialab-prado/</link>
      <pubDate>Mon, 13 Feb 2012 17:58:56 +0000</pubDate>
      
      <guid>/2012/02/13/r-y-alrededores-en-medialab-prado/</guid>
      <description>Con retraso —del que mis vacaciones en tierras australes tienen la culpa— doy noticia de la charla que dio Carlos Ortega, antiguo colaborador de esta bitácora, en MediaLab Prado, dentro del ciclo de periodismo de datos.

La presentación que hizo y su vídeo pueden consultarse en línea.
Quiero también subrayar y dejar constancia para los futuros historiadores de la cosa que esta ha sido la primera actividad pública promovida por la recientemente constituida Comunidad de Usuarios de R (que tengo, como es probable que sepan ya mis lectores, el honor de presidir).</description>
    </item>
    
    <item>
      <title>La frontera bayesiana en problemas de clasificación (simples)</title>
      <link>/2012/02/01/la-frontera-bayesiana-en-problemas-de-clasificacion-simples/</link>
      <pubDate>Wed, 01 Feb 2012 00:32:20 +0000</pubDate>
      
      <guid>/2012/02/01/la-frontera-bayesiana-en-problemas-de-clasificacion-simples/</guid>
      <description>Una de las preguntas formuladas dentro del foro desde el que seguimos la lectura del libro The Elements of Statistsical Learning se refiere a cómo construir la frontera bayesiana óptima en ciertos problemas de clasificación.
Voy a plantear aquí una discusión así como código en R para representarla (en casos simples y bidimensionales).
Supongamos que hay que crear un clasificador que distinga entre puntos rojos y verdes con la siguiente pinta,</description>
    </item>
    
    <item>
      <title>Nueve reinas con SAS (y R también)</title>
      <link>/2012/01/23/nueve-reinas-con-sas-y-r-tambien/</link>
      <pubDate>Mon, 23 Jan 2012 07:15:44 +0000</pubDate>
      
      <guid>/2012/01/23/nueve-reinas-con-sas-y-r-tambien/</guid>
      <description>No sé si habéis visto la película argentina Nueve reinas. Trata de unos timadores que engatusan a incautos para sacarles la platica.
Pero no voy a hablar de esas nueve reinas sino de las ocho de Solve Eight Queens Puzzle With SAS Macro. De su introducción extraigo y traduzco:
Queremos revisar esta comparación bajo otra perspectiva mostrando cómo SAS es el lenguaje perfecto para manejar estructuras de datos complejas y lo fácil que resulta implementar con él algoritmos complejos.</description>
    </item>
    
    <item>
      <title>Cosa prodigiosa, ahora con palabras (II)</title>
      <link>/2012/01/19/cosa-prodigiosa-ahora-con-palabras-ii/</link>
      <pubDate>Thu, 19 Jan 2012 06:32:41 +0000</pubDate>
      
      <guid>/2012/01/19/cosa-prodigiosa-ahora-con-palabras-ii/</guid>
      <description>Tal como prometí hace ahora una semana, voy a añadir las palabras que faltaban en aquella entrada. Pero primero, imaginad un bar en el que se venden cafés y cervezas. El coste de servir un café es de 1.10 euros pero se vende por 1. El coste de servir una cerveza es 1.30 euros pero se vende por 1.10. Entran los clientes y piden o café o cerveza. ¡Y resulta que a fin de mes el bar hace dinero!</description>
    </item>
    
    <item>
      <title>R, en el &#39;top 20&#39; de Tiobe</title>
      <link>/2012/01/18/r-en-el-top-20-de-tiobe/</link>
      <pubDate>Wed, 18 Jan 2012 16:40:33 +0000</pubDate>
      
      <guid>/2012/01/18/r-en-el-top-20-de-tiobe/</guid>
      <description>Más evidencias sobre la emergencia de R: ha entrado en el top 20 de lenguajes de programación elaborado por Tiobe por primera vez en enero de 2012:

La lista, según avisa el mismo Tiobe, no es científica: se basa en un índice de popularidad elaborado a partir de información de ofertas laborales, buscadores de internet, etc.
Nótese también que es el primero de los lenguajes de programación que no es de propósito general sino de dominio (la estadística).</description>
    </item>
    
    <item>
      <title>Muestreando la distribución uniforme sobre la esfera unidad en n dimensiones</title>
      <link>/2012/01/17/muestreando-la-distribucion-uniforme-sobre-la-esfera-unidad-en-n-dimensiones/</link>
      <pubDate>Tue, 17 Jan 2012 06:56:36 +0000</pubDate>
      
      <guid>/2012/01/17/muestreando-la-distribucion-uniforme-sobre-la-esfera-unidad-en-n-dimensiones/</guid>
      <description>Debo esta entrada a la diligencia de Juanjo Gibaja, que se tomó la molestia de ubicar los teoremas relevantes en el libro Simulation and the Monte Carlo Method de Rubinstein y Kroese.
Esencialmente, como la distribución normal multivariante (con matriz de covarianzas I) es simétrica, entonces, dadas $latex X_1,\dots, X_m \sim N( 0, I_n )$ independientes, los m puntos del espacion n-dimensional $latex X_i/| X_i |$ siguen una distribución uniforme sobre su esfera (su superficie, vale la pena reiterar) unidad.</description>
    </item>
    
    <item>
      <title>Eles, &#34;casts&#34; y el rizo del rizo de la programación eficiente (con R)</title>
      <link>/2012/01/16/eles-casts-y-el-rizo-del-rizo-de-la-programacion-eficiente-con-r/</link>
      <pubDate>Mon, 16 Jan 2012 07:16:10 +0000</pubDate>
      
      <guid>/2012/01/16/eles-casts-y-el-rizo-del-rizo-de-la-programacion-eficiente-con-r/</guid>
      <description>Ante las preguntas de alguno de mis lectores, voy a proporcionar una explicación acerca de la misteriosa L. Bueno, voy más bien a dejar que la deduzcan ellos mismos a partir de la siguiente serie de bloques de código:
a &amp;lt;- rep( 0, 10 ) typeof( a ) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/object.size&amp;quot;&amp;gt;object.size( a ) b &amp;lt;- rep( 0L, 10 ) typeof( b ) &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/object.size&amp;quot;&amp;gt;object.size( b ) ############## a &amp;lt;- 1:10 typeof( a ) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Cosa prodigiosa, sin palabras (I)</title>
      <link>/2012/01/12/cosa-prodigiosa-sin-palabras-i/</link>
      <pubDate>Thu, 12 Jan 2012 07:14:49 +0000</pubDate>
      
      <guid>/2012/01/12/cosa-prodigiosa-sin-palabras-i/</guid>
      <description>Hoy voy a hacer mención a una cosa prodigiosa. Pero sin palabras. Voy a regalar a mis lectores tres pedazos de código que son este
jugar &amp;lt;- function( n, make.step ){ tmp &amp;lt;- rep( 0L, n) for( i in 2:n ) tmp[i] &amp;lt;- make.step( tmp[i-1] ) tmp } juego.s &amp;lt;- function( x, prob.perder = 0.51 ){ x + ifelse( runif(1) &amp;lt; prob.perder, -1L, 1L ) } res.juego.s &amp;lt;- replicate( 1000, jugar( 1000, juego.</description>
    </item>
    
    <item>
      <title>Escribir el libro &#34;Estadística con R&#34; en tres meses, ¿quimera?</title>
      <link>/2012/01/10/escribir-el-libro-estadistica-con-r-en-tres-meses-%c2%bfquimera/</link>
      <pubDate>Tue, 10 Jan 2012 07:11:10 +0000</pubDate>
      
      <guid>/2012/01/10/escribir-el-libro-estadistica-con-r-en-tres-meses-%c2%bfquimera/</guid>
      <description>No sé si es quimera o no. Se me ocurrió el otro día. Dejo mi idea aquí escrita por ver por dónde respira la comunidad.
Se trata, sí, de un libro extenso sobre R. Que cubra el 90-95% de los métodos estadísticos que utilizan los usuarios —en sentido amplio— de la estadística: médicos, sociólogos, etc. Con R. Con la teoría justa pero, eso sí, con referencias a fuentes fiables: se supone que sus lectores saben ya algo de estadística, pero tal vez no cómo afrontar su problema con R.</description>
    </item>
    
    <item>
      <title>Comienza la lectura de “The Elements of Statistical Learning”</title>
      <link>/2012/01/09/comienza-la-lectura-de-%e2%80%9cthe-elements-of-statistical-learning%e2%80%9d/</link>
      <pubDate>Mon, 09 Jan 2012 11:53:28 +0000</pubDate>
      
      <guid>/2012/01/09/comienza-la-lectura-de-%e2%80%9cthe-elements-of-statistical-learning%e2%80%9d/</guid>
      <description>Mediante la presente, notifico a los interesados en la lectura de “The Elements of Statistical Learning” que esta semana tenemos que dar cuenta de los capítulos 1 (que es una introducción muy ligera) y 2 (donde comienza el tomate realmente).
Esta noche Juanjo Gibaja y yo estudiaremos la mecánica de lectura en común.
Los interesados pueden escribirme a cgb@datanalytics.com para, de momento, crear una lista de correo.</description>
    </item>
    
    <item>
      <title>¿Cuánto gana el banco con tu hipoteca?</title>
      <link>/2012/01/09/%c2%bfcuanto-gana-el-banco-con-tu-hipoteca/</link>
      <pubDate>Mon, 09 Jan 2012 06:44:41 +0000</pubDate>
      
      <guid>/2012/01/09/%c2%bfcuanto-gana-el-banco-con-tu-hipoteca/</guid>
      <description>Parece mentira, pero hay gente que lo calcula fatal. Hace tiempo, un antiguo colega mío, matemático él, había propuesto el ejercicio a sus alumnos y estimó, me contó, que el banco recibía, aproximadamente, el doble de lo que prestaba. La operación que había realizado era muy sencilla: calcular el saldo vivo inicial con la suma de todas las cuotas mensuales. Pero la operación es incorrecta. Veamos por qué. Y obtengamos, de paso, alguna estimación más ajustada.</description>
    </item>
    
    <item>
      <title>Gráficos de pares de variables mejorados (con R)</title>
      <link>/2011/12/29/graficos-de-pares-de-variables-mejorados-con-r/</link>
      <pubDate>Thu, 29 Dec 2011 06:51:03 +0000</pubDate>
      
      <guid>/2011/12/29/graficos-de-pares-de-variables-mejorados-con-r/</guid>
      <description>Un gráfico de pares de variables —que no he sabido traducir mejor desde el original inglés pairplot— es algo como lo siguiente:

Es posible ahora construir gráficos de pares más sofisticados e informativos usando el paquete GGally de R. Usando el código (extraído de SAS and R)
1 2 3 4 5 6 7 8 9 10  library(GGally) ds &amp;lt;- read.csv(&amp;#34;http://www.math.smith.edu/r/data/help.csv&amp;#34;) ds$sex &amp;lt;- as.factor( ifelse(ds$female==1, &amp;#34;female&amp;#34;, &amp;#34;male&amp;#34;) ) ds$housing &amp;lt;- as.</description>
    </item>
    
    <item>
      <title>El lucero del alba</title>
      <link>/2011/12/27/el-lucero-del-alba/</link>
      <pubDate>Tue, 27 Dec 2011 06:39:02 +0000</pubDate>
      
      <guid>/2011/12/27/el-lucero-del-alba/</guid>
      <description>Puede que algunos de mis lectores sepan que el lucero del alba es el nombre con que se conoce al planeta Venus cuando es visible en el cielo al amanecer.
En contextos menos poéticos se conoce por tal nombre a esto:

Es decir, una determinada configuración de los precios de apertura y cierre de tres días de cotización (bursátil, por ejemplo) de forma que:
 El primer día hay una bajada El tercer día hay una subida Los precios de apertura y cierre del segundo día son inferiores a los del cierre del primero y apertura del segundo.</description>
    </item>
    
    <item>
      <title>¿Nos leemos &#34;The Elements of Statistical Learning&#34; de tapa a tapa?</title>
      <link>/2011/12/23/nos-leemos-the-elements-of-statistical-learning-de-tapa-a-tapa/</link>
      <pubDate>Fri, 23 Dec 2011 07:13:32 +0000</pubDate>
      
      <guid>/2011/12/23/nos-leemos-the-elements-of-statistical-learning-de-tapa-a-tapa/</guid>
      <description>Propone Juan José Gibaja como propósito intelectual para el año nuevo el leer The Elements of Statistical Learning —libro que puede descargarse gratuita y legalmente del enlace anterior— de tapa a tapa, en grupo y a razón de capítulo por semana.

La idea es hacerlo en común, enlazando el contenido del libro con código —sea disponible o de nuevo cuño cuando la situación lo requiera— y haciendo públicos las ideas que resulten de esta lectura en una red de bitácoras (a la que esta pertenecería).</description>
    </item>
    
    <item>
      <title>Disponibles los vídeos de las charlas de las III Jornadas de Usuarios de R</title>
      <link>/2011/12/16/disponibles-los-videos-de-las-charlas-de-las-iii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Fri, 16 Dec 2011 06:51:52 +0000</pubDate>
      
      <guid>/2011/12/16/disponibles-los-videos-de-las-charlas-de-las-iii-jornadas-de-usuarios-de-r/</guid>
      <description>En las Jornadas de Usuarios de R íbamos a tener la posibilidad de grabar las charlas en vídeo pero resultó que no: aunque la EOI nos brindaba la infraestructura necesaria para la grabación y la retransmisión de las jornadas, corría por cuentra nuestra el pagar al operador de las cámaras, etc. Y éramos pobres.
Nos íbamos pues a quedarnos sin retransmisión en directo hasta que, a las dos de la tarde del día anterior, recibí este mensaje de Jose Antonio Palazón:</description>
    </item>
    
    <item>
      <title>Gráficos de embudo para controlar la varianza en muestras pequeñas</title>
      <link>/2011/12/15/graficos-de-embudo-para-controlar-la-varianza-en-muestras-pequenas/</link>
      <pubDate>Thu, 15 Dec 2011 06:43:13 +0000</pubDate>
      
      <guid>/2011/12/15/graficos-de-embudo-para-controlar-la-varianza-en-muestras-pequenas/</guid>
      <description>Publiqué hace un tiempo una entrada en esta bitácora sobre el problema que representa la desigualdad de los tamaños muestrales a la hora de comprender cierto tipo de datos, como por ejemplo, los que trata de representar el gráfico

que muestra la incidencia del cáncer de riñón en distintas zonas de en EE.UU. Como indiqué entonces, los valores extremos se encuentran en zonas menos pobladas: cuanto menor es la población, más probables son las proporciones inhabituales.</description>
    </item>
    
    <item>
      <title>Un lematizador para el español con R... ¿cutre? ¿mejorable?</title>
      <link>/2011/12/13/un-lematizador-para-el-espanol-con-r-cutre-mejorable/</link>
      <pubDate>Tue, 13 Dec 2011 07:23:56 +0000</pubDate>
      
      <guid>/2011/12/13/un-lematizador-para-el-espanol-con-r-cutre-mejorable/</guid>
      <description>Uno de los pasos previos para realizar lo que se viene llamando minería de texto es lematizar el texto. Desafortunadamente, no existen buenos lematizadores en español. Al menos, buenos lematizadores libres.
Existen el llamado algoritmo de porter y snowball pero, o son demasiado crudos o están más pensados para un lenguaje con muchas menos variantes morfológicas que el español.
Sinceramente, no sé a qué se dedican —me consta que los hay— los lingüistas computacionales de la hispanidad entera: ¿no son capaces de liberar una herramienta de lematización medianamente decente que podamos usar los demás?</description>
    </item>
    
    <item>
      <title>Bajo el capó de teradataR</title>
      <link>/2011/12/09/bajo-el-capo-de-teradatar/</link>
      <pubDate>Fri, 09 Dec 2011 06:50:57 +0000</pubDate>
      
      <guid>/2011/12/09/bajo-el-capo-de-teradatar/</guid>
      <description>Me gustaría haber podido indagar bajo el capó de teradataR, el paquete de R desarrollado por Teradata que permite que R realice lo que llaman por ahí _in database analytics _utilizando dicha plataforma propietaria.
Ya lo probé hace un tiempo con resultados bastante desiguales y que distaban muy mucho de mis expectativas originales, habida cuenta de las muchas bondades del gestor relacional. Durante mucho tiempo he tenido la intención de desentrañar los secretos del paquete, pero me contuvieron los términos desacostumbradamente restrictivos de la licencia:</description>
    </item>
    
    <item>
      <title>Creación de un &#34;R portable&#34;</title>
      <link>/2011/12/01/creacion-de-un-r-portable/</link>
      <pubDate>Thu, 01 Dec 2011 06:48:37 +0000</pubDate>
      
      <guid>/2011/12/01/creacion-de-un-r-portable/</guid>
      <description>Se supone que R, que está disponible en una multitud de plataformas y sin coste, debería poder instalarse por doquier. Pero sucede en ocasiones que sus usuarios sólo disponen de plataformas muy cerradas, sin acceso a privilegios de administración, en organizaciones hostiles al software libre, etc.
La solución para poder seguir disfrutando del poder de R en tales circunstancias puede pasar por la utilización de una versión portable de R: una que arranque desde un pincho de memoria sin interferir con el resto del software de la máquina ni requerir permisos de escritura en directorios vetados.</description>
    </item>
    
    <item>
      <title>R en la enseñanza: unos comentarios a los comentarios</title>
      <link>/2011/11/28/r-en-la-ensenanza-unos-comentarios-a-los-comentarios/</link>
      <pubDate>Mon, 28 Nov 2011 07:07:46 +0000</pubDate>
      
      <guid>/2011/11/28/r-en-la-ensenanza-unos-comentarios-a-los-comentarios/</guid>
      <description>Iba a responder a los comentarios de mi entrada sobre las Jornadas de R y, muy en particular a los de Fernando Fernández, uno de los más fieles lectores de esta bitácora, y me he extendido tanto que he acabado convirtiéndola en una nueva. Pido excusas por haber tal vez abusado de mis prerrogativas para auparme de esta manera.
Tanto a él como a otros les chirrió que escribiese comenzamos una nueva época que en el plazo de tres o cuatro años nos va a conducir, con casi total seguridad, a un escenario en el que [&amp;hellip;] R se use de manera casi exclusiva en la enseñanza de la estadística en los niveles universitarios.</description>
    </item>
    
    <item>
      <title>Grupo de trabajo sobre periodismo de datos en Madrid</title>
      <link>/2011/11/22/grupo-de-trabajo-sobre-periodismo-de-datos-en-madrid/</link>
      <pubDate>Tue, 22 Nov 2011 07:51:25 +0000</pubDate>
      
      <guid>/2011/11/22/grupo-de-trabajo-sobre-periodismo-de-datos-en-madrid/</guid>
      <description>El miércoles pasado, en el Medialab Prado de Madrid tuvo lugar la primera reunión del grupo de trabajo sobre Periodismo de datos. Contó con la presencia de Alberto Cairo, cuyo reciente libro, El arte funcional, espero que pase a engrosar mi colección pronto.

En el programa aparecen sesiones tan interesantes como las siguientes:
 12.01.2012. Mini taller y charla sobre la captura de datos. 09.02.2012. Mini taller y charla sobre el análisis y el tratamiento de los datos 08.</description>
    </item>
    
    <item>
      <title>III Jornadas de Usuarios de R: algunas reflexiones</title>
      <link>/2011/11/21/iii-jornadas-de-usuarios-de-r-algunas-reflexiones/</link>
      <pubDate>Mon, 21 Nov 2011 06:55:12 +0000</pubDate>
      
      <guid>/2011/11/21/iii-jornadas-de-usuarios-de-r-algunas-reflexiones/</guid>
      <description>La semana pasada no actualicé mi bitácora. Nunca había dejado pasar tanto tiempo sin escribir. Y es que, por si alguien no se había enterado aún, el jueves y el viernes tuvieron lugar las III Jornadas de Usuarios de R.
Hace dos años escribí un pequeño resumen sobre las primeras. El año pasado me atreví a hacer lo mismo con las segundas. Pero, lo siento, este año me excede el hacerlo para las terceras.</description>
    </item>
    
    <item>
      <title>Hoy, el primer encuentro del Grupo de Usuarios de R de Argentina</title>
      <link>/2011/11/11/hoy-el-primer-encuentro-del-grupo-de-usuarios-de-r-de-argentina/</link>
      <pubDate>Fri, 11 Nov 2011 07:15:41 +0000</pubDate>
      
      <guid>/2011/11/11/hoy-el-primer-encuentro-del-grupo-de-usuarios-de-r-de-argentina/</guid>
      <description>A una semana de las III Jornadas de Usuarios de R, hoy día 11 del 11 del 11, va a tener lugar el Primer Encuentro del Grupo de Usuarios de R de Argentina.

Quiero felicitar a los organizadores del encuentro e invitar a los usuarios de R de otros países a organizarse y organizar reuniones como las anteriores.</description>
    </item>
    
    <item>
      <title>Disponible el programa de las III Jornadas de Usuarios de R</title>
      <link>/2011/11/07/disponible-el-programa-de-las-iii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 07 Nov 2011 15:08:27 +0000</pubDate>
      
      <guid>/2011/11/07/disponible-el-programa-de-las-iii-jornadas-de-usuarios-de-r/</guid>
      <description>Acaba de publicarse el programa (casi) definitivo de las III Jornadas de Usuarios de R. Los números son impresionantes: 44 ponencias, una conferencia plenaria de primerísimo nivel, 5 talleres, más de 200 asistentes (estimados),&amp;hellip;
Además, dentro de las Jornadas se discutirán y aprobarán los estatutos de la futura Asociación de Usuarios de R (nombre tentativo).
¿Nos veremos todos en 10 días?</description>
    </item>
    
    <item>
      <title>Oracle R Enterprise</title>
      <link>/2011/10/27/oracle-r-enterprise/</link>
      <pubDate>Thu, 27 Oct 2011 06:40:03 +0000</pubDate>
      
      <guid>/2011/10/27/oracle-r-enterprise/</guid>
      <description>Repugna un tanto ver a R entre las palabras Oracle y Enterprise. Sobre todo siendo Oracle una compañía tan opuesta al espíritu del software libre. Pero es de celebrar que nuestra herramienta de elección esté penetrando el sancta sanctorum del software propietario. Y eso que Oracle se hizo años ya con Thinking Machines, empresa pionera en el campo de la minería de datos y cuyos algoritmos acabaron integrados en Oracle Data Mining.</description>
    </item>
    
    <item>
      <title>Herramientas de depuración en R</title>
      <link>/2011/10/26/herramientas-de-depuracion-en-r/</link>
      <pubDate>Wed, 26 Oct 2011 06:48:56 +0000</pubDate>
      
      <guid>/2011/10/26/herramientas-de-depuracion-en-r/</guid>
      <description>R dispone de un conjunto de herramientas para depurar (debug) programas. Yo suelo usar la función debug de manera casi exclusiva y sistemática, pero leyendo The Art of R Programming he dado con una discusión sistemática sobre el proceso de depuración así como algunas herramientas adicionales.
Una de las primeras que menciona el libro es la función stopifnot, que puede ser intercalada en el código para verificar condiciones necesarias (y lanzar un error en caso de que no se cumplan):</description>
    </item>
    
    <item>
      <title>Necesitamos una Asociación de Usuarios de R</title>
      <link>/2011/10/24/necesitamos-una-asociacion-de-usuarios-de-r/</link>
      <pubDate>Mon, 24 Oct 2011 13:47:36 +0000</pubDate>
      
      <guid>/2011/10/24/necesitamos-una-asociacion-de-usuarios-de-r/</guid>
      <description>Efectivamente, necesitamos una Asociación de Usuarios de R. Por ejemplo, durante la organización de las III Jornadas de Usuarios de R nos hemos enfrentado a muchos problemas que habrían sido mucho más llevaderos de contar con el paraguas institucional de un NIF. El número de actividades a las que una asociación podría dar cobertura es, con un poco de imaginación y generosidad, sumamente amplio.
Después de un par de arranques en falso, la cosa va en serio.</description>
    </item>
    
    <item>
      <title>Gestión avanzada de memoria en R: tracemem (II)</title>
      <link>/2011/10/14/gestion-avanzada-de-memoria-en-r-tracemem-ii/</link>
      <pubDate>Fri, 14 Oct 2011 07:43:29 +0000</pubDate>
      
      <guid>/2011/10/14/gestion-avanzada-de-memoria-en-r-tracemem-ii/</guid>
      <description>He leído estos días el capítulo 14 de The Art of R Programming que trata problemas y trucos para mejorar el rendimiento de R en términos de velocidad y memoria. Menciona la función tracemem de la que nos ocupamos el otro día.
Menciona el capítulo cómo uno de los estranguladores del rendimiento de R es su política de copiar al cambiar (copy-on-change). Generalmente, cuando modificamos un objeto, R realiza una copia íntegra de él (¿y qué pasa si realizamos pequeñas modificaciones en un objeto muy grande?</description>
    </item>
    
    <item>
      <title>Gestión avanzada de memoria en R: tracemem</title>
      <link>/2011/10/03/gestion-avanzada-de-memoria-en-r-tracemem/</link>
      <pubDate>Mon, 03 Oct 2011 07:15:16 +0000</pubDate>
      
      <guid>/2011/10/03/gestion-avanzada-de-memoria-en-r-tracemem/</guid>
      <description>Muchos usuarios de R se enfrentan en alguna ocasión a problemas con el uso y gestión de la memoria. La función tracemem es útil a la hora de identificar ineficiencias en el código.
En su página de ayuda se lee:
 Esta función marca un objeto de forma que se imprime un mensaje cada vez que se llama a la función interna duplicate. Esto sucede cuando dos objetos comparten la misma memoria y uno de ellos se modifica.</description>
    </item>
    
    <item>
      <title>Dont be loopy! (III: jackknife y paralelismo)</title>
      <link>/2011/09/30/dont-be-loopy-iii-jackknife-y-paralelismo/</link>
      <pubDate>Fri, 30 Sep 2011 06:52:59 +0000</pubDate>
      
      <guid>/2011/09/30/dont-be-loopy-iii-jackknife-y-paralelismo/</guid>
      <description>Esta es la tercera entrega de una serie de artículos en los que comparo SAS y R a la hora de realizar diversos tipos de simulaciones basados en Don&amp;rsquo;t Be Loopy: Re-Sampling and Simulation the SAS® Way.
Esta vez toca compararlos a la hora de aplicar el método del jackknife.
Primero, el código SAS que recomienda el autor del artículo, que calcula la curtosis de un conjunto de datos trivial (una muestra de 10k valores que siguen una distribución uniforme):</description>
    </item>
    
    <item>
      <title>Don’t be loopy! (II)</title>
      <link>/2011/09/23/dont-be-loopy-ii/</link>
      <pubDate>Fri, 23 Sep 2011 06:58:43 +0000</pubDate>
      
      <guid>/2011/09/23/dont-be-loopy-ii/</guid>
      <description>Continúo en esta la primera de las entradas que hice sobre el artículo Don&amp;rsquo;t Be Loopy: Re-Sampling and Simulation the SAS® Way.
Trata sobre lo siguiente:
 Construir un cojunto de datos simples (dos vectores, x e y). Hacer una regresión de y sobre x y capturar los residuos. Crear 1000 vectores y&#39; distintos añadiendo a $latex \hat{y}$ (la predicción de y) en el modelo anterior una reordenación de los residuos.</description>
    </item>
    
    <item>
      <title>Facetas en ggplot2 (al hilo de otra gañanada)</title>
      <link>/2011/09/21/facetas-en-ggplot2-al-hilo-de-otra-gananada/</link>
      <pubDate>Wed, 21 Sep 2011 07:33:55 +0000</pubDate>
      
      <guid>/2011/09/21/facetas-en-ggplot2-al-hilo-de-otra-gananada/</guid>
      <description>Hace años que no leo Expansión con la frecuencia de antaño. Los motivos son muchos. Pero el otro día, casi por nostalgia, pagué los 1.60 euros que no vale.
De entre los gañanes que trabajan en dicho diario hay uno que lo es más que todos: el responsable de las gráficas. En tiempos me irritaba. Luego me fui acostumbrando. Al final, casi, casi, le cogí cariño. Acabé interpretando sus gañanadas casi como si me dijese: &amp;ldquo;pues por aquí andamos, trabajando; de saludo, bien; y tus cosas ¿cómo van?</description>
    </item>
    
    <item>
      <title>La ley de Benford, revisitada</title>
      <link>/2011/09/20/la-ley-de-benford-revisitada/</link>
      <pubDate>Tue, 20 Sep 2011 07:11:53 +0000</pubDate>
      
      <guid>/2011/09/20/la-ley-de-benford-revisitada/</guid>
      <description>Revisito mi artículo sobre la ley de Benford no tanto por hacer mención a las entradas una, dos y tres que hizo Gregorio Serrano en su bitácora ni al oportunísimo artículo de The Guardian al respecto. Ni siquiera para mencionar la existencia de este sesudo artículo sobre el tema.
Lo hago porque me pliego a la demanda popular: voy a explicar con más detalle el código que dejé allí escrito y que, por referencia, es</description>
    </item>
    
    <item>
      <title>Linked, de Barabasi, capítulo I</title>
      <link>/2011/09/19/linked-de-barabasi-capitulo-i/</link>
      <pubDate>Mon, 19 Sep 2011 07:23:49 +0000</pubDate>
      
      <guid>/2011/09/19/linked-de-barabasi-capitulo-i/</guid>
      <description>No sé si seguir leyendo libros. Sus autores los llenan de letras. Y es un lujo poder disponer del tiempo de leerlas todas.
Uno de esos libros llenos de letras es Linked, de Barabasi. Es un libro estupendo y recomendable. Pero podría ocupar 20 páginas si el autor fuese un poco más escueto y no se empeñase de llenarlo todo de anécdotas y colores.
Su primer capítulo trata sobre las redes sociales aleatorias, también conocidas como redes de Poisson o de Erdös-Rényi.</description>
    </item>
    
    <item>
      <title>Otra sobre polígrafos, terrorismo y periodistas anuméricos</title>
      <link>/2011/09/16/otra-sobre-poligrafos-terrorismo-y-periodistas-anumericos/</link>
      <pubDate>Fri, 16 Sep 2011 07:23:33 +0000</pubDate>
      
      <guid>/2011/09/16/otra-sobre-poligrafos-terrorismo-y-periodistas-anumericos/</guid>
      <description>Dice el diario El País que científicos británicos desarrollan un sistema que permite saber si alguien no está diciendo la verdad analizando su rostro.
El aparato, según el artículo
 [&amp;hellip;] podría ser utilizado para cuestiones de seguridad, como, por ejemplo, en los aeropuertos para identificar a potenciales criminales o terroristas.
 Añade después que
 [&amp;hellip;] el sistema será capaz de coger al 90 % de los que mienten, porcentaje similar al obtenido por el polígrafo</description>
    </item>
    
    <item>
      <title>La ley de Benford</title>
      <link>/2011/09/15/la-ley-de-benford/</link>
      <pubDate>Thu, 15 Sep 2011 07:03:49 +0000</pubDate>
      
      <guid>/2011/09/15/la-ley-de-benford/</guid>
      <description>El otro día me preguntó una compañera el motivo por el que un proceso (de transformación de datos) se ejecutaba tan lentamente. De oficio, siempre hago lo mismo —además, lo saben: ¿para qué seguirán preguntando?—: ejecutar el proceso sólo sobre un porcentaje de los datos.
Con los que el id acababa en 123, era inmediato; con 12, también; con 1, se eternizaba. Pero con 2, 3 y 4 volvía a ser muy rápido.</description>
    </item>
    
    <item>
      <title>Datos patrimoniales de los senadores</title>
      <link>/2011/09/13/datos-patrimoniales-de-los-senadores/</link>
      <pubDate>Tue, 13 Sep 2011 06:53:45 +0000</pubDate>
      
      <guid>/2011/09/13/datos-patrimoniales-de-los-senadores/</guid>
      <description>David Cabo, de Pro Bono Público colgó el otro día una hoja de cálculo en Google Docs con referencias a las declaraciones del patrimonio (véase un ejemplo) a las que están ahora obligados los senadores y que cuelgan de la página de su benemérita y utilísima institución. Dado que los datos están en un formato no legible automáticamente, solicitó la colaboración de voluntarios para tabular la información.
Rápidamente logró completarse la tarea.</description>
    </item>
    
    <item>
      <title>Visualización de la actualización bayesiana (y unas cuantas funciones de R)</title>
      <link>/2011/09/12/visualizacion-de-la-actualizacion-bayesiana-y-unas-cuantas-funciones-de-r/</link>
      <pubDate>Mon, 12 Sep 2011 07:02:03 +0000</pubDate>
      
      <guid>/2011/09/12/visualizacion-de-la-actualizacion-bayesiana-y-unas-cuantas-funciones-de-r/</guid>
      <description>Me ha llegado noticia de una entrada en un blog, Visualizing Bayesian Updating, en el que se muestra visualmente cómo se actualiza la distribución a posteriori conforme aumenta el número de ensayos en un problema bayesiano simple. Explica también los fundamentos estadísticos del asunto.
Yo me limitaré a ofrecer una nueva versión del código —que no funcionaba copiando y pegando sin más— en el que he introducido ciertas modificaciones. Es el siguiente:</description>
    </item>
    
    <item>
      <title>Treemaps en R</title>
      <link>/2011/09/09/treemaps-en-r/</link>
      <pubDate>Fri, 09 Sep 2011 07:13:26 +0000</pubDate>
      
      <guid>/2011/09/09/treemaps-en-r/</guid>
      <description>Hay cierto interés por los treemaps en general y existen paquetes como treemap y la función map.market del paquete portfolio que permiten construirlos y obtener gráficos como este

que representa la capitalización bursátil de las empresas del IBEX-35 y el porcentaje que destinan al dividendo. Pero me produce cierto desasosiego utilizar áreas y colores para representar magnitudes: ¿es fácil comparar el tamaño relativo de TEF y ELE? ¿Cuánto mayor es ITX que BBVA?</description>
    </item>
    
    <item>
      <title>Códigos de caracteres en R</title>
      <link>/2011/09/08/codigos-de-caracteres-en-r/</link>
      <pubDate>Thu, 08 Sep 2011 07:00:47 +0000</pubDate>
      
      <guid>/2011/09/08/codigos-de-caracteres-en-r/</guid>
      <description>Esta entrada acompaña y remata para los usuarios de R la que escribí en general sobre los códigos de caracteres. Es un pequeño experimento en el que comparo lo que pasa al leer un fichero de texto codificado de dos maneras distintas en dos plataformas, Linux y Windows, que usan códigos de caracteres distintos.
Primero creo dos ficheros (en Linux) con el mismo contenido pero codificados de dos maneras distintas, utf-8 y latin1:</description>
    </item>
    
    <item>
      <title>El paquete reshape de R (I): melt</title>
      <link>/2011/09/07/el-paquete-reshape-de-r-i-melt/</link>
      <pubDate>Wed, 07 Sep 2011 07:45:36 +0000</pubDate>
      
      <guid>/2011/09/07/el-paquete-reshape-de-r-i-melt/</guid>
      <description>El paquete reshape de R consta esencialmene de dos funciones, melt y cast, muy útiles para determinado tipo de transformaciones de de datos.
La función melt se describe sucintamente con el siguiente gráfico:

Es decir, toma un data.frame y lo funde (¡dejaré de ser amigo de quien pronuncie meltea!) o, visto de otra manera, estira.
He aquí unos ejemplos:
1 2 3  library(reshape) iris.m &amp;lt;- melt(iris) iris.m   Nótese cómo melt es inteligente y no necesita (en muchas ocasiones) que se le especifiquen cosas evidentes.</description>
    </item>
    
    <item>
      <title>Códigos de caracteres, unicode y UTF-8</title>
      <link>/2011/09/06/codigos-de-caracteres-unicode-y-utf-8/</link>
      <pubDate>Tue, 06 Sep 2011 07:00:44 +0000</pubDate>
      
      <guid>/2011/09/06/codigos-de-caracteres-unicode-y-utf-8/</guid>
      <description>Unos quebraderos de cabeza en el desarrollo del paquete pxR concernientes a los distintos códigos de caracteres en que hay que transfomar los datos me han obligado a profundizar en este enojoso asunto.
En el principio, todo era felicidad. Existía el código ASCII que establecía una correspondencia entre caracteres, números y su representación binaria. Así, a la letra b le correspondía el número 98 cuya codificación binaria es el byte 01100010.</description>
    </item>
    
    <item>
      <title>Un paseo por cloudnumbers</title>
      <link>/2011/09/05/un-paseo-por-cloudnumbers/</link>
      <pubDate>Mon, 05 Sep 2011 07:57:03 +0000</pubDate>
      
      <guid>/2011/09/05/un-paseo-por-cloudnumbers/</guid>
      <description>Cloudnumbers es una empresa que ofrece servicios de computación de alto rendimiento en la nube con especial énfasis en aplicaciones que corren sobre R. Me ofrecieron una cuenta temporal y gratuita el otro día y en la entrada de hoy voy a describir mis primeros pasos en su plataforma.
Hace dos años hice, y dejé descrita, mi primera incursión en la computación con R en la nube. En dicha ocasión utilicé la plataforma EC2 de Amazon: en resumidas cuentas, Amazon alquila servidores con diversas configuraciones de software por horas a un precio muy competitivo y uno puede acceder a ellos vía ssh, instalar R, los paquetes necesarios, correr el código y descargar los resultados.</description>
    </item>
    
    <item>
      <title>&#34;Arte gráfico&#34; con R</title>
      <link>/2011/08/29/arte-grafico-con-r/</link>
      <pubDate>Mon, 29 Aug 2011 07:15:52 +0000</pubDate>
      
      <guid>/2011/08/29/arte-grafico-con-r/</guid>
      <description>El otro día dí con un blog dedicado al arte matemático y en particular con esta entrada sobre cómo crear figuras mediante rotación de segmentos:

El código (en matlab) estaba disponible y lo traduje a R:
1 2 3 4 5 6 7 8 9 10  graphic.art &amp;lt;- function( foo, n = 200, init = -1, end = 1, breaks = 20 ){ x &amp;lt;- seq( init, end, by = 1 / breaks ) base &amp;lt;- matrix( c( x, foo( x ) ), ncol = 2 ) rotate &amp;lt;- function(a,m) m %*% matrix(c(cos(a), -sin(a), sin(a), cos(a)), 2) my.</description>
    </item>
    
    <item>
      <title>Comparación de variables aleatorias de Poisson</title>
      <link>/2011/08/21/comparacion-de-variables-aleatorias-de-poisson/</link>
      <pubDate>Sun, 21 Aug 2011 07:53:08 +0000</pubDate>
      
      <guid>/2011/08/21/comparacion-de-variables-aleatorias-de-poisson/</guid>
      <description>El otro día apareció publicado en Significance una comparación entre el número de tarjetas recibidas por las selecciones inglesas de fúlbol masculina y femenina.
Los hombres habían recibido 196 tarjetas en los 48 partidos disputados en el periodo de referencia y las mujeres, 40 en 24 partidos. El promedio de tarjetas, por lo tanto, de 4.1 y 1.7 respectivamente. Y la pregunta es: ¿hay motivos razonables para pensar que las mujeres juegan menos sucio?</description>
    </item>
    
    <item>
      <title>Una feliz conjunción estadístico-algebraica (y II)</title>
      <link>/2011/08/16/una-feliz-conjuncion-estadistico-algebraica-y-ii/</link>
      <pubDate>Tue, 16 Aug 2011 06:52:30 +0000</pubDate>
      
      <guid>/2011/08/16/una-feliz-conjuncion-estadistico-algebraica-y-ii/</guid>
      <description>Abandonamos el otro día nuestra discusión sobre la feliz conjunción estadístico-algebraica que subyace a esa técnica conocida como análisis de correspondencias en el punto en que habíamos descompuesto la matriz $latex B$ de la forma $latex B = PDQ^\prime$, donde $latex P$ y $latex Q$ son matrices cuyas columnas son vectores ortonormales $latex p_i$ y $latex q_j$ y $latex D$ es una matriz diagonal (aunque no necesariamente cuadrada) cuyos elementos de la diagonal (en orden decreciente) son $latex \lambda_k$.</description>
    </item>
    
    <item>
      <title>Una feliz conjunción estadístico-algebraica</title>
      <link>/2011/08/12/una-feliz-conjuncion-estadistico-algebraica/</link>
      <pubDate>Fri, 12 Aug 2011 07:17:48 +0000</pubDate>
      
      <guid>/2011/08/12/una-feliz-conjuncion-estadistico-algebraica/</guid>
      <description>Tomemos una tabla de contingencia, p.e.,
1 2 3 4 5 6 7 8  library(MASS) a &amp;lt;- as.matrix(caith) # fair red medium dark black # blue 326 38 241 110 3 # light 688 116 584 188 4 # medium 343 84 909 412 26 # dark 98 48 403 681 85   que se refiere a los habitantes de una población de Escocia clasificados según el color de los ojos y el pelo.</description>
    </item>
    
    <item>
      <title>Don&#39;t be loopy!</title>
      <link>/2011/08/11/dont-be-loopy/</link>
      <pubDate>Thu, 11 Aug 2011 07:28:36 +0000</pubDate>
      
      <guid>/2011/08/11/dont-be-loopy/</guid>
      <description>Don&amp;rsquo;t be loopy! es el título de una presentación realizada en el SAS Global Forum de 2007. Tiene que ver con el motivo que me hizo en mi día abandonar SAS y buscar —entonces aún no lo conocía— el cobijo de R: sus limitaciones para todo lo que tiene que ver con simulaciones, remuestreos, jackknifes, _bootstraps _y similares.
El artículo muestra lo que debería ser el estado del arte para realizar este tipo de programas con SAS.</description>
    </item>
    
    <item>
      <title>SVD de matrices enormes con R</title>
      <link>/2011/08/05/svd-de-matrices-enormes-con-r/</link>
      <pubDate>Fri, 05 Aug 2011 07:38:55 +0000</pubDate>
      
      <guid>/2011/08/05/svd-de-matrices-enormes-con-r/</guid>
      <description>Supongo que mis lectores habrán leído acerca del Netfix Prize. En el vídeo de este viernes se ilustra cómo se puede R para implementar la parte más computacionalmente intensiva de la solución ganadora utilizando el paquete irlba, la descomposición de la matriz de datos en sus componentes singulares (más propiamente, obtener algunas de ellas).
  </description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (IV): funciones genéricas</title>
      <link>/2011/08/04/desarrollo-de-paquetes-con-r-iv-funciones-genericas/</link>
      <pubDate>Thu, 04 Aug 2011 07:26:52 +0000</pubDate>
      
      <guid>/2011/08/04/desarrollo-de-paquetes-con-r-iv-funciones-genericas/</guid>
      <description>La función plot es genérica. Uno puede aplicársela a un data.frame o a un objeto de la clase lm. Y en el fondo, plot sólo elige cuál de sus métodos, es decir, las funciones que realizan el trabajo verdaderamente, aplicar. Para ver cuáles son los métodos asociados a plot basta con ejecutar en R
1  methods(plot)   La salida es autoexplicativa.
Podemos hacer un pequeño experimento creando una función genérica, foo, bastante tonta:</description>
    </item>
    
    <item>
      <title>Los siete pecados capitales de la minería de datos</title>
      <link>/2011/07/29/los-siete-pecados-capitales-de-la-mineria-de-datos/</link>
      <pubDate>Fri, 29 Jul 2011 07:46:19 +0000</pubDate>
      
      <guid>/2011/07/29/los-siete-pecados-capitales-de-la-mineria-de-datos/</guid>
      <description>Por ser viernes, traigo a estas páginas un vídeo tan pedagógico como ameno. Es la conferencia de Dick De Veaux dentro la M2010 Data Mining Conference auspiciada por SAS.
El autor repasa los siete pecados capitales de la minería de datos, a saber
 No realizar las preguntas adecuadas No entender el problema correctamente No prestar suficiente atención a la preparación de los datos Ignorar lo que no está ahí Enamorarse de los modelos Trabajar en solitario Usar datos malos  Frente a ellas, propone las siguientes virtudes:</description>
    </item>
    
    <item>
      <title>El paquete pxR, en CRAN</title>
      <link>/2011/07/28/el-paquete-pxr-en-cran/</link>
      <pubDate>Thu, 28 Jul 2011 06:54:45 +0000</pubDate>
      
      <guid>/2011/07/28/el-paquete-pxr-en-cran/</guid>
      <description>El 1 de junio escribí en la lista de ayuda de R en español para ver si alguien se animaba a colaborar en la creación de un paquete de R para importar datos en formato PC-Axis.
Este formato es usado por gran número de institutos estadísticos, entre ellos el INE español, para difundir y pubicar datos en formato electrónico. Existe una herramienta gratuita pero cerrada para analizar este tipo de datos, pero clamaba al cielo que los usuarios de R no contásemos con una manera de importarlos directamente.</description>
    </item>
    
    <item>
      <title>Diagramas de puntos (dotplots)</title>
      <link>/2011/07/27/diagramas-de-puntos-dotplots/</link>
      <pubDate>Wed, 27 Jul 2011 07:07:36 +0000</pubDate>
      
      <guid>/2011/07/27/diagramas-de-puntos-dotplots/</guid>
      <description>Aunque los diagramas de puntos fueron introducidos por Cleveland  en los años ochenta, a pesar de sus ventajas, no gozan de la popularidad de otros métodos de representación gráfica.
Leí hace poco un artículo de Naomi Robbins en el que se proponían los gráficos de puntos como alternativa a los de barras. Encuentra en aquéllos tres ventajas:
 Una representación más limpia y con menos tinta inútil. Permite resolver el problema de la representación de varias observaciones por sujeto más elegantemente que yuxtaponiendo barras, como ilustra el gráfico que aparece debajo.</description>
    </item>
    
    <item>
      <title>¿Qué es un banco? ¿Qué son las pruebas de resistencia? (En primera derivada)</title>
      <link>/2011/07/26/que-es-un-banco-que-son-las-pruebas-de-resistencia-en-primera-derivada/</link>
      <pubDate>Tue, 26 Jul 2011 07:55:41 +0000</pubDate>
      
      <guid>/2011/07/26/que-es-un-banco-que-son-las-pruebas-de-resistencia-en-primera-derivada/</guid>
      <description>En primera derivada, un banco es un señor que pone 10, capta 90 en depósitos de ahorradores —a los que da un interés del 4 %— y presta 100 al 5 %. El código en R que aparece a continuación indica cuál es el beneficio del señor:
1 2 3 4 5 6 7 8 9 10 11 12  capital &amp;lt;- 10 depositos &amp;lt;- 90 int.dep &amp;lt;- 0.04 int.pres &amp;lt;- 0.</description>
    </item>
    
    <item>
      <title>Competición de estadística con R en las III Jornadas de Usuarios de R</title>
      <link>/2011/07/18/competicion-de-estadistica-con-r-en-las-iii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 18 Jul 2011 06:59:35 +0000</pubDate>
      
      <guid>/2011/07/18/competicion-de-estadistica-con-r-en-las-iii-jornadas-de-usuarios-de-r/</guid>
      <description>Como actividad complementaria a las III Jornadas de Usuarios de R, por gentileza de uno de sus patrocinadores, Nestoria y gracias al trabajo de Emilio Torres Manzanera, se ha anunciado hoy el I Concurso de Análisis de Datos con R.

Con 1.500€ en premios y la posibilidad de pasar a colaborar con la plantilla de Nestoria para los autores de las mejores soluciones, el concurso aspira a sondear la habilidad de la comunidad de usuarios de R para analizar datos reales y extraer valor de la base de datos de viviendas y precios de viviendas de Nestoria.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (III): check, check, check</title>
      <link>/2011/07/12/desarrollo-de-paquetes-con-r-iii-check-check-check/</link>
      <pubDate>Tue, 12 Jul 2011 07:35:00 +0000</pubDate>
      
      <guid>/2011/07/12/desarrollo-de-paquetes-con-r-iii-check-check-check/</guid>
      <description>Uno de los pasos más importantes en el desarrollo de un paquete es verificar que funciona correctamente. Un check comprueba la estructura del paquete, la consistencia entre el código y la documentación, que no faltan secciones importantes en esta última, que los ejemplos pueden ejecutarse sin problemas, etc.
De ahí que sirva para para muchos propósitos. En particular, si uno elige los ejemplos que acompañan a la documentación de las funciones con buen criterio, éstos servirán no sólo para ilustrar el comportamiento de las funciones sino, también, para verificar el funcionamiento del paquete.</description>
    </item>
    
    <item>
      <title>useR!, en Warwick, dentro de un mes</title>
      <link>/2011/07/06/user-en-warwick-dentro-de-un-mes/</link>
      <pubDate>Wed, 06 Jul 2011 18:07:36 +0000</pubDate>
      
      <guid>/2011/07/06/user-en-warwick-dentro-de-un-mes/</guid>
      <description>Dentro de un mes tendrá lugar laconferencia internacional de usuarios de R, useR!, en Warwick, R.U. A partir del documento que resume las ponencias, usando el paquete tm de R y Wordle para la parte artística, he creado la siguiente nube de palabras:

Y ya que toco estos temas, menciono dos:
 ¿Os habéis puntado a las III Jornadas de Usuarios de R? ¿Qué lematizador utilizáis en español? ¿Cuál os gusta más?</description>
    </item>
    
    <item>
      <title>Paquetes huérfanos de R</title>
      <link>/2011/07/01/paquetes-huerfanos-de-r/</link>
      <pubDate>Fri, 01 Jul 2011 07:13:49 +0000</pubDate>
      
      <guid>/2011/07/01/paquetes-huerfanos-de-r/</guid>
      <description>Ayer hablaba con Juan José Gibaja (al que finalmente conocí en persona) y me contaba cómo había usado un paquete de R —no recuerdo cuál— que misteriosamente había desaparecido de CRAN.
—¡Imposible! Los paquetes no desaparecen: quedan huérfanos.
Efectivamente, en la lista de paquetes de CRAN, abajo, se mencionan los llamados paquetes húerfanos. Según el README, se trata de paquetes cuyos autores o mantenedores
 han decidido desentenderse del paquete o los mensajes que les envían desde CRAN rebotan o no son contestados.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (II): primeros pasos</title>
      <link>/2011/06/30/desarrollo-de-paquetes-con-r-ii-primeros-pasos/</link>
      <pubDate>Thu, 30 Jun 2011 07:36:54 +0000</pubDate>
      
      <guid>/2011/06/30/desarrollo-de-paquetes-con-r-ii-primeros-pasos/</guid>
      <description>La segunda entrada en mi serie sobre la creación de paquetes con R cubre los primeros pasos en la creación de uno. Bastan para tener una primera versión de un paquete en minutos. Pero antes, unos consejos generales:
 Usar algún tipo de sistema operativo basado en Unix: Linux, Mac OS, etc. o Cygwin en el peor de los casos. Tengo que confesar que yo comencé a usar Linux precisamente por este motivo: los procedimientos y herramientas que se utilizan para construir paquetes de R están influenciadas por la tradición Unix.</description>
    </item>
    
    <item>
      <title>Sweave, investigación reproducible... y más</title>
      <link>/2011/06/23/sweave-investigacion-reproducible-y-mas/</link>
      <pubDate>Thu, 23 Jun 2011 07:08:45 +0000</pubDate>
      
      <guid>/2011/06/23/sweave-investigacion-reproducible-y-mas/</guid>
      <description>Me consta que algunos de mis lectores están al tanto de eso que llaman investigación reproducible. De acuerdo con la Wikipedia (en inglés),
 [E]l término investigación reproducible se atribuye a Jon Claerbout, de la Universidad de Stanford y se refiere a la idea de que el producto final de la investigación no debería circunscribirse a un artículo sino comprender también el entorno computacional completo usado en la generación los resultados que contiene, tales como el código, los datos, etc.</description>
    </item>
    
    <item>
      <title>Desarrollo de paquetes con R (I): ¿para qué?</title>
      <link>/2011/06/21/desarrollo-de-paquetes-con-r-i-para-que/</link>
      <pubDate>Tue, 21 Jun 2011 07:17:10 +0000</pubDate>
      
      <guid>/2011/06/21/desarrollo-de-paquetes-con-r-i-para-que/</guid>
      <description>Por popular demanda, voy a comenzar una serie de entradas sobre desarrollo de paquetes con R. Mi idea consiste en establecer un diálogo con mis lectores que me permita pulirlas para acabar escribiendo un documento que pueda resultar útil a los usuarios de R.
En el primero me voy a limitar a explicar para qué puede resultar útil desarrollar paquetes. Lo voy a hacer desde mi experiencia de desarrollador y desde el particular punto de vista de mis hábitos y manías personales.</description>
    </item>
    
    <item>
      <title>Una herramienta para construir paquetes de R sobre Windows</title>
      <link>/2011/06/15/una-herramienta-para-construir-paquetes-de-r-sobre-windows/</link>
      <pubDate>Wed, 15 Jun 2011 07:07:21 +0000</pubDate>
      
      <guid>/2011/06/15/una-herramienta-para-construir-paquetes-de-r-sobre-windows/</guid>
      <description>Construir paquetes multiplataforma con R supone todo un reto para quienes tenemos un acceso limitado o nulo a determinados sistemas operativos. En particular, a muchos nos resulta complicado acceder a una máquina Windows con todas las herramientas necesarias para crear y comprobar los paquetes.
Pero Uwe Ligges, el encargado de los paquetes binarios de Windows para CRAN ha puesto en funcionamiento un servicio para poder compilarlos. En la página de información de este servicio pueden consultarse las instrucciones para subir los paquetes y los caveats:</description>
    </item>
    
    <item>
      <title>Minitutorial de subversion</title>
      <link>/2011/06/13/minitutorial-de-subversion/</link>
      <pubDate>Mon, 13 Jun 2011 07:41:42 +0000</pubDate>
      
      <guid>/2011/06/13/minitutorial-de-subversion/</guid>
      <description>Por popular demanda, voy a ilustrar en esta entrada el uso de subversion para el desarrollo colaborativo de software. Lo escribo teniendo en mente el desarrollo de paquetes alojados en R-Forge y para usuarios de sistemas operativos más o menos decentes. A quienes usan Windows les recomiendo Tortoise, cuyo uso queda fuera del alcance de lo que sigue.
En primer lugar, para los desavisados: subversion es un programa para gestionar versiones de ficheros.</description>
    </item>
    
    <item>
      <title>Gestión de proyectos en R</title>
      <link>/2011/06/08/gestion-de-proyectos-en-r/</link>
      <pubDate>Wed, 08 Jun 2011 07:36:35 +0000</pubDate>
      
      <guid>/2011/06/08/gestion-de-proyectos-en-r/</guid>
      <description>Muchos de mis lectores tienen, seguro, maneras distintas —y probablemente mejores— de organizar sus proyectos en R que yo. Pero me consta que a algunos les cuesta no convertir sus carpetas en un caos en los que sólo ellos se manejan —hasta que pasa el tiempo, se olvidan y tienen que volver sobre ello—. Para ellos, para sugerirles un procedimiento eficiente de trabajo, va esta entrada. En ella describo cómo organizo mis propios proyectos con R.</description>
    </item>
    
    <item>
      <title>Sobre la encuesta sobre minería de datos de Rexer Analytics</title>
      <link>/2011/06/02/sobre-la-encuesta-sobre-mineria-de-datos-de-rexer-analytics/</link>
      <pubDate>Thu, 02 Jun 2011 07:13:39 +0000</pubDate>
      
      <guid>/2011/06/02/sobre-la-encuesta-sobre-mineria-de-datos-de-rexer-analytics/</guid>
      <description>Hace unos días se publicaron los resultado de la cuarta encuesta anual de minería de datos realizada por Rexer Analytics en la que 735 participantes de 60 países completaron sus 50 preguntas. Los hechos más relevantes que contiene son:
 La principal aplicación de la minería de datos (siempre pienso que desgraciadamente) es en el campo de la gestión (o inteligencia) de clientes, lo que por ahí denominan CRM. Los algoritmos más usados por los encuestados han sido árboles de decisión, regresión y análisis de conglomerados.</description>
    </item>
    
    <item>
      <title>Dos perspectivas sobre el problema de los valores no informados</title>
      <link>/2011/05/30/dos-perspectivas-sobre-el-problema-de-los-valores-no-informados/</link>
      <pubDate>Mon, 30 May 2011 07:48:59 +0000</pubDate>
      
      <guid>/2011/05/30/dos-perspectivas-sobre-el-problema-de-los-valores-no-informados/</guid>
      <description>Me llegó el otro día información acerca de un curso sobre métodos para afrontar el problema planteado por los valores no informados (missing observations) que su autor agrupaba bajo etiquetas bastante simpáticas: el bueno, el malo y el impensable. Tal vez faltaba el feo, tal vez porque lo son todos ellos, igual que el bendito problema que suponen. Añadía, sin mayores abundamientos, que
 explicaría cómo la solución común es en general la peor; mostraría por qué cierta solución sencilla, relativamente común y con mala fama no es habitualmente tan mala, explicando, además, cuáles son las situaciones en las que funciona y no funciona e indicaría dos soluciones que proporcionan resultados insesgados, una de las cuales es sencilla de implementar pero sólo funciona en ciertas circunstancias y la otra, aunque más complicada, funciona siempre.</description>
    </item>
    
    <item>
      <title>Se buscan &#34;alpha testers&#34; para rPython</title>
      <link>/2011/05/24/se-buscan-alpha-testers-para-rpython/</link>
      <pubDate>Tue, 24 May 2011 07:00:49 +0000</pubDate>
      
      <guid>/2011/05/24/se-buscan-alpha-testers-para-rpython/</guid>
      <description>Busco alpha testers para mi paquete rPython. El paquete es la evolución natural de rJython, un paquete de R que permite llamar a Jython, el dialecto de Python que corre sobre la máquina virtual de Java, desde R.
rPython permite llamar al verdadero Python. Funciona perfectamente en mi máquina, pero necesito ver qué problemas de instalación y uso aparecen en otras plataformas. De momento, sólo funcionaría sobre plataformas UNIX o Linux.</description>
    </item>
    
    <item>
      <title>La versión 0.7 del paquete colbycol, en CRAN</title>
      <link>/2011/05/23/la-version-0-7-del-paquete-colbycol-en-cran/</link>
      <pubDate>Mon, 23 May 2011 13:18:39 +0000</pubDate>
      
      <guid>/2011/05/23/la-version-0-7-del-paquete-colbycol-en-cran/</guid>
      <description>Me complace anunciar la subida a CRAN de la versión 0.7 del paquete colbycol.
La diferencia esencial con respecto a la anterior es:
 Utiliza el paquete filehash para crear el objeto que almacena los datos en disco. Incorpora algunas mejoras de uso sugeridas por los usuarios que facilitan la manipulación de los datos.  Espero poder publicar un estudio comparado del rendimiento en los próximos días.</description>
    </item>
    
    <item>
      <title>Solipsismo, comunidad y rendimiento</title>
      <link>/2011/05/18/solipsismo-comunidad-y-rendimiento/</link>
      <pubDate>Wed, 18 May 2011 07:45:20 +0000</pubDate>
      
      <guid>/2011/05/18/solipsismo-comunidad-y-rendimiento/</guid>
      <description>Desde esta bitácora hemos seguido atentamente el a veces espinoso asunto del rendimiento de R. De ello es muestra entradas como ésta. Por eso retomamos el asunto para comentar desde una óptica distinta un análisis publicado hace un mes cuyo autor estudia la ineficiencia de funciones básicas como la media y otras similares.
Y llega a conclusiones que no es necesario manifestar explícitamente a quien ejecute esto en R:
1 2 3 4 5 6 7 8 9  x &amp;lt;- rnorm(50000) foo.</description>
    </item>
    
    <item>
      <title>Consejos para utilizar R &#34;en producción&#34;</title>
      <link>/2011/05/13/consejos-para-utilizar-r-en-produccion/</link>
      <pubDate>Fri, 13 May 2011 07:58:02 +0000</pubDate>
      
      <guid>/2011/05/13/consejos-para-utilizar-r-en-produccion/</guid>
      <description>El otro día di con una entrada en una bitácora con cinco consejos para utilizar R en producción. Cuatro de ellos son razonables:
 Crear un sistema de validación, monitorización y alertas. Y, en particular, desarrollar un mecanismo para que R notifique los problemas encontrados por correo electrónico. En la entrada original hay código que puede utilizarse para tal fin. Usar la función sink para facilitar la detección y corrección de los errores.</description>
    </item>
    
    <item>
      <title>¿Qué nos jugamos?</title>
      <link>/2011/05/12/que-nos-jugamos/</link>
      <pubDate>Thu, 12 May 2011 07:18:12 +0000</pubDate>
      
      <guid>/2011/05/12/que-nos-jugamos/</guid>
      <description>Imagine que le proponen participar reiteradamente en un juego de azar. Dispone de una cantidad de dinero inicial, $latex a$ euros, y puede apostar en un juego en el que o gana con probabilidad $latex p$ $latex b$ veces la apuesta o la pierde enteramente. Puede repetir el juego cuantas veces quiera y apostar el porcentaje que desee de su dinero.
¿Cuánto se apostaría? ¿Qué porcentaje de su capital inicial se jugaría?</description>
    </item>
    
    <item>
      <title>Extensiones de la R2</title>
      <link>/2011/04/28/extensiones-de-la-r2/</link>
      <pubDate>Thu, 28 Apr 2011 07:58:46 +0000</pubDate>
      
      <guid>/2011/04/28/extensiones-de-la-r2/</guid>
      <description>Sin ir más lejos, cojamos el primer ejemplo que aparece en ?ls, es decir,
1 2 3 4 5 6  ctl &amp;lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14) trt &amp;lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69) group &amp;lt;- gl(2,10,20, labels=c(&amp;#34;Ctl&amp;#34;,&amp;#34;Trt&amp;#34;)) weight &amp;lt;- c(ctl, trt) lm.D9 &amp;lt;- lm(weight ~ group) summary( lm.D9 )   y hagamos
1  cor( weight, predict( lm.D9 ) )**2   ¿Qué obtenemos? Precisamente la R2 del modelo lm.D9. Esta relación abre la puerta a varias extensiones de esta medida de la bondad de ajuste a contextos en los que las expresiones suma de cuadrados de&amp;hellip; carecen de sentido.</description>
    </item>
    
    <item>
      <title>Teradata, R y las III Jornadas de Usuarios de R</title>
      <link>/2011/04/18/teradata-r-y-las-iii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 18 Apr 2011 07:50:32 +0000</pubDate>
      
      <guid>/2011/04/18/teradata-r-y-las-iii-jornadas-de-usuarios-de-r/</guid>
      <description>Como parte de mis atribuciones dentro del comité organizador de las III Jornadas de Usuarios de R estoy tratando de conseguir la participación (y tal vez la financiación) de empresas e instituciones. Me ha parecido oportuno invitar a tomar parte en ellas a Teradata, empresa que, según la Wikipedia,
 [está] especializada en herramientas de data warehousing y herramientas analíticas empresariales.
 Teradata no se postula como un vendedor de herramientas de almacenamiento: quiere ir más allá.</description>
    </item>
    
    <item>
      <title>Paralelización de bucles con foreach</title>
      <link>/2011/04/08/paralelizacion-de-bucles-con-foreach/</link>
      <pubDate>Fri, 08 Apr 2011 07:26:41 +0000</pubDate>
      
      <guid>/2011/04/08/paralelizacion-de-bucles-con-foreach/</guid>
      <description>Parcialmente en agradecimiento a Revolution Analytics por haber concedido una subvención a las III Jornadas de usuarios de R voy a discutir en esta entrada cómo paralelizar bucles usando los paquetes foreach y doMC desarrollados por dicha empresa.
El paquete foreach contiene, esencialmente, una única función, foreach, que, en su forma más básica, permite ejecutar bucles con una sintaxis un tanto peculiar:
1  foreach( i = 1:3 ) %do% log( i )   Volveré sobre algunas operaciones interesantes y bastante útiles que permite realizar esta función porque, de todas ellas, hoy me ocuparé sólo de una: la que abre la puerta de una manera sencilla a la paralelización de bucles.</description>
    </item>
    
    <item>
      <title>Nueva versión de paquete colbycol</title>
      <link>/2011/04/07/nueva-version-de-paquete-colbycol/</link>
      <pubDate>Thu, 07 Apr 2011 07:55:34 +0000</pubDate>
      
      <guid>/2011/04/07/nueva-version-de-paquete-colbycol/</guid>
      <description>Hace unos días subí a CRAN la última versión de mi paquete colbycol. Incluí algunas mejoras sugeridas por uno de sus usuarios así como otras que estaban esperando a que liberase mi agenda. Además, añadí un pequeño tutorial en la página del paquete.
El paquete colbycol está pensado para resolver —aunque sólo sea parcialmente— uno de los problemas más acuciantes de quienes usamos R para el análisis de datos muy grandes: leer ficheros de datos de gran tamaño.</description>
    </item>
    
    <item>
      <title>Anuncio de las III Jornadas de usuarios de R</title>
      <link>/2011/04/04/anuncio-de-las-iii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Mon, 04 Apr 2011 08:52:15 +0000</pubDate>
      
      <guid>/2011/04/04/anuncio-de-las-iii-jornadas-de-usuarios-de-r/</guid>
      <description>Más que me complace anunciar públicamente la convocatoria de las III Jornadas de usuarios de R, que tendrán lugar los días 17 y 18 de noviembre en la Escuela de Organización Industrial, Madrid.
Los interesados en asistir, participar y patrocinar —y subrayo lo de patrocinar— podrán encontrar los detalles en la página de las jornadas.
Desde esta bitácora, además, quiero invitar muy especialmente a los usuarios y entusiastas de R que trabajan en empresas e instituciones ajenas al mundo académico a aportar su peculiar visión sobre el universo de usos, aplicaciones y experiencias con el lenguaje.</description>
    </item>
    
    <item>
      <title>R y Excel: una alternativa</title>
      <link>/2011/03/23/r-y-excel-una-alternativa/</link>
      <pubDate>Wed, 23 Mar 2011 09:56:13 +0000</pubDate>
      
      <guid>/2011/03/23/r-y-excel-una-alternativa/</guid>
      <description>Los amantes de Excel están de enhorabuena. Ahora tienen una alternativa a RExcel, una extensión de Excel que le permite interactuar con R: XLConnect, un paquete multiplataforma de R que permite:
 Trabajar con ficheros de Excel 97 (.xls) y OOXML (.xlsx) Crear y eliminar hojas dentro de documentos Leer y escribir rangos de valores (ranges) Leer y escribir hojas de cálculo Añadir gráficos Asociar estilos a celdas Definir el tamaño de las filas y columnas Etc.</description>
    </item>
    
    <item>
      <title>Ya no si sino cuánto</title>
      <link>/2011/03/17/ya-no-si-sino-cuanto/</link>
      <pubDate>Thu, 17 Mar 2011 09:52:06 +0000</pubDate>
      
      <guid>/2011/03/17/ya-no-si-sino-cuanto/</guid>
      <description>Ya no te preguntan si usas R. Es el signo de los tiempos: ahora te preguntan cuánto; ahora te preguntan si lo usas siempre, casi siempre, a veces, poco y, para los raritos, si no lo usas nunca.
¿Dónde? En las famosas encuestas de Kdnuggets.
¡A ver cuándo vemos un estudio de uso de R por países que nos rojigualdee la cara!</description>
    </item>
    
    <item>
      <title>Paréntesis, corchetes y rendimiento en R</title>
      <link>/2011/03/16/parentesis-corchetes-y-rendimiento-en-r/</link>
      <pubDate>Wed, 16 Mar 2011 09:31:45 +0000</pubDate>
      
      <guid>/2011/03/16/parentesis-corchetes-y-rendimiento-en-r/</guid>
      <description>Conforme se populariza el uso de R, cobran creciente importancia las cuestiones concernientes a su rendimiento, su gestión de la memoria, etc. Hasta el punto que incluso uno de sus creadores, Ross Ihaka, ha expresado últimamente su descontento con las limitaciones de R (el enlace es gentileza de Daniel Castro) sugiriendo que sus componentes puramente estadísticos deberían construirse sobre la base de un lenguaje distinto, posiblemente Lisp.
Dentro de este contexto de preocupación sobre el rendimiento de R, han aflorado algunas cuestiones acerca de la eficiencia del intérprete a la hora de resolver expresiones matemáticas.</description>
    </item>
    
    <item>
      <title>R, HDF5 y bases de datos orientadas a columnas</title>
      <link>/2011/03/10/r-hdf5-y-bases-de-datos-orientadas-a-columnas/</link>
      <pubDate>Thu, 10 Mar 2011 09:25:23 +0000</pubDate>
      
      <guid>/2011/03/10/r-hdf5-y-bases-de-datos-orientadas-a-columnas/</guid>
      <description>Tras escribir el otro día sobre RevoscaleR, he tropezado con un paquete de R, HDF5 que le permite hacer cosas parecidas usando tecnologías libres. Puede encontrarse más información sobre HDF5 en la Wikipedia y en la página del proyecto.

De todos modos, y como dejé escrito como respuesta a un comentario en la entrada que indico más arriba, una solución definitiva al problema del análisis de conjuntos de datos grandes con R podría venir de la mano de una integración adecuada con un gestor de bases de datos orientado a columnas.</description>
    </item>
    
    <item>
      <title>¿Cómo mejorar tu estilo de programación en R?</title>
      <link>/2011/03/08/como-mejorar-tu-estilo-de-programacion-en-r/</link>
      <pubDate>Tue, 08 Mar 2011 09:59:28 +0000</pubDate>
      
      <guid>/2011/03/08/como-mejorar-tu-estilo-de-programacion-en-r/</guid>
      <description>En un hilo reciente en la lista de desarrollo de R ha habido una discusión interesante acerca de buenas prácticas a la hora programar con R y concretamente, para desarrollar paquetes que contuviesen llamadas a código desarrollado en C/C++.
En particular, el autor del primer mensaje del hilo criticaba varios usos que consideraba inadecuados a la hora de programar en R:
 El uso de variables misteriosas surgidas de la nada.</description>
    </item>
    
    <item>
      <title>Los dinosaurios y R: dos enlaces</title>
      <link>/2011/03/07/los-dinosaurios-y-r-dos-enlaces/</link>
      <pubDate>Mon, 07 Mar 2011 09:59:38 +0000</pubDate>
      
      <guid>/2011/03/07/los-dinosaurios-y-r-dos-enlaces/</guid>
      <description>Quiero compartir con mis lectores dos enlaces relacionados. Puede que a alguno le interese su sustancia misma. A mí no tanto. A mí me interesan en cuanto que ilustran la emergencia de R y el papel protagónico que está asumiendo en el universo de las cosas analíticas. Tan protagónico que hasta dos viejos dinosaurios pasan voluntariamente por su aro.
Tradicionalmente, para analizar grandes bases de datos empresariales, se realizaba en primer lugar una extracción masiva de datos.</description>
    </item>
    
    <item>
      <title>Nuevos comentarios sobre RevoScaleR</title>
      <link>/2011/03/04/comentarios-sobre-revoscaler/</link>
      <pubDate>Fri, 04 Mar 2011 09:38:29 +0000</pubDate>
      
      <guid>/2011/03/04/comentarios-sobre-revoscaler/</guid>
      <description>El reto lanzado por Revolution Analytics a SAS está relacionado con el lanzamiento por parte de la primera empresa de un paquete, RevoScaleR, diseñado para permitir el análisis de conjuntos de datos grandes. La lectura más detallada de uno de los pocos documentos técnicos que circulan sobre el paquete me invita a compartir con mis lectores mis impresiones más allá de las primeras y más someras que realicé hace unos días.</description>
    </item>
    
    <item>
      <title>RStudio, un nuevo editor multiplataforma para R</title>
      <link>/2011/03/01/rstudio-un-nuevo-editor-multiplataforma-para-r/</link>
      <pubDate>Tue, 01 Mar 2011 09:00:11 +0000</pubDate>
      
      <guid>/2011/03/01/rstudio-un-nuevo-editor-multiplataforma-para-r/</guid>
      <description>Noticia fresca, recién salida del horno: RStudio acaba de salir a la luz. Se trata de un nuevo editor multiplataforma y de código abierto de R .

Está desarrollado en C++ y corre en Linux, Windows y Mac OS X. Y no puedo decir mucho más de momento. Pero espero los comentarios de todos los entusiastas de R al respecto.</description>
    </item>
    
    <item>
      <title>Programación funcional en R: Reduce</title>
      <link>/2011/02/28/programacion-funcional-en-r-reduce/</link>
      <pubDate>Mon, 28 Feb 2011 09:07:36 +0000</pubDate>
      
      <guid>/2011/02/28/programacion-funcional-en-r-reduce/</guid>
      <description>Siguiendo con la serie de artículos sobre programación funcional que comencé hablando de Filter() hace un tiempo, trataré hoy la función Reduce(). El contenido de cuanto sigue debería ser familiar de quienes asistieron al Taller Avanzado de R en las II Jornadas de Usuarios de R.
Reduce es el segundo de los tiempos de una abstracción popularizado por Google y otros pero que tiene sus raíces en los lenguajes funcionales (Lisp y otros): map-reduce.</description>
    </item>
    
    <item>
      <title>Enredando con el paquete googleVis de R</title>
      <link>/2011/02/17/enredando-con-el-paquete-googlevis-de-r/</link>
      <pubDate>Thu, 17 Feb 2011 09:22:41 +0000</pubDate>
      
      <guid>/2011/02/17/enredando-con-el-paquete-googlevis-de-r/</guid>
      <description>Si el otro día denuncié un gráfico engañabobos (y algún otro me explayaré muy constructivamente sobre el intercambio de correos que mantuve con sus autores), hoy he querido reproducirlo con el paquete googleVis de R.
Habedlo:
[cf]googleViz[/cf]
El código utilizado para generarlo es:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  library(googleVis) library(reshape) a &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>Animaciones estadísticas con R</title>
      <link>/2011/02/16/animaciones-estadisticas-con-r/</link>
      <pubDate>Wed, 16 Feb 2011 09:22:39 +0000</pubDate>
      
      <guid>/2011/02/16/animaciones-estadisticas-con-r/</guid>
      <description>He encontrado una página que será, seguro, del gusto de mis lectores. Contiene animaciones en R tales desarrolladas con el paquete animation tales como ésta sobre la optimización por mínimos cuadrados o esta otra sobre k-medias.
¡A disfrutar!</description>
    </item>
    
    <item>
      <title>Cómo reordenar niveles de factores en R</title>
      <link>/2011/02/15/como-reordenar-niveles-de-factores-en-r/</link>
      <pubDate>Tue, 15 Feb 2011 02:10:57 +0000</pubDate>
      
      <guid>/2011/02/15/como-reordenar-niveles-de-factores-en-r/</guid>
      <description>En esta entrada voy a mostrar tres maneras (que vienen a ser la misma) de ordenar los niveles de un factor en R:
 La básica La sofisticada El atajo  Antes, responderé a una pregunta: ¿por qué reordenar niveles en factores? La mejor respuesta que se me ocurre: si no la sabes, deja de leer ya. Te aseguro que, a poco que trabajes con R, acabarás retomando la lectura.</description>
    </item>
    
    <item>
      <title>ggplot2 en su contexto</title>
      <link>/2011/02/10/ggplot2-en-su-contexto/</link>
      <pubDate>Thu, 10 Feb 2011 09:56:44 +0000</pubDate>
      
      <guid>/2011/02/10/ggplot2-en-su-contexto/</guid>
      <description>gplot2 es, sin duda, el paquete gráfico de moda en R. Hay quien lo ama, hay quien lo odia, pero cada vez son menos los que lo ignoran. Lo que igual no es tan sabido por los usuarios de R es el contexto en el que nació ggplot2, su relación con el motor gráfico de R y su relación con otros mecanismos de representación gráfica existentes en otros paquetes estadísticos.</description>
    </item>
    
    <item>
      <title>¿Un torpedo bajo la línea de flotación de SAS?</title>
      <link>/2011/02/07/un-torpedo-bajo-la-linea-de-flotacion-de-sas/</link>
      <pubDate>Mon, 07 Feb 2011 09:52:19 +0000</pubDate>
      
      <guid>/2011/02/07/un-torpedo-bajo-la-linea-de-flotacion-de-sas/</guid>
      <description>Revolution Analytics ha disparado un torpedo apuntando bajo la línea de flotación de SAS. Se trata del SAS to R challenge, una muy inteligente campaña de publicidad por la que se compromete a reescribir en R gratuitamente código SAS de clientes potenciales si el primero es más eficaz que el segundo.
Más allá de lo que la campaña parece ser, se esconde lo que realmente es: la constatación de que el premio gordo en el mundo de análisis empresarial es la actual base instalada de SAS y de que Revolution va a por todas.</description>
    </item>
    
    <item>
      <title>Rudimentos para la manipulación de fechas con R</title>
      <link>/2011/02/02/1387/</link>
      <pubDate>Wed, 02 Feb 2011 09:05:25 +0000</pubDate>
      
      <guid>/2011/02/02/1387/</guid>
      <description>Puede que a alguien le resulte sencillo, pero jamás ameno: trabajar con fechas y horas es, cuando menos, una molestia con cualquier lenguaje de programación. Y como mi compañero Raúl ofreció en su bitácora una pequeña guía de cómo operar con ellas usando SAS/WPS, me dispongo yo a hacer lo propio con R.
Leyendo fechas y horas: strptime El primer encontronazo con el insidioso problema de las fechas y las horas suele ser el tener que leerlas de algún fichero de texto.</description>
    </item>
    
    <item>
      <title>R-node, una interfaz &#34;web&#34; para R</title>
      <link>/2011/01/31/r-node-una-interfaz-web-para-r/</link>
      <pubDate>Mon, 31 Jan 2011 09:52:58 +0000</pubDate>
      
      <guid>/2011/01/31/r-node-una-interfaz-web-para-r/</guid>
      <description>Acabo de tener noticia de R-node, una interfaz web para R. Permite abrir una sesión de R remota (o local) a través del navegador e interactuar con R como a través de la consola habitual.
 Los interesados deberían visitar esta demo y, tal vez, el código fuente en Gitorious.</description>
    </item>
    
    <item>
      <title>La ley de los grandes números y el teorema central del límite en dos animaciones</title>
      <link>/2011/01/26/la-ley-de-los-grandes-numeros-y-el-teorema-central-del-limite-en-dos-animaciones/</link>
      <pubDate>Wed, 26 Jan 2011 09:21:40 +0000</pubDate>
      
      <guid>/2011/01/26/la-ley-de-los-grandes-numeros-y-el-teorema-central-del-limite-en-dos-animaciones/</guid>
      <description>No las voy a reproducir aquí por si se enfada el autor. Me limitaré a mostrar una captura de la animación correspondiente a la ley de los grandes números,

y a la del teorema central del límite,

La animación completa (hecha con R) y los detalles, en este enlace.</description>
    </item>
    
    <item>
      <title>Nuevo paquete para procesar texto en R: stringr</title>
      <link>/2011/01/20/nuevo-paquete-para-procesar-texto-en-r-stringr/</link>
      <pubDate>Thu, 20 Jan 2011 09:56:47 +0000</pubDate>
      
      <guid>/2011/01/20/nuevo-paquete-para-procesar-texto-en-r-stringr/</guid>
      <description>Hadley Wickman, el autor de plyr, reshape y ggplot2, ha vuelto a la carga en su exitoso empeño por hacernos cambiar de forma de programar en R.
Con su nuevo paquete, stringr, aspira a facilitarnos aún más la vida. En un reciente artículo, enumera sus ventajas:
 Procesa factores y caracteres de la misma manera (de verdad, muy práctico) Da a las funciones nombres y argumentos consistentes Simplifica las operaciones de procesamiento de cadenas eliminando opciones que apenas se usan Produce salidas que pueden ser utilizadas fácilmente como entradas a otras funciones Incorpora funciones para procesar texto presentes en otros lenguajes pero no en R  </description>
    </item>
    
    <item>
      <title>Navegando por ahí: un (otro) curso de estadística con R</title>
      <link>/2011/01/18/navegando-por-ahi-un-otro-curso-de-estadistica-con-r/</link>
      <pubDate>Tue, 18 Jan 2011 09:51:44 +0000</pubDate>
      
      <guid>/2011/01/18/navegando-por-ahi-un-otro-curso-de-estadistica-con-r/</guid>
      <description>Navegando por ahí he dado con otro curso de R y otro blog muy interesante. Para facilitar la búsqueda a mis lectores, les dejo acá los enlaces directos a los distintos capítulos:
 Introduccion a R Modelos lineales Modelos lineales generalizados Diseño de experimentos Modelos lineales mixtos Análisis multivariante  ¡Buena lectura!</description>
    </item>
    
    <item>
      <title>Graficaca a tutiplén</title>
      <link>/2011/01/05/1139/</link>
      <pubDate>Wed, 05 Jan 2011 09:36:55 +0000</pubDate>
      
      <guid>/2011/01/05/1139/</guid>
      <description>Al autor le preocupa de viejo el problema de la representación gráfica de datos. Piensa que tiene más de arte que de ciencia. Tal vez lo dice porque no se le da bien: confunde tonos y colores y desgarbado es el adjetivo que mejor describe sus trazos.
Y como casi todo diletante maltratado de las musas, ejerce de crítico. Y voto a Dios que su crítica es acerba. Le irritan todos los gráficos de tarta (menos éste), desea toda clase de malaventura al cretino que lleva lo de Excel en Expansión y vive prisionero de otras manías semejantes.</description>
    </item>
    
    <item>
      <title>Noticia de las II Jornadas de Usuarios de R</title>
      <link>/2010/12/29/noticia-de-las-ii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Wed, 29 Dec 2010 09:43:31 +0000</pubDate>
      
      <guid>/2010/12/29/noticia-de-las-ii-jornadas-de-usuarios-de-r/</guid>
      <description>Hace un año, al acabar las I Jornadas de Usuarios de R, escribí un pequeño resumen de lo habido en ellas en el blog de mi compañero de penas y oficios Raúl Vaquerizo. Este año, con cierta demora (justificada documentalmente) me dispongo a hacer lo mismo con lo que vivimos hace unos días en las II Jornadas en Mieres.
Es obligado en primer lugar agradecer a la Escuela Politécnica de Mieres por haberlas acogido y muy en particular a Belén Prendes, quien desde el primer momento impulsó este proyecto.</description>
    </item>
    
    <item>
      <title>Programación funcional en R: Filter</title>
      <link>/2010/11/24/programacion-funcional-en-r-filter/</link>
      <pubDate>Wed, 24 Nov 2010 09:08:05 +0000</pubDate>
      
      <guid>/2010/11/24/programacion-funcional-en-r-filter/</guid>
      <description>Quienes acudan a Mieres la semana que viene me oirán hablar de programación funcional en R. Algo de lo que no hablaré pero que dejaré acá escrito como abrebocas es un pequeño ejemplo de cómo la programación funcional hace tu vida más simple y, sobre todo, prolonga la vida de tu teclado.
Voy a ilustrar el uso de una función de R que echábamos de menos los usuarios de Python: Filter.</description>
    </item>
    
    <item>
      <title>Comportamiento inesperado... ¿sólo por mí?</title>
      <link>/2010/11/02/comportamiento-inesperado-solo-por-mi/</link>
      <pubDate>Tue, 02 Nov 2010 22:18:21 +0000</pubDate>
      
      <guid>/2010/11/02/comportamiento-inesperado-solo-por-mi/</guid>
      <description>El otro día, bajo el encabezamiento Unexpected behabiour of min, tapply and POSIXct/POSIXlt classes?, mandé a la lista de desarrolladores de R el siguiente pedazo de código:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  before &amp;lt;- Sys.time() Sys.sleep( 1 ) now1 &amp;lt;- now2 &amp;lt;- Sys.</description>
    </item>
    
    <item>
      <title>Una (propuesta de) guía de estilo de R</title>
      <link>/2010/11/01/una-propuesta-de-guia-de-estilo-de-r/</link>
      <pubDate>Mon, 01 Nov 2010 20:16:39 +0000</pubDate>
      
      <guid>/2010/11/01/una-propuesta-de-guia-de-estilo-de-r/</guid>
      <description>Síntoma del creciente interés por R es el hecho de que Google haya elaborado y publicado una guía de estilo para R. Me he tomado la libertad de traducirla. Espero que a Google no le importe.
Es conveniente (Google, yo y, seguramente, muchos otros lo creemos así) atenerse a un código de estilo a la hora de programar. No es éste foro en el que enumerar las ventajas que se derivan de ello: si habéis desarrollado código codo con codo con otros, sabréis a qué me refiero; si no, haced caso al consejo de quienes os precedieron y ahorraréis tiempo y dinero.</description>
    </item>
    
    <item>
      <title>II Jornadas de Usuarios de R</title>
      <link>/2010/10/29/ii-jornadas-de-usuarios-de-r/</link>
      <pubDate>Fri, 29 Oct 2010 14:31:07 +0000</pubDate>
      
      <guid>/2010/10/29/ii-jornadas-de-usuarios-de-r/</guid>
      <description>Ya es oficial: está abierta la inscripción para participar en las II Jornadas de Usuarios de R que tendrán lugar en la Escuela Politécnica de Mieres los días 1 y 2 de diciembre.
Me complace también formar parte del comité científico de dichas jornadas y de encargarme del taller avanzado de R (día 1 de diciembre a las siete de la tarde).
¿Nos veremos en Mieres?</description>
    </item>
    
    <item>
      <title>¡Qué mala suerte tengo con las anomalías!</title>
      <link>/2010/10/29/que-mala-suerte-tengo-con-las-anomalias/</link>
      <pubDate>Fri, 29 Oct 2010 00:16:28 +0000</pubDate>
      
      <guid>/2010/10/29/que-mala-suerte-tengo-con-las-anomalias/</guid>
      <description>El siempre muy benéfico Banco de Santander me ha proporcionado &amp;mdash;onerosamente: veráse el porqué&amp;mdash; un conjunto de datos con el que ilustrar a los lectores de este blog en el uso del paquete outliers de R. Los datos son los siguientes:
1 2  dia &amp;lt;- 17:26 precio &amp;lt;- 10 + c( 22, 21, 39, 18, 24, 26, 26,26,29, 28 ) / 100   Los días son los discurridos desde que di una orden de adquisición de un fondo de inversión a través de dicha entidad financiera hasta que tuve constancia de que se había completado: el dinero se había adeudado de la cuenta corriente y las participaciones, aparecían listadas en la cuenta de valores.</description>
    </item>
    
    <item>
      <title>¿Siete lenguajes de programación emergentes?</title>
      <link>/2010/10/27/siete-lenguajes-de-programacion-emergentes/</link>
      <pubDate>Wed, 27 Oct 2010 22:21:05 +0000</pubDate>
      
      <guid>/2010/10/27/siete-lenguajes-de-programacion-emergentes/</guid>
      <description>Hace un par de días apareció un artículo en InfoWorld en el que se enumeraban siete lenguajes de programación emergentes. Parece que por emergentes ha de entenderse cada vez más extendidos en la empresa. Como R hacía parte del rol, comencé alegrándome. Después me surgieron dos elementos de sospecha.
Véase la lista de los siete lenguajes seleccionados:
 Python, un viejo conocido. Ruby Matlab JavaScript, que está gozando de una segunda primavera gracias a AJAX y demás R, ¡cómo no!</description>
    </item>
    
    <item>
      <title>A vueltas con los fractales</title>
      <link>/2010/10/26/a-vueltas-con-los-fractales/</link>
      <pubDate>Tue, 26 Oct 2010 21:27:06 +0000</pubDate>
      
      <guid>/2010/10/26/a-vueltas-con-los-fractales/</guid>
      <description>Si bien no hace mucho publicaba una entrada sobre el triángulo de Sierpinsky, mi tocayo Carlos Ortega (y ahora gentil colaborador) nos ha proporcionado un enlace en este blog a un pedazo de código que bien vale la pena replicar aquí para el solaz (y tal vez, incluso, provecho) de los lectores de estas páginas. Es:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  library(fields) # for tim.</description>
    </item>
    
    <item>
      <title>Una solución al problema de la separación perfecta con regresiones logísticas</title>
      <link>/2010/10/25/una-solucion-al-problema-de-la-separacion-perfecta-con-regresiones-logisticas/</link>
      <pubDate>Mon, 25 Oct 2010 22:56:39 +0000</pubDate>
      
      <guid>/2010/10/25/una-solucion-al-problema-de-la-separacion-perfecta-con-regresiones-logisticas/</guid>
      <description>Cuando el otro día planteé al mis lectores el problema de cómo representar de manera efectiva un conjunto de datos pequeños, no lo hice de manera enteramente ociosa. Eran datos reales de un cliente que tropezó con el llamado problema de la separación perfecta al intentar aplicar una regresión logística.
Veamos de nuevo los datos:

En la gráfica cada punto representa un individuo (posiblemente una persona). Los grupos los distinguen en dos clases (posiblemente, enfermos y sanos).</description>
    </item>
    
    <item>
      <title>Tutorial: instalación de la extensión de R para RapidMiner</title>
      <link>/2010/10/22/tutorial-instalacion-de-la-extension-de-r-para-rapidminer/</link>
      <pubDate>Fri, 22 Oct 2010 22:59:24 +0000</pubDate>
      
      <guid>/2010/10/22/tutorial-instalacion-de-la-extension-de-r-para-rapidminer/</guid>
      <description>Por popular demanda, voy a explorar cómo de dificultoso es instalar el puente entre R y RapidMiner en Windows y a dejar escrito cómo se hace. Lo instalé hace días en Linux (Ubuntu) sin mayor problema. Pero hay quien parece que haberlos tenido en la ubicua plataforma.
No sé mucho de Windows y las diferentes versiones y configuraciones que pueda tener. Sólo sé que que he probado los pasos de este tutorial sobre un Windows 7 Profesional (creo) de 32 bits.</description>
    </item>
    
    <item>
      <title>Matlab es más rápido que R... ¿y?</title>
      <link>/2010/10/06/matlab-es-mas-rapido-que-r-y/</link>
      <pubDate>Wed, 06 Oct 2010 21:50:44 +0000</pubDate>
      
      <guid>/2010/10/06/matlab-es-mas-rapido-que-r-y/</guid>
      <description>No sé si alguna vez en la vida he visto una copia legal de Matlab. Creo que no. Ni forzando la memoria consigo recordar haber conocido a alguien que haya pagado los 2000 euros que cuesta una licencia comercial en España.
Eso sí, he conocido a mucha gente a la que le gusta mucho. Y que habla maravillas de él, etc. En algún sitio lo habrán probado, presumo.
Los aficionados a Matlab lo son también a comentar lo rápido que es.</description>
    </item>
    
    <item>
      <title>Proyectos de R en el Google Summer of Code 2010 (II)</title>
      <link>/2010/09/29/proyectos-de-r-en-el-google-summer-of-code-2010-ii/</link>
      <pubDate>Wed, 29 Sep 2010 22:09:37 +0000</pubDate>
      
      <guid>/2010/09/29/proyectos-de-r-en-el-google-summer-of-code-2010-ii/</guid>
      <description>Hace ya unos meses hablé de cómo había unos cuantos proyectos relacionados con R en el Google Summer of Code 2010. Recientemente se ha publicado un pequeño resumen de los logros alcanzados:
 De las quince propuestas originales, arrancaron cinco. De las cinco, cuatro llegaron a buen término. Lamentablemente, el —tal vez— más interesante de ellos, la implementación de un interfaz de R análogo a DBI para bases de datos no relacionales (NoSQL), acabó en nada.</description>
    </item>
    
    <item>
      <title>Rutinas de C en R</title>
      <link>/2010/09/26/rutinas-de-c-en-r/</link>
      <pubDate>Sun, 26 Sep 2010 23:13:39 +0000</pubDate>
      
      <guid>/2010/09/26/rutinas-de-c-en-r/</guid>
      <description>Esta entrada que ahora hago es un pequeño tutorial que publiqué en mi primera página de internet a principios de siglo, cuando todavía usaba Windows regularmente. Es posible que gran parte de lo que en ella cuente esté ya mandado a recoger. No obstante, tampoco hace tanto, eché mano de lo que en ella había dejado escrito para ver cómo migrar a Windows algo que había hecho en Linux y&amp;hellip; todavía funcionó.</description>
    </item>
    
    <item>
      <title>Un grupo de usuarios de R en España... ¿cuándo?</title>
      <link>/2010/09/24/un-grupo-de-usuarios-de-r-en-espana-cuando/</link>
      <pubDate>Fri, 24 Sep 2010 18:35:49 +0000</pubDate>
      
      <guid>/2010/09/24/un-grupo-de-usuarios-de-r-en-espana-cuando/</guid>
      <description>Hace poco recibí noticia de la creación de un grupo de usuarios de R en Brisbane, que no deja de ser una ciudad chiquita en un país poblacionalmente chiquito. ¡Y es ya el cuarto en Australia!
Miro también el siguiente gráfico y me da algo de grima:

¡No hay ni un sólo cerca de Madrid (que es la ubicación que a mí y ahora más me compete)! Así que si alguno de mis lectores está interesado en el asunto, podemos ir urdiendo cómo hacer para colocarle un pinchico rojo a ese mapa justo en Sol.</description>
    </item>
    
    <item>
      <title>useR! 2011</title>
      <link>/2010/09/17/user-2011/</link>
      <pubDate>Fri, 17 Sep 2010 15:02:01 +0000</pubDate>
      
      <guid>/2010/09/17/user-2011/</guid>
      <description>La próxima reunión anual de usuarios de R tendrá lugar del 16 al 18 de agosto del 2011 en la Universidad de Warwick, Inglaterra.
Los conferenciantes invitados de este año van a ser Adrian Bowman, Lee Edlefsen, Ulrike Grömping, Wolfgang Huber, Brian Ripley, Jonathan Rougier, Simon Urbanek y Brandon Whitcher.
Los usuarios de R están invitados a preparer charlas y presenter pósters ilustrando el uso de R.
¿Cuándo tocará en España?</description>
    </item>
    
    <item>
      <title>Representando gráficamente conjuntos de datos pequeños</title>
      <link>/2010/09/16/representando-graficamente-conjuntos-de-datos-pequenos/</link>
      <pubDate>Thu, 16 Sep 2010 23:24:46 +0000</pubDate>
      
      <guid>/2010/09/16/representando-graficamente-conjuntos-de-datos-pequenos/</guid>
      <description>Últimamente me están llegando conjuntos de datos para analizar con muy pocos registros. He aquí un subconjunto de uno de ellos (de hoy y debidamente anonimizado):
1 2 3 4 5 6  nivel.proteina &amp;lt;- c( 11.56, 10.43, 11.00, 10.92, 10.08, 9.98, 10.35, 9.55, 9.19, 7.00, 6.72, 6.43, 7.43, 7.26, 6.67, 7.49, 8.03, 8.17, 6.79, 7.68, 7.01, 7.51, 6.90, 7.27, 7.56, 8.61, 8.16, 7.12 ) grupo &amp;lt;- c(0,0,0,0,0,0,0,0,0, 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1) datos &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>Más sobre la integración de R y RapidMiner</title>
      <link>/2010/09/08/mas-sobre-la-integracion-de-r-y-rapidminer/</link>
      <pubDate>Wed, 08 Sep 2010 19:32:42 +0000</pubDate>
      
      <guid>/2010/09/08/mas-sobre-la-integracion-de-r-y-rapidminer/</guid>
      <description>Si el otro día anuncié la próximaintegración de RapidMiner con R, hoy quiero dar a conocer un vídeo en la que se ilustra:
  Tiene buena pinta, la verdad.</description>
    </item>
    
    <item>
      <title>Una tarea para mis lectores: ¡resultados!</title>
      <link>/2010/09/06/tarea-lectores-resultados/</link>
      <pubDate>Mon, 06 Sep 2010 22:41:11 +0000</pubDate>
      
      <guid>/2010/09/06/tarea-lectores-resultados/</guid>
      <description>El otro día dejé planteadauna tarea para mis lectores (que han sido menos diligentes que yo, incluso). Trataba de una comparación entre varios métodos para acceder a diccionarios (o hashes) de datos desde R para tratar de identificar el más eficiente en términos de velocidad de acceso.
Acá van los resultados:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  n &amp;lt;- 100000 dat &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>El vídeo de la conferencia &#34;alRededores&#34; disponible en DailyMotion</title>
      <link>/2010/09/05/el-video-de-la-conferencia-alrededores-disponible-en-dailymotion/</link>
      <pubDate>Sun, 05 Sep 2010 22:34:22 +0000</pubDate>
      
      <guid>/2010/09/05/el-video-de-la-conferencia-alrededores-disponible-en-dailymotion/</guid>
      <description>Como nunca conseguí ver el vídeo de la conferencia que di en las I Jornadas de Usuarios de R en noviembre del 2009 directamente desde los servidores de la Universidad de Murcia, lo he subido a DailyMotion. Los 60 minutos de la conferencia están partidos en tres partes que pueden verse consecutivamente aquí.
Nota: al final de cada parte aparece un enlace para continuar a la siguiente.</description>
    </item>
    
    <item>
      <title>Paquetes estadísticos: una anécdota sin moraleja</title>
      <link>/2010/09/04/paquetes-estadisticos-una-anecdota-sin-moraleja/</link>
      <pubDate>Sat, 04 Sep 2010 13:11:19 +0000</pubDate>
      
      <guid>/2010/09/04/paquetes-estadisticos-una-anecdota-sin-moraleja/</guid>
      <description>Un banco que gana mucho dinero quiso gastarse un nada desdeñable pellizco de sus ingresos contratando a unos consultores muy resabidos de un país extranjero donde, es fama, todos saben mucho. El resultado fue una documentación ininteligible y un larguísimo programa en VB sin apenas comentarios que se demoraba horas en realizar una simulación trivial.
El banco, cansado de quemar ciclos de CPU en vano, encargó a una consultora local la reimplementación del algoritmo en un afamado paquete estadístico.</description>
    </item>
    
    <item>
      <title>El paquete multicore de R</title>
      <link>/2010/09/01/el-paquete-multicore-de-r/</link>
      <pubDate>Wed, 01 Sep 2010 22:24:44 +0000</pubDate>
      
      <guid>/2010/09/01/el-paquete-multicore-de-r/</guid>
      <description>Tengo acceso a una máquina que, aunque anda un poco corta de memoria, cuenta con ocho CPUs. Tenía unas simulaciones bastante pesadas que correr y quise aprovechar su naturaleza perfectamente paralelizable. Y, de paso, hacer con R lo mismo por lo que he visto a un consultor de SAS cobrar a razón de 3.000 dólares diarios.
En el fondo, es una trivialidad. Supongamos que la función que implementa la simulación se llama foo.</description>
    </item>
    
    <item>
      <title>Anuncio de la integración de Rapidminer y R</title>
      <link>/2010/08/31/anuncio-de-la-integracion-de-rapidminer-y-r/</link>
      <pubDate>Tue, 31 Aug 2010 20:39:51 +0000</pubDate>
      
      <guid>/2010/08/31/anuncio-de-la-integracion-de-rapidminer-y-r/</guid>
      <description>RapidMiner es, posiblemente, la plataforma de minería de datos libre que mejor reputación goza. Hasta la publicación de la versión 5 le veía un pequeño problema: tenía una interfaz bastante poco intuitiva.
Hasta hace pocos días le veía otro: no podía extenderse —al menos de una manera obvia— programando en Java o, preferiblemente, R. Sin embargo, el módulo de integración de R con Rapidminer ya está listo y su lanzamiento va a ser el plato fuerte de RCOMM 2010, la conferencia de usuarios de Rapidminer (oficialmente, RapidMiner Community Meeting And Conference).</description>
    </item>
    
    <item>
      <title>La función ifelse &#34;a la SAS&#34;</title>
      <link>/2010/08/28/la-funcion-ifelse-a-la-sas/</link>
      <pubDate>Sat, 28 Aug 2010 17:24:29 +0000</pubDate>
      
      <guid>/2010/08/28/la-funcion-ifelse-a-la-sas/</guid>
      <description>Una función muy útil de R es ifelse:
1 2 3  val &amp;lt;- 0 var &amp;lt;- ifelse( val == 1, &amp;#34;uno&amp;#34;, &amp;#34;cero&amp;#34; ) print( var )   Un programador en SAS haría algo así como
1 2 3 4 5 6 7  %macro test(val); %if &amp;amp;val=1 %then %let var=one; %else %let var=zero;%put &amp;amp;var; %mend; %test(0);   SAS, sin embargo, recomienda hacerlo así:
1 2 3  %let val=0; %let var=%sysfunc(ifc(&amp;amp;val=1,one,zero));%put &amp;amp;var;   Una línea, sí, pero una línea muy críptica.</description>
    </item>
    
    <item>
      <title>Sobre la cuota de mercado mundial de las herramientas analíticas de negocio</title>
      <link>/2010/08/22/sobre-la-cuota-de-mercado-mundial-de-las-herramientas-analiticas-de-negocio/</link>
      <pubDate>Sun, 22 Aug 2010 13:50:11 +0000</pubDate>
      
      <guid>/2010/08/22/sobre-la-cuota-de-mercado-mundial-de-las-herramientas-analiticas-de-negocio/</guid>
      <description>Hace poco, IDC —una empresa que hace estudios de mercado a nivel global de distintas herramientas de sofware y hardware — hizo público su informe periódico Worldwide Business Intelligence Tools 2009 Vendor Shares. En su página 8, la más jugosa del informe, aparece la tabla que reproduzco a continuación:

Puede apreciarse cómo en el segmento de la minería de datos (que viene a ser a lo que se refieren con lo de advanced analytics) es SAS el claro dominador con IBM/SPSS en una débil segunda posición.</description>
    </item>
    
    <item>
      <title>R en Yotube y Facebook</title>
      <link>/2010/08/21/r-en-yotube-y-facebook/</link>
      <pubDate>Sat, 21 Aug 2010 12:52:31 +0000</pubDate>
      
      <guid>/2010/08/21/r-en-yotube-y-facebook/</guid>
      <description>Bebilda, que no sé quién es (misterio que me he propuesto resolver pronto) ha arrancado dos proyectos bastante interesantes:
 Un canal con tutoriales sobre R en Youtube Un grupo para usuarios de R, R project en Español, en Facebook.  Los tutoriales están francamente bien y los hay sobre temas diversos como análisis ANOVA, el test de Student, estadística descriptiva, creación de histogramas y otros asuntos de estadística básica.</description>
    </item>
    
    <item>
      <title>Una tarea para mis lectores</title>
      <link>/2010/08/17/una-tarea-para-mis-lectores/</link>
      <pubDate>Tue, 17 Aug 2010 21:09:38 +0000</pubDate>
      
      <guid>/2010/08/17/una-tarea-para-mis-lectores/</guid>
      <description>Ayer me dieron los resultados de unos análisis de sangre y, contra todo pronóstico, la médica me dijo que tengo el colesterol bajo control. ¡Con razón —me dije—, si en el blog lo hago yo todo! Así que para mejorar la circulación sanguínea de mis lectores, esta entrada es un ejercicio para quienes me leen. Espero pues que, a pesar de lo vacacional de las fechas, tengan tiempo de completar lo que queda sin hacer y lo hagan constar —antes de que pase lista— en un comentario explicando sus averiguaciones.</description>
    </item>
    
    <item>
      <title>Un ilustrador problema de compatibilidad de licencias libres</title>
      <link>/2010/08/05/un-ilustrador-problema-de-compatibilidad-de-licencias-libres/</link>
      <pubDate>Thu, 05 Aug 2010 14:40:52 +0000</pubDate>
      
      <guid>/2010/08/05/un-ilustrador-problema-de-compatibilidad-de-licencias-libres/</guid>
      <description>This whole thing is such a nuisance. It seems one can&amp;rsquo;t even give something away these days!
 Así de infeliz se mostraba G. Grothendieck hace unos días. Y es que habíamos enviado una primera versión del paquete rJython que subir a CRAN y nos encontramos con problemas de licencias.
Eso de las licencias de software es un tema enojoso. Importante, pero enojoso.
Además, da la impresión, que totalmente exótico a la ética y costumbres de este país desde el que escribo: algún día, como divertimento, contaré alguna historieta.</description>
    </item>
    
    <item>
      <title>Un curioso bug de R</title>
      <link>/2010/07/24/un-curioso-bug-de-r/</link>
      <pubDate>Sat, 24 Jul 2010 15:24:19 +0000</pubDate>
      
      <guid>/2010/07/24/un-curioso-bug-de-r/</guid>
      <description>A vueltas con los bugs, el otro día leí sobre uno bastante curioso de R. En resumen:
1 2 3 4 5 6 7  &amp;gt; a &amp;lt;- c(1,2, sqrt( 2) ^ 2 ) &amp;gt; table(a) a 1 2 1 2 &amp;gt; unique(a) [1] 1 2 2   ¿El motivo? La función unique compara el valor numérico de los valores del vector de manera que le afectan los errores de redondeo.</description>
    </item>
    
    <item>
      <title>rJython: un nuevo paquete para llamar a Python desde R</title>
      <link>/2010/07/13/rjython-un-nuevo-paquete-para-llamar-a-python-desde-r/</link>
      <pubDate>Tue, 13 Jul 2010 22:18:03 +0000</pubDate>
      
      <guid>/2010/07/13/rjython-un-nuevo-paquete-para-llamar-a-python-desde-r/</guid>
      <description>Ya está disponible el paquete rJython que permite llamar a Python desde R. Aunque todavía no se ha subido a CRAN, puede instalarse así:
1  install.packages(&amp;#34;rJython&amp;#34;, repos=&amp;#34;http://R-Forge.R-project.org&amp;#34;)   Una vez instalado puede probarse el paquete ejecutando, por ejemplo,
1 2 3 4 5 6 7 8 9 10 11  rJython &amp;lt;- rJython() a &amp;lt;- 1:4 jython.assign(rJython, &amp;#34;a&amp;#34;, a) jython.exec(rJython, &amp;#34;b = len( a )&amp;#34;) jython.get(rJython, &amp;#34;b&amp;#34;) rJython$exec(&amp;#34;import math&amp;#34;) jython.</description>
    </item>
    
    <item>
      <title>Gráficos en R con símbolos arbitrarios: código, comentarios y fin</title>
      <link>/2010/06/28/graficos-en-r-con-simbolos-arbitrarios-codigo-comentarios-y-fin/</link>
      <pubDate>Mon, 28 Jun 2010 22:36:10 +0000</pubDate>
      
      <guid>/2010/06/28/graficos-en-r-con-simbolos-arbitrarios-codigo-comentarios-y-fin/</guid>
      <description>Prometí el otro día revelar los secretos (pensaba que no lo eran tanto) del gráfico que mostré en esta entrada. Los impacientes tienen aquí todo lo que necesitan. Tienen que ejecutar primero el guión svg2ps.sh que invoca inkscape para transformar los ficheros svg (incluidos en la descarga) de las banderas (obtenidos de la Wikipedia) en ficheros postscript.
El programa src.R genera entonces el gráfico utilizando dos paquetes de R: grImport y lattice.</description>
    </item>
    
    <item>
      <title>Los &#34;mejores&#34; paquetes de R (II): análisis anual de la red social de los participantes en r-help</title>
      <link>/2010/06/28/los-mejores-paquetes-de-r-ii-analisis-anual-de-la-red-social-de-los-participantes-en-r-help/</link>
      <pubDate>Mon, 28 Jun 2010 02:22:59 +0000</pubDate>
      
      <guid>/2010/06/28/los-mejores-paquetes-de-r-ii-analisis-anual-de-la-red-social-de-los-participantes-en-r-help/</guid>
      <description>Hace un tiempo comencé una serie de entradas, que serán finalmente tres, sobre los &amp;ldquo;mejores&amp;rdquo; paquetes de R. Esta va a ser la segunda entrega. Siento haber tardado tanto en realizarla: quienes me conocen saben que ocioso no he permanecido. De mis actividades de este periodo daré cumplida cuenta en entradas subsiguientes.
Tengo que añadir también como preámbulo que ha sido una conversación sobre análisis de redes sociales con un ex-compañero muy ducho en apropiarse de contraseñas ajenas la que me ha empujado finalmente a ahondar este estudio que tenía, junto a tantos, postergado en una esquina de mi disco duro.</description>
    </item>
    
    <item>
      <title>useR! 2010</title>
      <link>/2010/06/21/user-2010/</link>
      <pubDate>Mon, 21 Jun 2010 21:17:30 +0000</pubDate>
      
      <guid>/2010/06/21/user-2010/</guid>
      <description>Mientras en España no sabemos aún qué pasa con las II Jornadas de Usuarios de R (de hecho, ni siquiera se han corregido las faltas de ortografía de la página de internet de las primeras), las useR! 2010 marchan a todo trapo: en Gaithersburg, Maryland, los días del 20 al 23 de julio no va a faltar ni rms.
No va faltar una charla a cuenta de la empresa a la que otras debieran parecerse.</description>
    </item>
    
    <item>
      <title>Gráficos en R con símbolos arbitrarios</title>
      <link>/2010/06/18/graficos-en-r-con-simbolos-arbitrarios/</link>
      <pubDate>Fri, 18 Jun 2010 19:23:52 +0000</pubDate>
      
      <guid>/2010/06/18/graficos-en-r-con-simbolos-arbitrarios/</guid>
      <description>Hace no mucho, en un blog hermano, se habló de cómo podían utilizarse símbolos distintos en los gráficos de R. También hablé yo de funcionarios y renta per cápita.
Ahora combino ambas entradas y algo más de mi cosecha para mostrar un gráfico hecho con R utilizando símbolos arbitrarios (las banderas de cada país).

El secreto de cómo lo he hecho (y el código completo, claro) lo revelaré la semana que viene.</description>
    </item>
    
    <item>
      <title>Algoritmos genéticos para la caracterización de máximos en random forests</title>
      <link>/2010/06/16/algoritmos-geneticos-para-la-caracterizacion-de-maximos-en-random-forests/</link>
      <pubDate>Wed, 16 Jun 2010 23:37:02 +0000</pubDate>
      
      <guid>/2010/06/16/algoritmos-geneticos-para-la-caracterizacion-de-maximos-en-random-forests/</guid>
      <description>En minería de datos se buscan modelos que permitan hacer predicciones acerca del comportamiento de los sujetos del estudio. Pero, típicamente, cuanto más complejas son las técnicas, menos intuición ofrecen acerca del porqué de la predicción, pierden inteligibilidad. Existe una omnipresente tensión entre inteligibilidad (una propiedad altamente deseable, incluso, en ocasiones, por requisito legal) y precisión.
Un modelo puede resumir mejor o peor una colección enorme de observaciones, pero en ocasiones los mismos modelos son demasiado complejos o herméticos como para ofrecer una interpretación plausible de los datos: ¿qué caracteriza a las observaciones para las que mi modelo predice los valores más altos (o bajos)?</description>
    </item>
    
    <item>
      <title>Agregador de noticias sobre R en español</title>
      <link>/2010/06/03/agregador-de-noticias-sobre-r-en-espanol/</link>
      <pubDate>Thu, 03 Jun 2010 02:11:19 +0000</pubDate>
      
      <guid>/2010/06/03/agregador-de-noticias-sobre-r-en-espanol/</guid>
      <description>Me es grato anunciar que está disponible (una versión beta de) un agregador de noticias sobre R en español. Ha sido desarrollado con el objetivo de proporcionar a la comunidad de usuarios un punto de acceso único a cuantas noticias sobre R se publiquen en la blogosfera en español. Es equivalente a su versión en inglés.
También está disponible como RSS.
Contenido agregable
Actualmente, el motor de agregación lista entradas en blogs que:</description>
    </item>
    
    <item>
      <title>De números y funcionarios</title>
      <link>/2010/05/31/de-numeros-y-funcionarios/</link>
      <pubDate>Mon, 31 May 2010 21:08:42 +0000</pubDate>
      
      <guid>/2010/05/31/de-numeros-y-funcionarios/</guid>
      <description>El otro día apareció una noticia en El País sobre los funcionarios en España y el resto de Europa, en el que aparecía este gráfico.
Como me resultaron curiosos los datos relativos a nuestros vecinos, me entretuve en sacarles algo de punta. Así que fui a la Wikipedia y asocié a cada país su renta per cápita PPA (son datos del 2008, creo) y obtuve esto:

Por respeto a la sagacidad de mis lectores (por ser lectores y míos los entiendo bien armados intelectualmente) me abstengo de realizar comentarios.</description>
    </item>
    
    <item>
      <title>Regresión por cuantiles en R y SAS</title>
      <link>/2010/05/18/regresion-por-cuantiles-en-r-y-sas/</link>
      <pubDate>Tue, 18 May 2010 20:52:08 +0000</pubDate>
      
      <guid>/2010/05/18/regresion-por-cuantiles-en-r-y-sas/</guid>
      <description>Hace un tiempo, con la aburridora perspectiva de un largo viaje en metro hasta mi casa ensombreciendo mi futuro más inminente, decidí regalarme algún tipo de amena lectura. A tal fin, imprimí un articulillo que, bajo la perspectiva de SAS, me introducía a una técnica que se vino a mí como por azar. O, bajo otro punto de vista, una técnica que, también por azar, había esquivado hasta tal fecha un encontronazo con mi husmeadora curiosidad.</description>
    </item>
    
    <item>
      <title>¡Hasta Microsoft!</title>
      <link>/2010/05/10/hasta-microsoft/</link>
      <pubDate>Mon, 10 May 2010 23:10:48 +0000</pubDate>
      
      <guid>/2010/05/10/hasta-microsoft/</guid>
      <description>El otro día incurrí de nuevo en la tan habitual como aburridora conversación acerca del papel que pueda jugar R en la empresa; más propiamente, tal vez, en determinadas áreas de determinadas empresas.
Carpetovetónico él, encumbrado a un otero mesetario, lo circunscribía al impermeable mundo académico español. Puede, sí, que la montaña no venga a Mahoma motu proprio; pero no hay que olvidar que a Mahoma no le faltan cumbres a las que encaramarse.</description>
    </item>
    
    <item>
      <title>Datatables: tablas con búsqueda binaria en R</title>
      <link>/2010/05/09/datatables-tablas-con-busqueda-binaria-en-r/</link>
      <pubDate>Sun, 09 May 2010 15:28:47 +0000</pubDate>
      
      <guid>/2010/05/09/datatables-tablas-con-busqueda-binaria-en-r/</guid>
      <description>No hace mucho me enfrenté con un problema en el trabajo. Quería cruzar dos tablas, una de algunos miles de millones de registros y otra de algunos cientos de miles para, simplemente, contar el número de filas finales que aparecían por fecha.
Cada una de las tablas tenía algunos filtros y agregaciones; el cruce final se realizaba sobre las subconsultas resultantes. El gestor de bases de datos que utilizamos, Teradata (sin comentarios), no podía con el cruce: las decisiones que tomaba internamente el presunto optimizador de consultas conducían inexorablemente a un error de espacio.</description>
    </item>
    
    <item>
      <title>R, ¿la herramienta de minería de datos más utilizada?</title>
      <link>/2010/05/05/r-la-herramienta-de-mineria-de-datos-mas-utilizada/</link>
      <pubDate>Wed, 05 May 2010 20:52:34 +0000</pubDate>
      
      <guid>/2010/05/05/r-la-herramienta-de-mineria-de-datos-mas-utilizada/</guid>
      <description>Pues eso es lo que parece indicar esta encuesta en el preciso momento en el que escribo. Cada uno le podrá otorgar la validez que desee, pero algún tipo de repercusión tendrá cuando:
 Hace unos años, cuando trabajaba para cierto fabricante de software, nos pasaron un correo invitándonos a emitir un voto en la que se realizó en ese año (el portal realiza una encuesta análoga cada año). Además, desde nuestras casas para que no se cancelasen por abusar del mismo rango de IPs.</description>
    </item>
    
    <item>
      <title>Para que copien, peguen y disfruten: addenda</title>
      <link>/2010/04/21/para-que-copien-peguen-y-disfruten-addenda/</link>
      <pubDate>Wed, 21 Apr 2010 21:53:21 +0000</pubDate>
      
      <guid>/2010/04/21/para-que-copien-peguen-y-disfruten-addenda/</guid>
      <description>Ayer dejé publicadas unas cuantas líneas de R y la promesa de contar de qué iba la cosa. Adelantando acontecimientos, he recibido comentarios públicos y privados al respecto que en esta entrada trataré de contestar.
El código era, una vez mínimamente desofuscado (no quería dar demasiadas pistas):
1 2 3 4 5 6 7 8 9 10 11  vertice.x &amp;lt;- c(0,1,2) # 1 vertice.y &amp;lt;- c(0,1,0) # 2 muestra &amp;lt;- sample( 1:3, 100000, replace = T ) # 3 iter &amp;lt;- function( ini, v ){ # 4 out &amp;lt;- rep( ini, length(v) ) # 5 for( i in 2:length(v) ) out[i] &amp;lt;- ( out[i-1] + v[i] ) / 2 # 6 out } plot( iter( runif(1), v.</description>
    </item>
    
    <item>
      <title>Para que copien, peguen y disfruten</title>
      <link>/2010/04/21/para-que-copien-peguen-y-disfruten/</link>
      <pubDate>Wed, 21 Apr 2010 00:18:06 +0000</pubDate>
      
      <guid>/2010/04/21/para-que-copien-peguen-y-disfruten/</guid>
      <description>El otro día hablé de una señora que había hecho algunos comentarios poco avisados sobre R. A las alegaciones de que el código de R que publicó en su página no es, siquiera, código de R respondió diciendo que lo había copiado &amp;ldquo;de internet&amp;rdquo; (¡cuánto de pernicioso hay por esas páginas por donde uno navega sin temor de Dios!).
Para incrementar la probabilidad de que cuando esto vuelva a ocurrir el código pegado de internet sea más bonito que el arriba mencionado dejo acá éste (e invito a mis lectores a ejecutarlo):</description>
    </item>
    
    <item>
      <title>Los &#34;mejores&#34; paquetes de R (I): la red social de los participantes en r-help</title>
      <link>/2010/04/18/los-mejores-paquetes-de-r-i-la-red-social-de-los-participantes-en-r-help/</link>
      <pubDate>Sun, 18 Apr 2010 19:43:28 +0000</pubDate>
      
      <guid>/2010/04/18/los-mejores-paquetes-de-r-i-la-red-social-de-los-participantes-en-r-help/</guid>
      <description>Hace no mucho leí un articulillo de SAS sobre el impacto de ciertas marcas en determinadas redes sociales. Como este tema, así como sus posibles aplicaciones, siempre me ha intrigado, llevado de la curiosidad y del aburrimiento, decidí realizar un estudio análogo.
El artículo de SAS utiliza como materia prima resúmenes de publicaciones científicas que tratan de determinados medicamentos. A los autores les interesa conocer de qué marca de medicamentos escribe cada autor ponderando a éstos últimos en función de su impacto.</description>
    </item>
    
    <item>
      <title>La opinión sobre R de una pobre señora</title>
      <link>/2010/04/14/la-opinion-sobre-r-de-una-pobre-senora/</link>
      <pubDate>Wed, 14 Apr 2010 22:36:49 +0000</pubDate>
      
      <guid>/2010/04/14/la-opinion-sobre-r-de-una-pobre-senora/</guid>
      <description>Me llegan noticias de una pobre señora que, se conoce, tiene un blog en el que habla de cosas que, da la impresion, le trascienden. Dice lo siguiente:
 Contrary to what some people seem to think, R is definitely not the next big thing, either. I am always surprised when people ask me why I think that, because to my mind it is obvious.
 Vamos, que no cree en R y que, además, esa idea suya le parece la más obvia del mundo.</description>
    </item>
    
    <item>
      <title>¿Puedo cambiar mi código retroactivamente?</title>
      <link>/2010/03/29/puedo-cambiar-mi-codigo-retroactivamente/</link>
      <pubDate>Mon, 29 Mar 2010 01:45:50 +0000</pubDate>
      
      <guid>/2010/03/29/puedo-cambiar-mi-codigo-retroactivamente/</guid>
      <description>La verdad, me gustaría, Me gustaría volver atrás y modificar algunas docenas de código en R que malescribí como un diletante por no estar al tanto de una función de R cuya verdadera utilidad descubrí recientemente (gracias le sean dadas, de nuevo, a Jorge Iván Vélez).
La verdad, no tengo excusa. Incluso se habló de ella en nuestro blog hermano.
Y es que nunca me había percatado de la potencia de la función mapply.</description>
    </item>
    
    <item>
      <title>Proyectos de R en el Google Summer of Code 2010</title>
      <link>/2010/03/28/proyectos-de-r-en-el-google-summer-of-code-2010/</link>
      <pubDate>Sun, 28 Mar 2010 14:09:18 +0000</pubDate>
      
      <guid>/2010/03/28/proyectos-de-r-en-el-google-summer-of-code-2010/</guid>
      <description>El Google Summer of Code es una iniciativa de Google por la cual la empresa otorga becas a estudiantes para que estos colaboren en determinados proyectos de código abierto. Y las becas no son moco de pavo: cada estudiante aceptado recibiría 5000 dólares de Google.
En estas colaboraciones, los estudiantes participan bajo la tutela de un mentor. Se buscan, por tanto, mentores con proyectos y estudiantes que quieran participar en alguno de ellos.</description>
    </item>
    
    <item>
      <title>R en &#34;The economist&#34;</title>
      <link>/2010/03/01/r-en-the-economist/</link>
      <pubDate>Mon, 01 Mar 2010 21:02:07 +0000</pubDate>
      
      <guid>/2010/03/01/r-en-the-economist/</guid>
      <description>El semanario The Economist ha publicado un suplemento especial sobrenuevos retos y tendencias en el proceso de cantidades ingentes de información. Aparte de multiplicar por 10 los informes que aparecen publicados periódicamente, en éste se menciona explícitamente que un free programming language called R lets companies examine and present big data sets.
También habla de Hadoop y otras técnicas y herramientas novedosas de las que sin duda voy a ir hablando en estas páginas.</description>
    </item>
    
    <item>
      <title>Edición especial del Journal of Statistical Software sobre GUIs para R</title>
      <link>/2010/02/28/edicion-especial-del-journal-of-statistical-software-sobre-guis-para-r/</link>
      <pubDate>Sun, 28 Feb 2010 04:27:58 +0000</pubDate>
      
      <guid>/2010/02/28/edicion-especial-del-journal-of-statistical-software-sobre-guis-para-r/</guid>
      <description>Se ha anunciado recientemente una edición especial del Journal of Statistical Software acerca de interfaces gráficas para R. Los editores son Pedro Valero Mora y Rubén Ledesma.
Me tomo la libertad de traducir el anuncio para este blog:
 Desde la publicación del artículo original de Gentleman and Ihaka, R ha sido adoptado por un porcentaje creciente de estadísticos profesionales en la universidad y fuera de ella, pero su difusión entre los usuarios nuevos u ocasionales de la estadística no ha progresado al mismo ritmo.</description>
    </item>
    
    <item>
      <title>Creando paquetes con R: r-forge</title>
      <link>/2010/02/27/creando-paquetes-con-r-r-forge/</link>
      <pubDate>Sat, 27 Feb 2010 19:58:01 +0000</pubDate>
      
      <guid>/2010/02/27/creando-paquetes-con-r-r-forge/</guid>
      <description>Hace poco no asistí a una conferencia del profesor Campo Elías Pardo en la Universidad Nacional de Colombia sobre la creación de paquetes de R. Me penó no poder asistir porque sospeché primero y corroboré después que se había obviado en ella una herramienta muy útil para la creación de paquetes con R: la forja oficial.
La conferencia trababa esencialmente de cómo crear paquetes bajo Windows. Windows es un sistema operativo del que sé poco y siempre me han parecido excesivamente arcanos los liturgias y herramientas necesarias para compilar los paquetes.</description>
    </item>
    
    <item>
      <title>febRero</title>
      <link>/2010/02/26/febrero/</link>
      <pubDate>Fri, 26 Feb 2010 07:25:43 +0000</pubDate>
      
      <guid>/2010/02/26/febrero/</guid>
      <description>Nada he publicado durante el mes de febrero en el blog. Pareciese que no estaba en el mundo. Estaba, sí, pero en otra parte, muy hermosa, de él. Y de parte de mis hechos da cuenta el siguiente afiche:

Como en él indica, en el Departamento de Estadística de la Universidad Nacional de Medellín tuvieron la gentileza de invitarme a dar de nuevo la conferencia que impartí en las I Jornadas de Usuarios de R en España.</description>
    </item>
    
    <item>
      <title>R y conjuntos de datos &#34;grandes&#34;</title>
      <link>/2010/01/26/r-y-conjuntos-de-datos-grandes/</link>
      <pubDate>Tue, 26 Jan 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/01/26/r-y-conjuntos-de-datos-grandes/</guid>
      <description>Leer datos grandes con R produce inmensos quebraderos de cabeza. Existen dos soluciones extra-R: filtrar los datos cuanto antes y comprar más RAM. Desde R existen trucos y alternativas y hace un tiempo, aunque sin aspiraciones de exhaustividad, quise explorar algunas.
De ahí surgió una entrada que realicé hace un tiempo, en mi antiguo blog. Publiqué Tres fracasos y medio con R mientras esperaba a un amigo. En él presenté varias opciones para trabajar y operar con datos grandes.</description>
    </item>
    
    <item>
      <title>Ayuda de R en StackOverflow</title>
      <link>/2010/01/25/ayuda-de-r-en-stackoverflow/</link>
      <pubDate>Mon, 25 Jan 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/01/25/ayuda-de-r-en-stackoverflow/</guid>
      <description>Los usuarios de R que necesiten ayuda pueden obtenerla de diversas fuentes, entre las que cabe destacar:
 La lista oficial de ayuda, R-help La lista oficial de ayuda en español,R-help-es, que fue promovida, entre otros, por quien suscribe (y que, además, es bastante activo en ella).  No obstante, para los amigos de la Web 2.0, existe una alternativa que permite, además de plantear preguntas, votar las respuestas, etc.: es StackOverflow y, en particular, las preguntas con la etiqueta R.</description>
    </item>
    
  </channel>
</rss>
