<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>poisson on datanalytics</title>
    <link>/tags/poisson/</link>
    <description>Recent content in poisson on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Fri, 05 Feb 2021 09:13:00 +0000</lastBuildDate><atom:link href="/tags/poisson/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Separación perfecta en el modelo de Poisson</title>
      <link>/2021/02/05/separacion-perfecta-en-el-modelo-de-poisson/</link>
      <pubDate>Fri, 05 Feb 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/02/05/separacion-perfecta-en-el-modelo-de-poisson/</guid>
      <description>El asunto de la separación perfecta en el modelo logístico es sobradamente conocido. Solo quiero añadir al respecto dos cosas que no se suelen decir:
 Es un dolor que solo duele a los frecuentistas que no usan regularización (y van quedando cada vez menos de esos). * Que no es malo sino bueno: ¿qué cosa mejor que tus datos puedan responder categóricamente las preguntas que les planteas (supuesto, claro, está, un N suficientemente grande).</description>
    </item>
    
    <item>
      <title>El modelo de Poisson es razonablemente robusto (pero atención a lo de &#34;razonablemente&#34;)</title>
      <link>/2020/10/07/el-modelo-de-poisson-es-razonablemente-robusto-pero-atencion-a-lo-de-razonablemente/</link>
      <pubDate>Wed, 07 Oct 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/10/07/el-modelo-de-poisson-es-razonablemente-robusto-pero-atencion-a-lo-de-razonablemente/</guid>
      <description>Una de las consencuencias del coronavirus es que vamos a tener que replantearnos lo que significa ajustar series temporales. Es decir, comenzar a ajustar series temporales y no repetir la consabida teoría que subyace a los modelos ARIMA simplemente porque es guay.
También tendremos que replantearnos qué hacer con los outliers que la pandemia va dejando tras de sí. Y tratar de hacerlo más elegantemente que cierta gente, por supuesto. En particular, habrá que ver cuál y cómo es el efecto de los outliers en determinados modelos.</description>
    </item>
    
    <item>
      <title>Las diapositivas de mi charla sobre sobredispersión en modelos de Poisson, disponibles</title>
      <link>/2020/09/28/las-diapositivas-de-mi-charla-sobre-sobredispersion-en-modelos-de-poisson-disponibles/</link>
      <pubDate>Mon, 28 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/28/las-diapositivas-de-mi-charla-sobre-sobredispersion-en-modelos-de-poisson-disponibles/</guid>
      <description>Están aquí.
Dos aclaraciones:
 El tipo de letra que uso es Windsor en homenaje a Woody Allen. * Las presentaciones las construyo con una versión tuneada y ad hoc de [revealjs](https://github.com/rstudio/revealjs).  </description>
    </item>
    
    <item>
      <title>Un decepcionante método de &#34;inferencia robusta&#34; para GLMs de Poisson</title>
      <link>/2020/09/24/un-decepcionante-metodo-de-inferencia-robusta-para-glms-de-poisson/</link>
      <pubDate>Thu, 24 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/24/un-decepcionante-metodo-de-inferencia-robusta-para-glms-de-poisson/</guid>
      <description>[Quod si sal evanuerit in quo sallietur ad nihilum valet ultra nisi ut mittatur foras et conculcetur ab hominibus.]
Vuelvo con mi monotema de los últimos días: cómo hacer GLMs de Poisson robustos. Encuentro la tesis Robust Inference for Generalized Linear Models: Binary and Poisson Regression y pienso: ajá, será cuestión de copipegar.
Nada más lejos de la realidad. El método propuesto en la tesis está basado en asignaciones de pesos a las observaciones usando kernels con centros y anchuras basadas respectivamente en</description>
    </item>
    
    <item>
      <title>Charla sobre cosas que no te han contado sobre le modelo de Poisson (y de paso, el logístico)</title>
      <link>/2020/09/16/charla-sobre-cosas-que-no-te-han-contado-sobre-le-modelo-de-poisson-y-de-paso-el-logistico/</link>
      <pubDate>Wed, 16 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/16/charla-sobre-cosas-que-no-te-han-contado-sobre-le-modelo-de-poisson-y-de-paso-el-logistico/</guid>
      <description>Este es un anuncio de una charla que daré este viernes (2020-09-18) dentro del congreso virtual EncuentRos en la fase R. Ni que decir tiene que los detalles logísticos pueden consultarse en el enlace anterior.
Hablaré de cuestiones relativas al modelo de Possion (gran parte de las cuales pueden trasladarse también al logístico) de las que se habla poco y sobre las que la teoría que uno tropieza por ahí no es del todo clara pero que se manifiestan claramente en datos como los de la monitorización de la mortalidad, que será discutida también de pasada.</description>
    </item>
    
    <item>
      <title>Aún más sobre la presunta sobredispersión en modelos de Poisson</title>
      <link>/2020/07/22/aun-mas-sobre-la-presunta-sobredispersion-en-modelos-de-poisson/</link>
      <pubDate>Wed, 22 Jul 2020 12:59:20 +0000</pubDate>
      
      <guid>/2020/07/22/aun-mas-sobre-la-presunta-sobredispersion-en-modelos-de-poisson/</guid>
      <description>[Esta entrada continúa el ciclo al que he dedicado esta y esta otra entradas durante los últimos días.]
Las dos entradas anteriores de la serie se resumen en que:
 el modelo de Poisson no recoge todas las fuentes de error que pueden existir en los datos y que * las soluciones al uso (como, p.e., usar modelos quasi-Poisson) son puros remiendos.  Si el error en el modelo de Poisson entra (también) en el término lineal, podemos modelar ese error explícitamente.</description>
    </item>
    
    <item>
      <title>Más sobre la presunta sobredispersión en el modelo de Poisson</title>
      <link>/2020/07/17/mas-sobre-la-presunta-sobredispersion-en-el-modelo-de-poisson/</link>
      <pubDate>Fri, 17 Jul 2020 17:17:38 +0000</pubDate>
      
      <guid>/2020/07/17/mas-sobre-la-presunta-sobredispersion-en-el-modelo-de-poisson/</guid>
      <description>[Esta entrada abunda sobre la de ayer y sin la cual no se entiende.]
Generemos unos datos, las x:
n &amp;lt;- 1000 sigma &amp;lt;- .5 x &amp;lt;- rep(-2:2, each = n) x_real &amp;lt;- -1 + .5 * x + rnorm(length(x), 0, sigma)  En el bloque anterior hemos creado una/la variable observada, x, el término lineal que operará en el modelo de Poisson, -1 + .5 * x, y el real, -1 + .</description>
    </item>
    
    <item>
      <title>No, tus datos no &#34;tienen sobredispersión&#34;: es que el gato de Nelder se ha merendado la epsilon</title>
      <link>/2020/07/16/no-tus-datos-no-tienen-sobredispersion-es-que-el-gato-de-nelder-se-ha-merendado-la-epsilon/</link>
      <pubDate>Thu, 16 Jul 2020 12:05:57 +0000</pubDate>
      
      <guid>/2020/07/16/no-tus-datos-no-tienen-sobredispersion-es-que-el-gato-de-nelder-se-ha-merendado-la-epsilon/</guid>
      <description>El modelo de Poisson viene a decir que si y es una variable con valores 0, 1,&amp;hellip; y x1,&amp;hellip;, xn son variables explicativas tiene cierto sentido en algunos casos plantear un modelo de la forma
$latex y | x_i \sim \text{Pois}(\exp(a_0 + \sum_i a_i x_i) ),$
Es decir , para cada combinación de las xi, el modelo proporciona el parámetro de una distribución de Poisson de la que y es una realización.</description>
    </item>
    
    <item>
      <title>Simulación de procesos de Poisson no homogéneos y autoexcitados</title>
      <link>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</link>
      <pubDate>Fri, 05 Apr 2019 09:13:37 +0000</pubDate>
      
      <guid>/2019/04/05/simulacion-de-procesos-de-poisson-no-homogeneos-y-autoexcitados/</guid>
      <description>Fueron mis modelos favoritos un tiempo, cuando modelaba visitas y revisitas de usuarios a cierto malhadado portal.
Si las visitas fuesen aleatorias (en cierto sentido), tendrían un aspecto no muy distinto del que se obtiene haciendo
library(IHSEP) suppressWarnings(set.seed(exp(pi * complex(imaginary = 1)))) tms &amp;lt;- simPois(int = function(x) .1, cens = 1000) hist(tms, breaks = 100, main = &amp;quot;Proceso homogéneo de Poisson&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;frecuencia&amp;quot;)  Es decir,</description>
    </item>
    
    <item>
      <title>Modelos de conteos con sobredispersión (con Stan)</title>
      <link>/2019/01/08/modelos-de-conteos-con-sobredispersion-con-stan/</link>
      <pubDate>Tue, 08 Jan 2019 08:13:00 +0000</pubDate>
      
      <guid>/2019/01/08/modelos-de-conteos-con-sobredispersion-con-stan/</guid>
      <description>Esta entrada muestra cómo afrontar (con Stan) un problema que encontré el otro día en un lugar que no puedo mencionar pero en el que sé que me leen (y los destinatarios sabrán que va por ellos).
El contexto es el siguiente: se hace un test A/B donde la variable de interés son unos conteos. Hay varios grupos (aquí los reduciré a dos) y los datos siguen aproximadamente (aquí omitiré la parte de la inflación de ceros) una distribución de Poisson.</description>
    </item>
    
    <item>
      <title>Los extraños números de los muertos en carretera por accidente</title>
      <link>/2018/05/28/los-extranos-numeros-de-los-muertos-en-carretera-por-accidente/</link>
      <pubDate>Mon, 28 May 2018 08:13:32 +0000</pubDate>
      
      <guid>/2018/05/28/los-extranos-numeros-de-los-muertos-en-carretera-por-accidente/</guid>
      <description>Escribo esta entrada con cierta prevención porque soy consciente de que dan pábulo a determinadas teorías conspiranoicas de las que soy declarado enemigo. Pero es que los números de muertos en carretera por accidente en España en los últimos años,
(extraídos de aquí) dan que pensar: la varianza de las observaciones correspondientes a los años 2013, 2014 y 2015 es muy baja, demasiado baja. Al menos, si se da como bueno un modelo de Poisson para modelar esos conteos.</description>
    </item>
    
    <item>
      <title>El z-score es una medida inadecuada de la perplejidad</title>
      <link>/2017/12/18/el-z-score-es-una-medida-inadecuada-de-la-perpejidad/</link>
      <pubDate>Mon, 18 Dec 2017 08:13:26 +0000</pubDate>
      
      <guid>/2017/12/18/el-z-score-es-una-medida-inadecuada-de-la-perpejidad/</guid>
      <description>Tenemos un dato y un valor de referencia. Por ejemplo, el valor predicho por uno modelo y el observado. Queremos medir la distancia entre ambos. ¿En qué unidades?
Antes de eso, incluso, ¿para qué queremos medir esa distancia? Esta es la pregunta fácil: para ver cómo encaja en el modelo propuesto, para ver cómo lo sorprende, para cuantificar la perplejidad.
Los estadísticos están acostumbrados a medir la perplejidad en unas unidades que solo ellos entienden, si es que las entienden: desviaciones estándar.</description>
    </item>
    
    <item>
      <title>La distribución de Poisson y la estabilización de la varianza</title>
      <link>/2017/12/15/la-poisson-y-la-estabilizacion-de-la-varianza/</link>
      <pubDate>Fri, 15 Dec 2017 20:07:25 +0000</pubDate>
      
      <guid>/2017/12/15/la-poisson-y-la-estabilizacion-de-la-varianza/</guid>
      <description>Imagínate que quieres estabilizar la varianza (¡para qué!) de una distribución de Poisson. Los libros viejunos te dirán que saques la raíz cuadrada de tus valores.
Si en lugar de mirar en libros viejunos prestas atención a tus propios ojos, harás algo parecido a:
lambdas &amp;lt;- -10:10 lambdas &amp;lt;- 2^lambdas res &amp;lt;- sapply(lambdas, function(lambda) sd(sqrt(rpois(1e5, lambda))))  para obtener
y averiguar dónde funciona y dónde no.
Si usas la transformación $latex f(x) = x^{2/3}$, como recomiendan en cierto artículo que no viene a cuento identificar, harás</description>
    </item>
    
    <item>
      <title>Al cabo de más de 50 meses hemos observado un fenómeno que ocurriría en uno de cada cincuenta</title>
      <link>/2017/02/28/al-cabo-de-mas-de-50-meses-hemos-observado-un-fenomeno-que-ocurriria-en-uno-de-cada-cincuenta/</link>
      <pubDate>Tue, 28 Feb 2017 08:13:23 +0000</pubDate>
      
      <guid>/2017/02/28/al-cabo-de-mas-de-50-meses-hemos-observado-un-fenomeno-que-ocurriria-en-uno-de-cada-cincuenta/</guid>
      <description>En efecto,
mean(rpois(100000, 28 * 60 / 365) &amp;gt;= 10) #[1] 0.01964  Por referencia,
 * 28 es el número de días de febrero * 60 viene de [aquí](http://www.ine.es/ss/Satellite?L=es_ES&amp;amp;c=INESeccion_C&amp;amp;cid=1259926144037&amp;amp;p=1254735110672&amp;amp;pagename=ProductosYServicios%2FPYSLayout) * 10 viene de [aquí](http://www.elmundo.es/cronica/2017/02/26/58b147d0468aebf1788b465c.html)  </description>
    </item>
    
    <item>
      <title>Otro ejemplo de infradispersión de conteos</title>
      <link>/2017/02/23/otro-ejemplo-de-infradispersion-de-conteos/</link>
      <pubDate>Thu, 23 Feb 2017 08:13:01 +0000</pubDate>
      
      <guid>/2017/02/23/otro-ejemplo-de-infradispersion-de-conteos/</guid>
      <description>???? ¿ESTÁN USTEDES LOCOS? ???? pic.twitter.com/hyqI9Ncxqg
 &amp;ndash; ? RadiactivoMan ? (@RadiactivoMan) 16 de febrero de 2017 Esta entrada, obviamente, viene a cuento de esta otra.</description>
    </item>
    
    <item>
      <title>¿Hay terroristas islámicos en Poissonistán?</title>
      <link>/2017/02/10/hay-terroristas-islamicos-en-poissonistan/</link>
      <pubDate>Fri, 10 Feb 2017 08:13:35 +0000</pubDate>
      
      <guid>/2017/02/10/hay-terroristas-islamicos-en-poissonistan/</guid>
      <description>La distribución binomial (de parámetro n, p) es una suma de n variables aleatorias de Bernoulli independientes de parámetro p.
Independientes, reitero.
La distribución de Poisson es aproximadamente, una distribución binomial con un n muy grande y un p muy pequeño.
Los eventos subyacentes siguen siendo independientes, reitero.
Viene esto al caso de una tabla que ha circulado por Twitter,
en la que se comparan estimaciones de los parámetros $latex \lambda$ de una serie de distribuciones de Poisson&amp;hellip; como si todas lo fuesen.</description>
    </item>
    
    <item>
      <title>Infradispersión de conteos: ¿buenos ejemplos?</title>
      <link>/2017/02/01/infradispersion-de-conteos-buenos-ejemplos/</link>
      <pubDate>Wed, 01 Feb 2017 08:13:15 +0000</pubDate>
      
      <guid>/2017/02/01/infradispersion-de-conteos-buenos-ejemplos/</guid>
      <description>La distribución de Poisson se utiliza de oficio cuando se quiere modelar datos relativos a conteos. Sin embargo, tiene un problema serio: la varianza está fijada a la media: ambas son $latex \lambda$, el parámetro de la distribución.
Muy frecuentemente se observan datos con sobredispersión. Si $latex \lambda$ es 1000, el número esperado de eventos está contenido en un intervalo demasiado estrecho,
qpois(c(0.025, 0.975), 1000) #[1] 938 1062  como para ser realista en muchas aplicaciones.</description>
    </item>
    
    <item>
      <title>Va de si hay una o dos lambdas</title>
      <link>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</link>
      <pubDate>Wed, 18 Jan 2017 08:13:16 +0000</pubDate>
      
      <guid>/2017/01/18/va-de-si-hay-una-o-dos-lambdas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mi otra debilidad: procesos de Poisson &#34;autoexcitados&#34;</title>
      <link>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</link>
      <pubDate>Thu, 19 Nov 2015 08:13:18 +0000</pubDate>
      
      <guid>/2015/11/19/mi-otra-debilidad-procesos-de-poisson-autoexcitados/</guid>
      <description>La primera es la factorización positiva de matrices positivas. La otra, como bien titula la entrada, los procesos de Poisson autoexcitados.
Por eso no podía dejar de traer a la atención de mis lectores seismic. Aunque lo de Twitter ya huela.</description>
    </item>
    
    <item>
      <title>La diapositiva perdida, versión algo más extendida</title>
      <link>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</link>
      <pubDate>Mon, 22 Sep 2014 07:13:49 +0000</pubDate>
      
      <guid>/2014/09/22/la-diapositiva-perdida-version-algo-mas-extendida/</guid>
      <description>Tuve que saltarme una diapositiva en el DataBeers de Madrid del pasado jueves.
(A propósito, aquí están las 1+20 diapositivas).
La decimonona, de la que trata la entrada, viene a hablar de lo siguiente. Tenemos una base de datos con sujetos (ids) que hacen cosas en determinados momentos. No es inhabitual calcular la frecuencia de esos sujetos así:
&amp;lt;code&amp;gt;select id, count(*) as freq from mytabla where fecha between current_date - 7 and current_date group by id ; &amp;lt;/code&amp;gt;  Esa variable se utiliza frecuentemente ya sea como descriptor de los sujetos o como alimento de otros modelos.</description>
    </item>
    
    <item>
      <title>(Mis) procesos puntuales con glm</title>
      <link>/2014/08/13/mis-procesos-puntuales-con-glm/</link>
      <pubDate>Wed, 13 Aug 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/08/13/mis-procesos-puntuales-con-glm/</guid>
      <description>Lo que escribí hace un par de días sobre procesos puntuales, ahora me doy cuenta, podía haberse resuelto con nuestro viejo amigo glm.
Ejecuto el código del otro día y obtengo (para un caso nuevo)
&amp;lt;code&amp;gt; mu alfa verosimilitud delta 1 0.4493158 0.50000000 340.6141 1 2 0.2675349 0.40457418 307.3939 2 3 0.1894562 0.28917407 293.4696 3 4 0.1495654 0.22237707 287.0784 4 5 0.1243791 0.18079703 281.3900 5 6 0.1142837 0.14913172 284.9227 6 7 0.</description>
    </item>
    
    <item>
      <title>Procesos puntuales: una primera aproximación</title>
      <link>/2014/08/11/procesos-puntuales-una-primera-aproximacion/</link>
      <pubDate>Mon, 11 Aug 2014 07:13:21 +0000</pubDate>
      
      <guid>/2014/08/11/procesos-puntuales-una-primera-aproximacion/</guid>
      <description>Tengo una serie de datos que se parecen a lo que cierta gente llama procesos puntuales y que se parecen a los que se introducen (muuuuy prolijamente) aquí. Gráficamente, tienen este aspecto:

Sobre un determinado periodo de tiempo (eje horizontal) suceden eventos y los cuento por fecha. Pero no suceden independientemente (como si generados por un proceso de Poisson) sino que tienden a agruparse: el que suceda un evento tiende a incrementar la probabilidad de que suceda otro poco después.</description>
    </item>
    
    <item>
      <title>Procesos de Poisson no homogéneos: la historia de un fracaso</title>
      <link>/2014/08/08/procesos-de-poisson-no-homogeneos-la-historia-de-un-fracaso/</link>
      <pubDate>Fri, 08 Aug 2014 07:13:03 +0000</pubDate>
      
      <guid>/2014/08/08/procesos-de-poisson-no-homogeneos-la-historia-de-un-fracaso/</guid>
      <description>Partamos el tiempo en, p.e., días y contemos una serie de eventos que suceden en ellos. Es posible que esos recuentos se distribuyan según un proceso de Poisson de parámetro $latex \lambda$, que es un valor que regula la intensidad.
Si los días son homogéneos, i.e., no hay variaciones de intensidad diaria, estimar $latex \lambda$ (por máxima verosimilitud), es tan fácil como calcular la media de los sucesos por día. Pero puede suceder que la intensidad varíe en el tiempo (p.</description>
    </item>
    
    <item>
      <title>Experimentos con el paquete gbm</title>
      <link>/2014/02/06/experimentos-con-el-paquete-gbm/</link>
      <pubDate>Thu, 06 Feb 2014 08:07:56 +0000</pubDate>
      
      <guid>/2014/02/06/experimentos-con-el-paquete-gbm/</guid>
      <description>No conocía el paquete gbm. Pero como ahora ando rodeado de data scientists que no son estadísticos&amp;hellip;
Bueno, la cuestión es que había que ajustar un modelo para el que yo habría hecho algo parecido a
dat &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/utils/read.csv&amp;quot;&amp;gt;read.csv(&amp;quot;http://www.ats.ucla.edu/stat/data/poisson_sim.csv&amp;quot;) summary(m.glm &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/glm&amp;quot;&amp;gt;glm(num_awards ~ prog + math, &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/family&amp;quot;&amp;gt;family = &amp;quot;poisson&amp;quot;, data = dat)) # Call: # glm(formula = num_awards ~ prog + math, family = &amp;quot;poisson&amp;quot;, data = dat) # # Deviance Residuals: # Min 1Q Median 3Q Max # -2.</description>
    </item>
    
    <item>
      <title>¡A los datos mismos!</title>
      <link>/2012/07/27/a-los-datos-mismos/</link>
      <pubDate>Fri, 27 Jul 2012 19:44:51 +0000</pubDate>
      
      <guid>/2012/07/27/a-los-datos-mismos/</guid>
      <description>Me llamaron (y aún no tengo claro qué hay de lo mío en el asunto) para un proyecto. Consistía en estimar el tiempo que lleva completar determinados procesos en una conocida empresa.
Cada proceso $latex P_i$, se ve, consistía en una sucesión de subprocesos parametrizados, por lo que las duraciones podrían calcularse algo así como
$latex P_i=p_{i1}+\dots+p_{ik}.$
Además, cada $latex p_{ij}$ dependía de ciertos parámetros, aunque eso no es lo más relevante para el caso.</description>
    </item>
    
    <item>
      <title>Comparación de variables aleatorias de Poisson</title>
      <link>/2011/08/21/comparacion-de-variables-aleatorias-de-poisson/</link>
      <pubDate>Sun, 21 Aug 2011 07:53:08 +0000</pubDate>
      
      <guid>/2011/08/21/comparacion-de-variables-aleatorias-de-poisson/</guid>
      <description>El otro día apareció publicado en Significance una comparación entre el número de tarjetas recibidas por las selecciones inglesas de fúlbol masculina y femenina.
Los hombres habían recibido 196 tarjetas en los 48 partidos disputados en el periodo de referencia y las mujeres, 40 en 24 partidos. El promedio de tarjetas, por lo tanto, de 4.1 y 1.7 respectivamente. Y la pregunta es: ¿hay motivos razonables para pensar que las mujeres juegan menos sucio?</description>
    </item>
    
  </channel>
</rss>
