<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>estadística bayesiana on datanalytics</title>
    <link>/tags/estad%C3%ADstica-bayesiana/</link>
    <description>Recent content in estadística bayesiana on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Fri, 05 Nov 2021 09:36:00 +0000</lastBuildDate><atom:link href="/tags/estad%C3%ADstica-bayesiana/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>¿Es Bunge un fraude?</title>
      <link>/2021/11/05/es-bunge-un-fraude/</link>
      <pubDate>Fri, 05 Nov 2021 09:36:00 +0000</pubDate>
      
      <guid>/2021/11/05/es-bunge-un-fraude/</guid>
      <description>Mi primer contacto con la obra de Mario Bunge fue en mi época de estudiante en Zaragoza. Por algún motivo —probablemente, porque en aquella época repasar los lomos de los libros en las bibliotecas y librerias era el equivalente al perder el tiempo en internet de hogaño— cayó en mis manos un libro suyo. Solo recuerdo que leerlo requirió más empeño que aprovechamiento trujo a aquel chaval de provincias.
El segundo —hará un par de años— fue una grabación de una conferencia que dio en Buenos Aires.</description>
    </item>
    
    <item>
      <title>Sobre el teorema de Aumann</title>
      <link>/2021/03/04/sobre-el-teorema-de-aumann/</link>
      <pubDate>Thu, 04 Mar 2021 09:13:55 +0000</pubDate>
      
      <guid>/2021/03/04/sobre-el-teorema-de-aumann/</guid>
      <description>[Del que ya hablé hace un tiempo desde una perspectiva diferente.]
Prioris
A y B (dos personas) tienen la misma priori Beta(1, 1) —que es uniforme en [0, 1]— sobre la probabilidad de cara de una moneda.
Datos
Entonces A presencia una tirada de la moneda (a la que no asiste B) y es cara. Su priori se actualiza a una Beta(1, 2).
Luego B presencia una tirada de la moneda (a la que no asiste A) y es cruz.</description>
    </item>
    
    <item>
      <title>¿Dónde son más frecuentes las muestras de una distribución en dimensiones altas?</title>
      <link>/2021/02/18/donde-son-mas-frecuentes-las-muestras-de-una-distribucion-en-dimensiones-altas/</link>
      <pubDate>Thu, 18 Feb 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/02/18/donde-son-mas-frecuentes-las-muestras-de-una-distribucion-en-dimensiones-altas/</guid>
      <description>Esta es una cosa bastante contraintituiva. Uno diría que en la moda, pero no es exactamente así.
En una dimensión tal vez sí (nótese que log(p) es función de la distancia al centro):
muestra &amp;lt;- rnorm(10000) logp &amp;lt;- log(dnorm(muestra)) hist(logp, breaks = 100, main = &amp;quot;distribución de log(p)&amp;quot;)  Pero en dimensiones más altas, la cosa cambia:
library(mvtnorm) muestra &amp;lt;- rmvnorm(10000, rep(0, 10), diag(rep(1, 10))) logp &amp;lt;- log(dmvnorm(muestra, rep(0, 10), diag(rep(1, 10)))) hist(logp, breaks = 100, main = &amp;quot;distribución de log(p)&amp;quot;)  Lo más frecuente es obtener observaciones ya no próximas al centro sino en un anillo alrededor de él y a cierta distancia del mismo.</description>
    </item>
    
    <item>
      <title>Encuestas (electorales), medios y sesgos</title>
      <link>/2020/12/14/encuestas-electorales-medios-y-sesgos/</link>
      <pubDate>Mon, 14 Dec 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/12/14/encuestas-electorales-medios-y-sesgos/</guid>
      <description>Me he entretenido estos días en crear un modelo que represente la siguiente hipótesis de trabajo:
Los encuestadores electorales combinan tres fuentes de información: sus propios datos, el &amp;ldquo;consenso&amp;rdquo; de los restantes encuestadores y la &amp;ldquo;voz de su amo&amp;rdquo;, es decir, el interés de quien paga la encuesta.
Es un modelo en el que se introduce (y se mide) el sesgo que introduce cada casa en los resultados. De momento (¡no fiarse!</description>
    </item>
    
    <item>
      <title>Más sobre el artículo raro, raro, raro</title>
      <link>/2020/07/15/mas-sobre-el-articulo-raro-raro-raro/</link>
      <pubDate>Wed, 15 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/15/mas-sobre-el-articulo-raro-raro-raro/</guid>
      <description>No he podido evitar darle vueltas al artículo que comenté el otro día aquí, Bayesian Estimation with Informative Priors is Indistinguishable from Data Falsification, de la manera más caritativa posible. En particular, me he preguntado:
 ¿Por qué se escribió (en lugar de no haberse escrito)? * ¿Por qué se escribió en esos términos (en lugar de en otros)?  Obviamente, el artículo no enseña nada desde el punto de vista técnico.</description>
    </item>
    
    <item>
      <title>Un artículo muy raro, raro, raro</title>
      <link>/2020/07/06/un-articulo-muy-raro-raro-raro/</link>
      <pubDate>Mon, 06 Jul 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/07/06/un-articulo-muy-raro-raro-raro/</guid>
      <description>Hoy voy a comentar un artículo muy raro que me ha llegado recientemente y que se titula nada menos que Bayesian Estimation with Informative Priors is Indistinguishable from Data Falsification.
Argumenta el artículo alrededor de lo siguiente (que creo que ya sabemos todos: son ejercicios matemáticos básicos de un curso introductorio de probabilidad):
 Que la inferencia bayesiana con prioris planas (degeneradas, de ser necesario) es equivalente a la inferencia frecuentista.</description>
    </item>
    
    <item>
      <title>¿Criptobayesianismo?</title>
      <link>/2020/06/26/criptobayesianismo/</link>
      <pubDate>Fri, 26 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/26/criptobayesianismo/</guid>
      <description>Titulo así a cuenta de un proceso mental de varios saltos producidos a partir de la lectura del muy recomendable Five ways to ensure that models serve society: a manifesto. En particular del parrafito
De hecho, el periodo 2007-2008 me pilló haciendo horario de oficina en la planta octava sede mundial de Barclays primero y en la tercera de la de KTB (Krung Thai Bank) luego.
Recuerdo comentar con algunos colegas cómo determinados modelos de gestión de riesgo no preveían la posibilidad de una caída en los precios de la vivienda.</description>
    </item>
    
    <item>
      <title>Análisis (bayesiano) de pruebas con sensibilidad/especificidad desconocida</title>
      <link>/2020/05/21/analisis-bayesiano-de-pruebas-con-sensibilidad-especificidad-desconocida/</link>
      <pubDate>Thu, 21 May 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/05/21/analisis-bayesiano-de-pruebas-con-sensibilidad-especificidad-desconocida/</guid>
      <description>Esto tiene que ver con lo del estudio ENECOVID, por supuesto.
Esto tiene que ver con los ajustes que hay que realizar en los resultados por la menos que perfecta sensibilidad y especificidad.
Porque no basta con lo que diga el prospecto de los kits chinos.
Por eso es recomendable leer Bayesian analysis of tests with unknown specificity and sensitivity.
Coda: Cuando era matemático y comencé a estudiar estadística, me llamaba mucho la atención (por no decir que me escandalizaba) la alegría con la que estimadores sujetos a error de un modelo se insertaban como verdad divina en otro.</description>
    </item>
    
    <item>
      <title>Regresión tradicional vs multinivel</title>
      <link>/2020/04/13/regresion-tradicional-vs-multinivel/</link>
      <pubDate>Mon, 13 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/13/regresion-tradicional-vs-multinivel/</guid>
      <description>Ayer se leía en Twitter que
https://twitter.com/joscani/status/1249017607199621123
Cabe preguntarse qué pasa si se analizan los mismos datos usando ambas técnicas. Obviamente, hay muchos tipos de datos y supongo que los resultados variarán según qué variante se utilice. Aquí voy a centrarme en unos donde hay medidas repetidas de un factor aleatorio. También voy a situarme en un contexto académico, en el que interesan más las estimaciones de los efectos fijos, que en uno más próximo a mi mundo, la consultoría, donde son más relevantes las estimaciones regularizadas de los efectos aleatorios.</description>
    </item>
    
    <item>
      <title>Spike and slab: otro método para seleccionar variables</title>
      <link>/2020/04/07/spike-and-slab-otro-metodo-para-seleccionar-variables/</link>
      <pubDate>Tue, 07 Apr 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/04/07/spike-and-slab-otro-metodo-para-seleccionar-variables/</guid>
      <description>Me sorprende ver todavía a gente utilizar técnicas stepwise para la selección de variables en modelos. Sobre todo, existiendo herramientas como elastic net o lasso.
Otra de las técnicas disponibles es la del spike and slab (de la que oí hablar, recuerdo, por primera vez en el artículo de Varian Big Data: New Tricks for Econometrics). Es una técnica de inspiración bayesiana en cuya versión más cruda se imponen sobre las variables del modelo de regresión prioris que son una mezcla de dos distribuciones:</description>
    </item>
    
    <item>
      <title>Comparación y selección de modelos bayesianos</title>
      <link>/2020/02/04/comparacion-y-seleccion-de-modelos-bayesianos/</link>
      <pubDate>Tue, 04 Feb 2020 08:13:00 +0000</pubDate>
      
      <guid>/2020/02/04/comparacion-y-seleccion-de-modelos-bayesianos/</guid>
      <description>En el mundo bayesiano existen, cuando menos, dos escuelas:
 La flowerpower, que sostiene que los modelos bayesianos son subjetivos y, por lo tanto, inasequibles a la confrontación con la realidad objetiva. * La de los que tienen un jefe que les paga un salario, al que le da igual si los modelos son bayesianos o no pero a quien le interesa por encima de todo saber si representan razonablemente el proceso subyacente.</description>
    </item>
    
    <item>
      <title>GoF para modelos bayesianos</title>
      <link>/2020/01/28/gof-para-modelos-bayesianos/</link>
      <pubDate>Tue, 28 Jan 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/01/28/gof-para-modelos-bayesianos/</guid>
      <description>Existe una muy perezosa escuela de pensamiento que sostiene que dado que las probabilidades son subjetivas, cualquier modelo y, en particular, los bayesianos, como expresión de la subjetividad de sus autores, no necesita ser contrastado con la realidad. Porque, de hecho, la realidad no existe y es una construcción que cada cual hace a su manera, deberían añadir.
Existe, por supuesto, una escuela realista tan mayoritaria que ni siquiera es consciente de que lo es.</description>
    </item>
    
    <item>
      <title>La probabilidad, ¿algo subjetivo?</title>
      <link>/2020/01/07/la-probabilidad-algo-subjetivo/</link>
      <pubDate>Tue, 07 Jan 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/01/07/la-probabilidad-algo-subjetivo/</guid>
      <description>Esta entrada es una contestación a
https://twitter.com/AnaBayes/status/1213446900743122945
I.
Habrá quien sostenga que la geometría (plana, euclídea, por antonomasia) es subjetiva, que es una construcción de la mente, de cada mente. Igual queda todavía alguno de los que, por el contrario, creían que los triángulos equiláteros residen en una especie de edén donde tienen una existencia ideal y que nuestra mente, de alguna manera, se limita a reflejarlos.
Sin embargo, a mí me vale (que es una forma de decir que tomo partido por) que la geometría tiene una existencia objetiva, ajena a la subjetividad de los individuos.</description>
    </item>
    
    <item>
      <title>Los factores de Bayes son las hamburguesas veganas</title>
      <link>/2019/11/25/los-factores-de-bayes-son-las-hamburguesas-veganas/</link>
      <pubDate>Mon, 25 Nov 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/11/25/los-factores-de-bayes-son-las-hamburguesas-veganas/</guid>
      <description>Si eres vegano, vale, come tu lechuga y tu berenjena. Pero, ¿qué necesidad tienes de hamburguesas veganas? ¿Y a qué viene ufanarte de que saben casi igual?
[Nota: el párrafo anterior está escrito en condicional y aplica a ciertos veganos, entrellos alguno que conozco.]
Siempre he visto todo lo que rodea a los factores de bayes un tufillo a hamburguesa vegana. Es decir, un intento por reproducir lo más fidedignamente posible aquello que —¿por razones metodológicas?</description>
    </item>
    
    <item>
      <title>bamlss promete regresión bayesiana flexible</title>
      <link>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</link>
      <pubDate>Tue, 19 Nov 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/11/19/bamlss-promete-regresion-bayesiana-flexible/</guid>
      <description>Un paquete relativamente nuevo de R (las primeras versiones son de 2017) que llevo un tiempo siguiendo de reojo es [bamlss](https://CRAN.R-project.org/package=bamlss).
bamlss es un paquete que permite especificar y ajustar varios tipos de modelos usando en principio métodos bayesianos, aunque tampoco necesariamente.
No puedo decir mucho más de él de momento. Habrá que ver cómo se comporta más allá de los ejemplos discutidos en la documentación. Muchos paquetes tienden a hacer trivial lo que antes era sencillo e imposible lo que antes difícil.</description>
    </item>
    
    <item>
      <title>A más gripe, ¿menos mortalidad? En determinados submundos frecuentistas, sí</title>
      <link>/2019/11/13/a-mas-gripe-menos-mortalidad-en-determinados-submundos-frecuentistas-si/</link>
      <pubDate>Wed, 13 Nov 2019 09:13:51 +0000</pubDate>
      
      <guid>/2019/11/13/a-mas-gripe-menos-mortalidad-en-determinados-submundos-frecuentistas-si/</guid>
      <description>Estos días he tenido que adaptar y ejecutar con datos españoles una serie de modelos para medir la virulencia de diversos subtipos de gripe. Y todo bien, salvo que para uno de ellos y determinados grupos de edad&amp;hellip; a mayor prevalencia, menor mortalidad. ¡Estupendo!
Todo sucede porque un coeficiente que debería haber sido necesariamente positivo fue estimado como negativo (además, significativamente).
Y el coeficiente tenía el signo cambiado (¡error de tipo S!</description>
    </item>
    
    <item>
      <title>tfprobability debería llamarse tfeoprobability</title>
      <link>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</link>
      <pubDate>Tue, 12 Nov 2019 09:13:04 +0000</pubDate>
      
      <guid>/2019/11/12/tfprobability-deberia-llamarse-tfeoprobability/</guid>
      <description>Porque, aunque la intención sea buena, el DSL (que ni siquiera llega a serlo) es muy, muy feo. Que en este contexto, además, quiere decir antinatural.
La demostración, aquí, aquí o aquí.</description>
    </item>
    
    <item>
      <title>Pyro</title>
      <link>/2019/10/14/pyro/</link>
      <pubDate>Mon, 14 Oct 2019 09:13:35 +0000</pubDate>
      
      <guid>/2019/10/14/pyro/</guid>
      <description>Leyendo sobre si dizque PyTorch le siega la hierba debajo de los pies a TensorFlow, averigué la existencia de Pyro.
Pyro se autopresenta como Deep Universal Probabilistic Programming, pero aplicando métodos porfirianos (ya sabéis: género próximo y diferencia específica), es, o pretende ser, Stan en Python y a escala.
Aquí van mis dos primeras impresiones, basadas en una inspección superficial de los tutoriales.
En primer lugar, aunque Pyro permite usar (distintas versiones de) MCMC, parece que su especialidad es la inferencia variacional estocástica.</description>
    </item>
    
    <item>
      <title>Rootclaim</title>
      <link>/2019/09/27/rootclaim/</link>
      <pubDate>Fri, 27 Sep 2019 09:13:15 +0000</pubDate>
      
      <guid>/2019/09/27/rootclaim/</guid>
      <description>Rootclaim es un portal donde la gente plantea preguntas como
plantea hipótesis como
se recogen evidencias y usando este método (leedlo, es sumamente aprovechable: usa la palabra bayesian 23 veces), llega a conclusiones tales como</description>
    </item>
    
    <item>
      <title>Bayes no había previsto esto</title>
      <link>/2019/06/18/bayes-no-habia-previsto-esto/</link>
      <pubDate>Tue, 18 Jun 2019 09:13:21 +0000</pubDate>
      
      <guid>/2019/06/18/bayes-no-habia-previsto-esto/</guid>
      <description>Muestreo. Se trata de seleccionar unas unidades experimentales (proceso caro) y tratar de estimar una proporción (p.e.) en la población total.
Existen técnicas para estimar el valor N mínimo para garantizar cierto margen de error. Pero dichas técnicas requieren conocer (algo d-) el resultado del experimento para estimar N (p.e. una estimación de la proporción que cabe esperar).
Circulus in demonstrando.
Bayes. Ve examinando unidades y actualiza tus intervalos de credibilidad hasta que tengan la anchura solicitada.</description>
    </item>
    
    <item>
      <title>Un recíproco para el teorema de Bernstein–von Mises</title>
      <link>/2019/05/10/un-reciproco-para-el-teorema-de-bernstein-von-mises/</link>
      <pubDate>Fri, 10 May 2019 09:13:59 +0000</pubDate>
      
      <guid>/2019/05/10/un-reciproco-para-el-teorema-de-bernstein-von-mises/</guid>
      <description>Aquí se describe una suerte de recíproco para el teorema de Bernstein–von Mises. Aquí se resume de esta manera:
En resumen:
 B-vM: frente a la misma evidencia, observadores con prioris distintas tienen posteriores similares. * Aumann: frente a evidencias disímiles, observadores con las mismas prioris pueden acordar posterioris similares.  </description>
    </item>
    
    <item>
      <title>Las altas dimensiones son campo minado para la intuición</title>
      <link>/2019/04/15/las-altas-dimensiones-son-campo-minado-para-la-intuicion/</link>
      <pubDate>Mon, 15 Apr 2019 09:13:16 +0000</pubDate>
      
      <guid>/2019/04/15/las-altas-dimensiones-son-campo-minado-para-la-intuicion/</guid>
      <description>Las dimensiones altas son un campo minado para la intuición. Hace poco (y he perdido la referencia) leí a un matemático que trabajaba en problemas en dimensiones altas decir que le gustaba representar y pensar en las bolas (regiones del espacio a distancia &amp;lt;1 de 0) en esos espacios usando figuras cóncavas, como las que aparecen a la izquierda de
precisamente porque una de las propiedades más fructíferas de las bolas en altas dimensiones es que apenas tienen interior.</description>
    </item>
    
    <item>
      <title>Un resultado contraintuitivo</title>
      <link>/2019/04/10/un-resultado-contraintuitivo/</link>
      <pubDate>Wed, 10 Apr 2019 09:13:23 +0000</pubDate>
      
      <guid>/2019/04/10/un-resultado-contraintuitivo/</guid>
      <description>[Esta entrada recoge la pregunta y la duda que motivó una conversación con Javier Nogales en Twitter hace unos días.]
Citaba (él) un resultado de Theobald de 1974 (¿tanto lleva ridge entre nosotros? ¡habría jurado que menos!) que viene a decir que siempre existe un peso $latex \lambda$ para el que ridge es mejor que OLS.
Ves el álgebra y piensas: verdad será.
Pero te fías de tu propia intuición y piensas: ¡vaya un resultado contraintuitivo si no contradictorio!</description>
    </item>
    
    <item>
      <title>¿Irán por aquí los tiros en el futuro de la &#34;ciencia de datos&#34;?</title>
      <link>/2019/04/01/iran-por-aqui-los-tiros-en-el-futuro-de-la-ciencia-de-datos/</link>
      <pubDate>Mon, 01 Apr 2019 09:13:27 +0000</pubDate>
      
      <guid>/2019/04/01/iran-por-aqui-los-tiros-en-el-futuro-de-la-ciencia-de-datos/</guid>
      <description>Para muchos, el futuro de la llamada ciencia de datos seguirá la estela dejada por
y sus continuadores usando cosas deep. Pero a la vez, sin tanto estruendo y con una mucho menor cobertura mediática, otros están trazando una ruta alternativa que ilustran artículos como Bayes and Big Data: The Consensus Monte Carlo Algorithm (atención todos a lo que hace uno de sus coautores, Steven L. Scott, que convierte en oro todo lo que toca).</description>
    </item>
    
    <item>
      <title>Quienes ignoran la estadística están condenados a reinventarla</title>
      <link>/2019/03/06/quienes-ignoran-la-estadistica-estan-condenados-a-reinventarla/</link>
      <pubDate>Wed, 06 Mar 2019 08:13:10 +0000</pubDate>
      
      <guid>/2019/03/06/quienes-ignoran-la-estadistica-estan-condenados-a-reinventarla/</guid>
      <description>Esa frase la he pronunciado en alguna ocasión y no sé si la habré escrito en este blog. La reescribo porque hace apenas unas horas he leído un artículo en el que un tipo ha redescubierto el partial pooling (quien lo ignore lea esto urgentemente). Claro, proponía unas cosas tan raras como ocurrentes que se reducían en la estrategia que he contado: tengo cierta intuición de una idea genial que no llego a aprehender enteramente y procedo a moverme dando tumbos y a golpe de ocurrencias en la difusa dirección en la que parece apuntar.</description>
    </item>
    
    <item>
      <title>Colinealidad y posterioris</title>
      <link>/2018/11/16/colinealidad-y-posterioris/</link>
      <pubDate>Fri, 16 Nov 2018 08:13:33 +0000</pubDate>
      
      <guid>/2018/11/16/colinealidad-y-posterioris/</guid>
      <description>En esta entrada voy a crear un conjunto de datos donde dos variables tienen una correlación muy alta, ajustar un modelo de regresión y obtener la siguiente representación de la distribución a posteriori de los coeficientes,
donde se aprecia el efecto de la correlación entre x1 y x2.
El código,
library(mvtnorm) library(rstan) library(psych) n &amp;lt;- 100 corr_coef &amp;lt;- .9 x &amp;lt;- rmvnorm(n, c(0, 0), sigma = matrix(c(1, corr_coef, corr_coef, 1), 2, 2)) plot(x) x1 &amp;lt;- x[,1] x2 &amp;lt;- x[,2] x3 &amp;lt;- runif(n) - 0.</description>
    </item>
    
    <item>
      <title>ABC (2)</title>
      <link>/2018/10/24/abc-2-2/</link>
      <pubDate>Wed, 24 Oct 2018 08:13:19 +0000</pubDate>
      
      <guid>/2018/10/24/abc-2-2/</guid>
      <description>Más sobre lo de ayer. O más bien, una justificación por analogía.
Con monedas.
Tiras una moneda 100 veces y obtienes 60 caras. Tienes una priori $latex B(a,b)$ (beta). Tomas una muestra de valores $latex p_i$ con esa distribución y para cada una de ellas repites el experimento, es decir, obtienes lo que en R se expresaría de la forma
rbinom(1, 100, p[i])  Si te quedas los valores $p_i$ tales que esa simulación es 60, enhorabuena, tienes una muestra de la distribución a posteriori.</description>
    </item>
    
    <item>
      <title>ABC</title>
      <link>/2018/10/23/abc-2/</link>
      <pubDate>Tue, 23 Oct 2018 08:13:01 +0000</pubDate>
      
      <guid>/2018/10/23/abc-2/</guid>
      <description>Que quiere decir approximate Bayesian computation. Es un truco para pobres y desafortunados que no pueden quitarle la A a BC y usar directamente cosas como Stan o similares. El que no quiera prioris, además, puede usar el ABC para estimar la forma de la verosimilitud alrededor de una estimación puntual.
Por supuesto, el objetivo es obtener una estimación de la posteriori para poder medir la incertidumbre de parámetros, etc. La idea es que se dispone de unos datos, $latex X$ y un mecanismo de generación de datos $latex X^\prime = f(\theta)$, donde $latex \theta$ es un vector de parámetros.</description>
    </item>
    
    <item>
      <title>Planes de búsqueda y rescate con R</title>
      <link>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</link>
      <pubDate>Tue, 02 Oct 2018 13:09:10 +0000</pubDate>
      
      <guid>/2018/10/02/planes-de-busqueda-y-rescate-con-r/</guid>
      <description>Existe un paquete muy curioso en CRAN, [rSARP](https://cran.r-project.org/package=rSARP) para diseñar, optimizar y comunicar la evolución de planes de búsqueda y/o rescate (p.e., de un niño desaparecido en un monte).
Es particularmente interesante porque este tipo de problemas lo tienen todo: desde distribuciones a priori (sobre dónde es más probable encontrar lo que se busca) hasta la decisión final (explórese tanto aquí y tanto allá) teniendo en cuenta restricciones de tiempo y recursos.</description>
    </item>
    
    <item>
      <title>Curso de estadística aplicada con Stan: ejercicio 1</title>
      <link>/2018/07/17/curso-de-estadistica-aplicada-con-stan-ejercicio-1/</link>
      <pubDate>Tue, 17 Jul 2018 08:13:10 +0000</pubDate>
      
      <guid>/2018/07/17/curso-de-estadistica-aplicada-con-stan-ejercicio-1/</guid>
      <description>A primeros de julio impartí un curso de estadística bayesiana aplicada con Stan. Tengo que examinar a los alumnos y he aquí el primero de los ejercicios:
En un país, se extrae una muestra de 2000 hombres y mujeres con la siguiente distribución:
men &amp;lt;- 170 + 3 * rt(1000, 6) women &amp;lt;- 160 + 2 * rt(1000, 5) heights &amp;lt;- c(men, women)  Ajusta una distribución (una mezcla de dos distribuciones de Student) usando los datos anteriores, i.</description>
    </item>
    
    <item>
      <title>Prioris informativas: un ejemplo</title>
      <link>/2018/05/24/prioris-informativas-un-ejemplo/</link>
      <pubDate>Thu, 24 May 2018 08:13:36 +0000</pubDate>
      
      <guid>/2018/05/24/prioris-informativas-un-ejemplo/</guid>
      <description>Imagina que tienes que generar (reitero: generar) datos compatibles con el siguiente modelo:
 * Tienes n sujetos a los que se proporciona un remedio para dormir en distintas dosis (conocidas) en distintos días. * El número adicional de horas que duerme cada sujeto es lineal con una pendiente que depende de la dosis (una serie de dosis fijas). * Esa recta tiene un término independiente (el número de horas que duerme el sujeto con una dosis igual a cero del remedio).</description>
    </item>
    
    <item>
      <title>Curso (mío) de estadística bayesiana aplicada con Stan en BCN</title>
      <link>/2018/05/09/curso-mio-de-estadistica-bayesiana-aplicada-con-stan-en-bcn/</link>
      <pubDate>Wed, 09 May 2018 08:13:44 +0000</pubDate>
      
      <guid>/2018/05/09/curso-mio-de-estadistica-bayesiana-aplicada-con-stan-en-bcn/</guid>
      <description>A primeros de julio (de 2018) impartiré un curso de 15 horas de estadística bayesiana aplicada con Stan en la UPC (Barcelona). La información relevante está aquí y aquí.
El proyecto y su definición es un tanto contradictorio en sus propios términos, lo reconozco. Es muy difícil hacer algo aplicado y, a la vez, bayesiano. Y más, con Stan. Además, podrían acusarme de hipócrita: ¿cuándo fue la última vez que facturé (recuérdese: facturable es el grado máximo de aplicado) por algo hecho con Stan?</description>
    </item>
    
    <item>
      <title>ABC</title>
      <link>/2018/01/12/abc/</link>
      <pubDate>Fri, 12 Jan 2018 08:13:58 +0000</pubDate>
      
      <guid>/2018/01/12/abc/</guid>
      <description>ABC significa, entre otras cosas, approximate bayesian computation. Por lo que parece, consiste en calcular $latex P(\theta ,|, \text{datos})$ por el tradicional y directo método del rechazo. Es decir:
 Planteas un modelo generativo, con sus prioris y todo. Simulas casos, casos y casos. Te quedas con los que cumplen un criterio de aceptación.  La distribución empírica de los parámetros en el subconjunto de los casos aceptados representa, en los libros está escrito, la distribución a posteriori.</description>
    </item>
    
    <item>
      <title>Arqueólogos bayesianos</title>
      <link>/2017/11/23/arqueologos-bayesianos/</link>
      <pubDate>Thu, 23 Nov 2017 08:13:26 +0000</pubDate>
      
      <guid>/2017/11/23/arqueologos-bayesianos/</guid>
      <description>Se ve que hay arqueólogos bayesianos. Un problema con el que se encuentran es que tropiezan con cacharros antiguos y quieren estimar su antigüedad.
Así que prueban distintos métodos (¿químicos?), cada uno de los cuales con su precisión, y acaban recopilando una serie de estimaciones y errores. Obviamente, tienen que combinarlas de alguna manera.
El modelo más simple es
$latex M_i \sim N(\mu, \sigma_i)$
donde $latex \mu$ es la antigüedad (desconocida) del artefacto y los $latex \sigma_i$ son las varianzas distintas de los distintos métodos de medida, que arrojan las estimaciones $latex M_i$.</description>
    </item>
    
    <item>
      <title>Militancia y datos</title>
      <link>/2017/09/18/militancia-y-datos/</link>
      <pubDate>Mon, 18 Sep 2017 08:13:14 +0000</pubDate>
      
      <guid>/2017/09/18/militancia-y-datos/</guid>
      <description>Allá por el 2007 publicó The Independent una portada en que se retractaba. El diario había sido un histórico defensor de la legalización de la marihuana. Ese día hizo público su cambio de postura. Al parecer, motivada por las evidencias sobre los efectos sobre la salud mental.
Este fin de semana he asistido a una serie de conferencias. En una de ellas participaba el representante de una organización que:
 * Adoptaba de partida una posición militante, de parte, en cierto asunto de interés público.</description>
    </item>
    
    <item>
      <title>Trucos cutrebayesianos</title>
      <link>/2017/09/13/trucos-cutrebayesianos/</link>
      <pubDate>Wed, 13 Sep 2017 08:13:29 +0000</pubDate>
      
      <guid>/2017/09/13/trucos-cutrebayesianos/</guid>
      <description>El contexto
Cada día $latex i$ ocurren eventos de cierta naturaleza (transacciones, fallecimientos, infartos, etc.) que interesa contar.
El problema
El número de eventos $latex n_i$ que ocurren el día $latex i$ no se conoce el día $latex i$ sino que va siendo conocido progresivamente los días $latex i+1, \dots$. Pero hace falta una estimación de $latex n_i$ antes del fin del mundo.
Los datos
 * La distribución de los $latex n_i$ (basados en el histórico).</description>
    </item>
    
    <item>
      <title>La h-filosofía de la estadística en once puntos</title>
      <link>/2017/01/20/la-h-filosofia-de-la-estadistica-en-once-puntos/</link>
      <pubDate>Fri, 20 Jan 2017 08:13:22 +0000</pubDate>
      
      <guid>/2017/01/20/la-h-filosofia-de-la-estadistica-en-once-puntos/</guid>
      <description>* La estadística tiene que estar totalmente integrada en la investigación: el diseño experimental es fundamental. * Que no te asuste utilizar métodos modernos * Preserva toda la información disponible en los datos: evita categorizar los predictores continuos y los valores predichos * No asumas que algo opera linealmente * Ten en cuenta la incerditumbre sobre el (no del) modelo y trata de minimizarlo usando conocimiento previo sobre la materia * Usa remuestreos * Considera el tamaño muestral una variable aleatoria cuando sea posible * Usa estadística bayesiana siempre que sea posible * Usa buenos gráficos frecuentemente * Para que sea creíble, la investigación tiene que ser reproducible * Toda la manipulación de datos y el análisis estadístico tiene que ser reproducible  No son míos, sino de Frank Harrel.</description>
    </item>
    
    <item>
      <title>Weapons of Math Destruction</title>
      <link>/2017/01/16/weapons-of-math-destruction/</link>
      <pubDate>Mon, 16 Jan 2017 08:13:58 +0000</pubDate>
      
      <guid>/2017/01/16/weapons-of-math-destruction/</guid>
      <description>Así se titula un libro que no he leído y que, pese a lo cual, como los malos críticos, voy a comentar. Los libros suelen estar plagados de hojarasca, tal vez porque de otra manera no se puede hacer crecer un par de ideas más o menos originales a las cientoypico páginas como mínimo que uno espera encontrar entre dos tapas. El relato corto no da caché. Y yo ando corto de tiempo.</description>
    </item>
    
    <item>
      <title>GLMs con prioris (casi) a voluntad</title>
      <link>/2016/07/06/glms-con-prioris-casi-a-voluntad/</link>
      <pubDate>Wed, 06 Jul 2016 08:13:34 +0000</pubDate>
      
      <guid>/2016/07/06/glms-con-prioris-casi-a-voluntad/</guid>
      <description>Esto que cuento hoy puede ser muy útil: cómo mejorar los GLMs mediante la introducción de prioris (casi) a voluntad sobre los coeficientes. Usando el paquete arm de R, claro.
De momento y porque aún tengo sucios los datos sobre los que me gustaría aplicar el modelo, extraeré un ejemplo de la ayuda de la función principal del paquete, bayesglm.
Primero, preparo unos datos:
n &amp;lt;- 100 x1 &amp;lt;- rnorm (n) x2 &amp;lt;- rbinom (n, 1, .</description>
    </item>
    
    <item>
      <title>Metropolis-Hastings en Scala</title>
      <link>/2016/06/16/metropolis-hastings-en-scala/</link>
      <pubDate>Thu, 16 Jun 2016 08:13:08 +0000</pubDate>
      
      <guid>/2016/06/16/metropolis-hastings-en-scala/</guid>
      <description>Tengo la sensación de que un lenguaje funcional (como Scala) está particularmente bien adaptado al tipo de operaciones que exige MCMC.
Juzguen Vds.
Primero, genero datos en R:
datos &amp;lt;- rnorm(500, 0.7, 1) writeLines(as.character(datos), &amp;quot;/tmp/datos.txt&amp;quot;)  Son de una normal con media 0.7. En el modelo que vamos a crear, suponemos conocida (e igual a 1) la varianza de la normal y trataremos de estimar la media suponiéndole una distribución a priori normal estándar.</description>
    </item>
    
    <item>
      <title>Si vas a Londres, déjate caer por (51.523841, -0.089310)</title>
      <link>/2016/06/10/si-vas-a-londres-dejate-caer-por-51-523841-0-089310/</link>
      <pubDate>Fri, 10 Jun 2016 08:13:26 +0000</pubDate>
      
      <guid>/2016/06/10/si-vas-a-londres-dejate-caer-por-51-523841-0-089310/</guid>
      <description>Porque ahí puedes tomarte una foto tal que
o
y luego tuitear cosas como
Para mayor referencia (y por tenerlo a mano cuando vuelva),</description>
    </item>
    
    <item>
      <title>Diapositivas de mi charla &#34;Datos, modelos y parámetros&#34;</title>
      <link>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</link>
      <pubDate>Thu, 14 Apr 2016 09:13:35 +0000</pubDate>
      
      <guid>/2016/04/14/diapositivas-de-mi-charla-datos-modelos-y-parametros/</guid>
      <description>Las diapositivas de mi charla Datos, modelos y parámetros en el grupo Machine Learning Spain pueden verse/bajarse de aquí.</description>
    </item>
    
    <item>
      <title>¿Nos vemos en el Machine Learning Spain XII?</title>
      <link>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</link>
      <pubDate>Tue, 05 Apr 2016 09:13:58 +0000</pubDate>
      
      <guid>/2016/04/05/nos-vemos-en-el-machine-learning-spain-xii/</guid>
      <description>Porque voy a dar una charla en él. Es este jueves, por la tarde, en el Campus de Google de Madrid (los detalles).
Se tratará de una introducción a y justificación de aproximaciones más bayesianas de lo habitual a problemas reales del análisis de datos. Que comenzará con una explicación sobre cuándo 100% no significa 100% para terminar con lo que viene siéndome habitual últimamente: un ejemplo en rstan con su discusión.</description>
    </item>
    
    <item>
      <title>Los tres contraargumentos habituales</title>
      <link>/2016/02/29/los-tres-contraargumentos-habituales/</link>
      <pubDate>Mon, 29 Feb 2016 09:13:50 +0000</pubDate>
      
      <guid>/2016/02/29/los-tres-contraargumentos-habituales/</guid>
      <description>Hago pública por su interés (parte de) una respuesta de Ramón Díaz Uriarte a un correo mío en el que yo sugería
Su respuesta:</description>
    </item>
    
    <item>
      <title>rstan y rstanarm en Medialab-Prado este jueves</title>
      <link>/2016/02/08/rstan-y-rstanarm-en-medialab-prado-este-jueves/</link>
      <pubDate>Mon, 08 Feb 2016 09:13:19 +0000</pubDate>
      
      <guid>/2016/02/08/rstan-y-rstanarm-en-medialab-prado-este-jueves/</guid>
      <description>Este jueves (2016-02-11), a las 19:00, hablaré de rstan y de rstanarm en Medialab-Prado dentro de la reunión de usuarios de R de Madrid. Con el concurso de estos paquetes, replantearé tres problemas estadísticos conocidos desde una óptica bayesiana:
 * Pruebas de hipótesis * Regresión lineal * Modelos estructurales de series temporales  Si quieres asistir, reserva tu plaza aquí.
Probablemente, discutiré todos esos modelos en estas páginas en los próximos días, además de colgar las diapositivas y sus fuentes.</description>
    </item>
    
    <item>
      <title>Y termino con lo de los intervalos</title>
      <link>/2016/02/04/y-termino-con-lo-de-los-intervalos/</link>
      <pubDate>Thu, 04 Feb 2016 09:13:51 +0000</pubDate>
      
      <guid>/2016/02/04/y-termino-con-lo-de-los-intervalos/</guid>
      <description>Y termino con lo de los intervalos. Me refiero a esto y esto.
Nunca me habría atrevido a escribir sobre el tema, y exponerme, de paso, a la muy razonadas explicaciones de quienes tuvieron a bien comentarlas, si no hubiese sido por un tema personal: el recuerdo de la frustración que me supuso hacerme en su día con la teoría subyacente tanto a las pruebas de hipótesis como a la construcción de intervalos de confianza.</description>
    </item>
    
    <item>
      <title>Análisis estadístico de respuestas ocultas en encuestas</title>
      <link>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</link>
      <pubDate>Fri, 22 Jan 2016 08:13:24 +0000</pubDate>
      
      <guid>/2016/01/22/analisis-estadistico-de-respuestas-ocultas-en-encuestas/</guid>
      <description>A veces se hacen encuestas sobre temas sobre los que los encuestados son reticentes a revelar la verdad (p.e., ¿es Vd. un zombi?). Un procedimiento conocido para recabar tal tipo de información es el siguiente:
 * Se le invita al encuestado a tirar al aire una _moneda_ con las caras etiquetadas con _sí_ y _no_; la _moneda_ no es una moneda porque tiene una probabidad conocida (y distinta del 50%) de caer en _sí_.</description>
    </item>
    
    <item>
      <title>El problema de los tanques alemanes y de la máxima verosimilitud esquinada</title>
      <link>/2016/01/18/el-problema-de-los-tanques-alemanes-y-de-la-maxima-verosimilitud-esquinada/</link>
      <pubDate>Mon, 18 Jan 2016 08:13:11 +0000</pubDate>
      
      <guid>/2016/01/18/el-problema-de-los-tanques-alemanes-y-de-la-maxima-verosimilitud-esquinada/</guid>
      <description>El problema en cuestión, que se ve, surgió durante la II Guerra Mundial, es el siguiente: se capturan tanques del enemigo y se anotan los números de serie, supuestos sucesivos. ¿Cuál es la mejor estimación del número total de tanques fabricados por el enemigo?
Si se capturan k, la distribución del máximo número observado, m, en función del número no observado (nuestro parámetro) de tanques es
$latex f(N;m,k)=\frac{\binom{m-1}{k-1}}{\binom{N}{k}}$
y como esta función es decreciente en $latex N$, la estimación por máxima verosimilitud es $latex \hat{N} = m$.</description>
    </item>
    
    <item>
      <title>Construcción de prioris informativas a la de Finetti</title>
      <link>/2016/01/14/construccion-de-prioris-informativas-a-la-de-finetti/</link>
      <pubDate>Thu, 14 Jan 2016 08:13:11 +0000</pubDate>
      
      <guid>/2016/01/14/construccion-de-prioris-informativas-a-la-de-finetti/</guid>
      <description>Un banco tiene clientes. Los clientes usan la tarjeta de débito. La pueden usar de dos maneras: en cajero o para pagar (por productos y servicios). De cada cliente se tiene una secuencia de transacciones, etiquetadas como 1 o 0 según la use en cajero o no.
Para cada cliente, la secuencia de transacciones (más o menos larga) puede considerarse una secuencia intercambiable y, de acuerdo con el teorema de representación de de Finetti,</description>
    </item>
    
    <item>
      <title>Prioris muy informativas y vagamente informativas: un ejemplo</title>
      <link>/2016/01/11/prioris-muy-informativas-y-vagamente-informativas-un-ejemplo/</link>
      <pubDate>Mon, 11 Jan 2016 08:13:31 +0000</pubDate>
      
      <guid>/2016/01/11/prioris-muy-informativas-y-vagamente-informativas-un-ejemplo/</guid>
      <description>Mi búsqueda de ejemplos de aplicaciones con prioris informativas me ha conducido a Physiological pharmacokinetic analysis using population modeling and informative prior distributions, un artículo en el que se plantea un modelo jerárquico con dos tipos de distribuciones a priori:
Distribuciones muy informativas. Por ejemplo, el parámetro que representa la proporción del peso del hígado en un adulto, alrededor del 3.3% en promedio, que se modela con una distribución centrada en ese valor y una desviación estándar baja.</description>
    </item>
    
    <item>
      <title>Las prioris no informativas están manifiestamente sobrevaloradas</title>
      <link>/2016/01/04/las-prioris-no-informativas-estan-manifiestamente-sobrevaloradas/</link>
      <pubDate>Mon, 04 Jan 2016 08:13:05 +0000</pubDate>
      
      <guid>/2016/01/04/las-prioris-no-informativas-estan-manifiestamente-sobrevaloradas/</guid>
      <description>La estadística bayesiana se enseña en cursos de estadística (y, frecuentemente, envuelto en un aparataje matemático tan ofuscante como innecesario). Lo malo es que en los cursos y textos de estadística no existe información previa. La información previa sobre los fenómenos en los que se utilizaría la estadística bayesiana están en las aplicaciones, extramuros del muy agnóstico mundo de la estadística y la matemática.
Por eso, a los autores de los libros de estadística bayesiana y quienes enseñan cursos sobre lo mismo, enfrentados al problema de llenar de sentido la problemática distribución a priori, no se les ocurre nada mejor que discutir muy sesudamente la excepción (la priori no informativa) en lugar de la regla (la priori informativa).</description>
    </item>
    
    <item>
      <title>La búsqueda de la causa más probable de un efecto</title>
      <link>/2015/12/16/la-busqueda-de-la-causa-mas-probable-de-un-efecto/</link>
      <pubDate>Wed, 16 Dec 2015 08:13:21 +0000</pubDate>
      
      <guid>/2015/12/16/la-busqueda-de-la-causa-mas-probable-de-un-efecto/</guid>
      <description>La búsqueda de la causa más probable de un efecto tiene un nombre: razonamiento abductivo. Que el visitante al enlace anterior aprenderá distinto del deductivo y el inductivo.
Y que los viejos de estas páginas reconocerán en esta entrada que la formaliza y cuantifica en un caso concreto.</description>
    </item>
    
    <item>
      <title>Prioris, ¿subjetivas?</title>
      <link>/2015/09/07/prioris-subjetivas/</link>
      <pubDate>Mon, 07 Sep 2015 08:13:27 +0000</pubDate>
      
      <guid>/2015/09/07/prioris-subjetivas/</guid>
      <description>Dentro de unos días voy a hablar de estadística bayesiana en Machine Learning Spain. Plantearé una distribución a priori muy poco informativa:
&amp;lt;code&amp;gt; alfa ~ gamma(10, 1); beta ~ gamma(10, 1);&amp;lt;/code&amp;gt;  Me estoy preparando sicológicamente para que alguien me dé guerrita con lo de la subjetividad de las distribuciones a priori. Si tal es el caso, replicaré lo que sigue.
Hace unos días quise replicar el análisis. Pero la URL de la que bajo los datos dejó de contener los de la liga del año anterior y cargó los correspondientes al inicio (¿dos jornadas?</description>
    </item>
    
    <item>
      <title>Un modelo jerárquico para lo de Casillas</title>
      <link>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</link>
      <pubDate>Wed, 15 Jul 2015 08:13:42 +0000</pubDate>
      
      <guid>/2015/07/15/un-modelo-jerarquico-para-lo-de-casillas/</guid>
      <description>Vuelvo a lo de Casillas inspirándome en el primer ejemplo de este artículo de Gelman et al.
El planteamiento es el siguiente: el número de paradas, $latex n_i$ que realiza el $latex i$-ésimo portero tiene una distribución binomial
$latex n_i \sim B(N_i, p_i)$
donde $latex N_i$ es el número de disparos entre los palos y $latex p_i$ es la habilidad innata del portero. Estas habilidades innatas siguen una distribución dada, la de habilidades innatas de los porteros de primera división, que podemos suponer que sigue una distribución beta</description>
    </item>
    
    <item>
      <title>Diferencia de medias a la bayesiana con salsa de stan</title>
      <link>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</link>
      <pubDate>Thu, 25 Jun 2015 08:13:35 +0000</pubDate>
      
      <guid>/2015/06/25/diferencia-de-medias-a-la-bayesiana-con-salsa-de-stan/</guid>
      <description>El habitual problema de la diferencia de medias suele formularse de la siguiente manera: hay observaciones $latex y_{1i}$ e $latex y_{2i}$ donde
$latex y_{ji} \sim N(\mu_j, \sigma)$
e interesa saber si $latex \mu_1 = \mu_2$. Obviamente, se desconoce $latex \sigma$. De cómo resolvió Gosset el problema están los libros de estadística llenos. En R,
&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/base/set.seed&amp;quot;&amp;gt;set.seed(1234) N1 &amp;lt;- 50 N2 &amp;lt;- 50 mu1 &amp;lt;- 1 mu2 &amp;lt;- -0.5 sig1 &amp;lt;- 1 sig2 &amp;lt;- 1 y1 &amp;lt;- rnorm(N1, mu1, sig1) y2 &amp;lt;- rnorm(N2, mu2, sig2) &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Intervalos de credibilidad para la beta: una alternativa</title>
      <link>/2015/05/05/intervalos-de-credibilidad-para-la-beta-una-alternativa/</link>
      <pubDate>Tue, 05 May 2015 08:13:44 +0000</pubDate>
      
      <guid>/2015/05/05/intervalos-de-credibilidad-para-la-beta-una-alternativa/</guid>
      <description>A partir de los comentarios de Olivier Núñez a mi entrada anterior casi homónima, se nos ha ocurrido a ambos de forma independiente y simultánea una manera alternativa de calcular el intervalo: minimizando su longitud.
a &amp;lt;- 3 b &amp;lt;- 5 alfa &amp;lt;- 0.05 # versión de la entrada anterior: f &amp;lt;- function(x){ (dbeta(x[2], a, b) - dbeta(x[1], a, b))^2 + (&amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/pbeta&amp;quot;&amp;gt;pbeta(x[2], a, b) - &amp;lt;a href=&amp;quot;http://inside-r.org/r-doc/stats/pbeta&amp;quot;&amp;gt;pbeta(x[1], a, b) -1 + alfa)^2 } res &amp;lt;- &amp;lt;a href=&amp;quot;http://inside-r.</description>
    </item>
    
    <item>
      <title>Intervalos de credibilidad para la distribución beta</title>
      <link>/2015/04/27/intervalos-de-credibilidad-para-la-distribucion-beta/</link>
      <pubDate>Mon, 27 Apr 2015 08:13:36 +0000</pubDate>
      
      <guid>/2015/04/27/intervalos-de-credibilidad-para-la-distribucion-beta/</guid>
      <description>Tengo un parámetro, la p de una binomial, que supongo distribuido según una beta. Me da igual para el caso si la distribución a priori es o no informativa. Solo digo que la distribución a posteriori es otra beta con parámetros a y b.
Quiero construir un intervalo de credibilidad para p, es decir, encontrar un subintervalo de [0,1]
 * dentro del cual la densidad de la beta sea mayor que fuera y que * capture $latex 1-\alpha$ de la probabilidad total.</description>
    </item>
    
    <item>
      <title>Dislexia probabilística</title>
      <link>/2014/11/04/dislexia-probabilistica/</link>
      <pubDate>Tue, 04 Nov 2014 07:13:14 +0000</pubDate>
      
      <guid>/2014/11/04/dislexia-probabilistica/</guid>
      <description>Esta entrada trata de cuadrados. Tales como estos

Son dos cuadrados de area 10 y 2.
En realidad, mi entrada trata de una configuración de cuadrados solo marginalmente más complicada, esta:

Todo el mundo podría decir (y es cierto) que el área de la intersección de los cuadrados es el 3.3% de la del mayor y el 16.5% de la del menor. Son dos afirmaciones ambas ciertas y, por supuesto, compatibles.</description>
    </item>
    
    <item>
      <title>Bootstrap bayesiano</title>
      <link>/2014/10/10/bootstrap-bayesiano/</link>
      <pubDate>Fri, 10 Oct 2014 07:13:55 +0000</pubDate>
      
      <guid>/2014/10/10/bootstrap-bayesiano/</guid>
      <description>Hoy voy a hablar de esa especie de oxímoron que es el el bootstrap bayesiano. Comenzaré planteando un pequeño problema bien conocido: tenemos números $latex x_1, \dots, x_n$ y hemos calculado su media. Pero nos preguntamos cómo podría variar dicha media (de realizarse otras muestras).
La respuesta de Efron (1979) es esta:
replicate(n, mean(sample(x, length(x), replace = TRUE)))  Es decir, crear muestras de $latex x_i$ con reemplazamiento y hacer la media de cada una de ellas para obtener su presunta distribución (o una muestra de la presunta distribución de esa media).</description>
    </item>
    
    <item>
      <title>El problema del 100% (y un ensayo de solución)</title>
      <link>/2014/10/06/el-problema-del-100-y-un-ensayo-de-solucion/</link>
      <pubDate>Mon, 06 Oct 2014 07:13:56 +0000</pubDate>
      
      <guid>/2014/10/06/el-problema-del-100-y-un-ensayo-de-solucion/</guid>
      <description>Te encargan un modelo. Por ejemplo, relacionado con el uso de tarjetas de débito y crédito (aunque a lo que me referiré ocurre en mil otros contextos). Una variable que consideras importante es la proporción de veces que se usa para sacar dinero de cajeros (y no para pagar en establecimientos). Así que, para cada cliente, divides el número de retiradas por el número de veces que la tarjeta se ha usado y obtienes ese número entre el 0 y el 1 (o entre el 0% y el 100%).</description>
    </item>
    
    <item>
      <title>Naive Bayes como red bayesiana</title>
      <link>/2014/08/06/naive-bayes-como-red-bayesiana/</link>
      <pubDate>Wed, 06 Aug 2014 07:13:12 +0000</pubDate>
      
      <guid>/2014/08/06/naive-bayes-como-red-bayesiana/</guid>
      <description>Una red bayesiana es algo de lo que ya hablé (y que me está volviendo a interesar mucho últimamente). En esencia, es un modelo probabilístico construido sobre un grafo dirigido acíclico.
Que, a su vez, es algo parecido a

que es un grafo (obviamente), dirigido (tiene flechas) y acíclico porque siguiéndolas no se llega nunca al punto de partida. Se puede construir modelos probabilísticos sobre ellos. Basta con definir para cada nodo $latex x$ la probabilidad condicional $latex P(x|A(x))$, donde $latex A(x)$ son sus padres directos.</description>
    </item>
    
    <item>
      <title>Combinación de probabilidades</title>
      <link>/2014/07/31/combinacion-de-probabilidades/</link>
      <pubDate>Thu, 31 Jul 2014 07:13:26 +0000</pubDate>
      
      <guid>/2014/07/31/combinacion-de-probabilidades/</guid>
      <description>Hace unos días alguien me pasó una fórmula que tiene una pinta no muy distinta de
$latex p = \frac{p_1 p_2 \cdots p_N}{p_1 p_2 \cdots p_N + (1 - p_1)(1 - p_2) \cdots (1 - p_N)}$
alegando que era una aplicación de métodos bayesianos (para estimar la probabilidad de algo combinando distintos indicios). Pero no está en mi libro (¿y en el tuyo?). El hilo (y varios correos) me condujeron a esto y de ahí, a través de referencias de referencias, a Combining Probabilities.</description>
    </item>
    
    <item>
      <title>El error en las encuestas: cuentas en una servilleta</title>
      <link>/2013/05/16/el-error-en-las-encuestas-cuentas-en-una-servilleta/</link>
      <pubDate>Thu, 16 May 2013 07:31:52 +0000</pubDate>
      
      <guid>/2013/05/16/el-error-en-las-encuestas-cuentas-en-una-servilleta/</guid>
      <description>Bien escondidita en las encuestas que se publican, puede encontrarse a veces una ficha técnica. Y esta suele contener una frase de esta guisa: Partiendo de los criterios del muestreo aleatorio simple, para un nivel de confianza del 95 % (que es el habitualmente adoptado) y en la hipótesis más desfavorable de máxima indeterminación (p=q=0.5), el margen de error de los datos referidos al total de la muestra es de 3.</description>
    </item>
    
    <item>
      <title>La frontera bayesiana en problemas de clasificación (simples)</title>
      <link>/2012/02/01/la-frontera-bayesiana-en-problemas-de-clasificacion-simples/</link>
      <pubDate>Wed, 01 Feb 2012 00:32:20 +0000</pubDate>
      
      <guid>/2012/02/01/la-frontera-bayesiana-en-problemas-de-clasificacion-simples/</guid>
      <description>Una de las preguntas formuladas dentro del foro desde el que seguimos la lectura del libro The Elements of Statistsical Learning se refiere a cómo construir la frontera bayesiana óptima en ciertos problemas de clasificación.
Voy a plantear aquí una discusión así como código en R para representarla (en casos simples y bidimensionales).
Supongamos que hay que crear un clasificador que distinga entre puntos rojos y verdes con la siguiente pinta,</description>
    </item>
    
    <item>
      <title>Visualización de la actualización bayesiana (y unas cuantas funciones de R)</title>
      <link>/2011/09/12/visualizacion-de-la-actualizacion-bayesiana-y-unas-cuantas-funciones-de-r/</link>
      <pubDate>Mon, 12 Sep 2011 07:02:03 +0000</pubDate>
      
      <guid>/2011/09/12/visualizacion-de-la-actualizacion-bayesiana-y-unas-cuantas-funciones-de-r/</guid>
      <description>Me ha llegado noticia de una entrada en un blog, Visualizing Bayesian Updating, en el que se muestra visualmente cómo se actualiza la distribución a posteriori conforme aumenta el número de ensayos en un problema bayesiano simple. Explica también los fundamentos estadísticos del asunto.
Yo me limitaré a ofrecer una nueva versión del código —que no funcionaba copiando y pegando sin más— en el que he introducido ciertas modificaciones. Es el siguiente:</description>
    </item>
    
  </channel>
</rss>
