<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>distribuciones on datanalytics</title>
    <link>/tags/distribuciones/</link>
    <description>Recent content in distribuciones on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 02 Mar 2021 09:13:46 +0000</lastBuildDate><atom:link href="/tags/distribuciones/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Un argumento para usar la normal: la maximización de la entropía</title>
      <link>/2021/03/02/un-argumento-para-usar-la-normal-la-maximizacion-de-la-entropia/</link>
      <pubDate>Tue, 02 Mar 2021 09:13:46 +0000</pubDate>
      
      <guid>/2021/03/02/un-argumento-para-usar-la-normal-la-maximizacion-de-la-entropia/</guid>
      <description>Llegaré a la normal. Antes, algo sobre la entropía.
Nos interesa saber y medir el grado de concentración de una distribución. Por ejemplo, si X es una variable aleatoria con función de densidad $latex f(x)$ y $latex x_1, \dots, x_n$ es una muestra de X, entonces, la expresión
$latex \frac{1}{n} \sum_i f(x_i)$
da una idea de la concentración vs dispersión de X:
 Si es grande, muchos de los $latex x_i$ procederán de lugares donde $latex f$ es grande; en un caso discreto, que tal vez ayude a mejorar la intuición sobre la cosa, habría muchos valores repetidos.</description>
    </item>
    
    <item>
      <title>Tres &#34;teoremas&#34; que son casi ciertos</title>
      <link>/2021/02/23/tres-teoremas-que-son-casi-ciertos/</link>
      <pubDate>Tue, 23 Feb 2021 09:13:00 +0000</pubDate>
      
      <guid>/2021/02/23/tres-teoremas-que-son-casi-ciertos/</guid>
      <description>I.
Si $latex X_1, \dots, X{12}$ son uniformes en [0,1] e independientes, entonces $latex X_1 + \dots + X_{12} - 6$ es una variable aleatoria normal._
Puede entenderse como un corolario práctico del teorema central del límite habida cuenta de que la varianza de $latex X_i$ es 1/12 y su media es 1/2.
Es útil porque, se ve, en algunos dispositivos embebidos no se dispone de una librería matemática extensa y, se ve, a veces hace falta muestrear la normal.</description>
    </item>
    
    <item>
      <title>Esto no es práctico, pero sí bonito; bonito, además, de esa forma inasequible a la chusma</title>
      <link>/2020/09/18/esto-no-es-practico-pero-si-bonito-bonito-ademas-de-esa-forma-inasequible-a-la-chusma/</link>
      <pubDate>Fri, 18 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/18/esto-no-es-practico-pero-si-bonito-bonito-ademas-de-esa-forma-inasequible-a-la-chusma/</guid>
      <description>Va de muestrear los números $latex 1, \dots, n$ que tienen asignadas probabilidades $latex p_1, \dots, p_n$. Una manera muy impráctica (en R, basta usar sample) y nada intuitiva de hacerlo es recurriendo a la distribución de Gumbel:
library(evd) pes &amp;lt;- runif(5) pes &amp;lt;- pes / sum(pes) gammas &amp;lt;- log(pes) + 2 x &amp;lt;- rgumbel(length(pes)) muestra &amp;lt;- which.max(gammas + x)  O, en masa, aplicando
get_samples &amp;lt;- function(n){ replicate(n, { x &amp;lt;- rgumbel(length(pes)) which.</description>
    </item>
    
    <item>
      <title>Distribuciones (¿de renta? ¿solo de renta?) a partir de histogramas</title>
      <link>/2020/09/10/distribuciones-de-renta-solo-de-renta-a-partir-de-histogramas/</link>
      <pubDate>Thu, 10 Sep 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/09/10/distribuciones-de-renta-solo-de-renta-a-partir-de-histogramas/</guid>
      <description>En el primer número de la novísima revista Spanish Journal of Statistics aparece un artículo con un título tentador: Recovering income distributions from aggregated data via micro-simulations.
Es decir, un artículo que nos puede permitir, por ejemplo, muestrear lo que la AEAT llama rendimientos a partir de lo que publica (aquí):
Uno de los métodos de los que sostienen el ignominioso a mí me funciona está basado en el modelo</description>
    </item>
    
    <item>
      <title>Sobre predicciones puntuales</title>
      <link>/2020/06/25/sobre-predicciones-puntuales/</link>
      <pubDate>Thu, 25 Jun 2020 09:13:00 +0000</pubDate>
      
      <guid>/2020/06/25/sobre-predicciones-puntuales/</guid>
      <description>Como tan a menudo se nos olvida, Taleb nos recuerda, breve y conciso, un par de cositas sobre las predicciones puntuales aquí. Además, casi todo lo que tiene que decir se resume en:</description>
    </item>
    
    <item>
      <title>¿Qué puede colgar de un árbol?</title>
      <link>/2019/05/21/que-puede-colgar-de-un-arbol/</link>
      <pubDate>Tue, 21 May 2019 09:13:54 +0000</pubDate>
      
      <guid>/2019/05/21/que-puede-colgar-de-un-arbol/</guid>
      <description>Predicciones puntuales:
O (sub)modelos:
Y parece que ahora también distribuciones:
Notas:
 Obviamente, la clasificación anterior no es mutuamente excluyente. * La tercera gráfica está extraída de Transformation Forests, un artículo donde se describe el paquete trtf de R. * Los autores dicen que [r]egression models for supervised learning problems with a continuous target are commonly understood as models for the conditional mean of the target given predictors. ¿Vosotros lo hacéis así?</description>
    </item>
    
    <item>
      <title>La simplicísima mas no por ello menos útil distribución de Dirac</title>
      <link>/2019/03/12/la-simplicisima-mas-no-por-ello-menos-util-distribucion-de-dirac/</link>
      <pubDate>Tue, 12 Mar 2019 08:13:05 +0000</pubDate>
      
      <guid>/2019/03/12/la-simplicisima-mas-no-por-ello-menos-util-distribucion-de-dirac/</guid>
      <description>Ayer alguien desconocía la distribución de probabilidad de Dirac. No sé ni si se llama así y no aparece en prácticamente ninguno de los manuales al uso.
Es una distribución de probabilidad aleatoria: concentra toda su masa en un punto determinado. Por ejemplo, en el nueve:
Y es útil por:
 Ser límite de cosas. * Porque las distribuciones discretas (de la Bernoulli en adelante) son mezclas de variables aleatorias de Dirac.</description>
    </item>
    
    <item>
      <title>Distribuciones hiperbólicas</title>
      <link>/2017/10/31/distribuciones-hiperbolicas/</link>
      <pubDate>Tue, 31 Oct 2017 08:13:21 +0000</pubDate>
      
      <guid>/2017/10/31/distribuciones-hiperbolicas/</guid>
      <description>curve(-sqrt(x^2 + 1), -5, 5)  pinta una rama de hipérbola,
que, una vez exponenciada, i.e.,
curve(exp(-sqrt(x^2 + 1)), -5, 5)  da
Es decir, una curva algo menos esbelta que la normal pero que bien podemos dividir por su integral para obtener la llamada distribución hiperbólica.
Tres notas sobre ella:
 * Tiene una historia curiosa. Fue considerada por [Ralph Bagnold](https://en.wikipedia.org/wiki/Ralph_Alger_Bagnold) al estudiar la forma de las dunas y la sedimentación de la arena arrastrada por el viento.</description>
    </item>
    
    <item>
      <title>Distribuciones sin media: ¿qué pueden suponer en la práctica?</title>
      <link>/2016/06/15/distribuciones-sin-media-que-pueden-suponer-en-la-practica/</link>
      <pubDate>Wed, 15 Jun 2016 08:13:53 +0000</pubDate>
      
      <guid>/2016/06/15/distribuciones-sin-media-que-pueden-suponer-en-la-practica/</guid>
      <description>Aunque esta entrada es sin duda resabida de los más de mis lectores, quedarán los que aún no sepan que ciertas distribuciones no tienen media. Condición necesaria para que una distribución la tenga es que
$latex \int_{-\infty}^\infty |x| f(x) dx$
tenga un valor finito, cosa que, por ejemplo, no cumple la de Cauchy. Igual hay a quien esto le parece una rareza matemática, un entretenimiento de math kiddies sin implicaciones prácticas.</description>
    </item>
    
    <item>
      <title>Las distribuciones (y platos) con nombre</title>
      <link>/2016/06/14/las-distribuciones-con-nombre-son-como-los-platos-con-nombre/</link>
      <pubDate>Tue, 14 Jun 2016 08:13:31 +0000</pubDate>
      
      <guid>/2016/06/14/las-distribuciones-con-nombre-son-como-los-platos-con-nombre/</guid>
      <description>Hay platos con nombre. P.e., tortilla de patata o tiramisú. También hay distribuciones (de probabilidad) con nombre. P.e., normal, binomial, Poisson, hipergeométrica.
Hay quienes quieren saber (1) todas (o muchas) de esas distribuciones con nombre y (2), dados unos datos, cuál de ellas siguen. Esta entrada va a tener la url a la que de ahora en adelante remita a quien me las formule.
A pesar de que algunos platos tienen nombre, el otro día se podía probar en el Diverxo espárrago blanco a la mantequilla negra con emulsión de leche de oveja, espardeña y salmonete.</description>
    </item>
    
  </channel>
</rss>
