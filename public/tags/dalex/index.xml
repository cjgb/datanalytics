<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dalex on datanalytics</title>
    <link>/tags/dalex/</link>
    <description>Recent content in dalex on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Wed, 27 Mar 2019 09:13:01 +0000</lastBuildDate><atom:link href="/tags/dalex/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sobre la (necesaria) validación a posteriori de modelos de caja negra</title>
      <link>/2019/03/27/sobre-la-necesaria-validacion-a-posteriori-de-modelos-de-caja-negra/</link>
      <pubDate>Wed, 27 Mar 2019 09:13:01 +0000</pubDate>
      
      <guid>/2019/03/27/sobre-la-necesaria-validacion-a-posteriori-de-modelos-de-caja-negra/</guid>
      <description>Esta entrada viene a cuento de una conversación que tuve el otro día con un economista clásico que me preguntaba mi opinión sobre los métodos del ML aplicados en su disciplina (y no solo en ella). Le causaba cierto desasosiego, muy razonable, el hecho de que le pusieran delante cajas negras que presuntamente, y eso era artículo de fe, predecían ciertos fenómenos macroeconómicos. ¿Qué —decía— si los modelos están recogiendo las correlaciones erróneas?</description>
    </item>
    
  </channel>
</rss>
