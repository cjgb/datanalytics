<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>pareto on datanalytics</title>
    <link>/tags/pareto/</link>
    <description>Recent content in pareto on datanalytics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es</language>
    <lastBuildDate>Tue, 26 Nov 2019 09:13:00 +0000</lastBuildDate><atom:link href="/tags/pareto/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ciencia de datos 1.0 vs ciencia de datos 2.0</title>
      <link>/2019/11/26/ciencia-de-datos-1-0-vs-ciencia-de-datos-2-0/</link>
      <pubDate>Tue, 26 Nov 2019 09:13:00 +0000</pubDate>
      
      <guid>/2019/11/26/ciencia-de-datos-1-0-vs-ciencia-de-datos-2-0/</guid>
      <description>[Mil perdones por utilizar el término ciencia de datos; lo he hecho por darme a entender sin enredarme en distingos.]
[Mil perdones por (ab)usar (de) la terminología X.0; de nuevo, lo he hecho por darme a entender sin enredarme en distingos.]
Todo es un caos y llega alguien con una idea paretiana. Por ejemplo, esta (que es la que ha motivado esta entrada). La idea paretiana puede ser usar regresión logística sobre un subconjunto de variables que tienen sentido; o automatizar una serie de reglas duras (sí, unos cuantos ifs) que la gente que conoce el asunto saben que funcionan sí o sí.</description>
    </item>
    
  </channel>
</rss>
