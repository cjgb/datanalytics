<!DOCTYPE html>
<html class="no-js" lang="es">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>estadística - datanalytics</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="estadística" />
<meta property="og:description" content="asdf" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/categories/estad%C3%ADstica/" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alegreya:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/categories/estad%C3%ADstica/index.xml" title="datanalytics">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="datanalytics" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">datanalytics</div>
					<div class="logo__tagline">Estadística y análisis de datos</div>
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<header class="main__header">
		<h1 class="main__title">estadística</h1>
	</header><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/08/11/procesos-puntuales-una-primera-aproximacion/" rel="bookmark">
			Procesos puntuales: una primera aproximación
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-08-11T07:13:21Z">2014-8-11</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>, <a class="meta__link" href="/categories/r/" rel="category">r</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Tengo una serie de datos que se parecen a lo que cierta gente llama procesos puntuales y que se parecen a los que se introducen (muuuuy prolijamente) aquí. Gráficamente, tienen este aspecto:

Sobre un determinado periodo de tiempo (eje horizontal) suceden eventos y los cuento por fecha. Pero no suceden independientemente (como si generados por un proceso de Poisson) sino que tienden a agruparse: el que suceda un evento tiende a incrementar la probabilidad de que suceda otro poco después.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/08/08/procesos-de-poisson-no-homogeneos-la-historia-de-un-fracaso/" rel="bookmark">
			Procesos de Poisson no homogéneos: la historia de un fracaso
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-08-08T07:13:03Z">2014-8-8</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Partamos el tiempo en, p.e., días y contemos una serie de eventos que suceden en ellos. Es posible que esos recuentos se distribuyan según un proceso de Poisson de parámetro $latex \lambda$, que es un valor que regula la intensidad.
Si los días son homogéneos, i.e., no hay variaciones de intensidad diaria, estimar $latex \lambda$ (por máxima verosimilitud), es tan fácil como calcular la media de los sucesos por día. Pero puede suceder que la intensidad varíe en el tiempo (p.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/08/07/la-historia-de-la-estadistica-comienza/" rel="bookmark">
			La historia de la estadística comienza...
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-08-07T07:13:57Z">2014-8-7</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El resto (son apenas ocho hojas), tenéis que leerlo (porque os intriga, ¿verdad?) aquí.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/08/06/naive-bayes-como-red-bayesiana/" rel="bookmark">
			Naive Bayes como red bayesiana
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-08-06T07:13:12Z">2014-8-6</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Una red bayesiana es algo de lo que ya hablé (y que me está volviendo a interesar mucho últimamente). En esencia, es un modelo probabilístico construido sobre un grafo dirigido acíclico.
Que, a su vez, es algo parecido a

que es un grafo (obviamente), dirigido (tiene flechas) y acíclico porque siguiéndolas no se llega nunca al punto de partida. Se puede construir modelos probabilísticos sobre ellos. Basta con definir para cada nodo $latex x$ la probabilidad condicional $latex P(x|A(x))$, donde $latex A(x)$ son sus padres directos.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/08/04/estadistica-viejuna/" rel="bookmark">
			Solo necesitarás estadística viejuna
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-08-04T07:13:44Z">2014-8-4</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El INE está realizando una convocatoria para cubrir varias plazas en el Cuerpo Superior de Estadísticos del Estado.
Si quieres presentarte mira el temario sobre el que te examinarán. Si no has estado al tanto de lo que ha ocurrido en el mundo de la estadística en los últimos 30 o 40 años o no sabes programar, no te preocupes: no entra.
Eso sí, si tienes diez publicaciones estadísticas de alto nivel en los temas relevantes&hellip; no te valen para nada.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/07/31/combinacion-de-probabilidades/" rel="bookmark">
			Combinación de probabilidades
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-07-31T07:13:26Z">2014-7-31</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Hace unos días alguien me pasó una fórmula que tiene una pinta no muy distinta de
$latex p = \frac{p_1 p_2 \cdots p_N}{p_1 p_2 \cdots p_N + (1 - p_1)(1 - p_2) \cdots (1 - p_N)}$
alegando que era una aplicación de métodos bayesianos (para estimar la probabilidad de algo combinando distintos indicios). Pero no está en mi libro (¿y en el tuyo?). El hilo (y varios correos) me condujeron a esto y de ahí, a través de referencias de referencias, a Combining Probabilities.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/07/30/incrementalidad-via-particionamiento-recursivo-basado-en-modelos/" rel="bookmark">
			Incrementalidad via particionamiento recursivo basado en modelos
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-07-30T07:13:24Z">2014-7-30</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/ciencia-de-datos/" rel="category">ciencia de datos</a>, <a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Planteas un modelo tal como resp ~ treat y no encuentras diferencia significativa. O incluso puede ser negativa. Globalmente.
La pregunta es, con el permiso del Sr. Simpson (o tal vez inspirados por él), ¿existirá alguna región del espacio en la que el tratamiento tiene un efecto beneficioso? Puede que sí. Y de haberla, ¿cómo identificarla?
De eso hablo hoy aquí. E incluyo una protorespuesta.
Primero, genero datos:
n &lt;- 20000 v1 &lt;- sample(0:1, n, replace = T) v2 &lt;- sample(0:1, n, replace = T) v3 &lt;- sample(0:1, n, replace = T) treat &lt;- sample(0:1, n, replace = T) y &lt;- v1 + treat * v1 * v2 y &lt;- exp(y) / (1 + exp(y)) y &lt;- sapply(y, function(x) rbinom(1,1,x)) dat &lt;- data.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/07/24/datos-antes-y-despues-del-pca/" rel="bookmark">
			Datos antes y después del PCA
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-07-24T07:13:00Z">2014-7-24</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		El autor de una entrada que casi fusilo hoy no pudo resistirse. Me ha parecido tan estupenda que yo tampoco.
Con una imagen simboliza el aspecto de un conjunto de datos antes y después de aplicar una técnica de reducción de la dimensionalidad (PCA, pero podría ser otra). Es esta:

A la izquierda, los datos originales. Con sus detalles y sus imperfecciones. A la derecha, los transformados, limpios de impurezas, con colores sólidos y trazos gruesos.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/07/16/dos-descomposiciones-positivas-de-tablas-de-contingencia/" rel="bookmark">
			Dos descomposiciones positivas de tablas de contingencia
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-07-16T07:13:13Z">2014-7-16</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/computaci%C3%B3n/" rel="category">computación</a>, <a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Voy a seguir poco a poco con este tema mío tan recurrente de las factorizaciones (aproximadas) positivas de matrices (también positivas). No escribo más porque, como casi todo lo que llamamos trabajo es, simplemente ruido, las cosas que llevan a otras nunca pasan por el asunto en cuestión.
Pero hay dos descomposiciones positivas de matrices positivas bien conocidas de todos. La primera es esta: $latex X=IX$, donde $latex X$ es una matriz de dimensión nxm e $latex I$ es la cosa más parecida a la matriz identidad de dicha dimensión.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/07/01/lecturas-disparatadas-la-salud-de-los-crios-y-el-desempleo/" rel="bookmark">
			Lecturas disparatadas: la salud de los críos y el desempleo
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-07-01T07:00:55Z">2014-7-1</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Hay gente que en lugar de escribir cosas debería invertir su tiempo en leer otras. Pero como
 * no me hacen caso, * escribiendo cosillas escalan poquito a poco escalafones académicos y, encima, * lo pagamos los contribuyentes felizmente engatusados eso del oropel del I+D y nosequé otros intangibles onerosos y de dudosa utilidad pública,  podemos hoy disfrutar de otro ejercicio más de ese añejo ritual de la búsqueda del numerito inferior a 0.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/06/25/el-indice-de-birrieza-para-distribuciones-de-probabilidad/" rel="bookmark">
			El índice de birrieza para distribuciones de probabilidad
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-06-25T07:11:26Z">2014-6-25</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Pido disculpas por usar birrieza, que no es una palabra que no existe. Si a alguien se le ocurre otro término mejor, que lo sugiera. Pero es que hay distribuciones de probabilidad que son una birria. Y de ellas me voy a ocupar hoy.
Pero antes, una digresión breve. Todas las distribuciones de probabilidad, en la práctica, están acotadas. Aunque sea por el número de átomos del universo. ¿Cuál es la importancia de dicha digresión?
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/06/24/causalidad-a-la-pearl-y-el-operador-do/" rel="bookmark">
			Causalidad a la Pearl y el operador do
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-06-24T07:06:49Z">2014-6-24</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>, <a class="meta__link" href="/categories/probabilidad/" rel="category">probabilidad</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Un tipo me pasó el librito de Pearl, Causality, y se ha pasado varios días dando la vara con que si me había leído ya el epígrafe. Pues sí, lo he leído este finde. Y no solo lo he leído sino que voy a escribir sobre ello.
Había tratado de leer cosas de Pearl en el pasado. Pero las encontraba demasiado llenas de letras difíciles de comprender si no se entendían bien las fórmulas.
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/2014/06/23/dos-citas-de-1983-sobre-estadistica-y-metodos-computacionales/" rel="bookmark">
			Dos citas de 1983 sobre estadística y métodos computacionales
			</a>
		</h2>
		<div class="list__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2014-06-23T07:27:45Z">2014-6-23</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/computaci%C3%B3n/" rel="category">computación</a>, <a class="meta__link" href="/categories/estad%C3%ADstica/" rel="category">estadística</a>
	</span>
</div></div>
	</header>
	<div class="content list__excerpt post__content clearfix">
		Rescato aquí para mis lectores dos citas de un artículo de 1983, Computer Intensive Methods in Statistics, de Efron y Diaconis, por dos motivos: su valor intrínseco y que consideren leer el resto, particularmente el principio y el final.
La primera es (con mi traducción):
Y la segunda:
Sin otros comentarios que los vuestros.
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/categories/estad%C3%ADstica/page/42/">«</a>
	<span class="pagination__item pagination__item--current">43/64</span>
	<a class="pagination__item pagination__item--next btn" href="/categories/estad%C3%ADstica/page/44/">»</a>
</div>

			</div>
			
<aside class="sidebar">
<div class="widget-recent widget">
	<h4 class="widget__title">Más Recientes</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/2021/12/09/mas-sobre-exceso-mortalidad-noviembre-2021/">Sobre el exceso de mortalidad en noviembre de 2021</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/09/mas-sobre-la-estimacion-de-probabilidades-de-eventos-que-no-se-repiten/">Más sobre la estimación de probabilidades de eventos que no se repiten</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/07/estadistica-vs-siquiatria-la-aparente-contradiccion-la-profunda-sintesis/">Estadística vs siquiatría: la aparente contradicción, la profunda síntesis</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/12/02/por-que-cabe-argumentar-que-estos-resultados-infraestiman-la-efectividad-de-las-vacunas-contra-el-covid/">¿Por qué cabe argumentar que estos resultados infraestiman la efectividad de las vacunas contra el covid?</a></li>
			<li class="widget__item"><a class="widget__link" href="/2021/11/25/un-episodio-relevante-para-estas-paginas-extraido-de-un-espia-perfecto/">Un episodio relevante para estas páginas extraído de &#34;Un espía perfecto&#34;</a></li>
		</ul>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 datanalytics.
      
		</div>
	</div>
</footer>

	</div>
<script async defer src="/js/menu.js"></script>

</body>
</html>