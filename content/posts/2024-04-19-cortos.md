---
author: Carlos J. Gil Bellosta
categories:
- cortos
date: 2024-04-19
lastmod: '2025-04-06T18:55:31.197456'
related:
- 2024-07-18-cortos-llms.md
- 2025-03-25-cortos-llms.md
- 2024-02-06-llm-obsidian.md
- 2024-09-03-cortos-llms.md
- 2024-03-21-cortos.md
tags:
- llms
title: Más cortos sobre LLMs
url: /2024/04/19/cortos
---

### I.

[Aquí](https://huggingface.co/blog/moe) se explica cómo es una _mezcla de expertos_, la arquitectura detrás de LLMs como [Mixtral](https://mistral.ai/news/mixtral-of-experts/) (el LLM que más uso, sobre todo en APIs). Curiosamente, la arquitectura está basada en ideas de [este artículo](https://www.cs.toronto.edu/~hinton/absps/jjnh91.pdf)... ¡de 1991!




### II.

[Aquí](https://huyenchip.com/2023/10/10/multimodal.html) se tratan los LMMs (donde la L de _language_ se ha reemplazado por la M de _multimodal_). Se dice:

> A muy alto nivel, un sistema multimodal consta de los siguientes componentes:
>
> 1. Un codificador para cada modo de datos que genere los _embeddings_ correspondientes.
> 2. Un procedimiento para alinear los _embeddings_ de los diferentes modos en el mismo espacio.
> 3. [Solo para modelos generativos] Un modelo de lenguaje para generar respuestas textuales. Como las entradas pueden contener tanto texto como elementos visuales, hace falta desarrollar técnicas para condicionar el modelo de lenguaje no solo al texto sino también a los elementos visuales.

El segundo punto me recuerda a lo de aquellos ratones que acordaron ponerle un cascabel al gato.

### III.

Generalmente, pasan cosas como

![](/wp-uploads/2024/jailbreak_01.png#center)

pero si lees lo que pone [aquí](https://llm-attacks.org/) verás cómo es posible conseguir


![](/wp-uploads/2024/jailbreak_02.png#center)

añadiendo _sufijos mágicos_.

### IV.


Se ve que [LMQL](https://towardsdatascience.com/lmql-sql-for-language-models-d7486d88c541) es _una cosa_ que permite escribir consultas del tipo

{{< highlight text >}}
beam(n=3)
    "Q: Say 'Hello, {name}!'"
    "A: [RESPONSE]"
from "openai/text-davinci-003"
where len(TOKENS(RESPONSE)) < 20
{{< / highlight >}}


### V.

[La segunda aplicación más obvia](https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736) (y que más se me ha resistido cuando la he probado _en casa_), de los LLMs: crear un LLM que razone sobre tus propios documentos.