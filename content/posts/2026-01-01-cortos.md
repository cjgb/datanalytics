---
author: Carlos J. Gil Bellosta
categories:
- cortos
date: 2026-01-01
description: ¿Es Claude Opus 4.5 el mejor modelo actual? Analizamos la dificultad
  de evaluar LLMs, el protocolo MCP de Google y el auge del "vibe engineering" y los
  agentes.
lastmod: '2026-01-05T12:32:49.080964'
related:
- 2025-06-24-cortos-tecnologia.md
- 2024-11-19-cortos-llms.md
- 2025-03-25-cortos-llms.md
- 2025-10-23-llms.md
- 2024-03-21-cortos.md
tags:
- llms
- claude
- vibe coding
- agentes
title: 'Notas (1): Claude Opus 4.5, agentes y el nuevo estándar del desarrollo con
  LLMs'
url: /2026/01/01/cortos-llms/
---

- [_Claude Opus 4.5 Is The Best Model Available_](https://thezvi.wordpress.com/2025/12/01/claude-opus-4-5-is-the-best-model-available/): Zvi sostiene que Claude Opus 4.5 es actualmente el mejor modelo disponible para uso práctico, superando a alternativas como GPT-5.2 y Gemini en muchas tareas cotidianas y de desarrollo. Destaca tanto _benchmarks_ como impresiones subjetivas para justificar su superioridad en razonamiento, programación y conversación. También analiza factores como ecosistema, latencia y usabilidad. (A pesar de ello, parece, se usa más en entornos laborales que fuera de ellos).
- [_Claude Opus 4.5, and why evaluating new LLMs is increasingly difficult_](https://simonwillison.net/2025/Nov/24/claude-opus/#atom-everything): Simon Willison reflexiona sobre Claude Opus 4.5 y explica que evaluar los LLM modernos es cada vez más difícil porque las mejoras son sutiles, dependen del contexto y no se reflejan bien en los _benchmarks_ tradicionales. Argumenta que la experiencia subjetiva y las evaluaciones basadas en tareas reales son más útiles que las clasificaciones en tablas y que, dado que los modelos están convergiendo sustancialmente, las comparaciones directas son cada vez más complicadas.
- [_METR: Measuring AI Ability to Complete Long Tasks – METR_](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/): Argumenta que los _benchmarks_ clásicos para medir la eficacia de los LLMs se centran en tareas cortas y aisladas que no reflejan su uso real. El enfoque de METR consiste en utilizar tareas largas que involucran múltiples pasos, lo que le permite evaluar su capacidad para planificar y mantener un estado coherente y continuo a lo largo del tiempo.
- [GitHub – google/mcp](https://github.com/google/mcp) — Repositorio MCP oficial de Google. Incluye servidores, ejemplos y documentación para integrar agentes y modelos con servicios externos como Google Workspace, BigQuery o Maps.
- [_JustHTML is a fascinating example of vibe engineering in action_](https://simonwillison.net/2025/Dec/14/justhtml/#atom-everything): Simon Willison presenta JustHTML, un parseador de HTML5 en Python puro que pasa la colección completa de pruebas de html5lib. Lo describe como un ejemplo de _vibe engineering_: usar agentes de código junto con buenas pruebas y supervisión humana. El artículo destaca que este enfoque produce software de alta calidad, no solo código generado sin criterio.
- [_I ported JustHTML from Python to JavaScript with Codex CLI and GPT-5.2 in 4.5 hours_](https://simonwillison.net/2025/Dec/15/porting-justhtml/#atom-everything): Abundando en lo anterior, Willison cuenta cómo portó JustHTML de Python a JavaScript usando Codex CLI y GPT-5.2 en unas 4.5 horas. El texto reflexiona sobre el impacto de los LLM en el desarrollo de software y la confianza en el código generado.
- [_Agent Skills_](https://simonwillison.net/2025/Dec/19/agent-skills): Willison, de nuevo, explica cómo los Agent Skills de Anthropic se han convertido en una especificación abierta y ligera para que los agentes puedan asumir y reutilizar _habilidades_. Aunque es una especificación pequeña y no enteramente definida, ya está siendo adoptada por herramientas como Cursor y VS Code. Se analiza su papel dentro del ecosistema más amplio de agentes y protocolos como MCP.

**Nota final:** A partir del 1 de enero de 2026, voy a comenzar a numerar las entradas consistentes en breves comentarios de artículos en su título. A ver hasta qué número llego antes de rendirme.
