---
author: Carlos J. Gil Bellosta
date: 2024-06-06
title: 'Cortos - datanalytics'
url: /2024/06/06/cortos
categories:
- cortos
tags:
- llms
- embeddings
- aplicaciones
- economía
---

### I.

Están apareciendo herramientas basadas en LLMs para industrializar la investigación. Tengo recopiladas, por el momento, tres:
[Consensus](https://consensus.app/search/),
[Tavily](https://docs.tavily.com/blog/building-gpt-researcher) y
[FutureSearch](https://futuresearch.ai/). De vez en cuando pruebo Consensus para valorar cómo va mejorando. Y le queda: la última vez, al preguntarle sobre el procedimiento científico para reproducir la dipladenia por esquejes, me sugirió algo así como aplicarle rayos gamma (!).

### II.

Unos cuantos enlaces sobre aplicaciones reales ---en la economía real--- de los LLMs (y los LMMs) en diversas áreas, como el
[vídeo](https://marginalrevolution.com/marginalrevolution/2024/02/what-will-the-main-commercial-uses-be-for-sora.html) (vía `sora`),
la [música](https://marginalrevolution.com/marginalrevolution/2024/03/my-review-of-suno-ai-generated-music.html) (vía `suno`),
la [programación](https://thezvi.wordpress.com/2024/03/18/on-devin/) (vía `devin`) o
el [RAG y/o _Finetuning_](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7).

### III.

Estimaciones sobre el impacto económico de la IA en la productividad, etc. en un artículo (glosado [aquí](https://marginalrevolution.com/marginalrevolution/2024/04/the-simple-macroeconomics-of-ai.html)) de Acemoglu (versión corta: una fracción de lo que presumen los más entusiastas).

Me ha resultado tambíén útil para entender ese impacto un artículo de Jeśus Fernández Villaverde, [_Simple Rules for a Complex World with Artiﬁcial Intelligence_](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3559378).

### IV.

Dicho lo cual, Jesse Lastunen mantiene una
[página con recursos basados en IA para economistas](https://sites.google.com/view/lastunen/ai-for-economists),
que puede ser útil para muchos otros también.


### V.

Diríase que  _embeddings_ son el hermanito feo de los LLMs. Están envueltos por una especie de halo mágico ---no sé si real o pretendido--- que los hace semánticamente relevantes y de ahí su interés (y encanto). Una serie de enlaces que he encontrado útiles para entenderlos y manipularlos son:

- [_Embeddings: BERT better than ChatGPT4?_](https://medium.com/@avinash.patil.0909/bert-embedding-vs-chatgpt4-embeddings-8cf023023fe7)
- [_Embeddings: What they are and why they matter_](https://simonwillison.net/2023/Oct/23/embeddings/)
- [_Introducing Nomic Embed: A Truly Open Embedding Model_](https://blog.nomic.ai/posts/nomic-embed-text-v1) y el correspondiente [_playground_](https://simonwillison.net/2024/Feb/15/adaptive-retrieval-with-matryoshka-embeddings/)
- [_Cohere int8 & binary Embeddings - Scale Your Vector Database to Large Datasets_](https://simonwillison.net/2024/Mar/26/cohere-int8-binary-embeddings/), que ilustra cómo también el mundo de los _embeddings_ participa de la carrera hacia la baja precisión numérica.





